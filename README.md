<h1 align="center"> 
    ğŸŒğŸ”DeepScholar-Bench: A Live Benchmark for Generative Research Synthesis
</h1>


<!-- [![Dataset](https://img.shields.io/badge/Dataset-deepscholar--bench%2FDeepScholarBench-blue)](https://huggingface.co/datasets/deepscholar-bench/DeepScholarBench)
[![GitHub](https://img.shields.io/badge/GitHub-deepscholar--bench-green)](https://github.com/guestrin-lab/deepscholar-bench)
[![License](https://img.shields.io/badge/License-MIT-yellow)](https://github.com/guestrin-lab/deepscholar-bench/blob/main/LICENSE)
[![Leaderboard](https://img.shields.io/badge/Leaderboard-DeepScholar%20Bench-orange)](https://guestrin-lab.github.io/deepscholar-leaderboard/leaderboard/deepscholar_bench_leaderboard.html)
-->

<!-- **ğŸ“Š Dataset**: [deepscholar-bench/DeepScholarBench](https://huggingface.co/datasets/deepscholar-bench/DeepScholarBench)  
**ğŸ”— GitHub**: [guestrin-lab/deepscholar-bench](https://github.com/guestrin-lab/deepscholar-bench)
**ğŸ† Leaderboard**: [DeepScholar Bench Leaderboard](https://guestrin-lab.github.io/deepscholar-leaderboard/leaderboard/deepscholar_bench_leaderboard.html) -->


<p align="center">
<a href="https://huggingface.co/datasets/deepscholar-bench/DeepScholarBench"><b> ğŸ“Š Dataset </b></a> | <a href="https://arxiv.org/abs/2508.20033"><b>ğŸ“„ Paper</b></a> | <a href="https://guestrin-lab.github.io/deepscholar-leaderboard/leaderboard/deepscholar_bench_leaderboard.html"><b> ğŸ† Live Leaderboard</b></a> | <a href="https://deep-scholar.vercel.app"><b> ğŸ¤– DeepResearch Preview </b></a>
</p>

---

DeepScholar-Bench provides a live benchmark dataset and holistic evaluation of generative research synthesis, an emerging capability among AI systems designed for DeepResearch.

This repository provides:
1. **[Dataset Scripts](data_pipeline/README.md)** - which allow you to collect new datasets from recent, high-quality Arxiv papers using our automated data-collection pipeline. You can set your own configurations (e.g., choice of valid date ranges and valid Arxiv domains) to customize your dataset
2. **[An Evaluation Suite](eval/README.md)** - for measuring performance of long-form research synthesis answers. Our evaluation framework supports a holistic set of metrics, which demonstrate high agreement with human annotations. Our eval suite is built using the [LOTUS framework for LLM-based data processing](https://github.com/lotus-data/lotus), which  provides a library for LLM-based evaluations and can be used directly to instantiate [your custom LLM-judges](https://lotus-ai.readthedocs.io/en/latest/evals.html#).


If you run into any problems with the code in this repo, leaderboard, or dataset, please feel free to raise an issue and we will address it promptly. If you would like to add your AI system to the DeepScholar-bench leaderboard, please fill out [this form](https://docs.google.com/forms/d/e/1FAIpQLSeug4igDHhVUU3XnrUSeMVRUJFKlHP28i8fcBAu_LHCkqdV1g/viewform).



## ğŸš€ Quick Start

To get started, make sure you are using Python 3.10, simply clone the repository and install dependencies as follows:

```bash
# Clone the repository
git clone git@github.com:guestrin-lab/deepscholar-bench.git
cd deepscholar-bench

# Install dependencies
conda create -n dsbench python=3.10 -y
conda activate dsbench
pip install -r requirements.txt
```

### Basic Usage

#### 1. Collect Research Data

```bash
# Collect recent AI papers since May 1, 2025
python -m data_pipeline.main \
    --categories cs.AI \
    --start-date 2025-05-01
```

#### 2. Evaluate Research Generation Systems

```bash
# Evaluate the system answers generated by deepscholar_base_gpt_4.1 using gpt-4o as a judge model to assess organization, nugget coverage, reference coverage, and citation precision metrics
python -m eval.main \
    --modes deepscholar_base \
    --evals organization nugget_coverage reference_coverage cite_p \
    --input_folder tests/baselines_results/deepscholar_base_gpt_4.1 \
    --output_folder results \
    --dataset_path dataset/related_works_combined.csv \
    --model_name gpt-4o
```

For more details and a full introduction, please continue to our **[Dataset Scripts Description](data_pipeline/README.md)** and/or our **[Evaluation library Description](eval/README.md)**.


## ğŸ“š DeepScholar Base

DeepScholar Base is our baseline research synthesis pipeline that transforms a research topic into a comprehensive, well-organized literature review with proper citations. Built on top of the [LOTUS framework](https://github.com/lotus-data/lotus) for LLM-powered data processing, it demonstrates a modular approach to automated deep research.

### How It Works

The pipeline takes a **research topic** (and optionally an **end date** to limit searches to papers before a certain dateâ€”useful for reproducibility or backdating research) and produces a **Markdown report** with categorized references, summaries, and inline citations.





```
                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                  â”‚   INPUT    â”‚
                                  â”‚   topic    â”‚
                                  â”‚  end_date  â”‚
                                  â”‚  configs   â”‚
                                  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                    STEP 1: SEARCH                     â”‚
          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
          â”‚  â”‚         use_agentic_search = True?              â”‚  â”‚
          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
          â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
          â”‚              â–¼                 â–¼                      â”‚
          â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
          â”‚     â”‚   Agentic    â”‚   â”‚   Recursive   â”‚              â”‚
          â”‚     â”‚   Search     â”‚   â”‚    Search     â”‚              â”‚
          â”‚     â”‚  (Agent+     â”‚   â”‚  (Multi-step  â”‚              â”‚
          â”‚     â”‚   Tools)     â”‚   â”‚   queries)    â”‚              â”‚
          â”‚     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
          â”‚            â”‚                   â”‚                      â”‚
          â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
          â”‚                      â”‚                                â”‚
          â”‚                      â–¼                                â”‚
          â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
          â”‚              â”‚   docs_df    â”‚   DataFrame with        â”‚
          â”‚              â”‚   queries    â”‚   title, url, snippet,  â”‚
          â”‚              â”‚   background â”‚   date, authors, etc.   â”‚
          â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                    STEP 2: FILTER                     â”‚
          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
          â”‚  â”‚  if use_sem_filter:                             â”‚  â”‚
          â”‚  â”‚    sem_filter() - Keep only relevant docs       â”‚  â”‚
          â”‚  â”‚                                                 â”‚  â”‚
          â”‚  â”‚  if use_sem_topk:                               â”‚  â”‚
          â”‚  â”‚    sem_topk(K=final_max_results_count)          â”‚  â”‚
          â”‚  â”‚    - Select top K most relevant docs            â”‚  â”‚
          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
          â”‚                                                       â”‚
          â”‚  If docs_df.empty â†’ Retry search (max_search_retries) â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚               STEP 3: GENERATE INTRO                  â”‚
          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
          â”‚  â”‚  generate_intro_section()                       â”‚  â”‚
          â”‚  â”‚   - Uses sem_agg() to summarize all docs        â”‚  â”‚
          â”‚  â”‚   - Creates cohesive background/intro section   â”‚  â”‚
          â”‚  â”‚   - Includes inline citations [author, date]    â”‚  â”‚
          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                 STEP 4: TAXONOMIZE                    â”‚
          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
          â”‚  â”‚  if categorize_references:                      â”‚  â”‚
          â”‚  â”‚    1. generate_categories()                     â”‚  â”‚
          â”‚  â”‚       - LLM creates â‰¤10 distinct categories     â”‚  â”‚
          â”‚  â”‚                                                 â”‚  â”‚
          â”‚  â”‚    2. match_references_to_categories()          â”‚  â”‚
          â”‚  â”‚       - sem_map() assigns each doc a category   â”‚  â”‚
          â”‚  â”‚                                                 â”‚  â”‚
          â”‚  â”‚    3. if generate_category_summary:             â”‚  â”‚
          â”‚  â”‚       - sem_agg() per category â†’ summaries      â”‚  â”‚
          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚               STEP 5: GENERATE INSIGHTS               â”‚
          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
          â”‚  â”‚  if generate_insights:                          â”‚  â”‚
          â”‚  â”‚    sem_extract() on each doc                    â”‚  â”‚
          â”‚  â”‚    - Extracts: "key idea/summary"               â”‚  â”‚
          â”‚  â”‚    - Adds new column(s) to docs_df              â”‚  â”‚
          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚             STEP 6: GENERATE FINAL REPORT             â”‚
          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
          â”‚  â”‚  generate_final_report()                        â”‚  â”‚
          â”‚  â”‚                                                 â”‚  â”‚
          â”‚  â”‚  If categorized:                                â”‚  â”‚
          â”‚  â”‚    - Creates outline with category links        â”‚  â”‚
          â”‚  â”‚    - Groups papers by category                  â”‚  â”‚
          â”‚  â”‚    - Adds category summaries                    â”‚  â”‚
          â”‚  â”‚                                           z      â”‚  â”‚
          â”‚  â”‚  Formats papers as Markdown tables              â”‚  â”‚
          â”‚  â”‚  Combines: intro + outline + categorized refs   â”‚  â”‚
          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚    OUTPUT     â”‚
                        â”‚  final_report â”‚ (Markdown string)
                        â”‚    docs_df    â”‚ (DataFrame)
                        â”‚     stats     â”‚ (Dict with usage)
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Search Modes

The pipeline begins by searching for relevant literature. You can choose between two search strategies:

**Agentic Search** (`use_agentic_search=True`, default)

An AI agent iteratively searches arXiv and the web using tools. The agent decides what to search, reads promising results, refines its queries, and synthesizes a background sectionâ€”all autonomously over up to 100 turns.

```
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚           AI AGENT                  â”‚
                              â”‚   (up to 100 autonomous turns)      â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                        â”‚                        â”‚
                    â–¼                        â–¼                        â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  search_arxiv() â”‚      â”‚  search_web()   â”‚      â”‚ read_abstracts()â”‚
          â”‚                 â”‚      â”‚    (Tavily)     â”‚      â”‚ read_webpages() â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                        â”‚                        â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
                                            â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚   Agent reviews results,    â”‚
                              â”‚   decides next action:      â”‚
                              â”‚   â€¢ Search more?            â”‚
                              â”‚   â€¢ Read specific papers?   â”‚
                              â”‚   â€¢ Done collecting?        â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚
                                             â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚  Synthesize background +    â”‚
                              â”‚  Return collected papers_df â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Recursive Search** (`use_agentic_search=False`)

A structured multi-step approach where the LLM generates queries, searches multiple corpuses in parallel, and uses accumulated results to generate better queries in subsequent iterations.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         RECURSIVE SEARCH LOOP                                   â”‚
â”‚                      (num_search_steps iterations)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 1                        Step 2                        Step N
â”€â”€â”€â”€â”€â”€â”€                       â”€â”€â”€â”€â”€â”€â”€                       â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Generate     â”‚             â”‚ Generate     â”‚             â”‚ Generate     â”‚
â”‚ Queries      â”‚             â”‚ Queries      â”‚             â”‚ Queries      â”‚
â”‚ (from topic) â”‚             â”‚ (topic +     â”‚             â”‚ (topic +     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚  background) â”‚             â”‚  background) â”‚
       â”‚                     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â–¼                            â–¼                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Search     â”‚             â”‚   Search     â”‚             â”‚   Search     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚             â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚             â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ arXiv  â”‚  â”‚             â”‚  â”‚ arXiv  â”‚  â”‚             â”‚  â”‚ arXiv  â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚             â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚             â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Tavily â”‚  â”‚             â”‚  â”‚ Tavily â”‚  â”‚             â”‚  â”‚ Tavily â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚             â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚             â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Google â”‚  â”‚             â”‚  â”‚ Google â”‚  â”‚             â”‚  â”‚ Google â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚             â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚             â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                            â”‚                            â”‚
       â–¼                            â–¼                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dedupe &    â”‚             â”‚  Dedupe &    â”‚             â”‚  Dedupe &    â”‚
â”‚  Accumulate  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Accumulate  â”‚â”€â”€â”€â”€...â”€â”€â”€â”€â”€â–¶â”‚  Accumulate  â”‚
â”‚  Results     â”‚             â”‚  Results     â”‚             â”‚  Results     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                            â”‚                            â”‚
       â–¼                            â–¼                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Summarize   â”‚             â”‚  Summarize   â”‚             â”‚    Final     â”‚
â”‚  Background  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Background  â”‚â”€â”€â”€â”€...â”€â”€â”€â”€â”€â–¶â”‚   Output     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                            â”‚
       â”‚    background informs      â”‚    background informs
       â””â”€â”€â”€â”€â”€â”€ next queries â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”€â”€â”€â”€â”€â”€ next queries â”€â”€â”€â”€â”€â”€â–¶
```

Both modes support an optional `end_date` parameter that filters results to only include papers published before that date. Web search can be disabled with `enable_web_search=False` to search only arXiv.

### Usage

```python
from deepscholar_base import deepscholar_base
from deepscholar_base.configs import Configs
from lotus.models import LM
from datetime import datetime
import asyncio

# Configure the pipeline with a base LM
configs = Configs(
    lm=LM(model="gpt-4o", temperature=1.0, max_tokens=10000)
)

# Or use different LMs for different stages
configs = Configs(
    search_lm=LM(model="gpt-4o", temperature=0.7),      # For query generation & agentic search
    filter_lm=LM(model="gpt-4o-mini", temperature=0),   # For semantic filtering
    taxonomize_lm=LM(model="gpt-4o", temperature=0.5),  # For categorization
    generation_lm=LM(model="gpt-4o", temperature=0.7),  # For summaries & report
)

# Run the pipeline
async def main():
    final_report, docs_df, stats = await deepscholar_base(
        topic="What are the latest developments in retrieval-augmented generation?",
        end_date=datetime(2025, 1, 1),  # Only papers before this date
        configs=configs,
    )
    print(final_report)
    print(f"Found {len(docs_df)} papers")
    print(f"Total tokens used: {stats['total_usage']['total_tokens']}")

asyncio.run(main())
```

### Configuration Reference

#### Search Settings
| Parameter | Default | Description |
|-----------|---------|-------------|
| `use_agentic_search` | `True` | Use autonomous AI agent for search (vs structured recursive search) |
| `enable_web_search` | `True` | Include web results via Tavily alongside arXiv |
|**(Only for recursive search)**| | |
| `per_query_max_search_results_count` | `10` | Maximum results to fetch per query |
| `max_search_retries` | `3` | Retries if search+filter yields no results |
| `num_search_steps` | `3` | Iterations for recursive search (ignored if agentic) |
| `num_search_queries_per_step_per_corpus` | `2` | Queries per step in recursive search |
| `web_corpuses` | `[TAVILY]` | Web search providers for recursive search |
|**(Only for agentic search)**| | |
| `use_responses_model` | `None` | Force OpenAI Responses vs Chat Completions API |

#### Filter Settings
| Parameter | Default | Description |
|-----------|---------|-------------|
| `use_sem_filter` | `True` | Apply semantic relevance filtering |
| `use_sem_topk` | `True` | Rank and select top-K most relevant papers |
| `final_max_results_count` | `30` | Maximum papers to keep after filtering |
| `sem_filter_kwargs` | `{strategy: COT}` | Arguments for LOTUS `sem_filter()` |
| `sem_topk_kwargs` | `{strategy: COT}` | Arguments for LOTUS `sem_topk()` |

#### Generation Settings
| Parameter | Default | Description |
|-----------|---------|-------------|
| `categorize_references` | `True` | Organize papers into thematic categories |
| `generate_category_summary` | `True` | Write summary paragraphs per category |
| `generate_insights` | `True` | Extract key ideas from each paper |
| `use_structured_output` | `True` | Use Pydantic models for LLM outputs |

#### Language Model Settings

You can provide a single `lm` parameter, which will be used as the default for all stages. Alternatively, you can specify different models for each stage to optimize for cost, speed, or capability:

| Parameter | Purpose |
|-----------|---------|
| `lm` | Default LM used when stage-specific LMs aren't provided |
| `search_lm` | Query generation and agentic search reasoning |
| `filter_lm` | Semantic filtering and ranking |
| `taxonomize_lm` | Category creation and paper-to-category mapping |
| `generation_lm` | Introduction, summaries, insights, and final report |

### Output

The pipeline returns a tuple of three values:

1. **`final_report`** (str): The complete Markdown document ready for display or export
2. **`docs_df`** (DataFrame): All filtered papers with columns: `id`, `title`, `url`, `snippet`, `date`, `authors`, `category`, `key idea/summary`
3. **`stats`** (dict): Detailed statistics including per-stage token usage, intermediate results, and any errors


## ğŸ¤ Contributing

We welcome contributions to DeepScholarBench! Please feel free to submit a PR for code contributions. If you would like to add your AI system to the DeepScholar-bench leaderboard, please fill out this [this form](https://docs.google.com/forms/d/e/1FAIpQLSeug4igDHhVUU3XnrUSeMVRUJFKlHP28i8fcBAu_LHCkqdV1g/viewform).


## Citation
If you use DeepScholar-Bench in an academic work, we would greatly appreciate it if you can cite this work as follows:
```bibtex
@article{patel2025deepscholarbench,
      title={DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis}, 
      author={Liana Patel and Negar Arabzadeh and Harshit Gupta and Ankita Sundar and Ion Stoica and Matei Zaharia and Carlos Guestrin},
      year={2025},
      url={https://arxiv.org/abs/2508.20033}, 
}
```
