\begin{thebibliography}{10}

\bibitem{wordembedding}
Sanjeev Arora, Yuanzhi Li, Yingyu Liang, Tengyu Ma, and Andrej Risteski.
\newblock A latent variable model approach to pmi-based word embeddings.
\newblock {\em Transactions of the Association for Computational Linguistics}, 4:385--399, 2016.

\bibitem{bandi2018detection}
Peter Bandi, Oscar Geessink, Quirine Manson, Marcory Van~Dijk, Maschenka Balkenhol, Meyke Hermsen, Babak~Ehteshami Bejnordi, Byungjae Lee, Kyunghyun Paeng, Aoxiao Zhong, et~al.
\newblock From detection of individual metastases to classification of lymph node status at the patient level: the camelyon17 challenge.
\newblock {\em IEEE Transactions on Medical Imaging}, 2018.

\bibitem{borkan2019nuanced}
Daniel Borkan, Lucas Dixon, Jeffrey Sorensen, Nithum Thain, and Lucy Vasserman.
\newblock Nuanced metrics for measuring unintended bias with real data for text classification.
\newblock In {\em Companion Proceedings of The 2019 World Wide Web Conference}, 2019.

\bibitem{lame}
Malik Boudiaf, Romain Mueller, Ismail Ben~Ayed, and Luca Bertinetto.
\newblock Parameter-free online test-time adaptation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 8344--8353, 2022.

\bibitem{adacontrast}
Dian Chen, Dequan Wang, Trevor Darrell, and Sayna Ebrahimi.
\newblock Contrastive test-time adaptation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 295--305, 2022.

\bibitem{cubuk2019autoaugment}
Ekin~D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc~V Le.
\newblock Autoaugment: Learning augmentation strategies from data.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 113--123, 2019.

\bibitem{cubuk2020randaugment}
Ekin~D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc~V Le.
\newblock Randaugment: Practical automated data augmentation with a reduced search space.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops}, pages 702--703, 2020.

\bibitem{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock {\em arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{gao2023out}
Irena Gao, Shiori Sagawa, Pang~Wei Koh, Tatsunori Hashimoto, and Percy Liang.
\newblock Out-of-domain robustness via targeted augmentations.
\newblock In {\em International Conference on Machine Learning}, pages 10800--10834. PMLR, 2023.

\bibitem{geirhos2018imagenettrained}
Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix~A. Wichmann, and Wieland Brendel.
\newblock Imagenet-trained {CNN}s are biased towards texture; increasing shape bias improves accuracy and robustness.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{goel2021model}
Karan Goel, Albert Gu, Yixuan Li, and Christopher Re.
\newblock Model patching: Closing the subgroup performance gap with data augmentation.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{sotta}
Taesik Gong, Yewon Kim, Taeckyung Lee, Sorn Chottananurak, and Sung-Ju Lee.
\newblock So{TTA}: Robust test-time adaptation on noisy data streams.
\newblock In {\em Advances in Neural Information Processing Systems}, 2023.

\bibitem{domainbed}
Ishaan Gulrajani and David Lopez-Paz.
\newblock In search of lost domain generalization.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{imagenet_r}
Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et~al.
\newblock The many faces of robustness: A critical analysis of out-of-distribution generalization.
\newblock In {\em Proceedings of the IEEE/CVF international conference on computer vision}, pages 8340--8349, 2021.

\bibitem{birdcalls_1}
W.~Alexander Hopping, Stefan Kahl, and Holger Klinck.
\newblock A collection of fully-annotated soundscape recordings from the southwestern amazon basin.
\newblock URL https://zenodo.org/records/7079124, 2022.

\bibitem{horn2012matrix}
Roger~A Horn and Charles~R Johnson.
\newblock {\em Matrix analysis}.
\newblock Cambridge university press, 2012.

\bibitem{pasle}
Yihao Hu, Congyu Qiao, Xin Geng, and Ning Xu.
\newblock Selective label enhancement learning for test-time adaptation.
\newblock In {\em International Conference on Learning Representations}, 2025.

\bibitem{dgp2}
Zhuo Huang, Xiaobo Xia, Li~Shen, Bo~Han, Mingming Gong, Chen Gong, and Tongliang Liu.
\newblock Harnessing out-of-distribution examples via augmenting content and style.
\newblock In {\em International Conference on Learning Representations}, 2023.

\bibitem{t3a}
Yusuke Iwasawa and Yutaka Matsuo.
\newblock Test-time classifier adjustment module for model-agnostic domain generalization.
\newblock In {\em Advances in Neural Information Processing Systems}, volume~34, pages 2427--2440, 2021.

\bibitem{pre_dfr}
Pavel Izmailov, Polina Kirichenko, Nate Gruver, and Andrew~Gordon Wilson.
\newblock On feature learning in the presence of spurious correlations.
\newblock In {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{tast}
Minguk Jang, Sae-Young Chung, and Hye~Won Chung.
\newblock Test-time adaptation via self-training with nearest neighbor information.
\newblock In {\em International Conference on Learning Representations}, 2023.

\bibitem{jolliffe2002principal}
I.T. Jolliffe.
\newblock {\em Principal Component Analysis}.
\newblock Springer Series in Statistics. Springer, 2002.

\bibitem{cafa}
Sanghun Jung, Jungsoo Lee, Nanhee Kim, Amirreza Shaban, Byron Boots, and Jaegul Choo.
\newblock Cafa: Class-aware feature alignment for test-time adaptation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 19060--19071, 2023.

\bibitem{birdcalls_2}
Stefan Kahl, Russell Charif, and Holger Klinck.
\newblock A collection of fully-annotated soundscape recordings from the northeastern united states.
\newblock URL https://zenodo.org/records/7018484, 2022.

\bibitem{crkd}
Juwon Kang, Nayeong Kim, Donghyeon Kwon, Jungseul Ok, and Suha Kwak.
\newblock Leveraging proxy of training data for test-time adaptation.
\newblock In {\em International Conference on Machine Learning}, pages 15737--15752. PMLR, 2023.

\bibitem{kaur2023modeling}
Jivat~Neet Kaur, Emre Kiciman, and Amit Sharma.
\newblock Modeling the data-generating process is necessary for out-of-distribution generalization.
\newblock In {\em International Conference on Learning Representations}, 2023.

\bibitem{dfr}
Polina Kirichenko, Pavel Izmailov, and Andrew~Gordon Wilson.
\newblock Last layer re-training is sufficient for robustness to spurious correlations.
\newblock In {\em International Conference on Learning Representations}, 2023.

\bibitem{WILDS}
Pang~Wei Koh, Shiori Sagawa, Henrik Marklund, Sang~Michael Xie, Marvin Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard~Lanas Phillips, Irena Gao, et~al.
\newblock Wilds: A benchmark of in-the-wild distribution shifts.
\newblock In {\em International Conference on Machine Learning}, pages 5637--5664. PMLR, 2021.

\bibitem{deyo}
Jonghyun Lee, Dahuin Jung, Saehyung Lee, Junsung Park, Juhyeon Shin, Uiwon Hwang, and Sungroh Yoon.
\newblock Entropy is not enough for test-time adaptation: From the perspective of disentangled factors.
\newblock In {\em International Conference on Learning Representations}, 2024.

\bibitem{shot}
Jian Liang, Dapeng Hu, and Jiashi Feng.
\newblock Do we really need to access the source data? {S}ource hypothesis transfer for unsupervised domain adaptation.
\newblock In {\em International Conference on Machine Learning}, pages 6028--6039. PMLR, 2020.

\bibitem{lv2022causality}
Fangrui Lv, Jian Liang, Shuang Li, Bin Zang, Chi~Harold Liu, Ziteng Wang, and Di~Liu.
\newblock Causality inspired representation learning for domain generalization.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 8046--8056, 2022.

\bibitem{mahajan2021domain}
Divyat Mahajan, Shruti Tople, and Amit Sharma.
\newblock Domain generalization using causal matching.
\newblock In {\em International Conference on Machine Learning}, pages 7313--7324. PMLR, 2021.

\bibitem{mikolov2013linguistic}
Tom{\'a}{\v{s}} Mikolov, Wen-tau Yih, and Geoffrey Zweig.
\newblock Linguistic regularities in continuous space word representations.
\newblock In {\em Proceedings of the 2013 conference of the north american chapter of the association for computational linguistics: Human language technologies}, pages 746--751, 2013.

\bibitem{birdcalls_3}
Amanda Navine, Stefan Kahl, Ann Tanimoto-Johnson, Holger Klinck, and Patrick Hart.
\newblock A collection of fully-annotated soundscape recordings from the island of hawai'i.
\newblock URL https://doi.org/10.5281/zenodo.7078499, 2022.

\bibitem{tipi}
A.~Tuan Nguyen, Thanh Nguyen-Tang, Ser-Nam Lim, and Philip~H.S. Torr.
\newblock Tipi: Test time adaptation with transformation invariance.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 24162--24171, June 2023.

\bibitem{foa}
Shuaicheng Niu, Chunyan Miao, Guohao Chen, Pengcheng Wu, and Peilin Zhao.
\newblock Test-time model adaptation with only forward passes.
\newblock In {\em International Conference on Machine Learning}, 2024.

\bibitem{eata}
Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan.
\newblock Efficient test-time model adaptation without forgetting.
\newblock In {\em International Conference on Machine Learning}, pages 16888--16905. PMLR, 2022.

\bibitem{sar}
Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Zhiquan Wen, Yaofo Chen, Peilin Zhao, and Mingkui Tan.
\newblock Towards stable test-time adaptation in dynamic wild world.
\newblock In {\em International Conference on Learning Representations}, 2023.

\bibitem{linear_representation}
Kiho Park, Yo~Joong Choe, and Victor Veitch.
\newblock The linear representation hypothesis and the geometry of large language models.
\newblock In {\em International Conference on Machine Learning}, pages 39643--39666. PMLR, 2024.

\bibitem{clip}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In {\em International Conference on Machine Learning}, pages 8748--8763. PmLR, 2021.

\bibitem{imagenet_v2}
Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar.
\newblock Do imagenet classifiers generalize to imagenet?
\newblock In {\em International conference on machine learning}, pages 5389--5400. PMLR, 2019.

\bibitem{ILSVRC15}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander~C. Berg, and Li~Fei-Fei.
\newblock {ImageNet Large Scale Visual Recognition Challenge}.
\newblock {\em International Journal of Computer Vision (IJCV)}, 115(3):211--252, 2015.

\bibitem{sanh2019distilbert}
Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf.
\newblock Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter.
\newblock {\em arXiv preprint arXiv:1910.01108}, 2019.

\bibitem{bn_adapt}
Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bringmann, Wieland Brendel, and Matthias Bethge.
\newblock Improving robustness against common corruptions by covariate shift adaptation.
\newblock In {\em Advances in Neural Information Processing Systems}, volume~33, pages 11539--11551, 2020.

\bibitem{selvaraju2017grad}
Ramprasaath~R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra.
\newblock Grad-cam: Visual explanations from deep networks via gradient-based localization.
\newblock In {\em Proceedings of the IEEE international conference on computer vision}, pages 618--626, 2017.

\bibitem{linear_representation_gan}
Yujun Shen, Jinjin Gu, Xiaoou Tang, and Bolei Zhou.
\newblock Interpreting the latent space of gans for semantic face editing.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 9243--9252, 2020.

\bibitem{program}
Haopeng Sun, Lumin Xu, Sheng Jin, Ping Luo, Chen Qian, and Wentao Liu.
\newblock {PROGRAM}: {PRO}totype {GRA}ph model based pseudo-label learning for test-time adaptation.
\newblock In {\em International Conference on Learning Representations}, 2024.

\bibitem{dgp}
Xinwei Sun, Botong Wu, Xiangyu Zheng, Chang Liu, Wei Chen, Tao Qin, and Tie-Yan Liu.
\newblock Recovering latent causal factor for generalization to distributional shifts.
\newblock In {\em Advances in Neural Information Processing Systems}, volume~34, pages 16846--16859, 2021.

\bibitem{tellez2018whole}
David Tellez, Maschenka Balkenhol, Irene Otte-H{\"o}ller, Rob Van De~Loo, Rob Vogels, Peter Bult, Carla Wauters, Willem Vreuls, Suzanne Mol, Nico Karssemeijer, et~al.
\newblock Whole-slide mitosis detection in h\&e breast histology using phh3 as a reference to train distilled stain-invariant convolutional networks.
\newblock {\em IEEE transactions on medical imaging}, 37(9):2126--2136, 2018.

\bibitem{linear_interpolation}
Paul Upchurch, Jacob Gardner, Geoff Pleiss, Robert Pless, Noah Snavely, Kavita Bala, and Kilian Weinberger.
\newblock Deep feature interpolation for image content changes.
\newblock In {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 7064--7073, 2017.

\bibitem{tent}
Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell.
\newblock Tent: Fully test-time adaptation by entropy minimization.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{cotta}
Qin Wang, Olga Fink, Luc Van~Gool, and Dengxin Dai.
\newblock Continual test-time domain adaptation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 7201--7211, 2022.

\bibitem{tsd}
Shuai Wang, Daoan Zhang, Zipei Yan, Jianguo Zhang, and Rui Li.
\newblock Feature alignment and uniformity for test time adaptation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 20050--20060, 2023.

\bibitem{wiles2022a}
Olivia Wiles, Sven Gowal, Florian Stimberg, Sylvestre-Alvise Rebuffi, Ira Ktena, Krishnamurthy~Dj Dvijotham, and Ali~Taylan Cemgil.
\newblock A fine-grained analysis on distribution shift.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{ye2022ood}
Nanyang Ye, Kaican Li, Haoyue Bai, Runpeng Yu, Lanqing Hong, Fengwei Zhou, Zhenguo Li, and Jun Zhu.
\newblock Ood-bench: Quantifying and understanding two dimensions of out-of-distribution generalization.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 7947--7958, 2022.

\bibitem{memo}
Marvin Zhang, Sergey Levine, and Chelsea Finn.
\newblock Memo: Test time robustness via adaptation and augmentation.
\newblock In {\em Advances in Neural Information Processing Systems}, volume~35, pages 38629--38642, 2022.

\bibitem{adanpc}
Yifan Zhang, Xue Wang, Kexin Jin, Kun Yuan, Zhang Zhang, Liang Wang, Rong Jin, and Tieniu Tan.
\newblock Adanpc: Exploring non-parametric classifier for test-time adaptation.
\newblock In {\em International Conference on Machine Learning}, pages 41647--41676. PMLR, 2023.

\bibitem{AdaRealign}
Zhen-Yu Zhang, Zhiyu Xie, Huaxiu Yao, and Masashi Sugiyama.
\newblock Test-time adaptation in non-stationary environments via adaptive representation alignment.
\newblock In {\em Advances in Neural Information Processing Systems}, volume~37, pages 94607--94632, 2024.

\bibitem{ttab}
Hao Zhao, Yuejiang Liu, Alexandre Alahi, and Tao Lin.
\newblock On pitfalls of test-time adaptation.
\newblock In {\em International Conference on Machine Learning}, pages 42058--42080. PMLR, 2023.

\end{thebibliography}
