\section{Implementation Details} \label{appendix:exp}

We provide implementation details for the experiments described in the main paper. All models are built on encoder-only Transformer architecture as described in \Cref{appendix:encoder}, with task-specific configurations detailed below.

\paragraph{Model Architecture}
All models are based on encoder-only Transformer architecture with rotary positional embeddings (RoPE). For AP-MDM, we add three binary classification heads (remask, insert, delete) on top of the standard unmask head. We use no timestep embedding and set time conditioning to zero during supervised training. For Sudoku, we use 6 layers, 4 attention heads, hidden dimension $d=256$, feed-forward dimension $4d=1024$, maximum sequence length 400, vocabulary size 31. For Parity, we use 1 layer, 1 attention head, hidden dimension $d=4$, feed-forward dimension $4d=16$, maximum sequence length 3, vocabulary size 6, with approximately 200 total parameters. For Graph, we use 8 layers, 4 attention heads, hidden dimension $d=256$, feed-forward dimension $4d=1024$, maximum sequence length set to accommodate graphs of varying sizes, vocabulary size 55; the same configuration is used for the ARM baseline.

\paragraph{Training Data Generation}
For supervised training as described in \Cref{appendix:training2}, training data consists of state-transition tuples $(\mathbf{x}_k, \mathbf{y}^*, \ctrlvec^*)$ generated by simulating the natural solving or generation algorithms for each task. Starting from ground-truth target solutions, we execute task-specific algorithms and record the intermediate computation states at each step. For each state, we capture the current sequence $\mathbf{x}_k$ (with unknown or unfilled positions represented as $\mask$), the target values $\mathbf{y}^*$ to be revealed, and the control decisions $\ctrlvec^*$ indicating which operations (unmask, remask, insert, delete) should be applied. Concrete examples of data generation for Sudoku, Parity, and Graph tasks are provided in \Cref{appendix:examples_sudoku}, \Cref{appendix:examples_parity}, and \Cref{appendix:examples_graph}, respectively.

\paragraph{Training Details}
We train all models using AdamW optimizer with learning rate $10^{-4}$, $(\beta_1, \beta_2) = (0.9, 0.999)$, weight decay $0.01$, and batch size 256. Learning rate follows a constant schedule with 250 warmup steps. We use mixed precision training (bfloat16) with gradient clipping at 1.0. Loss weights are set to $\lambda_r = \lambda_i = \lambda_d = 1.0$ by default. Models are trained for up to 1M steps or until convergence. For Graph generation, we use 100K graph instances for training both AP-MDM and the ARM baseline. For Parity, we use only 4 training samples for AP-MDM, while the ARM baseline is trained with up to 10K instances.




% \begin{figure}[t]
% 	\centering
% 	\includegraphics[width=1.0\textwidth]{figs/expanded_sample_5.pdf}
% 	\caption{This is a figure.}
% \end{figure} 

% \subsection{Sudoku Puzzle} \label{appendix:exp_sudoku}



% \subsection{Parity} \label{appendix:exp_parity}

% \subsection{Graph Generation} \label{appendix:exp_graph}