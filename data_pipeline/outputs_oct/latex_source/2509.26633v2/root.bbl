% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{li2023object}
J.~Li, J.~Wu, and C.~K. Liu, ``Object motion guided human motion synthesis,'' \emph{ACM Transactions on Graphics (TOG)}, 2023.

\bibitem{harvey2020robust}
F.~G. Harvey, M.~Yurick, D.~Nowrouzezahrai, and C.~Pal, ``Robust motion in-betweening,'' vol.~39, no.~4, 2020.

\bibitem{lee2020learning}
J.~Lee, J.~Hwangbo, L.~Wellhausen, V.~Koltun, and M.~Hutter, ``Learning quadrupedal locomotion over challenging terrain,'' \emph{Science robotics}, 2020.

\bibitem{peng2018deepmimic}
X.~B. Peng, P.~Abbeel, S.~Levine, and M.~Van~de Panne, ``Deepmimic: Example-guided deep reinforcement learning of physics-based character skills,'' \emph{ACM Transactions On Graphics (TOG)}, 2018.

\bibitem{xu2025parc}
M.~Xu, Y.~Shi, K.~Yin, and X.~B. Peng, ``Parc: Physics-based augmentation with reinforcement learning for character controllers,'' in \emph{Proceedings of the SIGGRAPH Conference Papers}, 2025.

\bibitem{wu2024human}
Z.~Wu, J.~Li, P.~Xu, and C.~K. Liu, ``Human-object interaction from human-level instructions,'' \emph{arXiv preprint arXiv:2406.17840}, 2024.

\bibitem{fu2024humanplus}
Z.~Fu, Q.~Zhao, Q.~Wu, G.~Wetzstein, and C.~Finn, ``Humanplus: Humanoid shadowing and imitation from humans,'' \emph{CoRL}, 2024.

\bibitem{he2024omnih2o}
T.~He, Z.~Luo, X.~He, W.~Xiao, C.~Zhang, W.~Zhang, K.~M. Kitani, C.~Liu, and G.~Shi, ``Omnih2o: Universal and dexterous human-to-humanoid whole-body teleoperation and learning,'' in \emph{CoRL}, 2025.

\bibitem{ze2025twist}
Y.~Ze, Z.~Chen, J.~P. Ara{\~A}{\v{s}}jo, Z.-a. Cao, X.~B. Peng, J.~Wu, and C.~K. Liu, ``Twist: Teleoperated whole-body imitation system,'' \emph{CoRL}, 2025.

\bibitem{Luo2023PerpetualHC}
Z.~Luo, J.~Cao, A.~W. Winkler, K.~Kitani, and W.~Xu, ``Perpetual humanoid control for real-time simulated avatars,'' in \emph{ICCV}, 2023.

\bibitem{videomimic}
A.~Allshire, H.~Choi, J.~Zhang, D.~McAllister, A.~Zhang, C.~M. Kim, T.~Darrell, P.~Abbeel, J.~Malik, and A.~Kanazawa, ``Visual imitation enables contextual humanoid control,'' \emph{CoRL}, 2025.

\bibitem{zhang2025hub}
T.~Zhang, B.~Zheng, R.~Nai, Y.~Hu, Y.-J. Wang, G.~Chen, F.~Lin, J.~Li, C.~Hong, K.~Sreenath \emph{et~al.}, ``Hub: Learning extreme humanoid balance,'' \emph{CoRL}, 2025.

\bibitem{he2025asap}
T.~He, J.~Gao, W.~Xiao, Y.~Zhang, Z.~Wang, J.~Wang, Z.~Luo, G.~He, N.~Sobanbabu, C.~Pan, Z.~Yi, G.~Qu, K.~Kitani, J.~Hodgins, L.~J. Fan, Y.~Zhu, C.~Liu, and G.~Shi, ``Asap: Aligning simulation and real-world physics for learning agile humanoid whole-body skills,'' \emph{arXiv}, 2025.

\bibitem{Ho2010Spatial}
E.~S.~L. Ho, T.~Komura, and C.-L. Tai, ``Spatial relationship preserving character motion adaptation,'' \emph{ACM Transactions on Graphics}, 2010.

\bibitem{yang2025physics}
L.~Yang, H.~Suh, T.~Zhao, B.~P. Graesdal, T.~Kelestemur, J.~Wang, T.~Pang, and R.~Tedrake, ``Physics-driven data generation for contact-rich manipulation via trajectory optimization,'' \emph{RSS}, 2025.

\bibitem{cheynel2023sparse}
T.~Cheynel, T.~Rossi, B.~Bellot-Gurlet, D.~Rohmer, and M.-P. Cani, ``Sparse motion semantics for contact-aware retargeting,'' in \emph{ACM SIGGRAPH Conference on Motion, Interaction and Games}, 2023.

\bibitem{kim2016retargeting}
Y.~Kim, H.~Park, S.~Bang, and S.-H. Lee, ``Retargeting human-object interaction to virtual avatars,'' \emph{IEEE transactions on visualization and computer graphics}, vol.~22, no.~11, pp. 2405--2412, 2016.

\bibitem{gleicher1998retargetting}
M.~Gleicher, ``Retargetting motion to new characters,'' in \emph{Proceedings of the 25th annual conference on Computer graphics and interactive techniques}, 1998, pp. 33--42.

\bibitem{aberman2020skeleton}
K.~Aberman, P.~Li, D.~Lischinski, O.~Sorkine-Hornung, D.~Cohen-Or, and B.~Chen, ``Skeleton-aware networks for deep motion retargeting,'' \emph{ACM Transactions on Graphics (TOG)}, vol.~39, no.~4, pp. 62--1, 2020.

\bibitem{villegas2018neural}
R.~Villegas, J.~Yang, D.~Ceylan, and H.~Lee, ``Neural kinematic networks for unsupervised motion retargetting,'' in \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, 2018.

\bibitem{zhang2023simulation}
Y.~Zhang, D.~Gopinath, Y.~Ye, J.~Hodgins, G.~Turk, and J.~Won, ``Simulation and retargeting of complex multi-character interactions,'' in \emph{ACM SIGGRAPH 2023 Conference Proceedings}, 2023.

\bibitem{Nakaoka2012Interaction}
S.~Nakaoka and T.~Komura, ``Interaction mesh based motion adaptation for biped humanoid robots,'' in \emph{Humanoids}, 2012.

\bibitem{dao2024sim}
J.~Dao, H.~Duan, and A.~Fern, ``Sim-to-real learning for humanoid box loco-manipulation,'' in \emph{ICRA}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2024.

\bibitem{long2024learning}
J.~Long, J.~Ren, M.~Shi, Z.~Wang, T.~Huang, P.~Luo, and J.~Pang, ``Learning humanoid locomotion with perceptive internal model,'' \emph{arXiv}, 2024.

\bibitem{he2025attention}
J.~He, C.~Zhang, F.~Jenelten, R.~Grandia, M.~B{\"a}cher, and M.~Hutter, ``Attention-based map encoding for learning generalized legged locomotion,'' \emph{Science Robotics}, vol.~10, no. 105, p. eadv3604, 2025.

\bibitem{he2025learning}
X.~He, R.~Dong, Z.~Chen, and S.~Gupta, ``Learning getting-up policies for real-world humanoid robots,'' \emph{RSS}, 2025.

\bibitem{kuang2025skillblender}
Y.~Kuang, H.~Geng, A.~Elhafsi, T.-D. Do, P.~Abbeel, J.~Malik, M.~Pavone, and Y.~Wang, ``Skillblender: Towards versatile humanoid whole-body loco-manipulation via skill blending,'' \emph{arXiv}, 2025.

\bibitem{zhang2025unleashing}
Z.~Zhang, C.~Chen, H.~Xue, J.~Wang, S.~Liang, Y.~Liu, Z.~Zhang, H.~Wang, and L.~Yi, ``Unleashing humanoid reaching potential via real-world-ready skill space,'' \emph{arXiv preprint arXiv:2505.10918}, 2025.

\bibitem{xue2025unified}
Y.~Xue, W.~Dong, M.~Liu, W.~Zhang, and J.~Pang, ``A unified and general humanoid whole-body controller for versatile locomotion,'' \emph{RSS}, 2025.

\bibitem{zhang2406wococo}
C.~Zhang, W.~Xiao, T.~He, and G.~Shi, ``Wococo: Learning whole-body humanoid control with sequential contacts, 2024,'' \emph{arXiv}, 2024.

\bibitem{zhang2025falcon}
Y.~Zhang, Y.~Yuan, P.~Gurunath, T.~He, S.~Omidshafiei, A.-a. Agha-mohammadi, M.~Vazquez-Chanlatte, L.~Pedersen, and G.~Shi, ``Falcon: Learning force-adaptive humanoid loco-manipulation,'' \emph{arXiv}, 2025.

\bibitem{li2025reinforcement}
Z.~Li, X.~B. Peng, P.~Abbeel, S.~Levine, G.~Berseth, and K.~Sreenath, ``Reinforcement learning for versatile, dynamic, and robust bipedal locomotion control,'' \emph{IJRR}, 2025.

\bibitem{liao2025beyondmimic}
Q.~Liao, T.~E. Truong, X.~Huang, G.~Tevet, K.~Sreenath, and C.~K. Liu, ``Beyondmimic: From motion tracking to versatile humanoid control via guided diffusion,'' \emph{arXiv e-prints}, pp. arXiv--2508, 2025.

\bibitem{unitree_lafan1_retargeting_dataset}
U.~Robotics and Contributors, ``Unitree lafan1 retargeting dataset,'' \url{https://huggingface.co/datasets/lvhaidong/LAFAN1_Retargeting_Dataset}, 2025.

\bibitem{seo2023deep}
M.~Seo, S.~Han, K.~Sim, S.~H. Bang, C.~Gonzalez, L.~Sentis, and Y.~Zhu, ``Deep imitation learning for humanoid loco-manipulation through human teleoperation,'' in \emph{Humanoids}, 2023.

\bibitem{ben2025homie}
Q.~Ben, F.~Jia, J.~Zeng, J.~Dong, D.~Lin, and J.~Pang, ``Homie: Humanoid loco-manipulation with isomorphic exoskeleton cockpit,'' \emph{RSS}, 2025.

\bibitem{zhang2024diffusion}
X.~Zhang, M.~Chang, P.~Kumar, and S.~Gupta, ``Diffusion meets dagger: Supercharging eye-in-hand imitation learning,'' in \emph{RSS}, 2024.

\bibitem{tian2024view}
S.~Tian, B.~Wulfe, K.~Sargent, K.~Liu, S.~Zakharov, V.~C. Guizilini, and J.~Wu, ``View-invariant policy learning via zero-shot novel view synthesis,'' in \emph{CoRL}, 2025.

\bibitem{chen2024rovi}
L.~Y. Chen, C.~Xu, K.~Dharmarajan, Z.~Irshad, R.~Cheng, K.~Keutzer, M.~Tomizuka, Q.~Vuong, and K.~Goldberg, ``Rovi-aug: Robot and viewpoint augmentation for cross-embodiment robot learning,'' in \emph{Conference on Robot Learning (CoRL)}, 2024.

\bibitem{mandi2022cacti}
Z.~Mandi, H.~Bharadhwaj, V.~Moens, S.~Song, A.~Rajeswaran, and V.~Kumar, ``Cacti: A framework for scalable multi-task multi-scene visual imitation learning,'' \emph{arXiv preprint arXiv:2212.05711}, 2022.

\bibitem{chen2023genaug}
Z.~Chen, S.~Kiami, A.~Gupta, and V.~Kumar, ``Genaug: Retargeting behaviors to unseen situations via generative augmentation,'' \emph{RSS}, 2023.

\bibitem{yu2023scaling}
T.~Yu, T.~Xiao, A.~Stone, J.~Tompson, A.~Brohan, S.~Wang, J.~Singh, C.~Tan, J.~Peralta, B.~Ichter \emph{et~al.}, ``Scaling robot learning with semantically imagined experience,'' \emph{RSS}, 2023.

\bibitem{mandlekar2023mimicgen}
A.~Mandlekar, S.~Nasiriany, B.~Wen, I.~Akinola, Y.~Narang, L.~Fan, Y.~Zhu, and D.~Fox, ``Mimicgen: A data generation system for scalable robot learning using human demonstrations,'' in \emph{CoRL}, 2023.

\bibitem{jiang2024dexmimicgen}
Z.~Jiang, Y.~Xie, K.~Lin, Z.~Xu, W.~Wan, A.~Mandlekar, L.~Fan, and Y.~Zhu, ``Dexmimicgen: Automated data generation for bimanual dexterous manipulation via imitation learning,'' \emph{ICRA}, 2025.

\bibitem{garrett2024skillmimicgen}
C.~Garrett, A.~Mandlekar, B.~Wen, and D.~Fox, ``Skillmimicgen: Automated demonstration generation for efficient skill learning and deployment,'' in \emph{Conference on Robot Learning (CoRL)}, 2024.

\bibitem{starke2019neural}
S.~Starke, H.~Zhang, T.~Komura, and J.~Saito, ``Neural state machine for character-scene interactions,'' \emph{ACM Transactions on Graphics}, vol.~38, no.~6, p. 178, 2019.

\bibitem{Zakka_Mink_Python_inverse_2025}
\BIBentryALTinterwordspacing
K.~Zakka, ``{Mink: Python inverse kinematics based on MuJoCo},'' May 2025. [Online]. Available: \url{https://github.com/kevinzakka/mink}
\BIBentrySTDinterwordspacing

\bibitem{si2005meshing}
H.~Si and K.~G{\"a}rtner, ``Meshing piecewise linear complexes by constrained delaunay tetrahedralizations,'' in \emph{Proceedings of the 14th international meshing roundtable}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2005, pp. 147--163.

\bibitem{alexa2003differential}
M.~Alexa, ``Differential coordinates for local mesh morphing and deformation,'' \emph{The Visual Computer}, vol.~19, no.~2, pp. 105--114, 2003.

\bibitem{zhou2005large}
K.~Zhou, J.~Huang, J.~Snyder, X.~Liu, H.~Bao, B.~Guo, and H.-Y. Shum, ``Large mesh deformation using the volumetric graph laplacian,'' in \emph{ACM SIGGRAPH 2005 Papers}.\hskip 1em plus 0.5em minus 0.4em\relax ACM, 2005, pp. 496--503.

\bibitem{drake}
R.~Tedrake and the Drake Development~Team, ``Drake: Model-based design and verification for robotics,'' 2019.

\bibitem{jackson2021planning}
B.~E. Jackson, K.~Tracy, and Z.~Manchester, ``Planning with attitude,'' \emph{IEEE Robotics and Automation Letters}, 2021.

\bibitem{BostonDynamics2023Atlas}
{Boston Dynamics}, ``{Atlas Gets a Grip},'' YouTube, available: \url{https://www.youtube.com/watch?v=-e1_QhJ1EhQ}.

\bibitem{SMPL:2015}
M.~Loper, N.~Mahmood, J.~Romero, G.~Pons-Moll, and M.~J. Black, ``{SMPL}: A skinned multi-person linear model,'' \emph{ACM Trans. Graphics (Proc. SIGGRAPH Asia)}, vol.~34, no.~6, pp. 248:1--248:16, Oct. 2015.

\end{thebibliography}
