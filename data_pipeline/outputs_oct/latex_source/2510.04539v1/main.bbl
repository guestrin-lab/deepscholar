\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Avrahami et~al.(2022)Avrahami, Lischinski, and Fried]{avrahami2022blended}
Omri Avrahami, Dani Lischinski, and Ohad Fried.
\newblock Blended diffusion for text-driven editing of natural images.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 18208--18218, 2022.

\bibitem[Avrahami et~al.(2023{\natexlab{a}})Avrahami, Fried, and Lischinski]{avrahami2023blended}
Omri Avrahami, Ohad Fried, and Dani Lischinski.
\newblock Blended latent diffusion.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 42\penalty0 (4):\penalty0 1--11, 2023{\natexlab{a}}.

\bibitem[Avrahami et~al.(2023{\natexlab{b}})Avrahami, Hertz, Vinker, Arar, Fruchter, Fried, Cohen-Or, and Lischinski]{avrahami2023chosen}
Omri Avrahami, Amir Hertz, Yael Vinker, Moab Arar, Shlomi Fruchter, Ohad Fried, Daniel Cohen-Or, and Dani Lischinski.
\newblock The chosen one: Consistent characters in text-to-image diffusion models.
\newblock \emph{arXiv preprint arXiv:2311.10093}, 2023{\natexlab{b}}.

\bibitem[Bansal et~al.(2023)Bansal, Chu, Schwarzschild, Sengupta, Goldblum, Geiping, and Goldstein]{bansal2023universal}
Arpit Bansal, Hong-Min Chu, Avi Schwarzschild, Soumyadip Sengupta, Micah Goldblum, Jonas Geiping, and Tom Goldstein.
\newblock Universal guidance for diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 843--852, 2023.

\bibitem[Barron et~al.(2022)Barron, Mildenhall, Verbin, Srinivasan, and Hedman]{barron2022mip}
Jonathan~T Barron, Ben Mildenhall, Dor Verbin, Pratul~P Srinivasan, and Peter Hedman.
\newblock Mip-nerf 360: Unbounded anti-aliased neural radiance fields.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 5470--5479, 2022.

\bibitem[Brooks et~al.(2023)Brooks, Holynski, and Efros]{brooks2023instructpix2pix}
Tim Brooks, Aleksander Holynski, and Alexei~A Efros.
\newblock Instructpix2pix: Learning to follow image editing instructions.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 18392--18402, 2023.

\bibitem[Cao et~al.(2024)Cao, Yu, Fu, Wang, and Xue]{cao2024mvinpainter}
Chenjie Cao, Chaohui Yu, Yanwei Fu, Fan Wang, and Xiangyang Xue.
\newblock Mvinpainter: Learning multi-view consistent inpainting to bridge 2d and 3d editing.
\newblock \emph{arXiv preprint arXiv:2408.08000}, 2024.

\bibitem[Chefer et~al.(2023)Chefer, Alaluf, Vinker, Wolf, and Cohen-Or]{chefer2023attend}
Hila Chefer, Yuval Alaluf, Yael Vinker, Lior Wolf, and Daniel Cohen-Or.
\newblock Attend-and-excite: Attention-based semantic guidance for text-to-image diffusion models.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 42\penalty0 (4):\penalty0 1--10, 2023.

\bibitem[Chen and Wang(2024)]{chen2024proedit}
Jun-Kun Chen and Yu-Xiong Wang.
\newblock Proedit: Simple progression is all you need for high-quality 3d scene editing.
\newblock \emph{arXiv preprint arXiv:2411.05006}, 2024.

\bibitem[Chen et~al.(2024{\natexlab{a}})Chen, Bul{\`o}, M{\"u}ller, Porzi, Kontschieder, and Wang]{chen2024consistdreamer}
Jun-Kun Chen, Samuel~Rota Bul{\`o}, Norman M{\"u}ller, Lorenzo Porzi, Peter Kontschieder, and Yu-Xiong Wang.
\newblock Consistdreamer: 3d-consistent 2d diffusion for high-fidelity scene editing.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 21071--21080, 2024{\natexlab{a}}.

\bibitem[Chen et~al.(2024{\natexlab{b}})Chen, Laina, and Vedaldi]{chen2024dge}
Minghao Chen, Iro Laina, and Andrea Vedaldi.
\newblock Dge: Direct gaussian 3d editing by consistent multi-view editing.
\newblock \emph{arXiv preprint arXiv:2404.18929}, 2024{\natexlab{b}}.

\bibitem[Chen et~al.(2023)Chen, Chen, Jiao, and Jia]{chen2023fantasia3d}
Rui Chen, Yongwei Chen, Ningxin Jiao, and Kui Jia.
\newblock Fantasia3d: Disentangling geometry and appearance for high-quality text-to-3d content creation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 22246--22256, 2023.

\bibitem[Chen et~al.(2024{\natexlab{c}})Chen, Chen, Zhang, Wang, Yang, Wang, Cai, Yang, Liu, and Lin]{chen2024gaussianeditor}
Yiwen Chen, Zilong Chen, Chi Zhang, Feng Wang, Xiaofeng Yang, Yikai Wang, Zhongang Cai, Lei Yang, Huaping Liu, and Guosheng Lin.
\newblock Gaussianeditor: Swift and controllable 3d editing with gaussian splatting.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 21476--21485, 2024{\natexlab{c}}.

\bibitem[Dong and Wang(2024)]{dong2024vica}
Jiahua Dong and Yu-Xiong Wang.
\newblock Vica-nerf: View-consistency-aware 3d editing of neural radiance fields.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Haque et~al.(2023)Haque, Tancik, Efros, Holynski, and Kanazawa]{haque2023instruct}
Ayaan Haque, Matthew Tancik, Alexei~A Efros, Aleksander Holynski, and Angjoo Kanazawa.
\newblock Instruct-nerf2nerf: Editing 3d scenes with instructions.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 19740--19750, 2023.

\bibitem[Hertz et~al.(2022)Hertz, Mokady, Tenenbaum, Aberman, Pritch, and Cohen-Or]{hertz2022prompt}
Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, and Daniel Cohen-Or.
\newblock Prompt-to-prompt image editing with cross attention control.
\newblock \emph{arXiv preprint arXiv:2208.01626}, 2022.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and Hochreiter]{heusel2017gans}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash equilibrium.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 6840--6851, 2020.

\bibitem[Houlsby et~al.(2019)Houlsby, Giurgiu, Jastrzebski, Morrone, De~Laroussilhe, Gesmundo, Attariyan, and Gelly]{houlsby2019parameter}
Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De~Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly.
\newblock Parameter-efficient transfer learning for nlp.
\newblock In \emph{International conference on machine learning}, pages 2790--2799. PMLR, 2019.

\bibitem[Hu et~al.(2021)Hu, Shen, Wallis, Allen-Zhu, Li, Wang, Wang, and Chen]{hu2021lora}
Edward~J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen.
\newblock Lora: Low-rank adaptation of large language models.
\newblock \emph{arXiv preprint arXiv:2106.09685}, 2021.

\bibitem[Kawar et~al.(2023)Kawar, Zada, Lang, Tov, Chang, Dekel, Mosseri, and Irani]{kawar2023imagic}
Bahjat Kawar, Shiran Zada, Oran Lang, Omer Tov, Huiwen Chang, Tali Dekel, Inbar Mosseri, and Michal Irani.
\newblock Imagic: Text-based real image editing with diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 6007--6017, 2023.

\bibitem[Kerbl et~al.(2023)Kerbl, Kopanas, Leimk{\"u}hler, and Drettakis]{kerbl20233d}
Bernhard Kerbl, Georgios Kopanas, Thomas Leimk{\"u}hler, and George Drettakis.
\newblock 3d gaussian splatting for real-time radiance field rendering.
\newblock \emph{ACM Trans. Graph.}, 42\penalty0 (4):\penalty0 139--1, 2023.

\bibitem[Kumari et~al.(2023)Kumari, Zhang, Zhang, Shechtman, and Zhu]{kumari2023multi}
Nupur Kumari, Bingliang Zhang, Richard Zhang, Eli Shechtman, and Jun-Yan Zhu.
\newblock Multi-concept customization of text-to-image diffusion.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 1931--1941, 2023.

\bibitem[Li and Liang(2021)]{li2021prefix}
Xiang~Lisa Li and Percy Liang.
\newblock Prefix-tuning: Optimizing continuous prompts for generation.
\newblock \emph{arXiv preprint arXiv:2101.00190}, 2021.

\bibitem[Lin et~al.(2023)Lin, Gao, Tang, Takikawa, Zeng, Huang, Kreis, Fidler, Liu, and Lin]{lin2023magic3d}
Chen-Hsuan Lin, Jun Gao, Luming Tang, Towaki Takikawa, Xiaohui Zeng, Xun Huang, Karsten Kreis, Sanja Fidler, Ming-Yu Liu, and Tsung-Yi Lin.
\newblock Magic3d: High-resolution text-to-3d content creation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 300--309, 2023.

\bibitem[Liu et~al.(2024)Liu, Xu, Jin, Chen, Varma~T, Xu, and Su]{liu2024one}
Minghua Liu, Chao Xu, Haian Jin, Linghao Chen, Mukund Varma~T, Zexiang Xu, and Hao Su.
\newblock One-2-3-45: Any single image to 3d mesh in 45 seconds without per-shape optimization.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Liu et~al.(2023)Liu, Wu, Van~Hoorick, Tokmakov, Zakharov, and Vondrick]{liu2023zero}
Ruoshi Liu, Rundi Wu, Basile Van~Hoorick, Pavel Tokmakov, Sergey Zakharov, and Carl Vondrick.
\newblock Zero-1-to-3: Zero-shot one image to 3d object.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pages 9298--9309, 2023.

\bibitem[Liu et~al.(2021)Liu, Ji, Fu, Tam, Du, Yang, and Tang]{liu2021p}
Xiao Liu, Kaixuan Ji, Yicheng Fu, Weng~Lam Tam, Zhengxiao Du, Zhilin Yang, and Jie Tang.
\newblock P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks.
\newblock \emph{arXiv preprint arXiv:2110.07602}, 2021.

\bibitem[Meng et~al.(2021)Meng, He, Song, Song, Wu, Zhu, and Ermon]{meng2021sdedit}
Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and Stefano Ermon.
\newblock Sdedit: Guided image synthesis and editing with stochastic differential equations.
\newblock \emph{arXiv preprint arXiv:2108.01073}, 2021.

\bibitem[Metzer et~al.(2023)Metzer, Richardson, Patashnik, Giryes, and Cohen-Or]{metzer2023latent}
Gal Metzer, Elad Richardson, Or Patashnik, Raja Giryes, and Daniel Cohen-Or.
\newblock Latent-nerf for shape-guided generation of 3d shapes and textures.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 12663--12673, 2023.

\bibitem[Mildenhall et~al.(2021)Mildenhall, Srinivasan, Tancik, Barron, Ramamoorthi, and Ng]{mildenhall2021nerf}
Ben Mildenhall, Pratul~P Srinivasan, Matthew Tancik, Jonathan~T Barron, Ravi Ramamoorthi, and Ren Ng.
\newblock Nerf: Representing scenes as neural radiance fields for view synthesis.
\newblock \emph{Communications of the ACM}, 65\penalty0 (1):\penalty0 99--106, 2021.

\bibitem[Poole et~al.(2022)Poole, Jain, Barron, and Mildenhall]{poole2022dreamfusion}
Ben Poole, Ajay Jain, Jonathan~T Barron, and Ben Mildenhall.
\newblock Dreamfusion: Text-to-3d using 2d diffusion.
\newblock \emph{arXiv preprint arXiv:2209.14988}, 2022.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{International conference on machine learning}, pages 8748--8763. PMLR, 2021.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and Chen]{ramesh2022hierarchical}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock \emph{arXiv preprint arXiv:2204.06125}, 1\penalty0 (2):\penalty0 3, 2022.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 10684--10695, 2022.

\bibitem[Seitzer(2020)]{Seitzer2020FID}
Maximilian Seitzer.
\newblock {pytorch-fid: FID Score for PyTorch}.
\newblock \url{https://github.com/mseitzer/pytorch-fid}, 2020.
\newblock Version 0.3.0.

\bibitem[Shi et~al.(2023)Shi, Wang, Ye, Long, Li, and Yang]{shi2023mvdream}
Yichun Shi, Peng Wang, Jianglong Ye, Mai Long, Kejie Li, and Xiao Yang.
\newblock Mvdream: Multi-view diffusion for 3d generation.
\newblock \emph{arXiv preprint arXiv:2308.16512}, 2023.

\bibitem[Srivastava et~al.(2025)Srivastava, Zhang, Wen, Wen, and Tu]{srivastava2025lay}
Divyansh Srivastava, Xiang Zhang, He Wen, Chenru Wen, and Zhuowen Tu.
\newblock Lay-your-scene: Natural scene layout generation with diffusion transformers.
\newblock \emph{arXiv preprint arXiv:2505.04718}, 2025.

\bibitem[Wang et~al.(2024)Wang, Lu, Wang, Bao, Li, Su, and Zhu]{wang2024prolificdreamer}
Zhengyi Wang, Cheng Lu, Yikai Wang, Fan Bao, Chongxuan Li, Hang Su, and Jun Zhu.
\newblock Prolificdreamer: High-fidelity and diverse text-to-3d generation with variational score distillation.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Xu et~al.(2024)Xu, Lei, Chen, Zhang, Zhao, Wang, and Tu]{xu2024bayesian}
Haiyang Xu, Yu Lei, Zeyuan Chen, Xiang Zhang, Yue Zhao, Yilin Wang, and Zhuowen Tu.
\newblock Bayesian diffusion models for 3d shape reconstruction.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 10628--10638, 2024.

\bibitem[Xu et~al.(2023)Xu, Guo, Wang, Huang, Essa, and Shi]{xu2023prompt}
Xingqian Xu, Jiayi Guo, Zhangyang Wang, Gao Huang, Irfan Essa, and Humphrey Shi.
\newblock Prompt-free diffusion: Taking" text" out of text-to-image diffusion models.
\newblock \emph{arXiv preprint arXiv:2305.16223}, 2023.

\bibitem[Zeng et~al.(2025)Zeng, Zhang, Wang, Xu, Chen, Li, and Tu]{zeng2025yolo}
Guanning Zeng, Xiang Zhang, Zirui Wang, Haiyang Xu, Zeyuan Chen, Bingnan Li, and Zhuowen Tu.
\newblock Yolo-count: Differentiable object counting for text-to-image generation.
\newblock \emph{arXiv preprint arXiv:2508.00728}, 2025.

\bibitem[Zhang et~al.(2023{\natexlab{a}})Zhang, Rao, and Agrawala]{zhang2023adding}
Lvmin Zhang, Anyi Rao, and Maneesh Agrawala.
\newblock Adding conditional control to text-to-image diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 3836--3847, 2023{\natexlab{a}}.

\bibitem[Zhang et~al.(2023{\natexlab{b}})Zhang, Chen, Wei, and Tu]{zhang2023uni}
Xiang Zhang, Zeyuan Chen, Fangyin Wei, and Zhuowen Tu.
\newblock Uni-3d: A universal model for panoptic 3d scene reconstruction.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 9256--9266, 2023{\natexlab{b}}.

\bibitem[Zhang et~al.(2024)Zhang, Yang, Cai, Yu, Xie, Tian, Xu, Tang, Yang, and Cui]{zhang2024realcompo}
Xinchen Zhang, Ling Yang, Yaqi Cai, Zhaochen Yu, Jiake Xie, Ye Tian, Minkai Xu, Yong Tang, Yujiu Yang, and Bin Cui.
\newblock Realcompo: Dynamic equilibrium between realism and compositionality improves text-to-image diffusion models.
\newblock \emph{arXiv preprint arXiv:2402.12908}, 2024.

\bibitem[Zhao et~al.(2025)Zhao, Zhang, Xu, Chen, Xie, Gao, and Tu]{zhao2025deprdepthguidedsingleview}
Qingcheng Zhao, Xiang Zhang, Haiyang Xu, Zeyuan Chen, Jianwen Xie, Yuan Gao, and Zhuowen Tu.
\newblock Depr: Depth guided single-view scene reconstruction with instance-level diffusion, 2025.

\bibitem[Zhengwentai(2023)]{taited2023CLIPScore}
SUN Zhengwentai.
\newblock {clip-score: CLIP Score for PyTorch}.
\newblock \url{https://github.com/taited/clip-score}, 2023.
\newblock Version 0.1.1.

\end{thebibliography}
