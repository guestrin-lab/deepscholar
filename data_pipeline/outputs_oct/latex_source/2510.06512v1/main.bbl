\begin{thebibliography}{46}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Akazaki \& Hasuo(2015)Akazaki and Hasuo]{Akazaki2015TimeRI}
Takumi Akazaki and Ichiro Hasuo.
\newblock Time robustness in mtl and expressivity in hybrid system falsification.
\newblock In \emph{International Conference on Computer Aided Verification}, 2015.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:14307127}.

\bibitem[Anderson et~al.(2023)Anderson, Fainekos, Hoxha, Okamoto, and Prokhorov]{strem}
Jacob Anderson, Georgios Fainekos, Bardh Hoxha, Hideki Okamoto, and Danil Prokhorov.
\newblock Pattern matching for perception streams.
\newblock In \emph{International Conference on Runtime Verification}, pp.\  251--270. Springer, 2023.

\bibitem[Anne~Hendricks et~al.(2017)Anne~Hendricks, Wang, Shechtman, Sivic, Darrell, and Russell]{didemo}
Lisa Anne~Hendricks, Oliver Wang, Eli Shechtman, Josef Sivic, Trevor Darrell, and Bryan Russell.
\newblock Localizing moments in video with natural language.
\newblock In \emph{Proceedings of the IEEE international conference on computer vision}, pp.\  5803--5812, 2017.

\bibitem[Bain et~al.(2021)Bain, Nagrani, Varol, and Zisserman]{Bain21}
Max Bain, Arsha Nagrani, G{\"u}l Varol, and Andrew Zisserman.
\newblock Frozen in time: A joint video and image encoder for end-to-end retrieval.
\newblock In \emph{IEEE International Conference on Computer Vision}, 2021.

\bibitem[Busso et~al.(2008)Busso, Bulut, Lee, Kazemzadeh, Mower, Kim, Chang, Lee, and Narayanan]{busso2008iemocap}
Carlos Busso, Murtaza Bulut, Chi-Chun Lee, Abe Kazemzadeh, Emily Mower, Samuel Kim, Jeannette~N Chang, Sungbok Lee, and Shrikanth~S Narayanan.
\newblock Iemocap: Interactive emotional dyadic motion capture database.
\newblock \emph{Language resources and evaluation}, 42:\penalty0 335--359, 2008.

\bibitem[Caesar et~al.(2020)Caesar, Bankiti, Lang, Vora, Liong, Xu, Krishnan, Pan, Baldan, and Beijbom]{nuscenes}
Holger Caesar, Varun Bankiti, Alex~H. Lang, Sourabh Vora, Venice~Erin Liong, Qiang Xu, Anush Krishnan, Yu~Pan, Giancarlo Baldan, and Oscar Beijbom.
\newblock nuscenes: A multimodal dataset for autonomous driving.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, June 2020.

\bibitem[Cai et~al.(2024)Cai, Tan, Zhang, Zou, Zhang, Yao, Zhu, Gu, Zhong, Shang, et~al.]{cai2024temporalbench}
Mu~Cai, Reuben Tan, Jianrui Zhang, Bocheng Zou, Kai Zhang, Feng Yao, Fangrui Zhu, Jing Gu, Yiwu Zhong, Yuzhang Shang, et~al.
\newblock Temporalbench: Benchmarking fine-grained temporal understanding for multimodal video models.
\newblock \emph{arXiv preprint arXiv:2410.10818}, 2024.

\bibitem[Chen et~al.(2024)Chen, Liao, Lin, Yu, Chen, and Wang]{chen2024rextime}
Jr-Jen Chen, Yu-Chien Liao, Hsi-Che Lin, Yu-Chu Yu, Yen-Chun Chen, and Frank Wang.
\newblock Rextime: A benchmark suite for reasoning-across-time in videos.
\newblock \emph{Advances in Neural Information Processing Systems}, 37:\penalty0 28662--28673, 2024.

\bibitem[Choi et~al.(2024)Choi, Goel, Omama, Yang, Shah, and Chinchali]{Choi2024TowardsNV}
Minkyu Choi, Harsh Goel, Mohammad Omama, Yunhao Yang, Sahil Shah, and Sandeep Chinchali.
\newblock Towards neuro-symbolic video understanding.
\newblock In \emph{European Conference on Computer Vision}, 2024.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:268513042}.

\bibitem[Chu et~al.(2023)Chu, Xu, Zhou, Yang, Zhang, Yan, Zhou, and Zhou]{Qwen-Audio}
Yunfei Chu, Jin Xu, Xiaohuan Zhou, Qian Yang, Shiliang Zhang, Zhijie Yan, Chang Zhou, and Jingren Zhou.
\newblock Qwen-audio: Advancing universal audio understanding via unified large-scale audio-language models.
\newblock \emph{arXiv preprint arXiv:2311.07919}, 2023.

\bibitem[Chu et~al.(2024)Chu, Xu, Yang, Wei, Wei, Guo, Leng, Lv, He, Lin, Zhou, and Zhou]{Qwen2-Audio}
Yunfei Chu, Jin Xu, Qian Yang, Haojie Wei, Xipin Wei, Zhifang Guo, Yichong Leng, Yuanjun Lv, Jinzheng He, Junyang Lin, Chang Zhou, and Jingren Zhou.
\newblock Qwen2-audio technical report.
\newblock \emph{arXiv preprint arXiv:2407.10759}, 2024.

\bibitem[De~Giacomo \& Vardi(2013)De~Giacomo and Vardi]{ltlf}
Giuseppe De~Giacomo and Moshe~Y. Vardi.
\newblock Linear temporal logic and linear dynamic logic on finite traces.
\newblock In \emph{Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence}, IJCAI '13, pp.\  854â€“860. AAAI Press, 2013.
\newblock ISBN 9781577356332.

\bibitem[Donz{\'e} \& Maler(2010)Donz{\'e} and Maler]{donze2010robust}
Alexandre Donz{\'e} and Oded Maler.
\newblock Robust satisfaction of temporal logic over real-valued signals.
\newblock In \emph{International Conference on Formal Modeling and Analysis of Timed Systems}, pp.\  92--106. Springer, 2010.

\bibitem[Fainekos \& Pappas(2009)Fainekos and Pappas]{FAINEKOS20094262}
Georgios~E. Fainekos and George~J. Pappas.
\newblock Robustness of temporal logic specifications for continuous-time signals.
\newblock \emph{Theoretical Computer Science}, 410\penalty0 (42):\penalty0 4262--4291, 2009.
\newblock ISSN 0304-3975.
\newblock \doi{https://doi.org/10.1016/j.tcs.2009.06.021}.
\newblock URL \url{https://www.sciencedirect.com/science/article/pii/S0304397509004149}.

\bibitem[Fainekos et~al.(2012)Fainekos, Sankaranarayanan, Ueda, and Yazarel]{fainekos2012verification}
Georgios~E Fainekos, Sriram Sankaranarayanan, Koichi Ueda, and Hakan Yazarel.
\newblock Verification of automotive control applications using s-taliro.
\newblock In \emph{2012 American Control Conference (ACC)}, pp.\  3567--3572. IEEE, 2012.

\bibitem[Feichtenhofer et~al.(2019)Feichtenhofer, Fan, Malik, and He]{feichtenhofer2019slowfast}
Christoph Feichtenhofer, Haoqi Fan, Jitendra Malik, and Kaiming He.
\newblock Slowfast networks for video recognition.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pp.\  6202--6211, 2019.

\bibitem[Fu et~al.(2024)Fu, Dai, Luo, Li, Ren, Zhang, Wang, Zhou, Shen, Zhang, et~al.]{videomme}
Chaoyou Fu, Yuhan Dai, Yongdong Luo, Lei Li, Shuhuai Ren, Renrui Zhang, Zihan Wang, Chenyu Zhou, Yunhang Shen, Mengdan Zhang, et~al.
\newblock Video-mme: The first-ever comprehensive evaluation benchmark of multi-modal llms in video analysis.
\newblock \emph{arXiv preprint arXiv:2405.21075}, 2024.

\bibitem[Ghosh et~al.(2023)Ghosh, Seth, Kumar, Tyagi, Evuru, Ramaneswaran, Sakshi, Nieto, Duraiswami, and Manocha]{ghosh2023compa}
Sreyan Ghosh, Ashish Seth, Sonal Kumar, Utkarsh Tyagi, Chandra~Kiran Evuru, S~Ramaneswaran, S~Sakshi, Oriol Nieto, Ramani Duraiswami, and Dinesh Manocha.
\newblock Compa: Addressing the gap in compositional reasoning in audio-language models.
\newblock \emph{arXiv preprint arXiv:2310.08753}, 2023.

\bibitem[Gu et~al.(2018)Gu, Sun, Ross, Vondrick, Pantofaru, Li, Vijayanarasimhan, Toderici, Ricco, Sukthankar, et~al.]{gu2018ava}
Chunhui Gu, Chen Sun, David~A Ross, Carl Vondrick, Caroline Pantofaru, Yeqing Li, Sudheendra Vijayanarasimhan, George Toderici, Susanna Ricco, Rahul Sukthankar, et~al.
\newblock Ava: A video dataset of spatio-temporally localized atomic visual actions.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.\  6047--6056, 2018.

\bibitem[Hensel et~al.(2022)Hensel, Junges, Katoen, Quatmann, and Volk]{storm}
Christian Hensel, Sebastian Junges, Joost-Pieter Katoen, Tim Quatmann, and Matthias Volk.
\newblock The probabilistic model checker storm.
\newblock \emph{International Journal on Software Tools for Technology Transfer}, pp.\  1--22, 2022.

\bibitem[Hsu et~al.(2021)Hsu, Bolte, Tsai, Lakhotia, Salakhutdinov, and Mohamed]{hsu2021hubert}
Wei-Ning Hsu, Benjamin Bolte, Yao-Hung~Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, and Abdelrahman Mohamed.
\newblock Hubert: Self-supervised speech representation learning by masked prediction of hidden units.
\newblock \emph{IEEE/ACM transactions on audio, speech, and language processing}, 29:\penalty0 3451--3460, 2021.

\bibitem[Huang et~al.(2023)Huang, Li, Naik, and Lim]{huang2023laser}
Jiani Huang, Ziyang Li, Mayur Naik, and Ser-Nam Lim.
\newblock Laser: A neuro-symbolic framework for learning spatial-temporal scene graphs with weak supervision.
\newblock \emph{arXiv preprint arXiv:2304.07647}, 2023.

\bibitem[Jocher et~al.(2023)Jocher, Chaurasia, and Qiu]{yolov8_ultralytics}
Glenn Jocher, Ayush Chaurasia, and Jing Qiu.
\newblock Ultralytics yolov8, 2023.
\newblock URL \url{https://github.com/ultralytics/ultralytics}.

\bibitem[Krishna et~al.(2017)Krishna, Hata, Ren, Fei-Fei, and Niebles]{krishna2017dense}
Ranjay Krishna, Kenji Hata, Frederic Ren, Li~Fei-Fei, and Juan~Carlos Niebles.
\newblock Dense-captioning events in videos.
\newblock In \emph{International Conference on Computer Vision (ICCV)}, 2017.

\bibitem[Lei et~al.(2021)Lei, Berg, and Bansal]{qvhighlights}
Jie Lei, Tamara~L Berg, and Mohit Bansal.
\newblock Detecting moments and highlights in videos via natural language queries.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 11846--11858, 2021.

\bibitem[Li et~al.(2022)Li, Xu, Tian, Wang, Yan, Bi, Ye, Chen, Xu, Cao, et~al.]{li2022mplug}
Chenliang Li, Haiyang Xu, Junfeng Tian, Wei Wang, Ming Yan, Bin Bi, Jiabo Ye, Hehong Chen, Guohai Xu, Zheng Cao, et~al.
\newblock mplug: Effective and efficient vision-language learning by cross-modal skip-connections.
\newblock \emph{arXiv preprint arXiv:2205.12005}, 2022.

\bibitem[Lin et~al.(2023)Lin, Ye, Zhu, Cui, Ning, Jin, and Yuan]{videollava}
Bin Lin, Yang Ye, Bin Zhu, Jiaxi Cui, Munan Ning, Peng Jin, and Li~Yuan.
\newblock Video-llava: Learning united visual representation by alignment before projection.
\newblock \emph{arXiv preprint arXiv:2311.10122}, 2023.

\bibitem[Liu et~al.(2024{\natexlab{a}})Liu, Zeng, Ren, Li, Zhang, Yang, Jiang, Li, Yang, Su, et~al.]{liu2024grounding}
Shilong Liu, Zhaoyang Zeng, Tianhe Ren, Feng Li, Hao Zhang, Jie Yang, Qing Jiang, Chunyuan Li, Jianwei Yang, Hang Su, et~al.
\newblock Grounding dino: Marrying dino with grounded pre-training for open-set object detection.
\newblock In \emph{European conference on computer vision}, pp.\  38--55. Springer, 2024{\natexlab{a}}.

\bibitem[Liu et~al.(2025)Liu, Wang, and Zhao]{liu-etal-2025-eliot}
Xuye Liu, Yimu Wang, and Jian Zhao.
\newblock {ELIOT}: Zero-shot video-text retrieval through relevance-boosted captioning and structural information extraction.
\newblock In Abteen Ebrahimi, Samar Haider, Emmy Liu, Sammar Haider, Maria Leonor~Pacheco, and Shira Wein (eds.), \emph{Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 4: Student Research Workshop)}, pp.\  381--391, Albuquerque, USA, April 2025. Association for Computational Linguistics.
\newblock ISBN 979-8-89176-192-6.
\newblock \doi{10.18653/v1/2025.naacl-srw.37}.
\newblock URL \url{https://aclanthology.org/2025.naacl-srw.37/}.

\bibitem[Liu et~al.(2024{\natexlab{b}})Liu, Li, Liu, Wang, Ren, Li, Chen, Sun, and Hou]{liu2024tempcompass}
Yuanxin Liu, Shicheng Li, Yi~Liu, Yuxiang Wang, Shuhuai Ren, Lei Li, Sishuo Chen, Xu~Sun, and Lu~Hou.
\newblock Tempcompass: Do video llms really understand videos?
\newblock \emph{arXiv preprint arXiv:2403.00476}, 2024{\natexlab{b}}.

\bibitem[Liu et~al.(2022)Liu, Xiong, Xu, Cao, and Jin]{liu2022ts2}
Yuqi Liu, Pengfei Xiong, Luhui Xu, Shengming Cao, and Qin Jin.
\newblock Ts2-net: Token shift and selection transformer for text-video retrieval.
\newblock In \emph{European conference on computer vision}, pp.\  319--335. Springer, 2022.

\bibitem[Luo et~al.(2021)Luo, Ji, Zhong, Chen, Lei, Duan, and Li]{luo2021clip4clip}
Huaishao Luo, Lei Ji, Ming Zhong, Yang Chen, Wen Lei, Nan Duan, and Tianrui Li.
\newblock Clip4clip: An empirical study of clip for end to end video clip retrieval.
\newblock \emph{arXiv preprint arXiv:2104.08860}, 2021.

\bibitem[Mehdipour et~al.(2024)Mehdipour, Vasile, and Belta]{gmrob}
Noushin Mehdipour, Cristian-Ioan Vasile, and Calin Belta.
\newblock Generalized mean robustness for signal temporal logic.
\newblock \emph{IEEE Transactions on Automatic Control}, pp.\  1--8, 2024.
\newblock \doi{10.1109/TAC.2024.3482104}.

\bibitem[Minderer et~al.(2023)Minderer, Gritsenko, and Houlsby]{minderer2023scaling}
Matthias Minderer, Alexey Gritsenko, and Neil Houlsby.
\newblock Scaling open-vocabulary object detection.
\newblock \emph{Advances in Neural Information Processing Systems}, 36:\penalty0 72983--73007, 2023.

\bibitem[Pnueli(1977)]{ltl}
Amir Pnueli.
\newblock The temporal logic of programs.
\newblock In \emph{18th annual symposium on foundations of computer science (sfcs 1977)}, pp.\  46--57. ieee, 1977.

\bibitem[Redmon et~al.(2016)Redmon, Divvala, Girshick, and Farhadi]{yolo}
Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi.
\newblock You only look once: Unified, real-time object detection.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.\  779--788, 2016.

\bibitem[Reimers \& Gurevych(2020)Reimers and Gurevych]{reimers-2020-multilingual-sentence-bert}
Nils Reimers and Iryna Gurevych.
\newblock Making monolingual sentence embeddings multilingual using knowledge distillation.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing}. Association for Computational Linguistics, 11 2020.
\newblock URL \url{https://arxiv.org/abs/2004.09813}.

\bibitem[Sakshi et~al.(2024)Sakshi, Tyagi, Kumar, Seth, Selvakumar, Nieto, Duraiswami, Ghosh, and Manocha]{sakshi2024mmau}
S~Sakshi, Utkarsh Tyagi, Sonal Kumar, Ashish Seth, Ramaneswaran Selvakumar, Oriol Nieto, Ramani Duraiswami, Sreyan Ghosh, and Dinesh Manocha.
\newblock Mmau: A massive multi-task audio understanding and reasoning benchmark.
\newblock \emph{arXiv preprint arXiv:2410.19168}, 2024.

\bibitem[Sun et~al.(2020)Sun, Kretzschmar, Dotiwalla, Chouard, Patnaik, Tsui, Guo, Zhou, Chai, Caine, Vasudevan, Han, Ngiam, Zhao, Timofeev, Ettinger, Krivokon, Gao, Joshi, Zhang, Shlens, Chen, and Anguelov]{waymo}
Pei Sun, Henrik Kretzschmar, Xerxes Dotiwalla, Aurelien Chouard, Vijaysai Patnaik, Paul Tsui, James Guo, Yin Zhou, Yuning Chai, Benjamin Caine, Vijay Vasudevan, Wei Han, Jiquan Ngiam, Hang Zhao, Aleksei Timofeev, Scott Ettinger, Maxim Krivokon, Amy Gao, Aditya Joshi, Yu~Zhang, Jonathon Shlens, Zhifeng Chen, and Dragomir Anguelov.
\newblock Scalability in perception for autonomous driving: Waymo open dataset.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, June 2020.

\bibitem[Tewel et~al.(2022)Tewel, Shalev, Nadler, Schwartz, and Wolf]{tewel2022zero}
Yoad Tewel, Yoav Shalev, Roy Nadler, Idan Schwartz, and Lior Wolf.
\newblock Zero-shot video captioning with evolving pseudo-tokens.
\newblock \emph{arXiv preprint arXiv:2207.11100}, 2022.

\bibitem[wen Yang et~al.(2021)wen Yang, Chi, Chuang, Lai, Lakhotia, Lin, Liu, Shi, Chang, Lin, Huang, Tseng, tik Lee, Liu, Huang, Dong, Li, Watanabe, Mohamed, and yi~Lee]{superb}
Shu wen Yang, Po-Han Chi, Yung-Sung Chuang, Cheng-I~Jeff Lai, Kushal Lakhotia, Yist~Y. Lin, Andy~T. Liu, Jiatong Shi, Xuankai Chang, Guan-Ting Lin, Tzu-Hsien Huang, Wei-Cheng Tseng, Ko~tik Lee, Da-Rong Liu, Zili Huang, Shuyan Dong, Shang-Wen Li, Shinji Watanabe, Abdelrahman Mohamed, and Hung yi~Lee.
\newblock {SUPERB: Speech Processing Universal PERformance Benchmark}.
\newblock In \emph{Proc. Interspeech 2021}, pp.\  1194--1198, 2021.
\newblock \doi{10.21437/Interspeech.2021-1775}.

\bibitem[Wu et~al.(2019)Wu, Kirillov, Massa, Lo, and Girshick]{wu2019detectron2}
Yuxin Wu, Alexander Kirillov, Francisco Massa, Wan-Yen Lo, and Ross Girshick.
\newblock Detectron2.
\newblock \url{https://github.com/facebookresearch/detectron2}, 2019.

\bibitem[Xiao et~al.(2021)Xiao, Shang, Yao, and Chua]{nextqa}
Junbin Xiao, Xindi Shang, Angela Yao, and Tat-Seng Chua.
\newblock Next-qa: Next phase of question-answering to explaining temporal actions.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  9777--9786, 2021.

\bibitem[Yang et~al.(2023)Yang, Gaglione, Chinchali, and Topcu]{yang2023specification}
Yunhao Yang, Jean-Rapha{\"e}l Gaglione, Sandeep Chinchali, and Ufuk Topcu.
\newblock Specification-driven video search via foundation models and formal verification.
\newblock \emph{arXiv preprint arXiv:2309.10171}, 2023.

\bibitem[Zhang et~al.(2024{\natexlab{a}})Zhang, Zhang, Li, Zeng, Yang, Zhang, Wang, Tan, Li, and Liu]{zhang2024longva}
Peiyuan Zhang, Kaichen Zhang, Bo~Li, Guangtao Zeng, Jingkang Yang, Yuanhan Zhang, Ziyue Wang, Haoran Tan, Chunyuan Li, and Ziwei Liu.
\newblock Long context transfer from language to vision.
\newblock \emph{arXiv preprint arXiv:2406.16852}, 2024{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2406.16852}.

\bibitem[Zhang et~al.(2024{\natexlab{b}})Zhang, Li, Liu, Lee, Gui, Fu, Feng, Liu, and Li]{zhang2024llavanextvideo}
Yuanhan Zhang, Bo~Li, haotian Liu, Yong~jae Lee, Liangke Gui, Di~Fu, Jiashi Feng, Ziwei Liu, and Chunyuan Li.
\newblock Llava-next: A strong zero-shot video understanding model, April 2024{\natexlab{b}}.
\newblock URL \url{https://llava-vl.github.io/blog/2024-04-30-llava-next-video/}.

\end{thebibliography}
