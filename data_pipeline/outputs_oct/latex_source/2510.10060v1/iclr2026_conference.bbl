\begin{thebibliography}{30}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert{-}Voss, Krueger, Henighan, Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess, Clark, Berner, McCandlish, Radford, Sutskever, and Amodei]{DBLP:conf/nips/BrownMRSKDNSSAA20}
Tom~B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert{-}Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel~M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei.
\newblock Language models are few-shot learners.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2020.

\bibitem[Dai et~al.(2019)Dai, Yang, Yang, Carbonell, Le, and Salakhutdinov]{DBLP:conf/acl/DaiYYCLS19}
Zihang Dai, Zhilin Yang, Yiming Yang, Jaime~G. Carbonell, Quoc~Viet Le, and Ruslan Salakhutdinov.
\newblock Transformer-xl: Attentive language models beyond a fixed-length context.
\newblock In \emph{Conference of the Association for Computational Linguistics (ACL)}, pp.\  2978--2988, 2019.

\bibitem[Dai et~al.(2021)Dai, Liu, Le, and Tan]{DBLP:conf/nips/DaiLLT21}
Zihang Dai, Hanxiao Liu, Quoc~V. Le, and Mingxing Tan.
\newblock Coatnet: Marrying convolution and attention for all data sizes.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, pp.\  3965--3977, 2021.

\bibitem[d'Ascoli et~al.(2021)d'Ascoli, Touvron, Leavitt, Morcos, Biroli, and Sagun]{DBLP:conf/icml/dAscoliTLMBS21}
St{\'{e}}phane d'Ascoli, Hugo Touvron, Matthew~L. Leavitt, Ari~S. Morcos, Giulio Biroli, and Levent Sagun.
\newblock Convit: Improving vision transformers with soft convolutional inductive biases.
\newblock In \emph{International Conference on Machine Learning (ICML)}, volume 139 of \emph{Proceedings of Machine Learning Research}, pp.\  2286--2296, 2021.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei{-}Fei]{DBLP:conf/cvpr/DengDSLL009}
Jia Deng, Wei Dong, Richard Socher, Li{-}Jia Li, Kai Li, and Li~Fei{-}Fei.
\newblock Imagenet: {A} large-scale hierarchical image database.
\newblock In \emph{{IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)}, pp.\  248--255, 2009.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{DBLP:conf/naacl/DevlinCLT19}
Jacob Devlin, Ming{-}Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT:} pre-training of deep bidirectional transformers for language understanding.
\newblock In \emph{Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)}, pp.\  4171--4186, 2019.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and Houlsby]{DBLP:conf/iclr/DosovitskiyB0WZ21}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2021.

\bibitem[Fan \& Yang(2019)Fan and Yang]{DBLP:journals/corr/abs-1910-08287}
Hehe Fan and Yi~Yang.
\newblock Pointrnn: Point recurrent neural network for moving point cloud processing.
\newblock \emph{arXiv}, 1910.08287, 2019.

\bibitem[Gao et~al.(2020)Gao, Biderman, Black, Golding, Hoppe, Foster, Phang, He, Thite, Nabeshima, Presser, and Leahy]{pile}
Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy.
\newblock The {P}ile: An 800gb dataset of diverse text for language modeling.
\newblock \emph{arXiv}, 2101.00027, 2020.

\bibitem[Gulati et~al.(2020)Gulati, Qin, Chiu, Parmar, Zhang, Yu, Han, Wang, Zhang, Wu, and Pang]{DBLP:conf/interspeech/GulatiQCPZYHWZW20}
Anmol Gulati, James Qin, Chung{-}Cheng Chiu, Niki Parmar, Yu~Zhang, Jiahui Yu, Wei Han, Shibo Wang, Zhengdong Zhang, Yonghui Wu, and Ruoming Pang.
\newblock Conformer: Convolution-augmented transformer for speech recognition.
\newblock In \emph{Interspeech}, pp.\  5036--5040, 2020.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{DBLP:conf/cvpr/HeZRS16}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{{IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)}, pp.\  770--778, 2016.

\bibitem[Huang et~al.(2019)Huang, Vaswani, Uszkoreit, Simon, Hawthorne, Shazeer, Dai, Hoffman, Dinculescu, and Eck]{DBLP:conf/iclr/HuangVUSHSDHDE19}
Cheng{-}Zhi~Anna Huang, Ashish Vaswani, Jakob Uszkoreit, Ian Simon, Curtis Hawthorne, Noam Shazeer, Andrew~M. Dai, Matthew~D. Hoffman, Monica Dinculescu, and Douglas Eck.
\newblock Music transformer: Generating music with long-term structure.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2019.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and Hinton]{DBLP:conf/nips/KrizhevskySH12}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E. Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, pp.\  1106--1114, 2012.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and Haffner]{DBLP:journals/pieee/LeCunBBH98}
Yann LeCun, L{\'{e}}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proc. {IEEE}}, 86\penalty0 (11):\penalty0 2278--2324, 1998.
\newblock \doi{10.1109/5.726791}.

\bibitem[Liu et~al.(2021)Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and Guo]{DBLP:conf/iccv/LiuL00W0LG21}
Ze~Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted windows.
\newblock In \emph{{IEEE} International Conference on Computer Vision (ICCV)}, pp.\  9992--10002, 2021.

\bibitem[Parmar et~al.(2019)Parmar, Ramachandran, Vaswani, Bello, Levskaya, and Shlens]{DBLP:conf/nips/ParmarRVBLS19}
Niki Parmar, Prajit Ramachandran, Ashish Vaswani, Irwan Bello, Anselm Levskaya, and Jonathon Shlens.
\newblock Stand-alone self-attention in vision models.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, pp.\  68--80, 2019.

\bibitem[Radford et~al.(2018)Radford, Narasimhan, Salimans, and Sutskever]{radford2018improving}
Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever.
\newblock Improving language understanding by generative pre-training.
\newblock Technical report, OpenAI, 2018.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, Sutskever, et~al.]{radford2019language}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et~al.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI blog}, 1\penalty0 (8):\penalty0 9, 2019.

\bibitem[Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena, Zhou, Li, and Liu]{DBLP:journals/jmlr/RaffelSRLNMZLL20}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter~J. Liu.
\newblock Exploring the limits of transfer learning with a unified text-to-text transformer.
\newblock \emph{J. Mach. Learn. Res.}, 21:\penalty0 140:1--140:67, 2020.

\bibitem[Shaw et~al.(2018)Shaw, Uszkoreit, and Vaswani]{DBLP:conf/naacl/ShawUV18}
Peter Shaw, Jakob Uszkoreit, and Ashish Vaswani.
\newblock Self-attention with relative position representations.
\newblock In Marilyn~A. Walker, Heng Ji, and Amanda Stent (eds.), \emph{Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)}, pp.\  464--468, 2018.

\bibitem[Simonyan \& Zisserman(2015)Simonyan and Zisserman]{DBLP:journals/corr/SimonyanZ14a}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2015.

\bibitem[Srinivas et~al.(2021)Srinivas, Lin, Parmar, Shlens, Abbeel, and Vaswani]{DBLP:conf/cvpr/SrinivasLPSAV21}
Aravind Srinivas, Tsung{-}Yi Lin, Niki Parmar, Jonathon Shlens, Pieter Abbeel, and Ashish Vaswani.
\newblock Bottleneck transformers for visual recognition.
\newblock In \emph{{IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)}, pp.\  16519--16529, 2021.

\bibitem[Srivastava et~al.(2015)Srivastava, Mansimov, and Salakhutdinov]{DBLP:conf/icml/SrivastavaMS15}
Nitish Srivastava, Elman Mansimov, and Ruslan Salakhutdinov.
\newblock Unsupervised learning of video representations using lstms.
\newblock In \emph{International Conference on Machine Learning (ICML)}, volume~37, pp.\  843--852, 2015.

\bibitem[Su et~al.(2024)Su, Ahmed, Lu, Pan, Bo, and Liu]{DBLP:journals/ijon/SuALPBL24}
Jianlin Su, Murtadha H.~M. Ahmed, Yu~Lu, Shengfeng Pan, Wen Bo, and Yunfeng Liu.
\newblock Roformer: Enhanced transformer with rotary position embedding.
\newblock \emph{Neurocomputing}, 568:\penalty0 127063, 2024.
\newblock \doi{10.1016/J.NEUCOM.2023.127063}.

\bibitem[Szegedy et~al.(2015)Szegedy, Liu, Jia, Sermanet, Reed, Anguelov, Erhan, Vanhoucke, and Rabinovich]{DBLP:conf/cvpr/SzegedyLJSRAEVR15}
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott~E. Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich.
\newblock Going deeper with convolutions.
\newblock In \emph{{IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)}, pp.\  1--9, 2015.

\bibitem[Touvron et~al.(2021)Touvron, Cord, Douze, Massa, Sablayrolles, and J{\'{e}}gou]{DBLP:conf/icml/TouvronCDMSJ21}
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, and Herv{\'{e}} J{\'{e}}gou.
\newblock Training data-efficient image transformers {\&} distillation through attention.
\newblock In \emph{International Conference on Machine Learning (ICML)}, volume 139, pp.\  10347--10357, 2021.

\bibitem[Tsai et~al.(2019)Tsai, Bai, Yamada, Morency, and Salakhutdinov]{DBLP:conf/emnlp/TsaiBYMS19}
Yao{-}Hung~Hubert Tsai, Shaojie Bai, Makoto Yamada, Louis{-}Philippe Morency, and Ruslan Salakhutdinov.
\newblock Transformer dissection: An unified understanding for transformer's attention via the lens of kernel.
\newblock In \emph{Conference on Empirical Methods in Natural Language Processing (EMNLP)}, pp.\  4343--4352, 2019.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{DBLP:conf/nips/VaswaniSPUJGKP17}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N. Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, pp.\  5998--6008, 2017.

\bibitem[Vaswani et~al.(2021)Vaswani, Ramachandran, Srinivas, Parmar, Hechtman, and Shlens]{DBLP:conf/cvpr/VaswaniRSPHS21}
Ashish Vaswani, Prajit Ramachandran, Aravind Srinivas, Niki Parmar, Blake~A. Hechtman, and Jonathon Shlens.
\newblock Scaling local self-attention for parameter efficient visual backbones.
\newblock In \emph{{IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)}, pp.\  12894--12904, 2021.

\bibitem[Yuan et~al.(2021)Yuan, Guo, Liu, Zhou, Yu, and Wu]{DBLP:conf/iccv/YuanG0ZYW21}
Kun Yuan, Shaopeng Guo, Ziwei Liu, Aojun Zhou, Fengwei Yu, and Wei Wu.
\newblock Incorporating convolution designs into visual transformers.
\newblock In \emph{{IEEE} International Conference on Computer Vision (ICCV)}, pp.\  559--568, 2021.

\end{thebibliography}
