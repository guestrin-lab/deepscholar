% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{Idrissi2022AROA}
M.~Idrissi, M.~Salami, and F.~Annaz, ``A review of quadrotor unmanned aerial
  vehicles: applications, architectural design and control algorithms,''
  \emph{Journal of Intelligent \& Robotic Systems}, vol. 104, no.~2, p.~22,
  2022.

\bibitem{Lyu2023UnmannedAVA}
M.~Lyu, Y.~Zhao, C.~Huang, and H.~Huang, ``Unmanned aerial vehicles for search
  and rescue: A survey,'' \emph{Remote Sensing}, vol.~15, no.~13, p. 3266,
  2023.

\bibitem{batra_decentralized_2022}
S.~Batra, Z.~Huang, A.~Petrenko, T.~Kumar, A.~Molchanov, and G.~S. Sukhatme,
  ``Decentralized control of quadrotor swarms with end-to-end deep
  reinforcement learning,'' in \emph{Conference on Robot Learning}.\hskip 1em
  plus 0.5em minus 0.4em\relax PMLR, 2022, pp. 576--586.

\bibitem{estevez_review_2024}
J.~Estevez, G.~Garate, J.~Lopez-Guede, and M.~Larrea, ``Review of aerial
  transportation of suspended-cable payloads with quadrotors.'' 2024.

\bibitem{kaufmann_champion-level_2023}
E.~Kaufmann, L.~Bauersfeld, A.~Loquercio, M.~M{\"u}ller, V.~Koltun, and
  D.~Scaramuzza, ``Champion-level drone racing using deep reinforcement
  learning,'' \emph{Nature}, vol. 620, no. 7976, pp. 982--987, 2023.

\bibitem{Eschmann2024}
J.~Eschmann, D.~Albani, and G.~Loianno, ``Learning to fly in seconds,''
  \emph{IEEE Robotics and Automation Letters}, vol.~9, no.~7, pp. 6336--6343,
  2024.

\bibitem{wahba_kinodynamic_2024}
K.~Wahba, J.~Ortiz-Haro, M.~Toussaint, and W.~H{\"o}nig, ``Kinodynamic motion
  planning for a team of multirotors transporting a cable-suspended payload in
  cluttered environments,'' in \emph{2024 IEEE/RSJ International Conference on
  Intelligent Robots and Systems (IROS)}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2024, pp. 12\,750--12\,757.

\bibitem{huang_collision_2024}
Z.~Huang, Z.~Yang, R.~Krupani, B.~{\c{S}}enba{\c{s}}lar, S.~Batra, and G.~S.
  Sukhatme, ``Collision avoidance and navigation for a quadrotor swarm using
  end-to-end deep reinforcement learning,'' in \emph{2024 IEEE International
  Conference on Robotics and Automation (ICRA)}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2024, pp. 300--306.

\bibitem{sreenath_dynamics_2013}
K.~Sreenath and V.~Kumar, ``Dynamics, control and planning for cooperative
  manipulation of payloads suspended by cables from multiple quadrotor
  robots,'' in \emph{Robotics: Science and Systems IX, Berlin, Germany},
  P.~Newman, D.~Fox, and D.~Hsu, Eds., 2013.

\bibitem{tognon_aerial_2018}
M.~Tognon, C.~Gabellieri, L.~Pallottino, and A.~Franchi, ``Aerial
  co-manipulation with cables: The role of internal force for equilibria,
  stability, and passivity,'' \emph{IEEE Robotics and Automation Letters},
  vol.~3, no.~3, pp. 2577--2583, 2018.

\bibitem{sun_nonlinear_2023}
S.~Sun and A.~Franchi, ``Nonlinear mpc for full-pose manipulation of a
  cable-suspended load using multiple uavs,'' \emph{arXiv preprint
  arXiv:2301.08545}, 2023.

\bibitem{de2025distributed}
N.~De~Carli, R.~Belletti, E.~Buzzurro, A.~Testa, G.~Notarstefano, and
  M.~Tognon, ``Distributed nmpc for cooperative aerial manipulation of
  cable-suspended loads,'' \emph{IEEE Robotics and Automation Letters}, 2025.

\bibitem{wahba2025pc}
K.~Wahba and W.~H{\"o}nig, ``pc-dbcbs: Kinodynamic motion planning of
  physically-coupled robot teams,'' \emph{arXiv preprint arXiv:2505.10355},
  2025.

\bibitem{Wang2025SafeAA}
Y.~Wang, J.~Wang, X.~Zhou, T.~Yang, C.~Xu, and F.~Gao, ``Safe and agile
  transportation of cable-suspended payload via multiple aerial robots,''
  \emph{arXiv preprint arXiv:2501.15272}, 2025.

\bibitem{sun2025agile}
S.~Sun, X.~Wang, D.~Sanalitro, A.~Franchi, M.~Tognon, and J.~Alonso-Mora,
  ``Agile and cooperative aerial manipulation of a cable-suspended load,''
  \emph{arXiv preprint arXiv:2501.18802}, 2025.

\bibitem{wang2024impact}
H.~Wang, H.~Li, B.~Zhou, F.~Gao, and S.~Shen, ``Impact-aware planning and
  control for aerial robots with suspended payloads,'' \emph{IEEE Transactions
  on Robotics}, vol.~40, pp. 2478--2497, 2024.

\bibitem{recalde2025hpc}
L.~F. Recalde, M.~Sarvaiya, G.~Loianno, and G.~Li, ``Es-hpc-mpc: Exponentially
  stable hybrid perception constrained mpc for quadrotor with suspended
  payloads,'' \emph{arXiv preprint arXiv:2504.08841}, 2025.

\bibitem{Koch2018ReinforcementLF}
W.~Koch, R.~Mancuso, R.~West, and A.~Bestavros, ``Reinforcement learning for
  uav attitude control,'' \emph{ACM Transactions on Cyber-Physical Systems},
  vol.~3, no.~2, pp. 1--21, 2019.

\bibitem{Song2023ReachingTL}
Y.~Song, A.~Romero, M.~M{\"u}ller, V.~Koltun, and D.~Scaramuzza, ``Reaching the
  limit in autonomous racing: Optimal control versus reinforcement learning,''
  \emph{Science Robotics}, vol.~8, no.~82, p. eadg1462, 2023.

\bibitem{xing_multi-task_2024}
J.~Xing, I.~Geles, Y.~Song, E.~Aljalbout, and D.~Scaramuzza, ``Multi-task
  reinforcement learning for quadrotors,'' \emph{IEEE Robotics and Automation
  Letters}, 2024.

\bibitem{hua_new_2022}
H.~Hua, Y.~Fang, X.~Zhang, and C.~Qian, ``A new nonlinear control strategy
  embedded with reinforcement learning for a multirotor transporting a
  suspended payload,'' \emph{IEEE/ASME Transactions on Mechatronics}, vol.~27,
  no.~2, pp. 1174--1184, 2021.

\bibitem{cao2025flare}
D.~Cao, J.~Zhou, X.~Wang, and S.~Li, ``Flare: Agile flights for quadrotor
  cable-suspended payload system via reinforcement learning,'' \emph{arXiv
  preprint arXiv:2508.09797}, 2025.

\bibitem{Lowe2017MultiAgentAF}
R.~Lowe, Y.~I. Wu, A.~Tamar, J.~Harb, O.~Pieter~Abbeel, and I.~Mordatch,
  ``Multi-agent actor-critic for mixed cooperative-competitive environments,''
  \emph{Advances in neural information processing systems}, vol.~30, 2017.

\bibitem{yu_surprising_2022}
C.~Yu, A.~Velu, E.~Vinitsky, J.~Gao, Y.~Wang, A.~Bayen, and Y.~Wu, ``The
  surprising effectiveness of ppo in cooperative multi-agent games,''
  \emph{Advances in neural information processing systems}, vol.~35, pp.
  24\,611--24\,624, 2022.

\bibitem{witt_is_2020}
C.~S. De~Witt, T.~Gupta, D.~Makoviichuk, V.~Makoviychuk, P.~H. Torr, M.~Sun,
  and S.~Whiteson, ``Is independent learning all you need in the starcraft
  multi-agent challenge?'' \emph{arXiv preprint arXiv:2011.09533}, 2020.

\bibitem{Pandit2024LearningDM}
B.~Pandit, A.~Gupta, M.~S. Gadde, A.~Johnson, A.~K. Shrestha, H.~Duan, J.~Dao,
  and A.~Fern, ``Learning decentralized multi-biped control for payload
  transport,'' \emph{arXiv preprint arXiv:2406.17279}, 2024.

\bibitem{Chen2025DecentralizedNO}
W.-T. Chen, M.~Nguyen, Z.~Li, G.~N. Sue, and K.~Sreenath, ``Decentralized
  navigation of a cable-towed load using quadrupedal robot team via marl,''
  \emph{arXiv preprint arXiv:2503.18221}, 2025.

\bibitem{zhao_deep_2024}
Z.~Zhao, Y.~Wan, and Y.~Chen, ``Deep reinforcement learning-driven
  collaborative rounding-up for multiple unmanned aerial vehicles in obstacle
  environments,'' \emph{Drones}, vol.~8, no.~9, p. 464, 2024.

\bibitem{Lin2024PayloadTW}
D.~Lin, J.~Han, K.~Li, J.~Zhang, and C.~Zhang, ``Payload transporting with two
  quadrotors by centralized reinforcement learning method,'' \emph{IEEE
  Transactions on Aerospace and Electronic Systems}, vol.~60, no.~1, pp.
  239--251, 2023.

\bibitem{Estevez2024Reinforcement}
J.~Estevez, J.~M. Lopez-Guede, J.~del Valle-Echavarri, and M.~Gra{\~n}a,
  ``Reinforcement learning based trajectory planning for multi-uav load
  transportation,'' \emph{IEEE Access}, 2024.

\bibitem{xu_omnidrones_2024}
B.~Xu, F.~Gao, C.~Yu, R.~Zhang, Y.~Wu, and Y.~Wang, ``Omnidrones: An efficient
  and flexible platform for reinforcement learning in drone control,''
  \emph{IEEE Robotics and Automation Letters}, vol.~9, no.~3, pp. 2838--2844,
  2024.

\bibitem{zeng2025decentralized}
J.~Zeng, A.~M. Gimenez, E.~Vinitsky, J.~Alonso-Mora, and S.~Sun,
  ``Decentralized aerial manipulation of a cable-suspended load using
  multi-agent reinforcement learning,'' \emph{arXiv preprint arXiv:2508.01522},
  2025.

\bibitem{todorov2012mujoco}
E.~Todorov, T.~Erez, and Y.~Tassa, ``Mujoco: A physics engine for model-based
  control,'' in \emph{2012 IEEE/RSJ international conference on intelligent
  robots and systems}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2012, pp.
  5026--5033.

\bibitem{flair2023jaxmarl}
A.~Rutherford, B.~Ellis, M.~Gallici, J.~Cook, A.~Lupu, G.~Ingvarsson~Juto,
  T.~Willi, R.~Hammond, A.~Khan, C.~Schroeder~de Witt \emph{et~al.}, ``Jaxmarl:
  Multi-agent rl environments and algorithms in jax,'' \emph{Advances in Neural
  Information Processing Systems}, vol.~37, pp. 50\,925--50\,951, 2024.

\bibitem{molchanov_sim--multi-real_2019}
A.~Molchanov, T.~Chen, W.~H{\"o}nig, J.~A. Preiss, N.~Ayanian, and G.~S.
  Sukhatme, ``Sim-to-(multi)-real: Transfer of low-level robust control
  policies to multiple quadrotors,'' in \emph{2019 IEEE/RSJ International
  Conference on Intelligent Robots and Systems (IROS)}.\hskip 1em plus 0.5em
  minus 0.4em\relax IEEE, 2019, pp. 59--66.

\bibitem{kaufmann_benchmark_2022}
E.~Kaufmann, L.~Bauersfeld, and D.~Scaramuzza, ``A benchmark comparison of
  learned control policies for agile quadrotor flight,'' in \emph{2022
  International Conference on Robotics and Automation (ICRA)}.\hskip 1em plus
  0.5em minus 0.4em\relax IEEE, 2022, pp. 10\,504--10\,510.

\end{thebibliography}
