\section*{APPENDIX}

\subsection{Reward Function Specifics}
Equation \eqref{eq:reward} defines our reward as $r = r_\mathrm{track} r_\mathrm{stable} + r_\mathrm{safe}$. Here, we describe the components of $r_\mathrm{track}, r_\mathrm{stable}$ and $r_\mathrm{safe}$.
In the following, the mean over agents or motors is denoted by $\avg[\cdot]$. 
We use a reward shaping function $\Phi_{s}(x)=\exp(-s\,|x|)$ to shape reward components so that each term is bounded and the derivatives are well-behaved.
Further, let $d=\|\mathbf{e}^P\|$ and $g(d)=\min(3d,1) + c_f$, which helps to shrink the allowed payload speed near the target and keeps a small floor through the use of the scalar constant $c_f$. 

\smallskip
\noindent\textbf{Tracking}: The reward for tracking is defined as
\begin{equation}
    r_{\mathrm{track}}
  = \tfrac{1}{2}\bigl(r_{\mathrm{pos}}+r_{\rm dir}\bigr),
\end{equation}
where
\begin{align*}
  r_{\mathrm{pos}}
  &= \Phi\!\bigl(\|\mathbf{e}^P\|\bigr),\\
  \mathbf{v}_{\rm dir}
  &= \frac{\mathbf{v}^P}{\|\mathbf{v}^P\|+\varepsilon},\qquad
  \mathbf{e}_{\rm dir}
  = \frac{\mathbf{e}^P}{\|\mathbf{e}^P\|+\varepsilon},\\
  s_{\rm align}
  &= \min\!\bigl(c_g\,\|\mathbf{e}^P\|,\,c_s\bigr),\\
  r_{\rm dir}
  &= \Phi_{s_{\rm align}}\!\bigl(1-\mathbf{v}_{\rm dir}\!\cdot\!\mathbf{e}_{\rm dir}\bigr)
\end{align*}
Here $r_{\mathrm{pos}}$ rewards small payload errors. The direction term aligns the payload velocity with the target direction, facilitating a linear trajectory. The factor $c_g$ yields strong guidance when far away, and the cap $c_s$ reduces sharpness near the goal.

\smallskip
\noindent\textbf{Stability}: The stability reward is defined as:
\begin{equation}
    r_{\mathrm{stable}}
  = \tfrac{1}{5}\Bigl(
      r_{\mathrm{velP}} + r_{\mathrm{velQ}} +  \lambda_{\mathrm{yaw}} r_{\mathrm{yaw}}
      + \lambda_{\mathrm{up}} r_{\mathrm{up}} + r_{\mathrm{taut}}
    \Bigr),
\end{equation}
where
\begin{align*}
  r_{\mathrm{velP}}
  &= \exp\!\left[
      -\left(\frac{\|\mathbf{v}^P\|}{c_\text{swing}\,v_{\max}\,g(d)}\right)^{c_\text{exp}}
     \right],\\
  r_{\mathrm{velQ}}
  &= \meanI{
      \exp\!\left[
        -\left(\frac{\|\mathbf{v}^i\|}{v_{\max}\,g(d)}\right)^{c_\text{exp}}
      \right]
     },\\
  r_{\mathrm{yaw}}
  &= \meanI{ \Phi(\omega^i_{z}) },\qquad
  r_{\mathrm{up}}
  = \meanI{ \Phi(\theta^i) },\\
  r_{\mathrm{taut}}
  &= \frac{1}{L}\!\left(
      \meanI{\|\mathbf{p}^i-\mathbf{p}^P\|}
      + \meanI{p^i_{z}-p^P_{z}}
     \right).
\end{align*}
The velocity term caps the speed smoothly. The exponent $c_\text{exp}$ gives a soft wall that becomes strict at the boundary. The factor $c_\text{swing}$ for the payload allows a slightly lower speed than the vehicles to limit swing. The yaw and tilt terms keep the body $z$ axis near vertical. The taut term increases radial and vertical separation relative to the payload to keep cables engaged, normalized by cable length $L$.
$\omega_z^i$ denotes the yaw rate and $\theta^i$ denotes the tilt angle between each quadrotorâ€™s body-frame z-axis and the world z-axis.
$\lambda_\text{yaw}$ and $\lambda_\text{up}$ are scaling terms.

\smallskip
\noindent\textbf{Safety}: The reward for safety is defined as 
\begin{equation}
    r_{\mathrm{safe}}
  = \tfrac{1}{5}\Bigl(
     - r_{\mathrm{coll}} - r_{\mathrm{oob}} - \lambda_{\mathrm{s}} r_{\mathrm{smooth}}
      - r_{\mathrm{energy}} + r_{\mathrm{dist}}
    \Bigr),
\end{equation}
where
\begin{align*}
  &r_{\mathrm{dist}} =
  \begin{cases}
    1, & Q = 1, \\
    \meanIJ{
      \operatorname{clip}\!\left(
        \frac{\|\mathbf{p}^i-\mathbf{p}^j\|-d_{\min}}
             {d_{\mathrm{safe}}-d_{\min}},
        0,\,1
      \right)}, & Q > 1,
  \end{cases} \\
  &r_{\mathrm{coll}}=c_\text{coll}\,\mathbb{I}_{\mathrm{coll}},\qquad
  r_{\mathrm{oob}}=c_\text{oob}\,\mathbb{I}_{\mathrm{oob}} 
\end{align*}
\begin{align*}
  &r_{\rm smooth}
  = \tfrac{1}{2}\!\left(
       \meanI{ \|\mathbf{a}^i_t-\mathbf{a}^i_{t-1}\|_{1} }
      + \meanI{ \|\mathbf{a}^i_t-\bar a^i_t\mathbf{1}\|_{1} }
     \right),\\
  & \bar a^i_t = \meanJ{ a^i_{t,j} },\\
  &r_{\mathrm{energy}}
  = \meanI{
      \meanJ{
        \exp\!\bigl(-c_\text{b}|a^i_{t,j}|\bigr)
        + \exp\!\bigl(c_\text{b}(a^i_{t,j}-1)\bigr)
      }
     }.
\end{align*}
where $d_\text{min},d_\text{safe}$ reflect Crazyflie arm span and cable clearance,
$r_{\mathrm{coll}}$, $r_{\mathrm{oob}}$ denote collision and out-of-bounds indicators respectively,
and $c_\text{coll}, c_\text{oob}$ dominate the other bounded positive terms, and strongly discourage unsafe behavior.


Here the left term in $r_{\rm smooth}$ penalizes changes between consecutive actions and enforces temporal smoothness, while the right term penalizes deviations of the four motor commands from their mean and encourages a balanced spatial thrust distribution. The energy barrier $r_{\mathrm{energy}}$ uses the coefficient $c_b$ to softly repel actions near $0$ and $1$, which discourages saturation while remaining bounded and smooth.
We use the following values of the empirically determined scalar constants:
$
s=2,
c_f=0.02, 
c_g=40,
c_s=2,
c_\text{exp} = 8,
c_\text{swing} = 0.75,
c_\text{coll} = c_\text{oob} = 10, 
c_b = 50.
$
We set $d_\text{min}$ to 0.15m, and  
$d_\text{safe}$ to 0.18m.
The coefficients $\lambda_i$ and the cap $v_{\max}$ tune the trade off between agility and caution. The rest of the reward coefficients do not require tuning. For two quadrotors we use $\lambda_{\mathrm{yaw}}{=}10$, $\lambda_{\mathrm{up}}{=}5$, $\lambda_{\mathrm{s}}{=}10$ and $v_{\max}=1.5m/s$ to get desired robust but agile behavior.
