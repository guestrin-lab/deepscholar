\section{Introduction}
\label{sec_introduction}
Autoregressive (AR) modeling, as the mainstream in language generation~\cite{touvron2023llama,achiam2023gpt,touvron2023llama2,yang2024qwen2technicalreport}, has recently demonstrate strong potential in visual generation~\cite{liu2024lumina_mgpt,sun2024llamagen}, offering improved scalability~\cite{tian2024var} and potential for unified vision-language modeling~\cite{wu2024janus,chen2025janus_pro}.
In this paradigm, images are first quantized into discrete token sequences~\cite{esser2021vqgan,yu2021vit_vqgan}, which are then generated either token-by-token in a raster-scan order~\cite{wu2024janus,chameleonteam2025chameleon}, or in parallel through multi-token generation strategies~\cite{tian2024var,ma2024star,chang2022maskgit}.


Unlike diffusion or flow models that regress continuous tokens ~\cite{rombach2022stablediffusion,peebles2023dit,esser2024sdv3}, AR models learn the probabilistic distribution over discrete vocabulary, and sampling strategies (e.g., top-$K$, top-$p$~\cite{holtzman2019top_p}) are required to specify a token, which is essential and significantly impacts the quality and characteristics of generated content.
Within the area of language modeling, strategies have been proposed to augment reasoning capabilities and mitigate hallucinations, including logit shaping~\cite{tang2024top_nsigma,zhang2024edt}, contrastive decoding~\cite{su2022contrastive,chuang2023dola}, leveraging model-specific features ~\cite{huang2024opera}, and search-based methods~\cite{luo2024sed,guan2025rstar}, which emphasize answer accuracy over generation diversity.

However, a clear distinction exists between image and language: \textit{images exhibit lower information density and highly non-uniform spatial information distribution}, as shown in Fig.~\ref{fig_motivation} (a), making language-oriented methods suboptimal for image generation. This mismatch often leads to a trade-off between diversity in image contents and text consistency. As observed in~\cite{liu2024lumina_mgpt,teng2024sjd}, increasing randomness (\textit{e.g.,} high top-$K$) helps enrich visual content but compromises structural stability, leading to artifacts, distorted structures, or chaotic textures. Conversely, reducing randomness stabilizes structure and improves alignment, but often yields flat, oversmoothed details, or simplistic background.
How to balance randomness and determinism during sampling is thus critical for high-quality image generation. Unfortunately, existing methods typically rely on uniform sampling approaches like fixed top-$K$ or top-$p$, overlooking the inherent spatial information imbalance, which limits their ability to achieve high-quality images.

In this work, we aim to leverage the uneven distribution of information in images, and propose a \textit{sampling method specifically for autoregressive image generation}.
We observe that entropy of predicted logits effectively reflects information density in image during generation—low entropy corresponds to large homogeneous regions, while high entropy highlights content-rich areas such as foreground objects and complex backgrounds (see Fig.~\ref{fig_entropy_analysis}).
An intuitive idea is to encourage higher randomness in low-entropy regions, while applying stricter sampling in high-entropy areas. This helps balance image richness with structural stability, and also allocating fewer inference resources to low-entropy regions, which enables further acceleration with minimal impact on generation quality.


Building on this observation, we propose an entropy-aware sampling strategy that adjusts token distributions dynamically during inference. By computing the entropy of each predicted token distribution, we assign adaptive temperatures—injecting more randomness in low-entropy (simple) regions and applying stricter sampling in high-entropy (complex) areas. This improves the balance between image quality, structural stability, and text-image alignment without additional training or inference cost.
Moreover, our method generalizes well to a variety of autoregressive frameworks based on discrete token prediction, including mask-based and scale-wise generation. We also extend the entropy-aware idea to acceleration: by incorporating entropy-dependent acceptance in speculative decoding, we reduce inference cost to ~85\% of standard baselines with minimal quality loss.
We summarize our contributions as follows:

\begin{enumerate}
    \item Motivated by the observation that image information is sparse and unevenly distributed, which can be reflected by the entropy of tokens, we introduce an entropy-driven sampling strategy tailored for AR image generation that dynamically adapts sampling behavior based on entropy.
    \item In contrast to conventional sampling methods like top-$K$ or top-$p$, our approach enhances image quality and structural stability without modifying the model or increasing inference cost, and benefits multiple types of AR generation frameworks.
    \item We further extend the entropy-aware perspective to speculative decoding, achieving a 15\% reduction in inference time while maintaining visual fidelity across multiple benchmarks.
\end{enumerate}
