\section{Experiments}
\label{sec_experiments}
\subsection{Implementation details}
Four representative models are selected for comparison: vanilla AR model LlamaGen~\cite{sun2024llamagen} and Lumina-mGPT~\cite{liu2024lumina_mgpt} based on next-token prediction, mask-based model Meissonic~\cite{bai2024meissonic}, and scale-wise model STAR~\cite{ma2024star}.
All models are evaluated under their original inference settings (e.g., CFG=4 and top-$K$=2000 for Lumina-mGPT, CFG=7.5 for LlamaGen). We use LlamaGen’s official Stage-1 model to evaluate the sampling strategy, while Stage-2 is used only for acceleration analysis due to its poor performance (FID 53.42, CLIP-Score 21.47), which makes quality differences hard to observe.

FID and CLIP-Score are tested on the MS-COCO 2017~\cite{lin2014coco} validation set to evaluate the image quality and prompt-following capability. Moreover,  DPG-bench~\cite{hu2024ella} and HPS~\cite{wu2023hps} are adopted to assess the semantic fidelity and perceptual quality of the generated images. All experiments are conducted on A100 GPUs.

\subsection{Sampling quality}
\label{sec_exp_sample}
As shown in Table~\ref{tab_results} and Fig.~\ref{fig_results_mgpt}–\ref{fig_results_star}, our dynamic temperature sampling strategy effectively adapts to regions with varying information density in the image, leading to more stable structures and clearer details in the generated outputs. Depending on the inherent sampling mechanism of each model, our method yields varying degrees of improvement across different approaches. In particular, it achieves an approximate 4-point gain on DPG for both Meissonic and LlamaGen, along with a notable enhancement in visual quality.
In addition, integrating our approach with the masking- and scale-wise strategies described in Sec.~\ref{sec_adaption_more_ar} can further enhance generation performance. See Table~\ref{tab_results} for results with ``+Prob'' (applying dynamic temperature to logits only), and ``+Masking / +Scale-wise'' (applying temperature based on mask or scale).

\input{figs/results_acc}
\input{tables/results_acc}

\subsection{Inference acceleration}
\label{sec_exp_acc}
By integrating with existing vision-based speculative decoding schemes and leveraging entropy to automatically control the acceptance condition, our method saves about 15\% inference cost with almost no loss in image generation quality compared to the approach in~\cite{teng2024sjd}, as shown in Table~\ref{tab_results_acc} and Fig.~\ref{fig_results_acc}. The entropy-based approach significantly reduces the number of inference steps and latency, while still maintaining comparable image quality to the original speculative decoding method.

\subsection{Ablation \& discussion}
\label{sec_ablation}
\noindent\textbf{Parameters in Eq.~\ref{eq_temperature}.}
The impact of parameters in entropy-aware dynamic temperature is provided in Fig.~\ref{fig_ab_param}(a). It is observed that smaller $\epsilon$ or $\theta$ values lead to higher FID and lower CLIP-Score, primarily due to decreased randomness and overly deterministic sampling. Meanwhile, FID shows a trend of initially decreasing and then increasing as $\alpha$ increases. This is because $\alpha$ governs the proportion of different temperatures. When $\alpha$ is too small, most tokens are assigned very low temperatures, causing the FID to increase. Conversely, when $\alpha$ is too large, the image content becomes overly chaotic, resulting in increased FID. CLIP-Score consistently decreases as $\alpha$ increases.

\input{figs/ab_param}

\noindent\textbf{Acceptance rate in Sec.~\ref{sec_ar_acceleration}.}
We propose to dynamically control the acceptance rate in existing speculative decoding methods based on the entropy of predicted distributions. By adjusting both the scale and randomness of the threshold $r$, we reduce latency while maintaining quality. As shown in Table~\ref{tab_ab_acc} and Fig.~\ref{fig_ab_acc}, controlling only scale of $r$ (``scale'') reduces inference cost but degrades performance, especially image quality. In contrast, jointly tuning both scale and randomness (``+random'') achieves a better trade-off, enabling high-quality generation with minimal inference overhead.


\input{figs/ab_acc}

\noindent\textbf{Compatibility with different AR models.}
Our sampling method brings notable performance gains for some models—for instance, DPG in LlamaGen and Meissonic outperforms baseline by over 3 points. In contrast, well-trained models like Lumina-mGPT benefit only marginally. This discrepancy stems from factors such as generation paradigm (\textit{e.g.}, inherent sampling limitations of mask-based methods discussed in Fig.~\ref{fig_visual_mask}), training datasets and iterations (\textit{e.g.}, whether has been thoroughly trained on large-scale data). Nevertheless, these models can still exploit entropy for further acceleration.

% \input{tables/discuss_entropy}
\input{figs/discuss_failurecase}

\noindent\textbf{Combination with top-$K$ and CFG.}
We further analyze the performance of our method when combined with top-$K$ sampling and CFG, as shown in Fig.~\ref{fig_ab_param}(b); results with top-$p$ and temperature are in the supplementary. By incorporating proposed method, FID metric becomes less sensitive to sampling parameters, enabling better fidelity while maintaining image-text alignment.


\noindent\textbf{Factors affecting entropy.} Unlike text generation with fixed tokenization rules, autoregressive image generation relies on pretrained tokenizers, and the underlying model differences—including parameter scale, data quality, and training corpus—lead to varying entropy distributions and optimal sampling parameters. Empirically, higher CFG and larger resolutions lead to lower average entropy (see Table~\ref{tab_discuss_entropy}). Further analyses are provided in supplementary material.

\noindent\textbf{Discussion of failure cases.}
Although our entropy-based dynamic sampling strategy brings notable performance improvements, we also observe several failure cases where the relationship between semantic information and the entropy map becomes less consistent (see Fig.~\ref{fig_discuss_failurecase}). In some cases, regions such as human faces exhibit unexpectedly high entropy, while complex backgrounds receive lower entropy values. Consequently, adjusting temperature based on such entropy patterns may lead to structural distortions and overly smooth details. This ambiguity may potentially limit further performance gains, especially for models that have been carefully optimized.