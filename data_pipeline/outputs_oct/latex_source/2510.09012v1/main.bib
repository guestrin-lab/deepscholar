% Long form of conference & journal abbreviations -- especially for camera ready
@String(PAMI  = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV  = {Int. J. Comput. Vis.})
@String(CVPR  = {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV  = {Int. Conf. Comput. Vis.})
@String(ECCV  = {Eur. Conf. Comput. Vis.})
@String(NeurIPS = {Adv. Neural Inform. Process. Syst.})
@String(ICML  = {Int. Conf. Mach. Learn.})
@String(ICLR  = {Int. Conf. Learn. Represent.})
@String(ACCV  = {Asian Conf. Comput. Vis.})
@String(BMVC  = {Brit. Mach. Vis. Conf.})
@String(CVPRW = {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {IEEE Int. Conf. Image Process.})
@String(ICPR  = {Int. Conf. Pattern Recog.})
@String(ICASSP=	{ICASSP})
@String(ICME  = {Int. Conf. Multimedia and Expo})
@String(JMLR  = {J. Mach. Learn. Res.})
@String(TMLR  = {Trans. Mach. Learn Res.})
@String(TOG   = {ACM Trans. Graph.})
@String(TIP   = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TCSVT = {IEEE Trans. Circuit Syst. Video Technol.})
@String(TMM   = {IEEE Trans. Multimedia})
@String(ACMMM = {ACM Int. Conf. Multimedia})
@String(PR    = {Pattern Recognition})

@String(MNI	  = {Nature Mach. Intell.})
@String(SPL	  = {IEEE Sign. Process. Letters})
@String(VR    = {Vis. Res.})
@String(JOV	  = {J. Vis.})
@String(TVC   = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF   = {Comput. Graph. Forum})
@String(CVM   = {Computational Visual Media})


% Short form of conference & journal abbreviations -- especially for submission version
% if desired, remove these macros in favor of the above ones
@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NeurIPS = {NeurIPS})
@String(ICML  = {ICML})
@String(ICLR  = {ICLR})
@String(ACCV  = {ACCV})
@String(BMVC  =	{BMVC})
@String(CVPRW = {CVPRW})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {ICIP})
@String(ICPR  = {ICPR})
@String(ICASSP=	{ICASSP})
@String(ICME  =	{ICME})
@String(JMLR  = {JMLR})
@String(TMLR  = {TMLR})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(PR    = {PR})


@misc{wu2024janus,
      title={Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation}, 
      author={Chengyue Wu and Xiaokang Chen and Zhiyu Wu and Yiyang Ma and Xingchao Liu and Zizheng Pan and Wen Liu and Zhenda Xie and Xingkai Yu and Chong Ruan and Ping Luo},
      year={2024},
      eprint={2410.13848},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.13848}, 
}

@article{tian2024var,
  title={Visual autoregressive modeling: Scalable image generation via next-scale prediction},
  author={Tian, Keyu and Jiang, Yi and Yuan, Zehuan and Peng, Bingyue and Wang, Liwei},
  journal={Advances in neural information processing systems},
  volume={37},
  pages={84839--84865},
  year={2024}
}

@article{ma2024star,
  title={Star: Scale-wise text-to-image generation via auto-regressive representations},
  author={Ma, Xiaoxiao and Zhou, Mohan and Liang, Tao and Bai, Yalong and Zhao, Tiejun and Chen, Huaian and Jin, Yi},
  journal={arXiv preprint arXiv:2406.10797},
  year={2024}
}

@article{liu2024lumina_mgpt,
  title={Lumina-mgpt: Illuminate flexible photorealistic text-to-image generation with multimodal generative pretraining},
  author={Liu, Dongyang and Zhao, Shitian and Zhuo, Le and Lin, Weifeng and Qiao, Yu and Li, Hongsheng and Gao, Peng},
  journal={arXiv preprint arXiv:2408.02657},
  year={2024}
}

@article{teng2024sjd,
  title={Accelerating auto-regressive text-to-image generation with training-free speculative jacobi decoding},
  author={Teng, Yao and Shi, Han and Liu, Xian and Ning, Xuefei and Dai, Guohao and Wang, Yu and Li, Zhenguo and Liu, Xihui},
  journal={arXiv preprint arXiv:2410.01699},
  year={2024}
}

@inproceedings{esser2021vqgan,
  title={Taming transformers for high-resolution image synthesis},
  author={Esser, Patrick and Rombach, Robin and Ommer, Bjorn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12873--12883},
  year={2021}
}

@article{yu2021vit_vqgan,
  title={Vector-quantized image modeling with improved vqgan},
  author={Yu, Jiahui and Li, Xin and Koh, Jing Yu and Zhang, Han and Pang, Ruoming and Qin, James and Ku, Alexander and Xu, Yuanzhong and Baldridge, Jason and Wu, Yonghui},
  journal={arXiv preprint arXiv:2110.04627},
  year={2021}
}

@article{van2016pixelcnn,
  title={Conditional image generation with pixelcnn decoders},
  author={Van den Oord, Aaron and Kalchbrenner, Nal and Espeholt, Lasse and Vinyals, Oriol and Graves, Alex and others},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{ding2021cogview,
  title={Cogview: Mastering text-to-image generation via transformers},
  author={Ding, Ming and Yang, Zhuoyi and Hong, Wenyi and Zheng, Wendi and Zhou, Chang and Yin, Da and Lin, Junyang and Zou, Xu and Shao, Zhou and Yang, Hongxia and others},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={19822--19835},
  year={2021}
}

@article{sun2024llamagen,
  title={Autoregressive model beats diffusion: Llama for scalable image generation},
  author={Sun, Peize and Jiang, Yi and Chen, Shoufa and Zhang, Shilong and Peng, Bingyue and Luo, Ping and Yuan, Zehuan},
  journal={arXiv preprint arXiv:2406.06525},
  year={2024}
}

@article{chern2024anole,
  title={Anole: An open, autoregressive, native large multimodal models for interleaved image-text generation},
  author={Chern, Ethan and Su, Jiadi and Ma, Yan and Liu, Pengfei},
  journal={arXiv preprint arXiv:2407.06135},
  year={2024}
}

@misc{chameleonteam2025chameleon,
      title={Chameleon: Mixed-Modal Early-Fusion Foundation Models}, 
      author={Chameleon Team},
      year={2025},
      eprint={2405.09818},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.09818}, 
}

@article{chen2025janus_pro,
  title={Janus-pro: Unified multimodal understanding and generation with data and model scaling},
  author={Chen, Xiaokang and Wu, Zhiyu and Liu, Xingchao and Pan, Zizheng and Liu, Wen and Xie, Zhenda and Yu, Xingkai and Ruan, Chong},
  journal={arXiv preprint arXiv:2501.17811},
  year={2025}
}

@inproceedings{chang2022maskgit,
  title={Maskgit: Masked generative image transformer},
  author={Chang, Huiwen and Zhang, Han and Jiang, Lu and Liu, Ce and Freeman, William T},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11315--11325},
  year={2022}
}

@article{han2024infinity,
  title={Infinity: Scaling bitwise autoregressive modeling for high-resolution image synthesis},
  author={Han, Jian and Liu, Jinlai and Jiang, Yi and Yan, Bin and Zhang, Yuqi and Yuan, Zehuan and Peng, Bingyue and Liu, Xiaobing},
  journal={arXiv preprint arXiv:2412.04431},
  year={2024}
}

@article{zhang2024edt,
  title={EDT: Improving Large Language Models' Generation by Entropy-based Dynamic Temperature Sampling},
  author={Zhang, Shimao and Bao, Yu and Huang, Shujian},
  journal={arXiv preprint arXiv:2403.14541},
  year={2024}
}

@article{chuang2023dola,
  title={Dola: Decoding by contrasting layers improves factuality in large language models},
  author={Chuang, Yung-Sung and Xie, Yujia and Luo, Hongyin and Kim, Yoon and Glass, James and He, Pengcheng},
  journal={arXiv preprint arXiv:2309.03883},
  year={2023}
}

@inproceedings{leviathan2023speculative_decoding,
  title={Fast inference from transformers via speculative decoding},
  author={Leviathan, Yaniv and Kalman, Matan and Matias, Yossi},
  booktitle={International Conference on Machine Learning},
  pages={19274--19286},
  year={2023},
  organization={PMLR}
}

@article{snell2024lookahead,
  title={Scaling llm test-time compute optimally can be more effective than scaling model parameters},
  author={Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral},
  journal={arXiv preprint arXiv:2408.03314},
  year={2024}
}

@misc{tang2024top_nsigma,
      title={Top-$n\sigma$: Not All Logits Are You Need}, 
      author={Chenxia Tang and Jianchun Liu and Hongli Xu and Liusheng Huang},
      year={2024},
      eprint={2411.07641},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2411.07641}, 
}

@article{su2022contrastive,
  title={A contrastive framework for neural text generation},
  author={Su, Yixuan and Lan, Tian and Wang, Yan and Yogatama, Dani and Kong, Lingpeng and Collier, Nigel},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21548--21561},
  year={2022}
}

@inproceedings{huang2024opera,
  title={Opera: Alleviating hallucination in multi-modal large language models via over-trust penalty and retrospection-allocation},
  author={Huang, Qidong and Dong, Xiaoyi and Zhang, Pan and Wang, Bin and He, Conghui and Wang, Jiaqi and Lin, Dahua and Zhang, Weiming and Yu, Nenghai},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13418--13427},
  year={2024}
}

@article{luo2024sed,
  title={Sed: Self-evaluation decoding enhances large language models for better generation},
  author={Luo, Ziqin and Han, Haixia and Zhao, Haokun and Jiang, Guochao and Du, Chengyu and Li, Tingyun and Liang, Jiaqing and Yang, Deqing and Xiao, Yanghua},
  journal={arXiv preprint arXiv:2405.16552},
  year={2024}
}

@article{guan2025rstar,
  title={rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking},
  author={Guan, Xinyu and Zhang, Li Lyna and Liu, Yifei and Shang, Ning and Sun, Youran and Zhu, Yi and Yang, Fan and Yang, Mao},
  journal={arXiv preprint arXiv:2501.04519},
  year={2025}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{bai2024meissonic,
  title={Meissonic: Revitalizing masked generative transformers for efficient high-resolution text-to-image synthesis},
  author={Bai, Jinbin and Ye, Tian and Chow, Wei and Song, Enxin and Chen, Qing-Guo and Li, Xiangtai and Dong, Zhen and Zhu, Lei and Yan, Shuicheng},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2024}
}

@article{xie2024show_o,
  title={Show-o: One single transformer to unify multimodal understanding and generation},
  author={Xie, Jinheng and Mao, Weijia and Bai, Zechen and Zhang, David Junhao and Wang, Weihao and Lin, Kevin Qinghong and Gu, Yuchao and Chen, Zhijie and Yang, Zhenheng and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2408.12528},
  year={2024}
}

@article{tang2024hart,
  title={Hart: Efficient visual generation with hybrid autoregressive transformer},
  author={Tang, Haotian and Wu, Yecheng and Yang, Shang and Xie, Enze and Chen, Junsong and Chen, Junyu and Zhang, Zhuoyang and Cai, Han and Lu, Yao and Han, Song},
  journal={arXiv preprint arXiv:2410.10812},
  year={2024}
}

@misc{jang2025lantern,
      title={LANTERN: Accelerating Visual Autoregressive Models with Relaxed Speculative Decoding}, 
      author={Doohyuk Jang and Sihwan Park and June Yong Yang and Yeonsung Jung and Jihun Yun and Souvik Kundu and Sung-Yub Kim and Eunho Yang},
      year={2025},
      eprint={2410.03355},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.03355}, 
}

@article{holtzman2019top_p,
  title={The curious case of neural text degeneration},
  author={Holtzman, Ari and Buys, Jan and Du, Li and Forbes, Maxwell and Choi, Yejin},
  journal={arXiv preprint arXiv:1904.09751},
  year={2019}
}

@inproceedings{peebles2023dit,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={4195--4205},
  year={2023}
}

@inproceedings{rombach2022stablediffusion,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

@article{esser2024sdv3,
  title={Scaling rectified flow transformers for high-resolution image synthesis},
  author={Esser, Patrick and Kulal, Sumith and Blattmann, Andreas and Entezari, Rahim and M{\"u}ller, Jonas and Saini, Harry and Levi, Yam and Lorenz, Dominik and Sauer, Axel and Boesel, Frederic and others},
  journal={arXiv preprint arXiv:2403.03206},
  year={2024}
}

@article{ge2023seed,
  title={Planting a seed of vision in large language model},
  author={Ge, Yuying and Ge, Yixiao and Zeng, Ziyun and Wang, Xintao and Shan, Ying},
  journal={arXiv preprint arXiv:2307.08041},
  year={2023}
}

@inproceedings{ramesh2021dalle,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International conference on machine learning},
  pages={8821--8831},
  year={2021},
  organization={Pmlr}
}

@article{yu2022parti,
  title={Scaling autoregressive models for content-rich text-to-image generation},
  author={Yu, Jiahui and Xu, Yuanzhong and Koh, Jing Yu and Luong, Thang and Baid, Gunjan and Wang, Zirui and Vasudevan, Vijay and Ku, Alexander and Yang, Yinfei and Ayan, Burcu Karagol and others},
  journal={arXiv preprint arXiv:2206.10789},
  volume={2},
  number={3},
  pages={5},
  year={2022}
}

@article{touvron2023llama2,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@misc{he2024mars,
      title={MARS: Mixture of Auto-Regressive Models for Fine-grained Text-to-image Synthesis}, 
      author={Wanggui He and Siming Fu and Mushui Liu and Xierui Wang and Wenyi Xiao and Fangxun Shu and Yi Wang and Lei Zhang and Zhelun Yu and Haoyuan Li and Ziwei Huang and LeiLei Gan and Hao Jiang},
      year={2024},
      eprint={2407.07614},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2407.07614}, 
}

@article{wang2024emu3,
  title={Emu3: Next-token prediction is all you need},
  author={Wang, Xinlong and Zhang, Xiaosong and Luo, Zhengxiong and Sun, Quan and Cui, Yufeng and Wang, Jinsheng and Zhang, Fan and Wang, Yueze and Li, Zhen and Yu, Qiying and others},
  journal={arXiv preprint arXiv:2409.18869},
  year={2024}
}

@article{yu2024titok,
  title={An Image is Worth 32 Tokens for Reconstruction and Generation},
  author={Yu, Qihang and Weber, Mark and Deng, Xueqing and Shen, Xiaohui and Cremers, Daniel and Chen, Liang-Chieh},
  journal={arXiv preprint arXiv:2406.07550},
  year={2024}
}

@inproceedings{lee2022rqvae,
  title={Autoregressive image generation using residual quantization},
  author={Lee, Doyup and Kim, Chiheon and Kim, Saehoon and Cho, Minsu and Han, Wook-Shin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11523--11532},
  year={2022}
}

@misc{zhang2025v2flow,
      title={V2Flow: Unifying Visual Tokenization and Large Language Model Vocabularies for Autoregressive Image Generation}, 
      author={Guiwei Zhang and Tianyu Zhang and Mohan Zhou and Yalong Bai and Biye Li},
      year={2025},
      eprint={2503.07493},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2503.07493}, 
}

@article{qu2024tokenflow,
  title={Tokenflow: Unified image tokenizer for multimodal understanding and generation},
  author={Qu, Liao and Zhang, Huichao and Liu, Yiheng and Wang, Xu and Jiang, Yi and Gao, Yiming and Ye, Hu and Du, Daniel K and Yuan, Zehuan and Wu, Xinglong},
  journal={arXiv preprint arXiv:2412.03069},
  year={2024}
}

@article{yu2023lfq,
  title={Language Model Beats Diffusion--Tokenizer is Key to Visual Generation},
  author={Yu, Lijun and Lezama, Jos{\'e} and Gundavarapu, Nitesh B and Versari, Luca and Sohn, Kihyuk and Minnen, David and Cheng, Yong and Birodkar, Vighnesh and Gupta, Agrim and Gu, Xiuye and others},
  journal={arXiv preprint arXiv:2310.05737},
  year={2023}
}

@misc{zhao2024bsq,
      title={Image and Video Tokenization with Binary Spherical Quantization}, 
      author={Yue Zhao and Yuanjun Xiong and Philipp Krähenbühl},
      year={2024},
      eprint={2406.07548},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.07548}, 
}

@article{he2025nar,
  title={Neighboring Autoregressive Modeling for Efficient Visual Generation},
  author={He, Yefei and He, Yuanyu and He, Shaoxuan and Chen, Feng and Zhou, Hong and Zhang, Kaipeng and Zhuang, Bohan},
  journal={arXiv preprint arXiv:2503.10696},
  year={2025}
}

@article{yu2024rar,
  title={Randomized autoregressive visual generation},
  author={Yu, Qihang and He, Ju and Deng, Xueqing and Shen, Xiaohui and Chen, Liang-Chieh},
  journal={arXiv preprint arXiv:2411.00776},
  year={2024}
}

@article{he2024zipar,
  title={Zipar: Accelerating autoregressive image generation through spatial locality},
  author={He, Yefei and Chen, Feng and He, Yuanyu and He, Shaoxuan and Zhou, Hong and Zhang, Kaipeng and Zhuang, Bohan},
  journal={arXiv preprint arXiv:2412.04062},
  year={2024}
}

@article{wang2024par,
  title={Parallelized Autoregressive Visual Generation},
  author={Wang, Yuqing and Ren, Shuhuai and Lin, Zhijie and Han, Yujin and Guo, Haoyuan and Yang, Zhenheng and Zou, Difan and Feng, Jiashi and Liu, Xihui},
  journal={arXiv preprint arXiv:2412.15119},
  year={2024}
}

@inproceedings{leviathan2023spec_decode,
  title={Fast inference from transformers via speculative decoding},
  author={Leviathan, Yaniv and Kalman, Matan and Matias, Yossi},
  booktitle={International Conference on Machine Learning},
  pages={19274--19286},
  year={2023},
  organization={PMLR}
}

@article{radford2019gpt2,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{keskar2019repetition_penalty,
  title={Ctrl: A conditional transformer language model for controllable generation},
  author={Keskar, Nitish Shirish and McCann, Bryan and Varshney, Lav R and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:1909.05858},
  year={2019}
}

@article{meister2020beam_search,
  title={If beam search is the answer, what was the question?},
  author={Meister, Clara and Vieira, Tim and Cotterell, Ryan},
  journal={arXiv preprint arXiv:2010.02650},
  year={2020}
}

@misc{lightman2023letsverifystepstep,
      title={Let's Verify Step by Step}, 
      author={Hunter Lightman and Vineet Kosaraju and Yura Burda and Harri Edwards and Bowen Baker and Teddy Lee and Jan Leike and John Schulman and Ilya Sutskever and Karl Cobbe},
      year={2023},
      eprint={2305.20050},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.20050}, 
}

@misc{snell2024scalingllmtts,
      title={Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters}, 
      author={Charlie Snell and Jaehoon Lee and Kelvin Xu and Aviral Kumar},
      year={2024},
      eprint={2408.03314},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2408.03314}, 
}

@article{chen2023accelerating,
  title={Accelerating large language model decoding with speculative sampling},
  author={Chen, Charlie and Borgeaud, Sebastian and Irving, Geoffrey and Lespiau, Jean-Baptiste and Sifre, Laurent and Jumper, John},
  journal={arXiv preprint arXiv:2302.01318},
  year={2023}
}

@misc{yang2024qwen2technicalreport,
      title={Qwen2 Technical Report}, 
      author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jianxin Yang and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Xuejing Liu and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhifang Guo and Zhihao Fan},
      year={2024},
      eprint={2407.10671},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.10671}, 
}

@misc{jiao2025unitoken,
      title={UniToken: Harmonizing Multimodal Understanding and Generation through Unified Visual Encoding}, 
      author={Yang Jiao and Haibo Qiu and Zequn Jie and Shaoxiang Chen and Jingjing Chen and Lin Ma and Yu-Gang Jiang},
      year={2025},
      eprint={2504.04423},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2504.04423}, 
}

@misc{hu2024ella,
      title={ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment}, 
      author={Xiwei Hu and Rui Wang and Yixiao Fang and Bin Fu and Pei Cheng and Gang Yu},
      year={2024},
      eprint={2403.05135},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2403.05135}, 
}

@article{wu2023hps,
  title={Human preference score v2: A solid benchmark for evaluating human preferences of text-to-image synthesis},
  author={Wu, Xiaoshi and Hao, Yiming and Sun, Keqiang and Chen, Yixiong and Zhu, Feng and Zhao, Rui and Li, Hongsheng},
  journal={arXiv preprint arXiv:2306.09341},
  year={2023}
}

@article{unitok,
  title={UniTok: A Unified Tokenizer for Visual Generation and Understanding},
  author={Ma, Chuofan and Jiang, Yi and Wu, Junfeng and Yang, Jihan and Yu, Xin and Yuan, Zehuan and Peng, Bingyue and Qi, Xiaojuan},
  journal={arXiv preprint arXiv:2502.20321},
  year={2025}
}

@inproceedings{lin2014coco,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer vision--ECCV 2014: 13th European conference, zurich, Switzerland, September 6-12, 2014, proceedings, part v 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@misc{wang2025varedit,
      title={Training-Free Text-Guided Image Editing with Visual Autoregressive Model}, 
      author={Yufei Wang and Lanqing Guo and Zhihao Li and Jiaxing Huang and Pichao Wang and Bihan Wen and Jian Wang},
      year={2025},
      eprint={2503.23897},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2503.23897}, 
}

@inproceedings{podell2023sdxl,
  title={SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis},
  author={Podell, Dustin and English, Zion and Lacey, Kyle and Blattmann, Andreas and Dockhorn, Tim and M{\"u}ller, Jonas and Penna, Joe and Rombach, Robin},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{chen2023pixart_alpha,
  title={PixArt-${\alpha}$: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis},
  author={Chen, Junsong and Yu, Jincheng and Ge, Chongjian and Yao, Lewei and Xie, Enze and Wu, Yue and Wang, Zhongdao and Kwok, James and Luo, Ping and Lu, Huchuan and others},
  journal={arXiv preprint arXiv:2310.00426},
  year={2023}
}