\begin{thebibliography}{10}

\bibitem{gedamu2024self}
K.~Gedamu, Y.~Ji, Y.~Yang, J.~Shao, and H.~T. Shen, ``Self-supervised subaction parsing network for semi-supervised action quality assessment,'' {\em IEEE Transactions on Image Processing}, 2024.

\bibitem{majeedi2024rica}
A.~Majeedi, V.~R. Gajjala, S.~S. S.~N. GNVV, and Y.~Li, ``Rica$^2$: Rubric-informed, calibrated assessment of actions,'' in {\em European Conference on Computer Vision}, vol.~15121, pp.~143--161, 2024.

\bibitem{dong2024interpretable}
X.~Dong, X.~Liu, W.~Li, A.~Adeyemi-Ejeye, and A.~Gilbert, ``Interpretable long-term action quality assessment,'' {\em arXiv preprint arXiv:2408.11687}, 2024.

\bibitem{liu2025adaptive}
J.~Liu, H.~Wang, W.~Zhou, K.~Stawarz, P.~Corcoran, Y.~Chen, and H.~Liu, ``Adaptive spatiotemporal graph transformer network for action quality assessment,'' {\em IEEE Transactions on Circuits and Systems for Video Technology}, 2025.

\bibitem{zeng2024multimodal}
L.-A. Zeng and W.-S. Zheng, ``Multimodal action quality assessment,'' {\em IEEE Transactions on Image Processing}, vol.~33, pp.~1600--1613, 2024.

\bibitem{ji2023localization}
Y.~Ji, L.~Ye, H.~Huang, L.~Mao, Y.~Zhou, and L.~Gao, ``Localization-assisted uncertainty score disentanglement network for action quality assessment,'' in {\em ACM International Conference on Multimedia}, pp.~8590--8597, 2023.

\bibitem{zhang2023logo}
S.~Zhang, W.~Dai, S.~Wang, X.~Shen, J.~Lu, J.~Zhou, and Y.~Tang, ``Logo: A long-form video dataset for group action quality assessment,'' in {\em IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.~2405--2414, 2023.

\bibitem{zhou2023video}
K.~Zhou, R.~Cai, Y.~Ma, Q.~Tan, X.~Wang, J.~Li, H.~P. Shum, F.~W. Li, S.~Jin, and X.~Liang, ``A video-based augmented reality system for human-in-the-loop muscle strength assessment of juvenile dermatomyositis,'' {\em IEEE Transactions on Visualization and Computer Graphics}, vol.~29, no.~5, pp.~2456--2466, 2023.

\bibitem{parmar2021piano}
P.~Parmar, J.~Reddy, and B.~Morris, ``Piano skills assessment,'' in {\em 2021 IEEE 23rd International Workshop on Multimedia Signal Processing (MMSP)}, pp.~1--5, IEEE, 2021.

\bibitem{li2022surgical}
Z.~Li, L.~Gu, W.~Wang, R.~Nakamura, and Y.~Sato, ``Surgical skill assessment via video semantic aggregation,'' in {\em International Conference on Medical Image Computing and Computer-Assisted Intervention}, pp.~410--420, Springer, 2022.

\bibitem{carreira2017quo}
J.~Carreira and A.~Zisserman, ``Quo vadis, action recognition? a new model and the kinetics dataset,'' in {\em IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.~6299--6308, 2017.

\bibitem{kay2017kinetics}
W.~Kay, J.~Carreira, K.~Simonyan, B.~Zhang, C.~Hillier, S.~Vijayanarasimhan, F.~Viola, T.~Green, T.~Back, P.~Natsev, {\em et~al.}, ``The kinetics human action video dataset,'' {\em arXiv preprint arXiv:1705.06950}, 2017.

\bibitem{wang2024comprehensive}
L.~Wang, X.~Zhang, H.~Su, and J.~Zhu, ``A comprehensive survey of continual learning: Theory, method and application,'' {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}, 2024.

\bibitem{chi2022metafscil}
Z.~Chi, L.~Gu, H.~Liu, Y.~Wang, Y.~Yu, and J.~Tang, ``Metafscil: A meta-learning approach for few-shot class incremental learning,'' in {\em IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.~14166--14175, 2022.

\bibitem{wang2023hierarchical}
L.~Wang, J.~Xie, X.~Zhang, M.~Huang, H.~Su, and J.~Zhu, ``Hierarchical decomposition of prompt-based continual learning: Rethinking obscured sub-optimality,'' {\em Advances in Neural Information Processing Systems}, vol.~36, 2024.

\bibitem{wang2021afec}
L.~Wang, M.~Zhang, Z.~Jia, Q.~Li, C.~Bao, K.~Ma, J.~Zhu, and Y.~Zhong, ``Afec: Active forgetting of negative transfer in continual learning,'' {\em Advances in Neural Information Processing Systems}, vol.~34, pp.~22379--22391, 2021.

\bibitem{zhou2025adaptive}
K.~Zhou, Z.~Hao, L.~Wang, and X.~Liang, ``Adaptive score alignment learning for continual perceptual quality assessment of 360-degree videos in virtual reality,'' {\em IEEE Transactions on Visualization and Computer Graphics}, 2025.

\bibitem{xin2024parameter}
Y.~Xin, J.~Yang, S.~Luo, H.~Zhou, J.~Du, X.~Liu, Y.~Fan, Q.~Li, and Y.~Du, ``Parameter-efficient fine-tuning for pre-trained vision models: A survey,'' {\em arXiv preprint arXiv:2402.02242}, 2024.

\bibitem{zhou2024comprehensivesurveyactionquality}
K.~Zhou, R.~Cai, L.~Wang, H.~P.~H. Shum, and X.~Liang, ``A comprehensive survey of action quality assessment: Method and benchmark,'' {\em arXiv preprint arXiv:2412.11149}, 2024.

\bibitem{zhou2024cofinal}
K.~Zhou, J.~Li, R.~Cai, L.~Wang, X.~Zhang, and X.~Liang, ``Cofinal: Enhancing action quality assessment with coarse-to-fine instruction alignment,'' in {\em International Joint Conference on Artificial Intelligence}, pp.~1771--1779, 2024.

\bibitem{zhou2025phi}
K.~Zhou, H.~P. Shum, F.~W. Li, X.~Zhang, and X.~Liang, ``Phi: Bridging domain shift in long-term action quality assessment via progressive hierarchical instruction,'' {\em IEEE Transactions on Image Processing}, vol.~34, pp.~3718--3732, 2025.

\bibitem{zhou2024magr}
K.~Zhou, L.~Wang, X.~Zhang, H.~P. Shum, F.~W. Li, J.~Li, and X.~Liang, ``Magr: Manifold-aligned graph regularization for continual action quality assessment,'' in {\em European Conference on Computer Vision}, pp.~375--392, 2024.

\bibitem{xu2022finediving}
J.~Xu, Y.~Rao, X.~Yu, G.~Chen, J.~Zhou, and J.~Lu, ``Finediving: A fine-grained dataset for procedure-aware action quality assessment,'' in {\em IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.~2949--2958, 2022.

\bibitem{parmar2019action}
P.~Parmar and B.~Morris, ``Action quality assessment across multiple actions,'' in {\em WACV}, pp.~1468--1476, IEEE, 2019.

\bibitem{pirsiavash2014assessing}
H.~Pirsiavash, C.~Vondrick, and A.~Torralba, ``Assessing the quality of actions,'' in {\em European Conference on Computer Vision}, pp.~556--571, Springer, 2014.

\bibitem{xu2025quality}
H.~Xu, H.~Wu, X.~Ke, Y.~Li, R.~Xu, and W.~Guo, ``Quality-guided vision-language learning for long-term action quality assessment,'' {\em IEEE Transactions on Multimedia}, 2025.

\bibitem{xu2024vision}
H.~Xu, X.~Ke, Y.~Li, R.~Xu, H.~Wu, X.~Lin, and W.~Guo, ``Vision-language action knowledge learning for semantic-aware action quality assessment,'' in {\em European Conference on Computer Vision}, 2024.

\bibitem{zia2016automated}
A.~Zia, Y.~Sharma, V.~Bettadapura, E.~L. Sarin, T.~Ploetz, M.~A. Clements, and I.~Essa, ``Automated video-based assessment of surgical skills for training and evaluation in medical schools,'' {\em International Journal of Computer Assisted Radiology and Surgery}, vol.~11, pp.~1623--1636, 2016.

\bibitem{pan2021adaptive}
J.-H. Pan, J.~Gao, and W.-S. Zheng, ``Adaptive action assessment,'' {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}, vol.~44, no.~12, pp.~8779--8795, 2021.

\bibitem{yu2021group}
X.~Yu, Y.~Rao, W.~Zhao, J.~Lu, and J.~Zhou, ``Group-aware contrastive regression for action quality assessment,'' in {\em IEEE/CVF International Conference on Computer Vision}, pp.~7919--7928, 2021.

\bibitem{parmar2019and}
P.~Parmar and B.~T. Morris, ``What and how well you performed? a multitask learning approach to action quality assessment,'' in {\em IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.~304--313, 2019.

\bibitem{zhou2023hierarchical}
K.~Zhou, Y.~Ma, H.~P. Shum, and X.~Liang, ``Hierarchical graph convolutional networks for action quality assessment,'' {\em IEEE Transactions on Circuits and Systems for Video Technology}, vol.~33, no.~12, pp.~7749--7763, 2023.

\bibitem{ke2024two}
X.~Ke, H.~Xu, X.~Lin, and W.~Guo, ``Two-path target-aware contrastive regression for action quality assessment,'' {\em Information Sciences}, vol.~664, p.~120347, 2024.

\bibitem{doughty2019pros}
H.~Doughty, W.~Mayol-Cuevas, and D.~Damen, ``The pros and cons: Rank-aware temporal attention for skill determination in long videos,'' in {\em IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.~7862--7871, 2019.

\bibitem{doughty2018s}
H.~Doughty, D.~Damen, and W.~Mayol-Cuevas, ``Who's better? who's best? pairwise deep ranking for skill determination,'' in {\em IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.~6057--6066, 2018.

\bibitem{dadashzadeh2024pecop}
A.~Dadashzadeh, S.~Duan, A.~Whone, and M.~Mirmehdi, ``Pecop: Parameter efficient continual pretraining for action quality assessment,'' in {\em WACV}, pp.~42--52, 2024.

\bibitem{xu2024fineparser}
J.~Xu, S.~Yin, G.~Zhao, Z.~Wang, and Y.~Peng, ``Fineparser: A fine-grained spatio-temporal action parser for human-centric action quality assessment,'' in {\em IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.~14628--14637, 2024.

\bibitem{xu2025human}
J.~Xu, S.~Yin, and Y.~Peng, ``Human-centric fine-grained action quality assessment,'' {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}, 2025.

\bibitem{li2024continual}
Y.-M. Li, L.-A. Zeng, J.-K. Meng, and W.-S. Zheng, ``Continual action assessment via task-consistent score-discriminative feature distribution modeling,'' {\em IEEE Transactions on Circuits and Systems for Video Technology}, 2024.

\bibitem{wang2023incorporating}
L.~Wang, X.~Zhang, Q.~Li, M.~Zhang, H.~Su, J.~Zhu, and Y.~Zhong, ``Incorporating neuro-inspired adaptability for continual learning in artificial intelligence,'' {\em Nature Machine Intelligence}, vol.~5, no.~12, pp.~1356--1368, 2023.

\bibitem{zenke2017continual}
F.~Zenke, B.~Poole, and S.~Ganguli, ``Continual learning through synaptic intelligence,'' in {\em International Conference on Machine Learning}, pp.~3987--3995, PMLR, 2017.

\bibitem{james2017ewc}
J.~Kirkpatrick, R.~Pascanu, N.~Rabinowitz, J.~Veness, G.~Desjardins, A.~A. Rusu, K.~Milan, J.~Quan, T.~Ramalho, A.~Grabska-Barwinska, D.~Hassabis, C.~Clopath, D.~Kumaran, and R.~Hadsell, ``Overcoming catastrophic forgetting in neural networks,'' {\em Proceedings of the National Academy of Sciences}, vol.~114, no.~13, pp.~3521--3526, 2017.

\bibitem{li2017learning}
Z.~Li and D.~Hoiem, ``Learning without forgetting,'' {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}, vol.~40, no.~12, pp.~2935--2947, 2017.

\bibitem{riemer2019learning}
M.~Riemer, I.~Cases, R.~Ajemian, M.~Liu, I.~Rish, Y.~Tu, and G.~Tesauro, ``Learning to learn without forgetting by maximizing transfer and minimizing interference,'' in {\em International Conference on Learning Representations}, 2019.

\bibitem{buzzega2020dark}
P.~Buzzega, M.~Boschini, A.~Porrello, D.~Abati, and S.~Calderara, ``Dark experience for general continual learning: A strong, simple baseline,'' {\em Advances in Neural Information Processing Systems}, vol.~33, pp.~15920--15930, 2020.

\bibitem{tao2020few}
X.~Tao, X.~Hong, X.~Chang, S.~Dong, X.~Wei, and Y.~Gong, ``Few-shot class-incremental learning,'' in {\em IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.~12183--12192, 2020.

\bibitem{kukleva2021generalized}
A.~Kukleva, H.~Kuehne, and B.~Schiele, ``Generalized and incremental few-shot learning by explicit learning and calibration without forgetting,'' in {\em IEEE/CVF International Conference on Computer Vision}, pp.~9020--9029, 2021.

\bibitem{zhang2023slca}
G.~Zhang, L.~Wang, G.~Kang, L.~Chen, and Y.~Wei, ``Slca: Slow learner with classifier alignment for continual learning on a pre-trained model,'' {\em IEEE/CVF International Conference on Computer Vision}, pp.~19148--19158, 2023.

\bibitem{zhang2024slca++}
G.~Zhang, L.~Wang, G.~Kang, L.~Chen, and Y.~Wei, ``Slca++: Unleash the power of sequential fine-tuning for continual learning with pre-training,'' {\em arXiv preprint arXiv:2408.08295}, 2024.

\bibitem{yang2023neural}
Y.~Yang, H.~Yuan, X.~Li, Z.~Lin, P.~Torr, and D.~Tao, ``Neural collapse inspired feature-classifier alignment for few-shot class incremental learning,'' {\em arXiv preprint arXiv:2302.03004}, 2023.

\bibitem{he2021towards}
J.~He, C.~Zhou, X.~Ma, T.~Berg-Kirkpatrick, and G.~Neubig, ``Towards a unified view of parameter-efficient transfer learning,'' {\em arXiv preprint arXiv:2110.04366}, 2021.

\bibitem{datta2025deep}
J.~Datta, R.~Rabbi, P.~Saha, A.~N. Zereen, M.~Abdullah-Al-Wadud, and J.~Uddin, ``Deep representation learning using layer-wise vicreg losses: J. datta et al.,'' {\em Scientific Reports}, vol.~15, no.~1, p.~27049, 2025.

\bibitem{wang2025hide}
L.~Wang, J.~Xie, X.~Zhang, H.~Su, and J.~Zhu, ``Hide-pet: continual learning via hierarchical decomposition of parameter-efficient tuning,'' {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}, 2025.

\bibitem{bao2023pcfgaze}
Y.~Bao and F.~Lu, ``Pcfgaze: Physics-consistent feature for appearance-based gaze estimation,'' {\em arXiv preprint arXiv:2309.02165}, 2023.

\bibitem{parmar2017learning}
P.~Parmar and B.~Tran~Morris, ``Learning to score olympic events,'' in {\em IEEE Conference on Computer Vision and Pattern Recognition Workshops}, pp.~20--28, 2017.

\bibitem{zhang2023few}
J.~Zhang, L.~Liu, O.~Silven, M.~Pietik{\"a}inen, and D.~Hu, ``Few-shot class-incremental learning: A survey,'' {\em arXiv preprint arXiv:2308.06764}, 2023.

\bibitem{xu2025comprehensive}
S.~Xu, P.~Chen, Y.~Liu, M.~Wang, S.~Wang, H.~Yan, and S.~Kwong, ``Comprehensive action quality assessment through multi-branch modeling,'' {\em IEEE Transactions on Multimedia}, 2025.

\bibitem{deng2021flattening}
D.~Deng, G.~Chen, J.~Hao, Q.~Wang, and P.-A. Heng, ``Flattening sharpness for dynamic gradient projection memory benefits continual learning,'' {\em Advances in Neural Information Processing Systems}, vol.~34, pp.~18710--18721, 2021.

\end{thebibliography}
