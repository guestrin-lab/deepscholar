\section{Conclusion and Future Work}
\label{sec:conclude}


Our work investigates the potential of leveraging LLMs as an ethical component within the software engineering pipeline to automate the generation of user ethical profiles. The profiles represent users' ethical preferences in a structured way, guiding system behavior to align its decisions with user values. To achieve this, we evaluated the ethical reasoning capabilities of 16 state-of-the-art Large Language Models (LLMs) by presenting them with 30 ethically charged scenarios. We prompted LLMs to identify which ethical theory among utilitarianism, deontology, and virtue ethics applies to the action detailed in the scenario, determine whether the action described is morally acceptable, and provide the reasoning behind their choice. We then computed inter-model agreement between the responses of the 16 LLMs using Theory Consistency Rate (TCR) and Binary Agreement Rate %metrics
(BAR) \major{metrics}. We replicated the same process with three expert ethicists and compared their responses with LLMs using z-score\major{s} to analyze the agreement between their responses. Moreover, we performed qualitative analysis of the LLM explanations to determine whether models produce meaningful and theory-consistent explanations. The results indicate LLMs' applicability within the software engineering pipeline to evaluate ethical contexts. Future work will prompt LLMs to identify actions based on a broader set of ethical theories, and will examine the applicability and interactions of these theories in more complex scenarios. Moreover, we plan to investigate how this framework could be integrated in existing SE toolchains. 


\begin{comment}
Our work investigates whether LLMs can generate and reason over ethical profiles that reflect individual user values, and how such models can be incorporated into the engineering process of adaptive software systems. By doing so, we aim to advance the personalization and moral responsiveness of intelligent systems, opening pathways for more ethically aligned user experiences.


Also, future work to expand this approach to more than three theories as we did.

\subsection{Future work}
Finally, future work should explore how this profiling framework can be embedded into concrete SE tasks such as:

\begin{itemize}
    \item Adaptive code synthesis with ethical constraints;
    \item Prioritization of bug reports or features based on value-sensitive design;
    \item Auditing tool outputs for fairness or ethical bias;
    \item Transparent decision logs for compliance and regulation.
\end{itemize}

These applications will require integration with existing SE toolchains, validation in user studies, and consideration of performance trade-offs.

%\subsection{Revisiting the System Pipeline}

Figure~\ref{fig:pipeline} already outlines the high-level architecture of our profiling system. Future extensions will evolve this structure into a bidirectional and multi-layered loop that connects ethical input (from users or behavior) with:

\begin{itemize}
    \item Adaptive LLM selection (based on calibration or context);
    \item Scenario disambiguation (e.g., adding clarification questions);
    \item Dynamic reliability thresholds based on TCR/BAR variance.
\end{itemize}

\end{comment}

%The results of this study open multiple directions for extending the pipeline for automated ethical profiling in software engineering contexts. Our current framework demonstrates the viability of using LLMs as interpretable ethical reasoning components; future work can build on this foundation in the following ways.


%This would yield an architecture not just for static evaluation, but for ongoing ethical inference, adaptation, and negotiation key capabilities in future AI-driven SE agents.
