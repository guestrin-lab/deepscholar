\begin{thebibliography}{38}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Baade et~al.()Baade, Peng, and Harwath]{baadesyllablelm}
Alan Baade, Puyuan Peng, and David Harwath.
\newblock Syllablelm: Learning coarse semantic units for speech language models.
\newblock In \emph{The Thirteenth International Conference on Learning Representations}.

\bibitem[Baevski et~al.(2020)Baevski, Zhou, Mohamed, and Auli]{baevski2020wav2vec}
Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli.
\newblock wav2vec 2.0: A framework for self-supervised learning of speech representations.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 12449--12460, 2020.

\bibitem[Beyer et~al.(2023)Beyer, Izmailov, Kolesnikov, Caron, Kornblith, Zhai, Minderer, Tschannen, Alabdulmohsin, and Pavetic]{beyer2023flexivit}
Lucas Beyer, Pavel Izmailov, Alexander Kolesnikov, Mathilde Caron, Simon Kornblith, Xiaohua Zhai, Matthias Minderer, Michael Tschannen, Ibrahim Alabdulmohsin, and Filip Pavetic.
\newblock Flexivit: One model for all patch sizes.
\newblock In \emph{CVPR}, 2023.

\bibitem[Borsos et~al.(2023)Borsos, Marinier, Vincent, Kharitonov, Pietquin, Sharifi, Roblek, Teboul, Grangier, Tagliasacchi, et~al.]{borsos2023audiolm}
Zal{\'a}n Borsos, Rapha{\"e}l Marinier, Damien Vincent, Eugene Kharitonov, Olivier Pietquin, Matt Sharifi, Dominik Roblek, Olivier Teboul, David Grangier, Marco Tagliasacchi, et~al.
\newblock Audiolm: a language modeling approach to audio generation.
\newblock \emph{IEEE/ACM transactions on audio, speech, and language processing}, 31:\penalty0 2523--2533, 2023.

\bibitem[Clifton et~al.(2020)Clifton, Pappu, Reddy, Yu, Karlgren, Carterette, and Jones]{clifton2020spotify}
Ann Clifton, Aasish Pappu, Sravana Reddy, Yongze Yu, Jussi Karlgren, Ben Carterette, and Rosie Jones.
\newblock The spotify podcast dataset.
\newblock \emph{arXiv preprint arXiv:2004.04270}, 2020.

\bibitem[Copet et~al.(2023)Copet, Kreuk, Gat, Remez, Kant, Synnaeve, Adi, and D{\'e}fossez]{copet2023simple}
Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi, and Alexandre D{\'e}fossez.
\newblock Simple and controllable music generation.
\newblock \emph{Advances in Neural Information Processing Systems}, 36:\penalty0 47704--47720, 2023.

\bibitem[Cuervo \& Marxer(2024)Cuervo and Marxer]{cuervo2024scaling}
Santiago Cuervo and Ricard Marxer.
\newblock Scaling properties of speech language models.
\newblock \emph{arXiv preprint arXiv:2404.00685}, 2024.

\bibitem[D{\'e}fossez et~al.(2024)D{\'e}fossez, Mazar{\'e}, Orsini, Royer, P{\'e}rez, J{\'e}gou, Grave, and Zeghidour]{defossez2024moshi}
Alexandre D{\'e}fossez, Laurent Mazar{\'e}, Manu Orsini, Am{\'e}lie Royer, Patrick P{\'e}rez, Herv{\'e} J{\'e}gou, Edouard Grave, and Neil Zeghidour.
\newblock Moshi: a speech-text foundation model for real-time dialogue.
\newblock \emph{arXiv e-prints}, pp.\  arXiv--2410, 2024.

\bibitem[Fang et~al.(2024)Fang, Guo, Zhou, Ma, Zhang, and Feng]{fang2024llama}
Qingkai Fang, Shoutao Guo, Yan Zhou, Zhengrui Ma, Shaolei Zhang, and Yang Feng.
\newblock Llama-omni: Seamless speech interaction with large language models.
\newblock \emph{arXiv preprint arXiv:2409.06666}, 2024.

\bibitem[Galvez et~al.(2021)Galvez, Diamos, Ciro, Cer{\'o}n, Achorn, Gopi, Kanter, Lam, Mazumder, and Reddi]{galvez2021people}
Daniel Galvez, Greg Diamos, Juan Ciro, Juan~Felipe Cer{\'o}n, Keith Achorn, Anjali Gopi, David Kanter, Maximilian Lam, Mark Mazumder, and Vijay~Janapa Reddi.
\newblock The people's speech: A large-scale diverse english speech recognition dataset for commercial usage.
\newblock \emph{arXiv preprint arXiv:2111.09344}, 2021.

\bibitem[Hassid et~al.(2023)Hassid, Remez, Nguyen, Gat, Conneau, Kreuk, Copet, Defossez, Synnaeve, Dupoux, et~al.]{hassid2023textually}
Michael Hassid, Tal Remez, Tu~Anh Nguyen, Itai Gat, Alexis Conneau, Felix Kreuk, Jade Copet, Alexandre Defossez, Gabriel Synnaeve, Emmanuel Dupoux, et~al.
\newblock Textually pretrained speech language models.
\newblock \emph{Advances in Neural Information Processing Systems}, 36:\penalty0 63483--63501, 2023.

\bibitem[hexgrad(2025)]{hexgrad2025kokoro}
hexgrad.
\newblock Kokoro-82m --- when smaller means better in text-to-speech.
\newblock \url{https://huggingface.co/hexgrad/Kokoro-82M}, 2025.
\newblock Accessed: 2025-04-22.

\bibitem[Hoffmann et~al.(2022)Hoffmann, Borgeaud, Mensch, Buchatskaya, Cai, Rutherford, de~Las~Casas, Hendricks, Welbl, Clark, et~al.]{hoffmann2022training}
Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de~Las~Casas, Lisa~Anne Hendricks, Johannes Welbl, Aidan Clark, et~al.
\newblock Training compute-optimal large language models.
\newblock In \emph{Proceedings of the 36th International Conference on Neural Information Processing Systems}, pp.\  30016--30030, 2022.

\bibitem[Hsu et~al.(2021)Hsu, Bolte, Tsai, Lakhotia, Salakhutdinov, and Mohamed]{hsu2021hubert}
Wei-Ning Hsu, Benjamin Bolte, Yao-Hung~Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, and Abdelrahman Mohamed.
\newblock Hubert: Self-supervised speech representation learning by masked prediction of hidden units.
\newblock \emph{IEEE/ACM transactions on audio, speech, and language processing}, 29:\penalty0 3451--3460, 2021.

\bibitem[Kahn et~al.(2020)Kahn, Riviere, Zheng, Kharitonov, Xu, Mazar{\'e}, Karadayi, Liptchinsky, Collobert, Fuegen, et~al.]{kahn2020libri}
Jacob Kahn, Morgane Riviere, Weiyi Zheng, Evgeny Kharitonov, Qiantong Xu, Pierre-Emmanuel Mazar{\'e}, Julien Karadayi, Vitaliy Liptchinsky, Ronan Collobert, Christian Fuegen, et~al.
\newblock Libri-light: A benchmark for asr with limited or no supervision.
\newblock In \emph{ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pp.\  7669--7673. IEEE, 2020.

\bibitem[Kong et~al.(2020)Kong, Kim, and Bae]{kong2020hifi}
Jungil Kong, Jaehyeon Kim, and Jaekyoung Bae.
\newblock Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 17022--17033, 2020.

\bibitem[Kudo \& Richardson(2018)Kudo and Richardson]{kudo2018sentencepiece}
Taku Kudo and John Richardson.
\newblock Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations}. Association for Computational Linguistics, 2018.

\bibitem[Lakhotia et~al.(2021)Lakhotia, Kharitonov, Hsu, Adi, Polyak, Bolte, Nguyen, Copet, Baevski, Mohamed, et~al.]{lakhotia2021generative}
Kushal Lakhotia, Eugene Kharitonov, Wei-Ning Hsu, Yossi Adi, Adam Polyak, Benjamin Bolte, Tu-Anh Nguyen, Jade Copet, Alexei Baevski, Abdelrahman Mohamed, et~al.
\newblock On generative spoken language modeling from raw audio.
\newblock \emph{Transactions of the Association for Computational Linguistics}, 9:\penalty0 1336--1354, 2021.

\bibitem[Li et~al.(2024)Li, Shen, Guo, Wang, Chen, and Yu]{li2024effectiveness}
Bohan Li, Feiyu Shen, Yiwei Guo, Shuai Wang, Xie Chen, and Kai Yu.
\newblock On the effectiveness of acoustic bpe in decoder-only tts.
\newblock In \emph{Proc. Interspeech 2024}, pp.\  4134--4138, 2024.

\bibitem[Mostafazadeh et~al.(2016)Mostafazadeh, Chambers, He, Parikh, Batra, Vanderwende, Kohli, and Allen]{mostafazadeh2016corpus}
Nasrin Mostafazadeh, Nathanael Chambers, Xiaodong He, Devi Parikh, Dhruv Batra, Lucy Vanderwende, Pushmeet Kohli, and James Allen.
\newblock A corpus and evaluation framework for deeper understanding of commonsense stories.
\newblock \emph{arXiv preprint arXiv:1604.01696}, 2016.

\bibitem[Nachmani et~al.()Nachmani, Levkovitch, Hirsch, Salazar, Asawaroengchai, Mariooryad, Rivlin, Skerry-Ryan, and Ramanovich]{nachmanispoken}
Eliya Nachmani, Alon Levkovitch, Roy Hirsch, Julian Salazar, Chulayuth Asawaroengchai, Soroosh Mariooryad, Ehud Rivlin, RJ~Skerry-Ryan, and Michelle~Tadmor Ramanovich.
\newblock Spoken question answering and speech continuation using spectrogram-powered llm.
\newblock In \emph{The Twelfth International Conference on Learning Representations}.

\bibitem[Nguyen et~al.(2020)Nguyen, de~Seyssel, Roz{\'e}, Rivi{\`e}re, Kharitonov, Baevski, Dunbar, and Dupoux]{nguyen2020zero}
Tu~Anh Nguyen, Maureen de~Seyssel, Patricia Roz{\'e}, Morgane Rivi{\`e}re, Evgeny Kharitonov, Alexei Baevski, Ewan Dunbar, and Emmanuel Dupoux.
\newblock The zero resource speech benchmark 2021: Metrics and baselines for unsupervised spoken language modeling.
\newblock In \emph{NeuRIPS Workshop on Self-Supervised Learning for Speech and Audio Processing}, 2020.

\bibitem[Nguyen et~al.(2025)Nguyen, Muller, Yu, Costa-Jussa, Elbayad, Popuri, Ropers, Duquenne, Algayres, Mavlyutov, et~al.]{nguyen2025spirit}
Tu~Anh Nguyen, Benjamin Muller, Bokai Yu, Marta~R Costa-Jussa, Maha Elbayad, Sravya Popuri, Christophe Ropers, Paul-Ambroise Duquenne, Robin Algayres, Ruslan Mavlyutov, et~al.
\newblock Spirit-lm: Interleaved spoken and written language model.
\newblock \emph{Transactions of the Association for Computational Linguistics}, 13:\penalty0 30--52, 2025.

\bibitem[Pagnoni et~al.(2024)Pagnoni, Pasunuru, Rodriguez, Nguyen, Muller, Li, Zhou, Yu, Weston, Zettlemoyer, et~al.]{pagnoni2024byte}
Artidoro Pagnoni, Ram Pasunuru, Pedro Rodriguez, John Nguyen, Benjamin Muller, Margaret Li, Chunting Zhou, Lili Yu, Jason Weston, Luke Zettlemoyer, et~al.
\newblock Byte latent transformer: Patches scale better than tokens.
\newblock \emph{arXiv preprint arXiv:2412.09871}, 2024.

\bibitem[Pang et~al.(2024)Pang, Jin, Yang, Lin, Zhu, Tang, Chen, Tay, Lim, Yang, et~al.]{pang2024next}
Yatian Pang, Peng Jin, Shuo Yang, Bin Lin, Bin Zhu, Zhenyu Tang, Liuhan Chen, Francis~EH Tay, Ser-Nam Lim, Harry Yang, et~al.
\newblock Next patch prediction for autoregressive visual generation.
\newblock \emph{CoRR}, 2024.

\bibitem[Pratap et~al.(2020)Pratap, Xu, Sriram, Synnaeve, and Collobert]{pratap2020mls}
Vineel Pratap, Qiantong Xu, Anuroop Sriram, Gabriel Synnaeve, and Ronan Collobert.
\newblock Mls: A large-scale multilingual dataset for speech research.
\newblock \emph{arXiv preprint arXiv:2012.03411}, 2020.

\bibitem[Ren et~al.(2022)Ren, Liu, Wu, Zhou, and Wei]{ren2022speech}
Shuo Ren, Shujie Liu, Yu~Wu, Long Zhou, and Furu Wei.
\newblock Speech pre-training with acoustic piece.
\newblock In \emph{Proc. Interspeech 2022}, pp.\  2648--2652, 2022.

\bibitem[Rousseeuw(1987)]{rousseeuw1987silhouettes}
Peter Rousseeuw.
\newblock Silhouettes: a graphical aid to the interpretation and validation of cluster analysis.
\newblock \emph{Journal of Computational and Applied Mathematics}, 20\penalty0 (1):\penalty0 53--65, 1987.

\bibitem[Rubenstein et~al.(2023)Rubenstein, Asawaroengchai, Nguyen, Bapna, Borsos, Quitry, Chen, Badawy, Han, Kharitonov, et~al.]{rubenstein2023audiopalm}
Paul~K Rubenstein, Chulayuth Asawaroengchai, Duc~Dung Nguyen, Ankur Bapna, Zal{\'a}n Borsos, F{\'e}lix de~Chaumont Quitry, Peter Chen, Dalia~El Badawy, Wei Han, Eugene Kharitonov, et~al.
\newblock Audiopalm: A large language model that can speak and listen.
\newblock \emph{arXiv preprint arXiv:2306.12925}, 2023.

\bibitem[Touvron et~al.(2023)Touvron, Martin, Stone, Albert, Almahairi, Babaei, Bashlykov, Batra, Bhargava, Bhosale, et~al.]{touvron2023llama}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock \emph{arXiv preprint arXiv:2307.09288}, 2023.

\bibitem[Tseng et~al.(2025)Tseng, Chen, Lee, Shiu, and Lee]{tseng2025taste}
Liang-Hsuan Tseng, Yi-Chang Chen, Kuan-Yi Lee, Da-Shan Shiu, and Hung-yi Lee.
\newblock Taste: Text-aligned speech tokenization and embedding for spoken language modeling.
\newblock \emph{arXiv preprint arXiv:2504.07053}, 2025.

\bibitem[van~den Oord et~al.(2016)van~den Oord, Dieleman, Zen, Simonyan, Vinyals, Graves, Kalchbrenner, Senior, and Kavukcuoglu]{van2016wavenet}
A{\"a}ron van~den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu.
\newblock Wavenet: A generative model for raw audio.
\newblock In \emph{Proc. SSW 2016}, pp.\  125--125, 2016.

\bibitem[van~der Maaten \& Hinton(2008)van~der Maaten and Hinton]{van2008visualizing}
Laurens van~der Maaten and Geoffrey Hinton.
\newblock Visualizing data using t-sne.
\newblock \emph{Journal of Machine Learning Research}, 9:\penalty0 2579--2605, 2008.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Videau et~al.(2025)Videau, Idrissi, Leite, Schoenauer, Teytaud, and Lopez-Paz]{videau2025bytes}
Mathurin Videau, Badr~Youbi Idrissi, Alessandro Leite, Marc Schoenauer, Olivier Teytaud, and David Lopez-Paz.
\newblock From bytes to ideas: Language modeling with autoregressive u-nets.
\newblock \emph{arXiv preprint arXiv:2506.14761}, 2025.

\bibitem[Yu et~al.(2023)Yu, Simig, Flaherty, Aghajanyan, Zettlemoyer, and Lewis]{yu2023megabyte}
Lili Yu, D{\'a}niel Simig, Colin Flaherty, Armen Aghajanyan, Luke Zettlemoyer, and Mike Lewis.
\newblock Megabyte: Predicting million-byte sequences with multiscale transformers.
\newblock \emph{Advances in Neural Information Processing Systems}, 36:\penalty0 78808--78823, 2023.

\bibitem[Zeghidour et~al.(2021)Zeghidour, Luebs, Omran, Skoglund, and Tagliasacchi]{zeghidour2021soundstream}
Neil Zeghidour, Alejandro Luebs, Ahmed Omran, Jan Skoglund, and Marco Tagliasacchi.
\newblock Soundstream: An end-to-end neural audio codec.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 30:\penalty0 495--507, 2021.

\bibitem[Zellers et~al.(2019)Zellers, Holtzman, Bisk, Farhadi, and Choi]{zellers2019hellaswag}
Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi.
\newblock Hellaswag: Can a machine really finish your sentence?
\newblock \emph{arXiv preprint arXiv:1905.07830}, 2019.

\end{thebibliography}
