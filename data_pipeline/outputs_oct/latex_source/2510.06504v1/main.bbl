\begin{thebibliography}{50}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahn et~al.(2018)Ahn, Ha, Choi, Yoo, and Oh]{ahn2018text2action}
Hyemin Ahn, Timothy Ha, Yunho Choi, Hwiyeon Yoo, and Songhwai Oh.
\newblock Text2action: Generative adversarial synthesis from language to action.
\newblock In \emph{2018 IEEE International Conference on Robotics and Automation (ICRA)}, pp.\  5915--5920. IEEE, 2018.

\bibitem[Ahuja \& Morency(2019)Ahuja and Morency]{ahuja2019language2pose}
Chaitanya Ahuja and Louis-Philippe Morency.
\newblock Language2pose: Natural language grounded pose forecasting.
\newblock In \emph{2019 International conference on 3D vision (3DV)}, pp.\  719--728. IEEE, 2019.

\bibitem[Cai et~al.(2024)Cai, Jiang, Qing, Guo, Zhang, Lin, Mei, Wei, Wang, Yin, et~al.]{cai2024digital}
Zhongang Cai, Jianping Jiang, Zhongfei Qing, Xinying Guo, Mingyuan Zhang, Zhengyu Lin, Haiyi Mei, Chen Wei, Ruisi Wang, Wanqi Yin, et~al.
\newblock Digital life project: Autonomous 3d characters with social intelligence.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  582--592, 2024.

\bibitem[Chen et~al.(2023)Chen, Jiang, Liu, Huang, Fu, Chen, and Yu]{chen2023executing}
Xin Chen, Biao Jiang, Wen Liu, Zilong Huang, Bin Fu, Tao Chen, and Gang Yu.
\newblock Executing your commands via motion diffusion in latent space.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  18000--18010, 2023.

\bibitem[Cong et~al.(2024)Cong, Wang, Dou, Ren, Yin, Cheng, Sun, Long, Zhu, and Ma]{cong2024laserhuman}
Peishan Cong, Ziyi Wang, Zhiyang Dou, Yiming Ren, Wei Yin, Kai Cheng, Yujing Sun, Xiaoxiao Long, Xinge Zhu, and Yuexin Ma.
\newblock Laserhuman: Language-guided scene-aware human motion generation in free environment.
\newblock \emph{arXiv preprint arXiv:2403.13307}, 2024.

\bibitem[Dou et~al.(2023)Dou, Chen, Fan, Komura, and Wang]{dou2023c}
Zhiyang Dou, Xuelin Chen, Qingnan Fan, Taku Komura, and Wenping Wang.
\newblock C{\textperiodcentered} ase: Learning conditional adversarial skill embeddings for physics-based characters.
\newblock In \emph{SIGGRAPH Asia 2023 Conference Papers}, pp.\  1--11, 2023.

\bibitem[Fan et~al.(2024)Fan, Tang, Cao, Yi, Li, Gong, Zhang, Wang, Wang, and Ma]{fan2024freemotion}
Ke~Fan, Junshu Tang, Weijian Cao, Ran Yi, Moran Li, Jingyu Gong, Jiangning Zhang, Yabiao Wang, Chengjie Wang, and Lizhuang Ma.
\newblock Freemotion: A unified framework for number-free text-to-motion synthesis.
\newblock In \emph{European Conference on Computer Vision}, pp.\  93--109. Springer, 2024.

\bibitem[Guo et~al.(2022)Guo, Zou, Zuo, Wang, Ji, Li, and Cheng]{guo2022generating}
Chuan Guo, Shihao Zou, Xinxin Zuo, Sen Wang, Wei Ji, Xingyu Li, and Li~Cheng.
\newblock Generating diverse and natural 3d human motions from text.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  5152--5161, 2022.

\bibitem[Guo et~al.(2024)Guo, Mu, Javed, Wang, and Cheng]{guo2024momask}
Chuan Guo, Yuxuan Mu, Muhammad~Gohar Javed, Sen Wang, and Li~Cheng.
\newblock Momask: Generative masked modeling of 3d human motions.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  1900--1910, 2024.

\bibitem[Ho \& Salimans(2022)Ho and Salimans]{ho2022classifier}
Jonathan Ho and Tim Salimans.
\newblock Classifier-free diffusion guidance.
\newblock \emph{arXiv preprint arXiv:2207.12598}, 2022.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 6840--6851, 2020.

\bibitem[Huang et~al.(2024{\natexlab{a}})Huang, Li, Xu, Pan, Wang, and Lee]{huang2024closely}
Buzhen Huang, Chen Li, Chongyang Xu, Liang Pan, Yangang Wang, and Gim~Hee Lee.
\newblock Closely interactive human reconstruction with proxemics and physics-guided adaption.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  1011--1021, 2024{\natexlab{a}}.

\bibitem[Huang et~al.(2024{\natexlab{b}})Huang, Wan, Yang, Callison-Burch, Yatskar, and Liu]{huang2024controllable}
Yiming Huang, Weilin Wan, Yue Yang, Chris Callison-Burch, Mark Yatskar, and Lingjie Liu.
\newblock Como: Controllable motion generation through language guided pose code editing.
\newblock In \emph{European Conference on Computer Vision}, pp.\  180--196. Springer, 2024{\natexlab{b}}.

\bibitem[Huang et~al.(2025)Huang, Dou, and Liu]{huang2025modskill}
Yiming Huang, Zhiyang Dou, and Lingjie Liu.
\newblock Modskill: Physical character skill modularization.
\newblock \emph{arXiv preprint arXiv:2502.14140}, 2025.

\bibitem[Javed et~al.(2024)Javed, Guo, Cheng, and Li]{javed2024intermask}
Muhammad~Gohar Javed, Chuan Guo, Li~Cheng, and Xingyu Li.
\newblock Intermask: 3d human interaction generation via collaborative masked modelling.
\newblock \emph{arXiv preprint arXiv:2410.10010}, 2024.

\bibitem[Jeong et~al.(2024)Jeong, Park, and Yoon]{jeong2024multi}
Jaewoo Jeong, Daehee Park, and Kuk-Jin Yoon.
\newblock Multi-agent long-term 3d human pose forecasting via interaction-aware trajectory conditioning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  1617--1628, 2024.

\bibitem[Jiang et~al.(2023{\natexlab{a}})Jiang, Chen, Liu, Yu, Yu, and Chen]{jiang2023motiongpt}
Biao Jiang, Xin Chen, Wen Liu, Jingyi Yu, Gang Yu, and Tao Chen.
\newblock Motiongpt: Human motion as a foreign language.
\newblock \emph{Advances in Neural Information Processing Systems}, 36:\penalty0 20067--20079, 2023{\natexlab{a}}.

\bibitem[Jiang et~al.(2023{\natexlab{b}})Jiang, Won, Ye, and Liu]{jiang2023drop}
Yifeng Jiang, Jungdam Won, Yuting Ye, and C~Karen Liu.
\newblock Drop: Dynamics responses from human motion prior and projective dynamics.
\newblock In \emph{SIGGRAPH Asia 2023 Conference Papers}, pp.\  1--11, 2023{\natexlab{b}}.

\bibitem[Karunratanakul et~al.(2023)Karunratanakul, Preechakul, Suwajanakorn, and Tang]{karunratanakul2023guided}
Korrawe Karunratanakul, Konpat Preechakul, Supasorn Suwajanakorn, and Siyu Tang.
\newblock Guided motion diffusion for controllable human motion synthesis.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  2151--2162, 2023.

\bibitem[Li et~al.(2023)Li, Dong, Jia, Huang, Kampffmeyer, Lin, and Liang]{li2023coordinate}
Haoyuan Li, Haoye Dong, Hanchao Jia, Dong Huang, Michael~C Kampffmeyer, Liang Lin, and Xiaodan Liang.
\newblock Coordinate transformer: Achieving single-stage multi-person mesh recovery from videos.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  8744--8753, 2023.

\bibitem[Liang et~al.(2024)Liang, Zhang, Li, Yu, and Xu]{liang2024intergen}
Han Liang, Wenqian Zhang, Wenxuan Li, Jingyi Yu, and Lan Xu.
\newblock Intergen: Diffusion-based multi-human motion generation under complex interactions.
\newblock \emph{International Journal of Computer Vision}, 132\penalty0 (9):\penalty0 3463--3483, 2024.

\bibitem[Liu et~al.(2024)Liu, Feng, Xue, Wang, Wu, Lu, Zhao, Deng, Zhang, Ruan, et~al.]{liu2024deepseek}
Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, et~al.
\newblock Deepseek-v3 technical report.
\newblock \emph{arXiv preprint arXiv:2412.19437}, 2024.

\bibitem[Loshchilov \& Hutter(2017)Loshchilov and Hutter]{loshchilov2017decoupled}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock \emph{arXiv preprint arXiv:1711.05101}, 2017.

\bibitem[Lu et~al.(2024)Lu, Wang, Lu, Chen, Dai, Dong, Dou, Dai, and Zhang]{lu2024scamo}
Shunlin Lu, Jingbo Wang, Zeyu Lu, Ling-Hao Chen, Wenxun Dai, Junting Dong, Zhiyang Dou, Bo~Dai, and Ruimao Zhang.
\newblock Scamo: Exploring the scaling law in autoregressive motion generation model.
\newblock \emph{CVPR 2025}, 2024.

\bibitem[Luo et~al.(2023)Luo, Cao, Merel, Winkler, Huang, Kitani, and Xu]{luo2023universal}
Zhengyi Luo, Jinkun Cao, Josh Merel, Alexander Winkler, Jing Huang, Kris Kitani, and Weipeng Xu.
\newblock Universal humanoid motion representations for physics-based control.
\newblock \emph{arXiv preprint arXiv:2310.04582}, 2023.

\bibitem[McInnes et~al.(2018)McInnes, Healy, and Melville]{mcinnes2018umap}
Leland McInnes, John Healy, and James Melville.
\newblock Umap: Uniform manifold approximation and projection for dimension reduction.
\newblock \emph{arXiv preprint arXiv:1802.03426}, 2018.

\bibitem[Nichol \& Dhariwal(2021)Nichol and Dhariwal]{nichol2021improved}
Alexander~Quinn Nichol and Prafulla Dhariwal.
\newblock Improved denoising diffusion probabilistic models.
\newblock In \emph{International conference on machine learning}, pp.\  8162--8171. PMLR, 2021.

\bibitem[Peng et~al.(2018)Peng, Abbeel, Levine, and Van~de Panne]{peng2018deepmimic}
Xue~Bin Peng, Pieter Abbeel, Sergey Levine, and Michiel Van~de Panne.
\newblock Deepmimic: Example-guided deep reinforcement learning of physics-based character skills.
\newblock \emph{ACM Transactions On Graphics (TOG)}, 37\penalty0 (4):\penalty0 1--14, 2018.

\bibitem[Peng et~al.(2022)Peng, Guo, Halper, Levine, and Fidler]{peng2022ase}
Xue~Bin Peng, Yunrong Guo, Lina Halper, Sergey Levine, and Sanja Fidler.
\newblock Ase: Large-scale reusable adversarial skill embeddings for physically simulated characters.
\newblock \emph{ACM Transactions On Graphics (TOG)}, 41\penalty0 (4):\penalty0 1--17, 2022.

\bibitem[Petrovich et~al.(2022)Petrovich, Black, and Varol]{petrovich2022temos}
Mathis Petrovich, Michael~J Black, and G{\"u}l Varol.
\newblock Temos: Generating diverse human motions from textual descriptions.
\newblock In \emph{European Conference on Computer Vision}, pp.\  480--497. Springer, 2022.

\bibitem[Ponce et~al.(2024)Ponce, Barquero, Palmero, Escalera, and Garcia-Rodriguez]{ponce2024in2in}
Pablo~Ruiz Ponce, German Barquero, Cristina Palmero, Sergio Escalera, and Jose Garcia-Rodriguez.
\newblock in2in: Leveraging individual information to generate human interactions.
\newblock \emph{arXiv preprint arXiv:2404.09988}, 2024.

\bibitem[Qiu et~al.(2023)Qiu, Yang, Wang, Feng, Han, Ding, Xu, Fu, and Wang]{qiu2023psvt}
Zhongwei Qiu, Qiansheng Yang, Jian Wang, Haocheng Feng, Junyu Han, Errui Ding, Chang Xu, Dongmei Fu, and Jingdong Wang.
\newblock Psvt: End-to-end multi-person 3d pose and shape estimation with progressive video transformers.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  21254--21263, 2023.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{International conference on machine learning}, pp.\  8748--8763. PmLR, 2021.

\bibitem[Ruiz-Ponce et~al.(2024)Ruiz-Ponce, Barquero, Palmero, Escalera, and Garc{\'\i}a-Rodr{\'\i}guez]{ruiz2024in2in}
Pablo Ruiz-Ponce, German Barquero, Cristina Palmero, Sergio Escalera, and Jos{\'e} Garc{\'\i}a-Rodr{\'\i}guez.
\newblock in2in: Leveraging individual information to generate human interactions.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  1941--1951, 2024.

\bibitem[Shafir et~al.(2023)Shafir, Tevet, Kapon, and Bermano]{shafir2023human}
Yonatan Shafir, Guy Tevet, Roy Kapon, and Amit~H Bermano.
\newblock Human motion diffusion as a generative prior.
\newblock \emph{arXiv preprint arXiv:2303.01418}, 2023.

\bibitem[Song et~al.(2020)Song, Meng, and Ermon]{song2020denoising}
Jiaming Song, Chenlin Meng, and Stefano Ermon.
\newblock Denoising diffusion implicit models.
\newblock \emph{arXiv preprint arXiv:2010.02502}, 2020.

\bibitem[Tanaka \& Fujiwara(2023)Tanaka and Fujiwara]{tanaka2023role}
Mikihiro Tanaka and Kent Fujiwara.
\newblock Role-aware interaction generation from textual description.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pp.\  15999--16009, 2023.

\bibitem[Tanke et~al.(2023)Tanke, Zhang, Zhao, Tang, Cai, Wang, Wu, Gall, and Keskin]{tanke2023social}
Julian Tanke, Linguang Zhang, Amy Zhao, Chengcheng Tang, Yujun Cai, Lezi Wang, Po-Chen Wu, Juergen Gall, and Cem Keskin.
\newblock Social diffusion: Long-term multiple human motion anticipation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  9601--9611, 2023.

\bibitem[Tevet et~al.(2022{\natexlab{a}})Tevet, Gordon, Hertz, Bermano, and Cohen-Or]{tevet2022motionclip}
Guy Tevet, Brian Gordon, Amir Hertz, Amit~H Bermano, and Daniel Cohen-Or.
\newblock Motionclip: Exposing human motion generation to clip space.
\newblock In \emph{European Conference on Computer Vision}, pp.\  358--374. Springer, 2022{\natexlab{a}}.

\bibitem[Tevet et~al.(2022{\natexlab{b}})Tevet, Raab, Gordon, Shafir, Cohen-Or, and Bermano]{tevet2022human}
Guy Tevet, Sigal Raab, Brian Gordon, Yonatan Shafir, Daniel Cohen-Or, and Amit~H Bermano.
\newblock Human motion diffusion model.
\newblock \emph{arXiv preprint arXiv:2209.14916}, 2022{\natexlab{b}}.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Wan et~al.(2024)Wan, Dou, Komura, Wang, Jayaraman, and Liu]{wan2024tlcontrol}
Weilin Wan, Zhiyang Dou, Taku Komura, Wenping Wang, Dinesh Jayaraman, and Lingjie Liu.
\newblock Tlcontrol: Trajectory and language control for human motion synthesis.
\newblock In \emph{ECCV 2024}. 2024.

\bibitem[Wang et~al.(2024)Wang, Wang, Zhang, Fan, Wu, Jiang, and Liu]{wang2024temporal}
Yabiao Wang, Shuo Wang, Jiangning Zhang, Ke~Fan, Jiafu Wu, Zhengkai Jiang, and Yong Liu.
\newblock Temporal and interactive modeling for efficient human-human motion generation.
\newblock \emph{arXiv preprint arXiv:2408.17135}, 2024.

\bibitem[Xie et~al.(2023)Xie, Jampani, Zhong, Sun, and Jiang]{xie2023omnicontrol}
Yiming Xie, Varun Jampani, Lei Zhong, Deqing Sun, and Huaizu Jiang.
\newblock Omnicontrol: Control any joint at any time for human motion generation.
\newblock \emph{arXiv preprint arXiv:2310.08580}, 2023.

\bibitem[Xu et~al.(2025)Xu, Dou, Shi, Pan, Ho, Wang, Liu, Lin, Ma, Wang, and Komura]{xu2025mospa}
Shuyang Xu, Zhiyang Dou, Mingyi Shi, Liang Pan, Leo Ho, Jingbo Wang, Yuan Liu, Cheng Lin, Yuexin Ma, Wenping Wang, and Taku Komura.
\newblock Mospa: Human motion generation driven by spatial audio.
\newblock \emph{NeurIPS 2025 Spotlight}, 2025.

\bibitem[Yuan et~al.(2022)Yuan, Iqbal, Molchanov, Kitani, and Kautz]{yuan2022glamr}
Ye~Yuan, Umar Iqbal, Pavlo Molchanov, Kris Kitani, and Jan Kautz.
\newblock Glamr: Global occlusion-aware human mesh recovery with dynamic cameras.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  11038--11049, 2022.

\bibitem[Zhang et~al.(2023{\natexlab{a}})Zhang, Zhang, Cun, Zhang, Zhao, Lu, Shen, and Shan]{zhang2023generating}
Jianrong Zhang, Yangsong Zhang, Xiaodong Cun, Yong Zhang, Hongwei Zhao, Hongtao Lu, Xi~Shen, and Ying Shan.
\newblock Generating human motion from textual descriptions with discrete representations.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  14730--14740, 2023{\natexlab{a}}.

\bibitem[Zhang et~al.(2023{\natexlab{b}})Zhang, Guo, Pan, Cai, Hong, Li, Yang, and Liu]{zhang2023remodiffuse}
Mingyuan Zhang, Xinying Guo, Liang Pan, Zhongang Cai, Fangzhou Hong, Huirong Li, Lei Yang, and Ziwei Liu.
\newblock Remodiffuse: Retrieval-augmented motion diffusion model.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  364--373, 2023{\natexlab{b}}.

\bibitem[Zhang et~al.(2024)Zhang, Kephart, Cui, and Ji]{zhang2024physpt}
Yufei Zhang, Jeffrey~O Kephart, Zijun Cui, and Qiang Ji.
\newblock Physpt: Physics-aware pretrained transformer for estimating human dynamics from monocular videos.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  2305--2317, 2024.

\bibitem[Zhou et~al.(2024)Zhou, Dou\#, Cao, Liao, Wang, Wang, Liu, Komura, Wang, and Liu]{zhou2024emdm}
Wenyang Zhou, Zhiyang Dou\#, Zeyu Cao, Zhouyingcheng Liao, Jingbo Wang, Wenjia Wang, Yuan Liu, Taku Komura, Wenping Wang, and Lingjie Liu.
\newblock Emdm: Efficient motion diffusion model for fast and high-quality motion generation.
\newblock In \emph{ECCV 2024}. 2024.

\end{thebibliography}
