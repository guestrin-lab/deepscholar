\section{Introduction}
\label{sec:intro}

Automated visual defect detection is critical for quality assurance in numerous industrial and logistics processes. Particularly at the scale of large retailers that handle millions of unique items, accurate detection of anomalies can significantly reduce costs, minimize waste, and enhance overall operational efficiency. However, developing robust visual defect detection systems in retail logistics applications presents significant challenges that have yet to be fully addressed by existing research.
The primary challenge stems from the diversity of items and the rarity of defects, which makes building supervised-learning datasets costly and time-consuming. This scarcity of training data leads to highly imbalanced datasets, necessitating unsupervised and anomaly-detection (AD) approaches.

State-of-the-art unsupervised and AD methods for visual defect detection achieve exceptional performance under controlled manufacturing conditions, reaching 99.9\% \cite{chen2024unified} and 99.5\% \cite{yao2024gladbetterreconstructionglobal} AUROC on MVTec-AD~\citep{bergmann_mvtec_2021} and VisA~\citep{zou2022spot} datasets, respectively. However, these methods struggle in complex logistics environments like Amazon's retail operations, where millions of diverse products flow through logistics centers. The challenges are multifaceted (Figure~\ref{fig:damage_comparison}): products range from consumables to electronics, each with distinct physical properties; defects vary from minor creases to major spillages, often with subtle manifestations that challenge even human inspectors; most items are observed only a few times, limiting both defective and non-defective sample availability; and significant pose variation occurs due to random product placement.

To enable researchers to overcome these challenges, we introduce a novel large-scale dataset for \emph{visual defect detection in retail logistics applications}. Our dataset significantly advances the field by addressing key limitations of existing benchmarks and poses the following key question: How can we build generalizable visual defect detection methods under challenging conditions such as limited instances per item, limited availability of both defective and non-defective samples per item, and significant intra-class variation?

Our key contribution is a challenging defect detection dataset with unparalleled scale and diversity of products, structured to enable the development of novel supervised, unsupervised, and hybrid approaches. The dataset comprises 238,421 images of 48,376 unique items. Items are presented in random poses and orientations, closely mirroring real-world retail logistics scenarios. The dataset is split into annotated and unannotated portions: the annotated \emph{query image} dataset contains 100,267 images, including 29,316 defective instances. For all query images, we provide qualitative defect severity and fine-grained defect type annotations, reflecting the subjectivity present in defect assessment. Additionally, each query image is associated with up to three unannotated \emph{reference images} that depict items in a ``normal`` condition (Figure~\ref{fig:query_reference_samples}). We feature diverse product categories, seven distinct defect types, and high-resolution images capturing obvious and subtle defects.

To substantiate the challenge posed by our dataset, we evaluate numerous state-of-the-art baselines. First, we demonstrate that supervised baselines~\citep{resnet2016,dosovitskiy_vit_2020} with access to a large training set of defective instances achieve up to 94.27\% AUROC. These methods achieve high performance by learning common defect pattern priors, while struggling in edge cases and ``adversarial'' items, such as items with damage-like designs (\eg a printed hole) or deformable items where creases may arise naturally without negatively impacting the product. We then demonstrate that these supervised methods fall short of yielding such performance under more realistic conditions, when only few defective samples are available for training. In such scenarios, unsupervised and anomaly detection baselines~\citep{roth2022towards,jeong2023winclip} were shown to excel~\citep{yao2024gladbetterreconstructionglobal} on related datasets like MVTec-AD~\citep{bergmann_mvtec_2021} or VisA~\citep{zou2022spot}. However, we demonstrate that these methods, as well as state-of-the-art vision-language models~\citep{claude-model-card, agrawal2024pixtral12b}, fail to surpass 56.96\% AUROC on our dataset. Qualitative analyses confirm that these methods struggle with item and pose variability as well as limited access to non-defective samples of the query item.

These results underscore the relevance of our dataset to the anomaly detection community in developing more robust and generalizable methods. By introducing this comprehensive dataset, we aim to stimulate progress in visual defect detection for retail logistics applications. We believe this unique resource will enable researchers and practitioners to develop more robust and generalizable models, capable of handling the complexities and nuances of real-world defect detection tasks.
The dataset is available for download under \url{https://www.kaputt-dataset.com}.
