\begin{thebibliography}{57}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abdin et~al.(2025)Abdin, Agarwal, Awadallah, Balachandran, Behl, Chen, de~Rosa, Gunasekar, Javaheripi, Joshi, et~al.]{abdin2025phi}
Marah Abdin, Sahaj Agarwal, Ahmed Awadallah, Vidhisha Balachandran, Harkirat Behl, Lingjiao Chen, Gustavo de~Rosa, Suriya Gunasekar, Mojan Javaheripi, Neel Joshi, et~al.
\newblock Phi-4-reasoning technical report.
\newblock \emph{arXiv preprint arXiv:2504.21318}, 2025.

\bibitem[Andriushchenko et~al.(2025)Andriushchenko, Souly, Dziemian, Duenas, Lin, Wang, Hendrycks, Zou, Kolter, Fredrikson, Gal, and Davies]{andriushchenko2025agentharm}
Maksym Andriushchenko, Alexandra Souly, Mateusz Dziemian, Derek Duenas, Maxwell Lin, Justin Wang, Dan Hendrycks, Andy Zou, J~Zico Kolter, Matt Fredrikson, Yarin Gal, and Xander Davies.
\newblock Agentharm: A benchmark for measuring harmfulness of {LLM} agents.
\newblock In \emph{The Thirteenth International Conference on Learning Representations}, 2025.
\newblock URL \url{https://openreview.net/forum?id=AC5n7xHuR1}.

\bibitem[Anonymous(2025)]{2025bhasha}
Authors Anonymous.
\newblock Bhashakritika: Building synthetic pretraining data at scale for indic languages.
\newblock \emph{Under submission}, 2025.

\bibitem[Ardila et~al.(2020)Ardila, Branson, Davis, Kohler, Meyer, Henretty, Morais, Saunders, Tyers, and Weber]{ardila-etal-2020-common}
Rosana Ardila, Megan Branson, Kelly Davis, Michael Kohler, Josh Meyer, Michael Henretty, Reuben Morais, Lindsay Saunders, Francis Tyers, and Gregor Weber.
\newblock Common voice: A massively-multilingual speech corpus.
\newblock In Nicoletta Calzolari, Fr{\'e}d{\'e}ric B{\'e}chet, Philippe Blache, Khalid Choukri, Christopher Cieri, Thierry Declerck, Sara Goggi, Hitoshi Isahara, Bente Maegaard, Joseph Mariani, H{\'e}l{\`e}ne Mazo, Asuncion Moreno, Jan Odijk, and Stelios Piperidis (eds.), \emph{Proceedings of the Twelfth Language Resources and Evaluation Conference}, pp.\  4218--4222, Marseille, France, May 2020. European Language Resources Association.
\newblock ISBN 979-10-95546-34-4.
\newblock URL \url{https://aclanthology.org/2020.lrec-1.520/}.

\bibitem[Basu et~al.(2025)Basu, Abdelaziz, Kate, Agarwal, Crouse, Rizk, Bradford, Munawar, Kumaravel, Goyal, Wang, Lastras, and Kapanipathi]{basu2025nestfulbenchmarkevaluatingllms}
Kinjal Basu, Ibrahim Abdelaziz, Kiran Kate, Mayank Agarwal, Maxwell Crouse, Yara Rizk, Kelsey Bradford, Asim Munawar, Sadhana Kumaravel, Saurabh Goyal, Xin Wang, Luis~A. Lastras, and Pavan Kapanipathi.
\newblock Nestful: A benchmark for evaluating llms on nested sequences of api calls, 2025.
\newblock URL \url{https://arxiv.org/abs/2409.03797}.

\bibitem[Boisvert et~al.(2025)Boisvert, Puri, Huang, Bansal, Evuru, Bose, Fazel, Cappart, Lacoste, Drouin, and Dvijotham]{boisvert2025doomarena}
L{\'e}o Boisvert, Abhay Puri, Gabriel Huang, Mihir Bansal, Chandra Kiran~Reddy Evuru, Avinandan Bose, Maryam Fazel, Quentin Cappart, Alexandre Lacoste, Alexandre Drouin, and Krishnamurthy~Dj Dvijotham.
\newblock Doomarena: A framework for testing {AI} agents against evolving security threats.
\newblock In \emph{Second Conference on Language Modeling}, 2025.
\newblock URL \url{https://openreview.net/forum?id=GanmYQ0RpE}.

\bibitem[Chen et~al.(2024{\natexlab{a}})Chen, Yue, Zhang, Gao, Tan, and Li]{DBLP:journals/corr/abs-2410-17196}
Yiming Chen, Xianghu Yue, Chen Zhang, Xiaoxue Gao, Robby~T. Tan, and Haizhou Li.
\newblock Voicebench: Benchmarking llm-based voice assistants.
\newblock \emph{CoRR}, abs/2410.17196, 2024{\natexlab{a}}.
\newblock URL \url{https://doi.org/10.48550/arXiv.2410.17196}.

\bibitem[Chen et~al.(2024{\natexlab{b}})Chen, Huang, Andrusenko, Hrinchuk, Puvvada, Li, Ghosh, Balam, and Ginsburg]{chen2024salm}
Zhehuai Chen, He~Huang, Andrei Andrusenko, Oleksii Hrinchuk, Krishna~C. Puvvada, Jason Li, Subhankar Ghosh, Jagadeesh Balam, and Boris Ginsburg.
\newblock Salm: Speech-augmented language model with in-context learning for speech recognition and translation.
\newblock In \emph{ICASSP}, pp.\  13521--13525, 2024{\natexlab{b}}.
\newblock URL \url{https://doi.org/10.1109/ICASSP48485.2024.10447553}.

\bibitem[Chu et~al.(2024)Chu, Xu, Yang, Wei, Wei, Guo, Leng, Lv, He, Lin, Zhou, and Zhou]{chu2024qwen2audiotechnicalreport}
Yunfei Chu, Jin Xu, Qian Yang, Haojie Wei, Xipin Wei, Zhifang Guo, Yichong Leng, Yuanjun Lv, Jinzheng He, Junyang Lin, Chang Zhou, and Jingren Zhou.
\newblock Qwen2-audio technical report, 2024.
\newblock URL \url{https://arxiv.org/abs/2407.10759}.

\bibitem[DeepSeek-AI et~al.(2024)DeepSeek-AI, Zhu, Guo, Shao, Yang, Wang, Xu, Wu, Li, Gao, Ma, Zeng, Bi, Gu, Xu, Dai, Dong, Zhang, Piao, Gou, Xie, Hao, Wang, Song, Chen, Xie, Guan, You, Liu, Du, Gao, Lu, Chen, Wang, Deng, Li, Zhao, Ruan, Luo, and Liang]{DBLP:journals/corr/abs-2406-11931}
DeepSeek-AI, Qihao Zhu, Daya Guo, Zhihong Shao, Dejian Yang, Peiyi Wang, Runxin Xu, Y.~Wu, Yukun Li, Huazuo Gao, Shirong Ma, Wangding Zeng, Xiao Bi, Zihui Gu, Hanwei Xu, Damai Dai, Kai Dong, Liyue Zhang, Yishi Piao, Zhibin Gou, Zhenda Xie, Zhewen Hao, Bingxuan Wang, Junxiao Song, Deli Chen, Xin Xie, Kang Guan, Yuxiang You, Aixin Liu, Qiushi Du, Wenjun Gao, Xuan Lu, Qinyu Chen, Yaohui Wang, Chengqi Deng, Jiashi Li, Chenggang Zhao, Chong Ruan, Fuli Luo, and Wenfeng Liang.
\newblock Deepseek-coder-v2: Breaking the barrier of closed-source models in code intelligence.
\newblock \emph{CoRR}, abs/2406.11931, 2024.
\newblock URL \url{https://doi.org/10.48550/arXiv.2406.11931}.

\bibitem[Desplanques et~al.(2020)Desplanques, Thienpondt, and Demuynck]{Desplanques_2020}
Brecht Desplanques, Jenthe Thienpondt, and Kris Demuynck.
\newblock Ecapa-tdnn: Emphasized channel attention, propagation and aggregation in {TDNN} based speaker verification.
\newblock In \emph{Interspeech 2020}. ISCA, October 2020.
\newblock \doi{10.21437/Interspeech.2020-2650}.

\bibitem[Di~Gangi et~al.(2019)Di~Gangi, Cattoni, Bentivogli, Negri, and Turchi]{di-gangi-etal-2019-must}
Mattia~A. Di~Gangi, Roldano Cattoni, Luisa Bentivogli, Matteo Negri, and Marco Turchi.
\newblock {M}u{ST}-{C}: a {M}ultilingual {S}peech {T}ranslation {C}orpus.
\newblock In Jill Burstein, Christy Doran, and Thamar Solorio (eds.), \emph{Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)}, pp.\  2012--2017, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/N19-1202}.
\newblock URL \url{https://aclanthology.org/N19-1202/}.

\bibitem[Elizalde et~al.(2023)Elizalde, Deshmukh, Ismail, and Wang]{10095889}
Benjamin Elizalde, Soham Deshmukh, Mahmoud~Al Ismail, and Huaming Wang.
\newblock Clap learning audio concepts from natural language supervision.
\newblock In \emph{ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pp.\  1--5, 2023.
\newblock \doi{10.1109/ICASSP49357.2023.10095889}.

\bibitem[Farn \& Shin(2023)Farn and Shin]{farn2023tooltalkevaluatingtoolusageconversational}
Nicholas Farn and Richard Shin.
\newblock Tooltalk: Evaluating tool-usage in a conversational setting, 2023.
\newblock URL \url{https://arxiv.org/abs/2311.10775}.

\bibitem[Gao et~al.(2024)Gao, Xiong, Gao, Jia, Pan, Bi, Dai, Sun, Wang, and Wang]{gao2024retrievalaugmentedgenerationlargelanguage}
Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi~Dai, Jiawei Sun, Meng Wang, and Haofen Wang.
\newblock Retrieval-augmented generation for large language models: A survey, 2024.
\newblock URL \url{https://arxiv.org/abs/2312.10997}.

\bibitem[Ghosh \& Duraiswami(2025)Ghosh and Duraiswami]{ghosh2025audio}
Sreyan Ghosh and Ramani Duraiswami.
\newblock Audio flamingo 3: Advancing audio intelligence with fully open large audio language models.
\newblock In \emph{TTIC Summer Workshop on Foundations of Speech and Audio Foundation Models 2025}, 2025.
\newblock URL \url{https://openreview.net/forum?id=6QVkUdLJFK}.

\bibitem[Gong et~al.(2024)Gong, Luo, Liu, Karlinsky, and Glass]{gong2024listen}
Yuan Gong, Hongyin Luo, Alexander~H. Liu, Leonid Karlinsky, and James~R. Glass.
\newblock Listen, think, and understand.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=nBZBPXdJlC}.

\bibitem[Grattafiori et~al.(2024)Grattafiori, Dubey, Jauhri, Pandey, Kadian, Al-Dahle, Letman, Mathur, Schelten, Vaughan, et~al.]{grattafiori2024llama}
Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, et~al.
\newblock The llama 3 herd of models.
\newblock \emph{arXiv preprint arXiv:2407.21783}, 2024.

\bibitem[Guo et~al.(2025)Guo, Yang, Zhang, Song, Zhang, Xu, Zhu, Ma, Wang, Bi, et~al.]{guo2025deepseek}
Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et~al.
\newblock Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2501.12948}, 2025.

\bibitem[Guzhov et~al.(2022)Guzhov, Raue, Hees, and Dengel]{9747631}
Andrey Guzhov, Federico Raue, Jörn Hees, and Andreas Dengel.
\newblock Audioclip: Extending clip to image, text and audio.
\newblock In \emph{ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 2022.

\bibitem[Hu et~al.(2024)Hu, Zhou, Liu, Chen, Hao, Pan, Liu, Li, Sivasankaran, Liu, and Wei]{DBLP:journals/corr/abs-2404-00656}
Shujie Hu, Long Zhou, Shujie Liu, Sanyuan Chen, Hongkun Hao, Jing Pan, Xunying Liu, Jinyu Li, Sunit Sivasankaran, Linquan Liu, and Furu Wei.
\newblock Wavllm: Towards robust and adaptive speech large language model.
\newblock \emph{CoRR}, abs/2404.00656, 2024.
\newblock URL \url{https://doi.org/10.48550/arXiv.2404.00656}.

\bibitem[Huang et~al.(2024)Huang, Li, Yang, Shi, Chang, Ye, Wu, Hong, Huang, Liu, Ren, Zou, Zhao, and Watanabe]{DBLP:conf/aaai/HuangLYSCYWHHLR24}
Rongjie Huang, Mingze Li, Dongchao Yang, Jiatong Shi, Xuankai Chang, Zhenhui Ye, Yuning Wu, Zhiqing Hong, Jiawei Huang, Jinglin Liu, Yi~Ren, Yuexian Zou, Zhou Zhao, and Shinji Watanabe.
\newblock Audiogpt: Understanding and generating speech, music, sound, and talking head.
\newblock In \emph{AAAI}, pp.\  23802--23804, 2024.
\newblock URL \url{https://doi.org/10.1609/aaai.v38i21.30570}.

\bibitem[Hurst et~al.(2024)Hurst, Lerer, Goucher, Perelman, Ramesh, Clark, Ostrow, Welihinda, Hayes, Radford, et~al.]{hurst2024gpt}
Aaron Hurst, Adam Lerer, Adam~P Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ~Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, et~al.
\newblock Gpt-4o system card.
\newblock \emph{arXiv preprint arXiv:2410.21276}, 2024.

\bibitem[Javed et~al.(2022)Javed, Bhogale, Raman, Kunchukuttan, Kumar, and Khapra]{javed2022indicsuperbspeechprocessinguniversal}
Tahir Javed, Kaushal~Santosh Bhogale, Abhigyan Raman, Anoop Kunchukuttan, Pratyush Kumar, and Mitesh~M. Khapra.
\newblock Indicsuperb: A speech processing universal performance benchmark for indian languages, 2022.
\newblock URL \url{https://arxiv.org/abs/2208.11761}.

\bibitem[Javed et~al.(2024)Javed, Nawale, Joshi, George, Bhogale, Mehendale, and Khapra]{javed24_interspeech}
Tahir Javed, Janki Nawale, Sakshi Joshi, Eldho George, Kaushal Bhogale, Deovrat Mehendale, and Mitesh~M. Khapra.
\newblock {LAHAJA: A Robust Multi-accent Benchmark for Evaluating Hindi ASR Systems}.
\newblock In \emph{{Interspeech 2024}}, pp.\  2320--2324, 2024.
\newblock \doi{10.21437/Interspeech.2024-2376}.

\bibitem[KimiTeam et~al.(2025)KimiTeam, Ding, Ju, Leng, Liu, Liu, Shang, Shen, Song, Tan, Tang, Wang, et~al.]{kimiteam2025kimiaudiotechnicalreport}
KimiTeam, Ding Ding, Zeqian Ju, Yichong Leng, Songxiang Liu, Tong Liu, Zeyu Shang, Kai Shen, Wei Song, Xu~Tan, Heyi Tang, Zhengtao Wang, et~al.
\newblock Kimi-audio technical report, 2025.
\newblock URL \url{https://arxiv.org/abs/2504.18425}.

\bibitem[Li et~al.(2023)Li, Zhao, Yu, Song, Li, Yu, Li, Huang, and Li]{li2023apibank}
Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang, and Yongbin Li.
\newblock {API}-bank: A comprehensive benchmark for tool-augmented {LLM}s.
\newblock In \emph{The 2023 Conference on Empirical Methods in Natural Language Processing}, 2023.
\newblock URL \url{https://openreview.net/forum?id=o2HBfgY20b}.

\bibitem[Ma et~al.(2025)Ma, Chen, Wang, Chng, and Chen]{ma2025audiocotexploringchainofthoughtreasoning}
Ziyang Ma, Zhuo Chen, Yuping Wang, Eng~Siong Chng, and Xie Chen.
\newblock Audio-cot: Exploring chain-of-thought reasoning in large audio language model, 2025.
\newblock URL \url{https://arxiv.org/abs/2501.07246}.

\bibitem[Panayotov et~al.(2015)Panayotov, Chen, Povey, and Khudanpur]{7178964}
Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur.
\newblock Librispeech: An asr corpus based on public domain audio books.
\newblock In \emph{2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pp.\  5206--5210, 2015.
\newblock \doi{10.1109/ICASSP.2015.7178964}.

\bibitem[Patil et~al.(2024)Patil, Zhang, Wang, and Gonzalez]{patil2024gorilla}
Shishir~G Patil, Tianjun Zhang, Xin Wang, and Joseph~E. Gonzalez.
\newblock Gorilla: Large language model connected with massive {API}s.
\newblock In \emph{The Thirty-eighth Annual Conference on Neural Information Processing Systems}, 2024.
\newblock URL \url{https://openreview.net/forum?id=tBRNC6YemY}.

\bibitem[Patil et~al.(2025)Patil, Mao, Yan, Ji, Suresh, Stoica, and Gonzalez]{patil2025the}
Shishir~G Patil, Huanzhi Mao, Fanjia Yan, Charlie Cheng-Jie Ji, Vishnu Suresh, Ion Stoica, and Joseph~E. Gonzalez.
\newblock The berkeley function calling leaderboard ({BFCL}): From tool use to agentic evaluation of large language models.
\newblock In \emph{Forty-second International Conference on Machine Learning}, 2025.
\newblock URL \url{https://openreview.net/forum?id=2GmDdhBdDk}.

\bibitem[Qi et~al.(2017)Qi, Yi, Su, and Guibas]{PointNet++}
Charles~Ruizhongtai Qi, Li~Yi, Hao Su, and Leonidas~J Guibas.
\newblock Pointnet++: Deep hierarchical feature learning on point sets in a metric space.
\newblock In I.~Guyon, U.~Von Luxburg, S.~Bengio, H.~Wallach, R.~Fergus, S.~Vishwanathan, and R.~Garnett (eds.), \emph{Advances in Neural Information Processing Systems}, volume~30. Curran Associates, Inc., 2017.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2017/file/d8bf84be3800d12f74d8b05e9b89836f-Paper.pdf}.

\bibitem[Qin et~al.(2024)Qin, Liang, Ye, Zhu, Yan, Lu, Lin, Cong, Tang, Qian, Zhao, Hong, Tian, Xie, Zhou, Gerstein, dahai li, Liu, and Sun]{qin2024toolllm}
Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Lauren Hong, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, dahai li, Zhiyuan Liu, and Maosong Sun.
\newblock Tool{LLM}: Facilitating large language models to master 16000+ real-world {API}s.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=dHng2O0Jjr}.

\bibitem[Radford et~al.(2022)Radford, Kim, Xu, Brockman, McLeavey, and Sutskever]{radford2022robustspeechrecognitionlargescale}
Alec Radford, Jong~Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever.
\newblock Robust speech recognition via large-scale weak supervision, 2022.
\newblock URL \url{https://arxiv.org/abs/2212.04356}.

\bibitem[Rozière et~al.(2024)Rozière, Gehring, Gloeckle, Sootla, Gat, Tan, Adi, Liu, Sauvestre, Remez, Rapin, Kozhevnikov, Evtimov, Bitton, Bhatt, Ferrer, Grattafiori, Xiong, Défossez, Copet, Azhar, Touvron, Martin, Usunier, Scialom, and Synnaeve]{rozière2024codellamaopenfoundation}
Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing~Ellen Tan, Yossi Adi, Jingyu Liu, Romain Sauvestre, Tal Remez, Jérémy Rapin, Artyom Kozhevnikov, Ivan Evtimov, Joanna Bitton, Manish Bhatt, Cristian~Canton Ferrer, Aaron Grattafiori, Wenhan Xiong, Alexandre Défossez, Jade Copet, Faisal Azhar, Hugo Touvron, Louis Martin, Nicolas Usunier, Thomas Scialom, and Gabriel Synnaeve.
\newblock Code llama: Open foundation models for code, 2024.
\newblock URL \url{https://arxiv.org/abs/2308.12950}.

\bibitem[Rubenstein et~al.(2023)Rubenstein, Asawaroengchai, Nguyen, Bapna, Borsos, de~Chaumont~Quitry, Chen, Badawy, Han, Kharitonov, Muckenhirn, Padfield, Qin, Rozenberg, Sainath, Schalkwyk, Sharifi, Ramanovich, Tagliasacchi, Tudor, Velimirović, Vincent, Yu, Wang, Zayats, Zeghidour, Zhang, Zhang, Zilka, and Frank]{rubenstein2023audiopalmlargelanguagemodel}
Paul~K. Rubenstein, Chulayuth Asawaroengchai, Duc~Dung Nguyen, Ankur Bapna, Zalán Borsos, Félix de~Chaumont~Quitry, Peter Chen, Dalia~El Badawy, Wei Han, Eugene Kharitonov, Hannah Muckenhirn, Dirk Padfield, James Qin, Danny Rozenberg, Tara Sainath, Johan Schalkwyk, Matt Sharifi, Michelle~Tadmor Ramanovich, Marco Tagliasacchi, Alexandru Tudor, Mihajlo Velimirović, Damien Vincent, Jiahui Yu, Yongqiang Wang, Vicky Zayats, Neil Zeghidour, Yu~Zhang, Zhishuai Zhang, Lukas Zilka, and Christian Frank.
\newblock Audiopalm: A large language model that can speak and listen, 2023.
\newblock URL \url{https://arxiv.org/abs/2306.12925}.

\bibitem[Sakshi et~al.(2025)Sakshi, Tyagi, Kumar, Seth, Selvakumar, Nieto, Duraiswami, Ghosh, and Manocha]{sakshi2025mmau}
S~Sakshi, Utkarsh Tyagi, Sonal Kumar, Ashish Seth, Ramaneswaran Selvakumar, Oriol Nieto, Ramani Duraiswami, Sreyan Ghosh, and Dinesh Manocha.
\newblock {MMAU}: A massive multi-task audio understanding and reasoning benchmark.
\newblock In \emph{The Thirteenth International Conference on Learning Representations}, 2025.
\newblock URL \url{https://openreview.net/forum?id=TeVAZXr3yv}.

\bibitem[Shah et~al.(2025)Shah, Saxena, Bharadwaj, Adavanne, and Adiga]{11011192}
Sanket Shah, Kavya~Ranjan Saxena, Kancharana~Manideep Bharadwaj, Sharath Adavanne, and Nagaraj Adiga.
\newblock Indicst: Indian multilingual translation corpus for evaluating speech large language models.
\newblock In \emph{2025 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW)}, pp.\  1--5, 2025.
\newblock \doi{10.1109/ICASSPW65056.2025.11011192}.

\bibitem[Sharma et~al.(2025)Sharma, Ekbote, and Gupta]{sharma-etal-2025-indicsynth}
Divya~V Sharma, Vijval Ekbote, and Anubha Gupta.
\newblock {I}ndic{S}ynth: A large-scale multilingual synthetic speech dataset for low-resource {I}ndian languages.
\newblock In Wanxiang Che, Joyce Nabende, Ekaterina Shutova, and Mohammad~Taher Pilehvar (eds.), \emph{Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, Vienna, Austria, July 2025. Association for Computational Linguistics.
\newblock URL \url{https://aclanthology.org/2025.acl-long.1070/}.

\bibitem[Shon et~al.(2023)Shon, Arora, Lin, Pasad, Wu, Sharma, Wu, Lee, Livescu, and Watanabe]{shon-etal-2023-slue}
Suwon Shon, Siddhant Arora, Chyi-Jiunn Lin, Ankita Pasad, Felix Wu, Roshan Sharma, Wei-Lun Wu, Hung-yi Lee, Karen Livescu, and Shinji Watanabe.
\newblock {SLUE} phase-2: A benchmark suite of diverse spoken language understanding tasks.
\newblock In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (eds.), \emph{Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pp.\  8906--8937, Toronto, Canada, July 2023. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2023.acl-long.496}.
\newblock URL \url{https://aclanthology.org/2023.acl-long.496/}.

\bibitem[Tang et~al.(2024)Tang, Yu, Sun, Chen, Tan, Li, Lu, MA, and Zhang]{tang2024salmonn}
Changli Tang, Wenyi Yu, Guangzhi Sun, Xianzhao Chen, Tian Tan, Wei Li, Lu~Lu, Zejun MA, and Chao Zhang.
\newblock {SALMONN}: Towards generic hearing abilities for large language models.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=14rn7HpKVk}.

\bibitem[Team et~al.(2025)Team, Kamath, Ferret, Pathak, Vieillard, Merhej, Perrin, Matejovicova, Ramé, Rivière, Rouillard, Mesnard, Cideron, bastien Grill, Ramos, et~al.]{gemmateam2025gemma3technicalreport}
Gemma Team, Aishwarya Kamath, Johan Ferret, Shreya Pathak, Nino Vieillard, Ramona Merhej, Sarah Perrin, Tatiana Matejovicova, Alexandre Ramé, Morgane Rivière, Louis Rouillard, Thomas Mesnard, Geoffrey Cideron, Jean bastien Grill, Sabela Ramos, et~al.
\newblock Gemma 3 technical report, 2025.
\newblock URL \url{https://arxiv.org/abs/2503.19786}.

\bibitem[Touvron et~al.(2023)]{touvron2023llama}
Hugo Touvron et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock \emph{arXiv preprint arXiv:2302.13971}, 2023.

\bibitem[Wang et~al.(2024)Wang, Zou, Lin, Sun, Liu, Zhang, Liu, Aw, and Chen]{DBLP:journals/corr/abs-2406-16020}
Bin Wang, Xunlong Zou, Geyu Lin, Shuo Sun, Zhuohan Liu, Wenyu Zhang, Zhengyuan Liu, AiTi Aw, and Nancy~F. Chen.
\newblock Audiobench: A universal benchmark for audio large language models.
\newblock \emph{CoRR}, abs/2406.16020, 2024.
\newblock URL \url{https://doi.org/10.48550/arXiv.2406.16020}.

\bibitem[Wang et~al.(2025)Wang, Shen, Guo, Stallone, Kim, Golland, and Panda]{wang2025diversity}
Peiqi Wang, Yikang Shen, Zhen Guo, Matthew Stallone, Yoon Kim, Polina Golland, and Rameswar Panda.
\newblock Diversity measurement and subset selection for instruction tuning datasets.
\newblock In \emph{ICLR 2025 Workshop on Navigating and Addressing Data Problems for Foundation Models}, 2025.
\newblock URL \url{https://openreview.net/forum?id=cV9OF45hBb}.

\bibitem[Wei et~al.(2022)Wei, Wang, Schuurmans, Bosma, brian ichter, Xia, Chi, Le, and Zhou]{wei2022chain}
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed~H. Chi, Quoc~V Le, and Denny Zhou.
\newblock Chain of thought prompting elicits reasoning in large language models.
\newblock In Alice~H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.), \emph{Advances in Neural Information Processing Systems}, 2022.
\newblock URL \url{https://openreview.net/forum?id=_VjQlMeSB_J}.

\bibitem[wen Yang et~al.(2021)wen Yang, Chi, Chuang, Lai, Lakhotia, Lin, Liu, Shi, Chang, Lin, Huang, Tseng, tik Lee, Liu, Huang, Dong, Li, Watanabe, Mohamed, and yi~Lee]{yang21c_interspeech}
Shu wen Yang, Po-Han Chi, Yung-Sung Chuang, Cheng-I~Jeff Lai, Kushal Lakhotia, Yist~Y. Lin, Andy~T. Liu, Jiatong Shi, Xuankai Chang, Guan-Ting Lin, Tzu-Hsien Huang, Wei-Cheng Tseng, Ko~tik Lee, Da-Rong Liu, Zili Huang, Shuyan Dong, Shang-Wen Li, Shinji Watanabe, Abdelrahman Mohamed, and Hung yi~Lee.
\newblock Superb: Speech processing universal performance benchmark.
\newblock In \emph{Interspeech 2021}, pp.\  1194--1198, 2021.
\newblock \doi{10.21437/Interspeech.2021-1775}.

\bibitem[Xu et~al.(2025)Xu, Guo, He, Hu, He, Bai, Chen, Wang, Fan, Dang, Zhang, Wang, Chu, and Lin]{xu2025qwen25omnitechnicalreport}
Jin Xu, Zhifang Guo, Jinzheng He, Hangrui Hu, Ting He, Shuai Bai, Keqin Chen, Jialin Wang, Yang Fan, Kai Dang, Bin Zhang, Xiong Wang, Yunfei Chu, and Junyang Lin.
\newblock Qwen2.5-omni technical report, 2025.
\newblock URL \url{https://arxiv.org/abs/2503.20215}.

\bibitem[Yang et~al.(2025{\natexlab{a}})Yang, Li, Yang, Zhang, Hui, Zheng, Yu, Gao, Huang, Lv, Zheng, Liu, et~al.]{yang2025qwen3technicalreport}
An~Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo~Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, Chujie Zheng, Dayiheng Liu, et~al.
\newblock Qwen3 technical report, 2025{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2505.09388}.

\bibitem[Yang et~al.(2025{\natexlab{b}})Yang, Li, Yang, Zhang, Hui, Zheng, Yu, Gao, Huang, Lv, et~al.]{yang2025qwen3}
An~Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo~Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, et~al.
\newblock Qwen3 technical report.
\newblock \emph{arXiv preprint arXiv:2505.09388}, 2025{\natexlab{b}}.

\bibitem[Yang et~al.(2024)Yang, Xu, Liu, Chu, Jiang, Zhou, Leng, Lv, Zhao, Zhou, and Zhou]{yang-etal-2024-air}
Qian Yang, Jin Xu, Wenrui Liu, Yunfei Chu, Ziyue Jiang, Xiaohuan Zhou, Yichong Leng, Yuanjun Lv, Zhou Zhao, Chang Zhou, and Jingren Zhou.
\newblock {AIR}-bench: Benchmarking large audio-language models via generative comprehension.
\newblock In Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), \emph{Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pp.\  1979--1998, Bangkok, Thailand, August 2024. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2024.acl-long.109}.
\newblock URL \url{https://aclanthology.org/2024.acl-long.109/}.

\bibitem[Yang et~al.(2025{\natexlab{c}})Yang, Li, Wei, Fang, and Chen]{yang2025speechrbenchmarkspeechreasoning}
Wanqi Yang, Yanda Li, Yunchao Wei, Meng Fang, and Ling Chen.
\newblock Speechr: A benchmark for speech reasoning in large audio-language models, 2025{\natexlab{c}}.
\newblock URL \url{https://arxiv.org/abs/2508.02018}.

\bibitem[Yang et~al.(2025{\natexlab{d}})Yang, Nan, Ye, Dou, Wang, Li, Lv, Wu, Gui, Zhang, and Huang]{yang2025measuringdatadiversityinstruction}
Yuming Yang, Yang Nan, Junjie Ye, Shihan Dou, Xiao Wang, Shuo Li, Huijie Lv, Mingqi Wu, Tao Gui, Qi~Zhang, and Xuanjing Huang.
\newblock Measuring data diversity for instruction tuning: A systematic analysis and a reliable metric, 2025{\natexlab{d}}.
\newblock URL \url{https://arxiv.org/abs/2502.17184}.

\bibitem[Yao et~al.(2023)Yao, Zhao, Yu, Du, Shafran, Narasimhan, and Cao]{yao2023react}
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik~R Narasimhan, and Yuan Cao.
\newblock React: Synergizing reasoning and acting in language models.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=WE_vluYUL-X}.

\bibitem[Yao et~al.(2025)Yao, Shinn, Razavi, and Narasimhan]{yao2025taubench}
Shunyu Yao, Noah Shinn, Pedram Razavi, and Karthik~R Narasimhan.
\newblock \{\${\textbackslash}tau\$\}-bench: A benchmark for {\textbackslash}underline\{T\}ool-{\textbackslash}underline\{A\}gent-{\textbackslash}underline\{U\}ser interaction in real-world domains.
\newblock In \emph{The Thirteenth International Conference on Learning Representations}, 2025.
\newblock URL \url{https://openreview.net/forum?id=roNSXZpUDN}.

\bibitem[Zhao et~al.(2024)Zhao, Wang, Cen, Zha, Tan, Dong, and Tang]{DBLP:journals/corr/abs-2410-18050}
Qingfei Zhao, Ruobing Wang, Yukuo Cen, Daren Zha, Shicheng Tan, Yuxiao Dong, and Jie Tang.
\newblock Longrag: A dual-perspective retrieval-augmented generation paradigm for long-context question answering.
\newblock \emph{CoRR}, abs/2410.18050, 2024.
\newblock URL \url{https://doi.org/10.48550/arXiv.2410.18050}.

\bibitem[Zhuang et~al.(2023)Zhuang, Yu, Wang, Sun, and Zhang]{zhuang2023toolqa}
Yuchen Zhuang, Yue Yu, Kuan Wang, Haotian Sun, and Chao Zhang.
\newblock Tool{QA}: A dataset for {LLM} question answering with external tools.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track}, 2023.
\newblock URL \url{https://openreview.net/forum?id=pV1xV2RK6I}.

\end{thebibliography}
