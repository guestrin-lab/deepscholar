
@inproceedings{CLIP,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{BLIP,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}

@inproceedings{instructBLIP,
  author       = {Wenliang Dai and
                  Junnan Li and
                  Dongxu Li and
                  Anthony Meng Huat Tiong and
                  Junqi Zhao and
                  Weisheng Wang and
                  Boyang Li and
                  Pascale Fung and
                  Steven C. H. Hoi},
  editor       = {Alice Oh and
                  Tristan Naumann and
                  Amir Globerson and
                  Kate Saenko and
                  Moritz Hardt and
                  Sergey Levine},
  title        = {InstructBLIP: Towards General-purpose Vision-Language Models with
                  Instruction Tuning},
  booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference
                  on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,
                  LA, USA, December 10 - 16, 2023},
  year         = {2023},
  url          = {http://papers.nips.cc/paper\_files/paper/2023/hash/9a6a435e75419a836fe47ab6793623e6-Abstract-Conference.html},
  timestamp    = {Fri, 01 Mar 2024 16:26:20 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/Dai0LTZW0FH23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={19730--19742},
  year={2023},
  organization={PMLR}
}

@article{llava,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@article{flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@article{MIMIC-IT,
  title={Mimic-it: Multi-modal in-context instruction tuning},
  author={Li, Bo and Zhang, Yuanhan and Chen, Liangyu and Wang, Jinghao and Pu, Fanyi and Yang, Jingkang and Li, Chunyuan and Liu, Ziwei},
  journal={arXiv preprint arXiv:2306.05425},
  year={2023}
}

@article{qwen-vl,
  title={Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  year={2023}
}


@inproceedings{bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@inproceedings{distinct,
  title={A Diversity-Promoting Objective Function for Neural Conversation Models},
  author={Li, Jiwei and Galley, Michel and Brockett, Chris and Gao, Jianfeng and Dolan, William B},
  booktitle={Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={110--119},
  year={2016}
}

@inproceedings{rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}

@inproceedings{banerjee2005meteor,
  title={METEOR: An automatic metric for MT evaluation with improved correlation with human judgments},
  author={Banerjee, Satanjeev and Lavie, Alon},
  booktitle={Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization},
  pages={65--72},
  year={2005}
}

@inproceedings{vedantam2015cider,
  title={Cider: Consensus-based image description evaluation},
  author={Vedantam, Ramakrishna and Lawrence Zitnick, C and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4566--4575},
  year={2015}
}

@inproceedings{zhang2019bertscore,
  title={BERTScore: Evaluating Text Generation with BERT},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  booktitle={International Conference on Learning Representations}
}

@inproceedings{wang2024rolellm,
  title={RoleLLM: Benchmarking, Eliciting, and Enhancing Role-Playing Abilities of Large Language Models},
  author={Wang, Noah and Peng, Zy and Que, Haoran and Liu, Jiaheng and Zhou, Wangchunshu and Wu, Yuhan and Guo, Hongcheng and Gan, Ruitong and Ni, Zehao and Yang, Jian and others},
  booktitle={Findings of the Association for Computational Linguistics ACL 2024},
  pages={14743--14777},
  year={2024}
}

@inproceedings{wang2024incharacter,
  title={InCharacter: Evaluating Personality Fidelity in Role-Playing Agents through Psychological Interviews},
  author={Wang, Xintao and Xiao, Yunze and Huang, Jen-tse and Yuan, Siyu and Xu, Rui and Guo, Haoran and Tu, Quan and Fei, Yaying and Leng, Ziang and Wang, Wei and others},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1840--1873},
  year={2024}
}

@inproceedings{tu2024charactereval,
  title={CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation},
  author={Tu, Quan and Fan, Shilong and Tian, Zihang and Shen, Tianhao and Shang, Shuo and Gao, Xin and Yan, Rui},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={11836--11850},
  year={2024}
}

@inproceedings{lu2024ditto,
  title={Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment},
  author={Lu, Keming and Yu, Bowen and Zhou, Chang and Zhou, Jingren},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={7828--7840},
  year={2024}
}

@misc{li2024llavanext-strong,
    title={LLaVA-NeXT: Stronger LLMs Supercharge Multimodal Capabilities in the Wild},
    url={https://llava-vl.github.io/blog/2024-05-10-llava-next-stronger-llms/},
    author={Li, Bo and Zhang, Kaichen and Zhang, Hao and Guo, Dong and Zhang, Renrui and Li, Feng and Zhang, Yuanhan and Liu, Ziwei and Li, Chunyuan},
    month={May},
    year={2024}
}

@inproceedings{ahn2023mpchat,
  title={MPCHAT: Towards Multimodal Persona-Grounded Conversation},
  author={Ahn, Jaewoo and Song, Yeda and Yun, Sangdoo and Kim, Gunhee},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={3354--3377},
  year={2023}
}

@inproceedings{lee2024stark,
  title={Stark: Social Long-Term Multi-Modal Conversation with Persona Commonsense Knowledge},
  author={Lee, Young-Jun and Lee, Dokyong and Youn, Junyoung and Oh, Kyeong-Jin and Ko, Byungsoo and Hyeon, Jonghwan and Choi, Ho-Jin},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  pages={12137--12162},
  year={2024}
}

@inproceedings{tang2023enhancing,
  title={Enhancing Personalized Dialogue Generation with Contrastive Latent Variables: Combining Sparse and Dense Persona},
  author={Tang, Yihong and Wang, Bo and Fang, Miao and Zhao, Dongming and Huang, Kun and He, Ruifang and Hou, Yuexian},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={5456--5468},
  year={2023}
}

@inproceedings{sun2022multimodal,
  title={Multimodal Dialogue Response Generation},
  author={Sun, Qingfeng and Wang, Yujing and Xu, Can and Zheng, Kai and Yang, Yaming and Hu, Huang and Xu, Fei and Zhang, Jessica and Geng, Xiubo and Jiang, Daxin},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2854--2866},
  year={2022}
}

@article{li2023chatharuhi,
  title={Chatharuhi: Reviving anime character in reality via large language model},
  author={Li, Cheng and Leng, Ziang and Yan, Chenxi and Shen, Junyi and Wang, Hao and Mi, Weishi and Fei, Yaying and Feng, Xiaoyang and Yan, Song and Wang, HaoSheng and others},
  journal={arXiv preprint arXiv:2308.09597},
  year={2023}
}

@article{gao2023livechat,
  title={LiveChat: A large-scale personalized dialogue dataset automatically constructed from live streaming},
  author={Gao, Jingsheng and Lian, Yixin and Zhou, Ziyi and Fu, Yuzhuo and Wang, Baoyuan},
  journal={arXiv preprint arXiv:2306.08401},
  year={2023}
}

@inproceedings{lin2024screen,
  title={SCREEN: A Benchmark for Situated Conversational Recommendation},
  author={Lin, Dongding and Wang, Jian and Leong, Chak Tou and Li, Wenjie},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={9591--9600},
  year={2024}
}

@inproceedings{hurrypotter,
  title={Evaluating Character Understanding of Large Language Models via Character Profiling from Fictional Works},
  author={Yuan, Xinfeng and Yuan, Siyu and Cui, Yuhan and Lin, Tianhe and Wang, Xintao and Xu, Rui and Chen, Jiangjie and Yang, Deqing},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={8015--8036},
  year={2024}
}

@inproceedings{harrypotter1,
  title={Large language models meet harry potter: A dataset for aligning dialogue agents with characters},
  author={Chen, Nuo and Wang, Yan and Jiang, Haiyun and Cai, Deng and Li, Yuhan and Chen, Ziyang and Wang, Longyue and Li, Jia},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
  pages={8506--8520},
  year={2023}
}

@article{lifechoice,
  title={Character is Destiny: Can Large Language Models Simulate Persona-Driven Decisions in Role-Playing?},
  author={Xu, Rui and Wang, Xintao and Chen, Jiangjie and Yuan, Siyu and Yuan, Xinfeng and Liang, Jiaqing and Chen, Zulong and Dong, Xiaoqing and Xiao, Yanghua},
  journal={arXiv e-prints},
  pages={arXiv--2404},
  year={2024}
}



@article{survey,
  title={From Persona to Personalization: A Survey on Role-Playing Language Agents},
  author={Chen, Jiangjie and Wang, Xintao and Xu, Rui and Yuan, Siyu and Zhang, Yikai and Shi, Wei and Xie, Jian and Li, Shuang and Yang, Ruihan and Zhu, Tinghui and others},
  journal={Transactions on Machine Learning Research}
}

@inproceedings{yu2024neeko,
  title={Neeko: Leveraging Dynamic LoRA for Efficient Multi-Character Role-Playing Agent},
  author={Yu, Xiaoyan and Luo, Tongxu and Wei, Yifan and Lei, Fangyu and Huang, Yiming and Peng, Hao and Zhu, Liehuang},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={12540--12557},
  year={2024}
}


@article{wang2025coser,
  title={CoSER: Coordinating LLM-Based Persona Simulation of Established Roles},
  author={Wang, Xintao and Wang, Heng and Zhang, Yifei and Yuan, Xinfeng and Xu, Rui and Huang, Jen-tse and Yuan, Siyu and Guo, Haoran and Chen, Jiangjie and Wang, Wei and others},
  journal={arXiv preprint arXiv:2502.09082},
  year={2025}
}

@article{dai2024mmrole,
  title={Mmrole: A comprehensive framework for developing and evaluating multimodal role-playing agents},
  author={Dai, Yanqi and Hu, Huanran and Wang, Lei and Jin, Shengjie and Chen, Xu and Lu, Zhiwu},
  journal={arXiv preprint arXiv:2408.04203},
  year={2024}
}

@inproceedings{zhang2024stickerconv,
  title={STICKERCONV: Generating Multimodal Empathetic Responses from Scratch},
  author={Zhang, Yiqun and Kong, Fanheng and Wang, Peidong and Sun, Shuang and SWangLing, SWangLing and Feng, Shi and Wang, Daling and Zhang, Yifei and Song, Kaisong},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={7707--7733},
  year={2024}
}

@article{2023rolenature,
  title={Role play with large language models},
  author={Shanahan, Murray and McDonell, Kyle and Reynolds, Laria},
  journal={Nature},
  volume={623},
  number={7987},
  pages={493--498},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{wu2023mathchat,
  title={Mathchat: Converse to tackle challenging math problems with llm agents},
  author={Wu, Yiran and Jia, Feiran and Zhang, Shaokun and Li, Hangyu and Zhu, Erkang and Wang, Yue and Lee, Yin Tat and Peng, Richard and Wu, Qingyun and Wang, Chi},
  journal={arXiv preprint arXiv:2306.01337},
  year={2023}
}

@inproceedings{naseem2024vaccine,
  title={Vaccine Misinformation Detection in X using Cooperative Multimodal Framework},
  author={Naseem, Usman and Dunn, Adam G and Khushi, Matloob and Kim, Jinman},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={4034--4042},
  year={2024}
}

@article{medicine,
  title={ChatGPT and large language model (LLM) chatbots: The current state of acceptability and a proposal for guidelines on utilization in academic medicine},
  author={Kim, Jin K and Chua, Michael and Rickard, Mandy and Lorenzo, Armando},
  journal={Journal of Pediatric Urology},
  volume={19},
  number={5},
  pages={598--604},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{zhao2024ct2c,
  title={CT2C-QA: Multimodal Question Answering over Chinese Text, Table and Chart},
  author={Zhao, Bowen and Cheng, Tianhao and Zhang, Yuejie and Cheng, Ying and Feng, Rui and Zhang, Xiaobo},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={3897--3906},
  year={2024}
}

@inproceedings{reccommend,
  title={Llm based generation of item-description for recommendation system},
  author={Acharya, Arkadeep and Singh, Brijraj and Onoe, Naoyuki},
  booktitle={Proceedings of the 17th ACM conference on recommender systems},
  pages={1204--1207},
  year={2023}
}

@article{yang2023llm4drive,
  title={Llm4drive: A survey of large language models for autonomous driving},
  author={Yang, Zhenjie and Jia, Xiaosong and Li, Hongyang and Yan, Junchi},
  journal={arXiv preprint arXiv:2311.01043},
  year={2023}
}

@article{chen2024roleinteract,
  title={Roleinteract: Evaluating the social interaction of role-playing agents},
  author={Chen, Hongzhan and Chen, Hehong and Yan, Ming and Xu, Wenshen and Gao, Xing and Shen, Weizhou and Quan, Xiaojun and Li, Chenliang and Zhang, Ji and Huang, Fei and others},
  journal={arXiv e-prints},
  pages={arXiv--2403},
  year={2024}
}


@article{huang2024social,
  title={Social Science Meets LLMs: How Reliable Are Large Language Models in Social Simulations?},
  author={Huang, Yue and Yuan, Zhengqing and Zhou, Yujun and Guo, Kehan and Wang, Xiangqi and Zhuang, Haomin and Sun, Weixiang and Sun, Lichao and Wang, Jindong and Ye, Yanfang and others},
  journal={arXiv preprint arXiv:2410.23426},
  year={2024}
}

@article{zhuang2023generation,
  title={Toolqa: A dataset for llm question answering with external tools},
  author={Zhuang, Yuchen and Yu, Yue and Wang, Kuan and Sun, Haotian and Zhang, Chao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={50117--50143},
  year={2023}
}

@article{li2024generation,
  title={Snapkv: Llm knows what you are looking for before generation},
  author={Li, Yuhong and Huang, Yingbing and Yang, Bowen and Venkitesh, Bharat and Locatelli, Acyr and Ye, Hanchen and Cai, Tianle and Lewis, Patrick and Chen, Deming},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={22947--22970},
  year={2024}
}

@article{application,
  title={Large language models: a comprehensive survey of its applications, challenges, limitations, and future prospects},
  author={Hadi, Muhammad Usman and Qureshi, Rizwan and Shah, Abbas and Irfan, Muhammad and Zafar, Anas and Shaikh, Muhammad Bilal and Akhtar, Naveed and Wu, Jia and Mirjalili, Seyedali and others},
  journal={Authorea Preprints},
  volume={1},
  pages={1--26},
  year={2023},
  publisher={Authorea}
}

@inproceedings{chi,
  title={Bridging the gulf of envisioning: Cognitive challenges in prompt based interactions with LLMs},
  author={Subramonyam, Hari and Pea, Roy and Pondoc, Christopher and Agrawala, Maneesh and Seifert, Colleen},
  booktitle={Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
  pages={1--19},
  year={2024}
}

@article{jiang2024codesurvey,
  title={A survey on large language models for code generation},
  author={Jiang, Juyong and Wang, Fan and Shen, Jiasi and Kim, Sungju and Kim, Sunghun},
  journal={arXiv preprint arXiv:2406.00515},
  year={2024}
}

@inproceedings{chen2024internvl,
  title={Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks},
  author={Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and others},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={24185--24198},
  year={2024}
}


@inproceedings{tong2024eyes,
  title={Eyes wide shut? exploring the visual shortcomings of multimodal llms},
  author={Tong, Shengbang and Liu, Zhuang and Zhai, Yuexiang and Ma, Yi and LeCun, Yann and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9568--9578},
  year={2024}
}

@article{consistency1,
  title={What is cognitive consistency, and why does it matter?},
  author={Gawronski, Bertram and Brannon, Skylar M},
  year={2019},
  publisher={American Psychological Association}
}

@article{consistency2,
  title={Theories of cognitive consistency: A sourcebook.},
  author={Abelson, Robert P and Aronson, Elliot Ed and McGuire, William J and Newcomb, Theodore M and Rosenberg, Milton J and Tannenbaum, Percy H},
  year={1968},
  publisher={Chicago}
}

@article{emotionalsupport1,
  title={Building emotional support chatbots in the era of llms},
  author={Zheng, Zhonghua and Liao, Lizi and Deng, Yang and Nie, Liqiang},
  journal={arXiv preprint arXiv:2308.11584},
  year={2023}
}

@article{zhao2023mmicl,
  title={Mmicl: Empowering vision-language model with multi-modal in-context learning},
  author={Zhao, Haozhe and Cai, Zefan and Si, Shuzheng and Ma, Xiaojian and An, Kaikai and Chen, Liang and Liu, Zixuan and Wang, Sheng and Han, Wenjuan and Chang, Baobao},
  journal={arXiv preprint arXiv:2309.07915},
  year={2023}
}

@inproceedings{chen2024emotionqueen,
  title={EmotionQueen: A Benchmark for Evaluating Empathy of Large Language Models},
  author={Chen, Yuyan and Yan, Songzhou and Liu, Sijia and Li, Yueze and Xiao, Yanghua},
  booktitle={Findings of the Association for Computational Linguistics ACL 2024},
  pages={2149--2176},
  year={2024}
}

@article{zheng2023judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46595--46623},
  year={2023}
}


@inproceedings{personality,
  title={LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models},
  author={Frisch, Ivar and Giulianelli, Mario},
  booktitle={Proceedings of the 1st Workshop on Personalization of Generative AI Systems (PERSONALIZE 2024)},
  pages={102--111},
  year={2024}
}


@inproceedings{jiang2024personallm,
  title={PersonaLLM: Investigating the Ability of Large Language Models to Express Personality Traits},
  author={Jiang, Hang and Zhang, Xiajie and Cao, Xubo and Breazeal, Cynthia and Roy, Deb and Kabbara, Jad},
  booktitle={Findings of the Association for Computational Linguistics: NAACL 2024},
  pages={3605--3627},
  year={2024}
}

@article{hu2022lora,
  title={Lora: Low-rank adaptation of large language models.},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
  journal={ICLR},
  volume={1},
  number={2},
  pages={3},
  year={2022}
}

@article{gaoretrieval,
  title={Retrieval-Augmented Generation for Large Language Models: A Survey},
  author={Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Guo, Qianyu and Wang, Meng and others}
}

@article{wang2023parameter,
  title={Parameter-efficient tuning of large-scale multimodal foundation model},
  author={Wang, Haixin and Yang, Xinlong and Chang, Jianlong and Jin, Dian and Sun, Jinan and Zhang, Shikun and Luo, Xiao and Tian, Qi},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={15752--15774},
  year={2023}
}

@inproceedings{dong2024survey,
  title={A Survey on In-context Learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Ma, Jingyuan and Li, Rui and Xia, Heming and Xu, Jingjing and Wu, Zhiyong and Chang, Baobao and others},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={1107--1128},
  year={2024}
}

@inproceedings{hong2024cogagent,
  title={Cogagent: A visual language model for gui agents},
  author={Hong, Wenyi and Wang, Weihan and Lv, Qingsong and Xu, Jiazheng and Yu, Wenmeng and Ji, Junhui and Wang, Yan and Wang, Zihan and Dong, Yuxiao and Ding, Ming and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14281--14290},
  year={2024}
}

@article{xu2023exploring,
  title={Exploring large language models for communication games: An empirical study on werewolf},
  author={Xu, Yuzhuang and Wang, Shuo and Li, Peng and Luo, Fuwen and Wang, Xiaolong and Liu, Weidong and Liu, Yang},
  journal={arXiv preprint arXiv:2309.04658},
  year={2023}
}

@inproceedings{liu2024improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26296--26306},
  year={2024}
}

@inproceedings{jiang2024many,
  title={Many-shot in-context learning in multimodal foundation models},
  author={Jiang, Yixing and Irvin, Jeremy Andrew and Wang, Ji Hun and Chaudhry, Muhammad Ahmed and Chen, Jonathan H and Ng, Andrew Y},
  booktitle={ICML 2024 Workshop on In-Context Learning}
}

@inproceedings{zeng2024not,
  title={Not Just Imitation: Enhancing Role-Playing Through Retrieve Fine-Tuned Collaborative Large Language Model},
  author={Zeng, Yating and Guo, Bin and Jing, Yao and Wang, Hao and Ding, Yasan and Liang, Yunji and Yu, Zhiwen},
  booktitle={2024 IEEE Smart World Congress (SWC)},
  pages={1234--1241},
  year={2024},
  organization={IEEE}
}

@article{huang2024emotional,
  title={Emotional RAG: Enhancing Role-Playing Agents through Emotional Retrieval},
  author={Huang, Le and Lan, Hengzhi and Sun, Zijun and Shi, Chuan and Bai, Ting},
  journal={arXiv preprint arXiv:2410.23041},
  year={2024}
}

@article{LUandLI2025RoleMRC,
  title={RoleMRC: A Fine-Grained Composite Benchmark for Role-Playing and Instruction-Following},
  author={Lu, Junru and Li, Jiazheng and Shen, Guodong and Gui, Lin and An, Siyu and He, Yulan and Yin, Di and Sun, Xing},
  journal={arXiv preprint arXiv:2502.11387},
  year={2025}
}

@article{wang2025opencharacter,
  title={OpenCharacter: Training Customizable Role-Playing LLMs with Large-Scale Synthetic Personas},
  author={Wang, Xiaoyang and Zhang, Hongming and Ge, Tao and Yu, Wenhao and Yu, Dian and Yu, Dong},
  journal={arXiv preprint arXiv:2501.15427},
  year={2025}
}

@inproceedings{ran2024rolepersonality,
  title={Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data},
  author={Ran, Yiting and Wang, Xintao and Xu, Rui and Yuan, Xinfeng and Liang, Jiaqing and Xiao, Yanghua and Yang, Deqing},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  pages={14566--14576},
  year={2024}
}

@inproceedings{zhou2025characterbench,
  title={CharacterBench: Benchmarking Character Customization of Large Language Models},
  author={Zhou, Jinfeng and Huang, Yongkang and Wen, Bosi and Bi, Guanqun and Chen, Yuxuan and Ke, Pei and Chen, Zhuang and Xiao, Xiyao and Peng, Libiao and Tang, Kuntian and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  number={24},
  pages={26101--26110},
  year={2025}
}

@inproceedings{characterllm,
  title={Character-LLM: A Trainable Agent for Role-Playing},
  author={Shao, Yunfan and Li, Linyang and Dai, Junqi and Qiu, Xipeng},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={13153--13187},
  year={2023}
}

@inproceedings{zhou2024characterglm,
  title={CharacterGLM: Customizing Social Characters with Large Language Models},
  author={Zhou, Jinfeng and Chen, Zhuang and Wan, Dazhen and Wen, Bosi and Song, Yi and Yu, Jifan and Huang, Yongkang and Ke, Pei and Bi, Guanqun and Peng, Libiao and others},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing: Industry Track},
  pages={1457--1476},
  year={2024}
}

@inproceedings{character100,
  title={Characteristic AI Agents via Large Language Models},
  author={Wang, Xi and Dai, Hongliang and Gao, Shen and Li, Piji},
  booktitle={Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},
  pages={3016--3027},
  year={2024}
}

@article{chen2024sharegpt4video,
  title={Sharegpt4video: Improving video understanding and generation with better captions},
  author={Chen, Lin and Wei, Xilin and Li, Jinsong and Dong, Xiaoyi and Zhang, Pan and Zang, Yuhang and Chen, Zehui and Duan, Haodong and Tang, Zhenyu and Yuan, Li and others},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={19472--19495},
  year={2024}
}

@inproceedings{Recap,
  title={Video recap: Recursive captioning of hour-long videos},
  author={Islam, Md Mohaiminul and Ho, Ngan and Yang, Xitong and Nagarajan, Tushar and Torresani, Lorenzo and Bertasius, Gedas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18198--18208},
  year={2024}
}

@article{LLava-video178k,
  title={Video instruction tuning with synthetic data},
  author={Zhang, Yuanhan and Wu, Jinming and Li, Wei and Li, Bo and Ma, Zejun and Liu, Ziwei and Li, Chunyuan},
  journal={arXiv preprint arXiv:2410.02713},
  year={2024}
}

@inproceedings{malmm,
  title={Ma-lmm: Memory-augmented large multimodal model for long-term video understanding},
  author={He, Bo and Li, Hengduo and Jang, Young Kyun and Jia, Menglin and Cao, Xuefei and Shah, Ashish and Shrivastava, Abhinav and Lim, Ser-Nam},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13504--13514},
  year={2024}
}

@inproceedings{weng2024longvlm,
  title={Longvlm: Efficient long video understanding via large language models},
  author={Weng, Yuetian and Han, Mingfei and He, Haoyu and Chang, Xiaojun and Zhuang, Bohan},
  booktitle={European Conference on Computer Vision},
  pages={453--470},
  year={2024},
  organization={Springer}
}

@inproceedings{wang2024videoagent,
  title={Videoagent: Long-form video understanding with large language model as agent},
  author={Wang, Xiaohan and Zhang, Yuhui and Zohar, Orr and Yeung-Levy, Serena},
  booktitle={European Conference on Computer Vision},
  pages={58--76},
  year={2024},
  organization={Springer}
}

@article{chen2024longvila,
  title={Longvila: Scaling long-context visual language models for long videos},
  author={Chen, Yukang and Xue, Fuzhao and Li, Dacheng and Hu, Qinghao and Zhu, Ligeng and Li, Xiuyu and Fang, Yunhao and Tang, Haotian and Yang, Shang and Liu, Zhijian and others},
  journal={arXiv preprint arXiv:2408.10188},
  year={2024}
}

@article{llmsurvey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  volume={1},
  number={2},
  year={2023}
}

@article{rolesurvey,
  title={The oscars of ai theater: A survey on role-playing with language models},
  author={Chen, Nuo and Wang, Yan and Deng, Yang and Li, Jia},
  journal={arXiv preprint arXiv:2407.11484},
  year={2024}
}

@article{wei2025videorope,
  title={VideoRoPE: What Makes for Good Video Rotary Position Embedding?},
  author={Wei, Xilin and Liu, Xiaoran and Zang, Yuhang and Dong, Xiaoyi and Zhang, Pan and Cao, Yuhang and Tong, Jian and Duan, Haodong and Guo, Qipeng and Wang, Jiaqi and others},
  journal={arXiv preprint arXiv:2502.05173},
  year={2025}
}

@article{shen2024longvu,
  title={Longvu: Spatiotemporal adaptive compression for long video-language understanding},
  author={Shen, Xiaoqian and Xiong, Yunyang and Zhao, Changsheng and Wu, Lemeng and Chen, Jun and Zhu, Chenchen and Liu, Zechun and Xiao, Fanyi and Varadarajan, Balakrishnan and Bordes, Florian and others},
  journal={arXiv preprint arXiv:2410.17434},
  year={2024}
}

@article{wang2025internvideo2.5,
  title={InternVideo2.5: Empowering Video MLLMs with Long and Rich Context Modeling},
  author={Wang, Yi and Li, Xinhao and Yan, Ziang and He, Yinan and Yu, Jiashuo and Zeng, Xiangyu and Wang, Chenting and Ma, Changlian and Huang, Haian and Gao, Jianfei and others},
  journal={arXiv preprint arXiv:2501.12386},
  year={2025}
}

@article{liu2025videomind,
  title={VideoMind: A Chain-of-LoRA Agent for Long Video Reasoning},
  author={Liu, Ye and Lin, Kevin Qinghong and Chen, Chang Wen and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2503.13444},
  year={2025}
}

@article{li2024IVA,
  title={Llms meet long video: Advancing long video comprehension with an interactive visual adapter in llms},
  author={Li, Yunxin and Chen, Xinyu and Hu, Baotain and Zhang, Min},
  journal={arXiv preprint arXiv:2402.13546},
  volume={3},
  number={7},
  year={2024}
}


@inproceedings{videollava,
  title={Video-LLaVA: Learning United Visual Representation by Alignment Before Projection},
  author={Lin, Bin and Ye, Yang and Zhu, Bin and Cui, Jiaxi and Ning, Munan and Jin, Peng and Yuan, Li},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={5971--5984},
  year={2024}
}

@inproceedings{wang2024gpt4video,
  title={Gpt4video: A unified multimodal large language model for lnstruction-followed understanding and safety-aware generation},
  author={Wang, Zhanyu and Wang, Longyue and Zhao, Zhen and Wu, Minghao and Lyu, Chenyang and Li, Huayang and Cai, Deng and Zhou, Luping and Shi, Shuming and Tu, Zhaopeng},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={3907--3916},
  year={2024}
}

@inproceedings{sun2024emu,
  title={Emu: Generative Pretraining in Multimodality},
  author={Sun, Quan and Yu, Qiying and Cui, Yufeng and Zhang, Fan and Zhang, Xiaosong and Wang, Yueze and Gao, Hongcheng and Liu, Jingjing and Huang, Tiejun and Wang, Xinlong},
  booktitle={ICLR},
  year={2024}
}

@article{wei2022chainofthought,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{ICL,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{lian2024videollm,
  title={LLM-grounded Video Diffusion Models},
  author={Lian, Long and Shi, Baifeng and Yala, Adam and Darrell, Trevor and Li, Boyi},
  booktitle={ICLR},
  year={2024}
}

@article{videoemotion,
  title={Emotional video captioning with vision-based emotion interpretation network},
  author={Song, Peipei and Guo, Dan and Yang, Xun and Tang, Shengeng and Wang, Meng},
  journal={IEEE Transactions on Image Processing},
  volume={33},
  pages={1122--1135},
  year={2024},
  publisher={IEEE}
}

@article{mou2024revideomotion,
  title={Revideo: Remake a video with motion and content control},
  author={Mou, Chong and Cao, Mingdeng and Wang, Xintao and Zhang, Zhaoyang and Shan, Ying and Zhang, Jian},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={18481--18505},
  year={2024}
}

@inproceedings{yang2024videoscene,
  title={DoraemonGPT: toward understanding dynamic scenes with large language models (exemplified as a video agent)},
  author={Yang, Zongxin and Chen, Guikun and Li, Xiaodi and Wang, Wenguan and Yang, Yi},
  booktitle={Proceedings of the 41st International Conference on Machine Learning},
  pages={55976--55997},
  year={2024}
}

@inproceedings{adam,
  title={Decoupled Weight Decay Regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle={International Conference on Learning Representations},
  year={2019}
}