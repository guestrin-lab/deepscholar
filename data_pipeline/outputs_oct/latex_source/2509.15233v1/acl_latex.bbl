\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Alayrac et~al.(2022)Alayrac, Donahue, Luc, Miech, Barr, Hasson, Lenc, Mensch, Millican, Reynolds et~al.}]{flamingo}
Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, and 1 others. 2022.
\newblock Flamingo: a visual language model for few-shot learning.
\newblock \emph{Advances in neural information processing systems}, 35:23716--23736.

\bibitem[{Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell et~al.}]{icl}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, and 1 others. 2020.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems}, 33:1877--1901.

\bibitem[{Chen et~al.(2024{\natexlab{a}})Chen, Wei, Li, Dong, Zhang, Zang, Chen, Duan, Tang, Yuan et~al.}]{chen2024sharegpt4video}
Lin Chen, Xilin Wei, Jinsong Li, Xiaoyi Dong, Pan Zhang, Yuhang Zang, Zehui Chen, Haodong Duan, Zhenyu Tang, Li~Yuan, and 1 others. 2024{\natexlab{a}}.
\newblock Sharegpt4video: Improving video understanding and generation with better captions.
\newblock \emph{Advances in Neural Information Processing Systems}, 37:19472--19495.

\bibitem[{Chen et~al.(2024{\natexlab{b}})Chen, Wang, Deng, and Li}]{rolesurvey}
Nuo Chen, Yan Wang, Yang Deng, and Jia Li. 2024{\natexlab{b}}.
\newblock The oscars of ai theater: A survey on role-playing with language models.
\newblock \emph{arXiv preprint arXiv:2407.11484}.

\bibitem[{Chen et~al.(2024{\natexlab{c}})Chen, Wu, Wang, Su, Chen, Xing, Zhong, Zhang, Zhu, Lu et~al.}]{chen2024internvl}
Zhe Chen, Jiannan Wu, Wenhai Wang, Weijie Su, Guo Chen, Sen Xing, Muyan Zhong, Qinglong Zhang, Xizhou Zhu, Lewei Lu, and 1 others. 2024{\natexlab{c}}.
\newblock Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 24185--24198.

\bibitem[{Dai et~al.(2023)Dai, Li, Li, Tiong, Zhao, Wang, Li, Fung, and Hoi}]{instructBLIP}
Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng~Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, and Steven C.~H. Hoi. 2023.
\newblock \href {http://papers.nips.cc/paper\_files/paper/2023/hash/9a6a435e75419a836fe47ab6793623e6-Abstract-Conference.html} {Instructblip: Towards general-purpose vision-language models with instruction tuning}.
\newblock In \emph{Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023}.

\bibitem[{Dai et~al.(2024)Dai, Hu, Wang, Jin, Chen, and Lu}]{dai2024mmrole}
Yanqi Dai, Huanran Hu, Lei Wang, Shengjie Jin, Xu~Chen, and Zhiwu Lu. 2024.
\newblock Mmrole: A comprehensive framework for developing and evaluating multimodal role-playing agents.
\newblock \emph{arXiv preprint arXiv:2408.04203}.

\bibitem[{Islam et~al.(2024)Islam, Ho, Yang, Nagarajan, Torresani, and Bertasius}]{Recap}
Md~Mohaiminul Islam, Ngan Ho, Xitong Yang, Tushar Nagarajan, Lorenzo Torresani, and Gedas Bertasius. 2024.
\newblock Video recap: Recursive captioning of hour-long videos.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 18198--18208.

\bibitem[{Li et~al.(2024)Li, Zhang, Zhang, Guo, Zhang, Li, Zhang, Liu, and Li}]{li2024llavanext-strong}
Bo~Li, Kaichen Zhang, Hao Zhang, Dong Guo, Renrui Zhang, Feng Li, Yuanhan Zhang, Ziwei Liu, and Chunyuan Li. 2024.
\newblock \href {https://llava-vl.github.io/blog/2024-05-10-llava-next-stronger-llms/} {Llava-next: Stronger llms supercharge multimodal capabilities in the wild}.

\bibitem[{Li et~al.(2023{\natexlab{a}})Li, Leng, Yan, Shen, Wang, Mi, Fei, Feng, Yan, Wang et~al.}]{li2023chatharuhi}
Cheng Li, Ziang Leng, Chenxi Yan, Junyi Shen, Hao Wang, Weishi Mi, Yaying Fei, Xiaoyang Feng, Song Yan, HaoSheng Wang, and 1 others. 2023{\natexlab{a}}.
\newblock Chatharuhi: Reviving anime character in reality via large language model.
\newblock \emph{arXiv preprint arXiv:2308.09597}.

\bibitem[{Li et~al.(2023{\natexlab{b}})Li, Li, Savarese, and Hoi}]{li2023blip}
Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. 2023{\natexlab{b}}.
\newblock Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models.
\newblock In \emph{International conference on machine learning}, pages 19730--19742. PMLR.

\bibitem[{Lian et~al.(2024)Lian, Shi, Yala, Darrell, and Li}]{lian2024videollm}
Long Lian, Baifeng Shi, Adam Yala, Trevor Darrell, and Boyi Li. 2024.
\newblock Llm-grounded video diffusion models.
\newblock In \emph{ICLR}.

\bibitem[{Lin et~al.(2024)Lin, Ye, Zhu, Cui, Ning, Jin, and Yuan}]{videollava}
Bin Lin, Yang Ye, Bin Zhu, Jiaxi Cui, Munan Ning, Peng Jin, and Li~Yuan. 2024.
\newblock Video-llava: Learning united visual representation by alignment before projection.
\newblock In \emph{Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing}, pages 5971--5984.

\bibitem[{Liu et~al.(2024)Liu, Li, Wu, and Lee}]{llava}
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong~Jae Lee. 2024.
\newblock Visual instruction tuning.
\newblock \emph{Advances in neural information processing systems}, 36.

\bibitem[{Loshchilov and Hutter(2019)}]{adam}
Ilya Loshchilov and Frank Hutter. 2019.
\newblock Decoupled weight decay regularization.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Lu et~al.(2025)Lu, Li, Shen, Gui, An, He, Yin, and Sun}]{LUandLI2025RoleMRC}
Junru Lu, Jiazheng Li, Guodong Shen, Lin Gui, Siyu An, Yulan He, Di~Yin, and Xing Sun. 2025.
\newblock Rolemrc: A fine-grained composite benchmark for role-playing and instruction-following.
\newblock \emph{arXiv preprint arXiv:2502.11387}.

\bibitem[{Lu et~al.(2024)Lu, Yu, Zhou, and Zhou}]{lu2024ditto}
Keming Lu, Bowen Yu, Chang Zhou, and Jingren Zhou. 2024.
\newblock Large language models are superpositions of all characters: Attaining arbitrary role-play via self-alignment.
\newblock In \emph{Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 7828--7840.

\bibitem[{Mou et~al.(2024)Mou, Cao, Wang, Zhang, Shan, and Zhang}]{mou2024revideomotion}
Chong Mou, Mingdeng Cao, Xintao Wang, Zhaoyang Zhang, Ying Shan, and Jian Zhang. 2024.
\newblock Revideo: Remake a video with motion and content control.
\newblock \emph{Advances in Neural Information Processing Systems}, 37:18481--18505.

\bibitem[{Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark et~al.}]{CLIP}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, and 1 others. 2021.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{International conference on machine learning}, pages 8748--8763. PMLR.

\bibitem[{Ran et~al.(2024)Ran, Wang, Xu, Yuan, Liang, Xiao, and Yang}]{ran2024rolepersonality}
Yiting Ran, Xintao Wang, Rui Xu, Xinfeng Yuan, Jiaqing Liang, Yanghua Xiao, and Deqing Yang. 2024.
\newblock Capturing minds, not just words: Enhancing role-playing language models with personality-indicative data.
\newblock In \emph{Findings of the Association for Computational Linguistics: EMNLP 2024}, pages 14566--14576.

\bibitem[{Shao et~al.(2023)Shao, Li, Dai, and Qiu}]{characterllm}
Yunfan Shao, Linyang Li, Junqi Dai, and Xipeng Qiu. 2023.
\newblock Character-llm: A trainable agent for role-playing.
\newblock In \emph{Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing}, pages 13153--13187.

\bibitem[{Shen et~al.(2024)Shen, Xiong, Zhao, Wu, Chen, Zhu, Liu, Xiao, Varadarajan, Bordes et~al.}]{shen2024longvu}
Xiaoqian Shen, Yunyang Xiong, Changsheng Zhao, Lemeng Wu, Jun Chen, Chenchen Zhu, Zechun Liu, Fanyi Xiao, Balakrishnan Varadarajan, Florian Bordes, and 1 others. 2024.
\newblock Longvu: Spatiotemporal adaptive compression for long video-language understanding.
\newblock \emph{arXiv preprint arXiv:2410.17434}.

\bibitem[{Song et~al.(2024)Song, Guo, Yang, Tang, and Wang}]{videoemotion}
Peipei Song, Dan Guo, Xun Yang, Shengeng Tang, and Meng Wang. 2024.
\newblock Emotional video captioning with vision-based emotion interpretation network.
\newblock \emph{IEEE Transactions on Image Processing}, 33:1122--1135.

\bibitem[{Sun et~al.(2024)Sun, Yu, Cui, Zhang, Zhang, Wang, Gao, Liu, Huang, and Wang}]{sun2024emu}
Quan Sun, Qiying Yu, Yufeng Cui, Fan Zhang, Xiaosong Zhang, Yueze Wang, Hongcheng Gao, Jingjing Liu, Tiejun Huang, and Xinlong Wang. 2024.
\newblock Emu: Generative pretraining in multimodality.
\newblock In \emph{ICLR}.

\bibitem[{Tu et~al.(2024)Tu, Fan, Tian, Shen, Shang, Gao, and Yan}]{tu2024charactereval}
Quan Tu, Shilong Fan, Zihang Tian, Tianhao Shen, Shuo Shang, Xin Gao, and Rui Yan. 2024.
\newblock Charactereval: A chinese benchmark for role-playing conversational agent evaluation.
\newblock In \emph{Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 11836--11850.

\bibitem[{Wang et~al.(2024{\natexlab{a}})Wang, Peng, Que, Liu, Zhou, Wu, Guo, Gan, Ni, Yang et~al.}]{wang2024rolellm}
Noah Wang, Zy~Peng, Haoran Que, Jiaheng Liu, Wangchunshu Zhou, Yuhan Wu, Hongcheng Guo, Ruitong Gan, Zehao Ni, Jian Yang, and 1 others. 2024{\natexlab{a}}.
\newblock Rolellm: Benchmarking, eliciting, and enhancing role-playing abilities of large language models.
\newblock In \emph{Findings of the Association for Computational Linguistics ACL 2024}, pages 14743--14777.

\bibitem[{Wang et~al.(2024{\natexlab{b}})Wang, Dai, Gao, and Li}]{character100}
Xi~Wang, Hongliang Dai, Shen Gao, and Piji Li. 2024{\natexlab{b}}.
\newblock Characteristic ai agents via large language models.
\newblock In \emph{Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)}, pages 3016--3027.

\bibitem[{Wang et~al.(2024{\natexlab{c}})Wang, Zhang, Zohar, and Yeung-Levy}]{wang2024videoagent}
Xiaohan Wang, Yuhui Zhang, Orr Zohar, and Serena Yeung-Levy. 2024{\natexlab{c}}.
\newblock Videoagent: Long-form video understanding with large language model as agent.
\newblock In \emph{European Conference on Computer Vision}, pages 58--76. Springer.

\bibitem[{Wang et~al.(2025{\natexlab{a}})Wang, Zhang, Ge, Yu, Yu, and Yu}]{wang2025opencharacter}
Xiaoyang Wang, Hongming Zhang, Tao Ge, Wenhao Yu, Dian Yu, and Dong Yu. 2025{\natexlab{a}}.
\newblock Opencharacter: Training customizable role-playing llms with large-scale synthetic personas.
\newblock \emph{arXiv preprint arXiv:2501.15427}.

\bibitem[{Wang et~al.(2025{\natexlab{b}})Wang, Wang, Zhang, Yuan, Xu, Huang, Yuan, Guo, Chen, Wang et~al.}]{wang2025coser}
Xintao Wang, Heng Wang, Yifei Zhang, Xinfeng Yuan, Rui Xu, Jen-tse Huang, Siyu Yuan, Haoran Guo, Jiangjie Chen, Wei Wang, and 1 others. 2025{\natexlab{b}}.
\newblock Coser: Coordinating llm-based persona simulation of established roles.
\newblock \emph{arXiv preprint arXiv:2502.09082}.

\bibitem[{Wang et~al.(2024{\natexlab{d}})Wang, Xiao, Huang, Yuan, Xu, Guo, Tu, Fei, Leng, Wang et~al.}]{wang2024incharacter}
Xintao Wang, Yunze Xiao, Jen-tse Huang, Siyu Yuan, Rui Xu, Haoran Guo, Quan Tu, Yaying Fei, Ziang Leng, Wei Wang, and 1 others. 2024{\natexlab{d}}.
\newblock Incharacter: Evaluating personality fidelity in role-playing agents through psychological interviews.
\newblock In \emph{Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 1840--1873.

\bibitem[{Wang et~al.(2025{\natexlab{c}})Wang, Li, Yan, He, Yu, Zeng, Wang, Ma, Huang, Gao et~al.}]{wang2025internvideo2.5}
Yi~Wang, Xinhao Li, Ziang Yan, Yinan He, Jiashuo Yu, Xiangyu Zeng, Chenting Wang, Changlian Ma, Haian Huang, Jianfei Gao, and 1 others. 2025{\natexlab{c}}.
\newblock Internvideo2.5: Empowering video mllms with long and rich context modeling.
\newblock \emph{arXiv preprint arXiv:2501.12386}.

\bibitem[{Wang et~al.(2024{\natexlab{e}})Wang, Wang, Zhao, Wu, Lyu, Li, Cai, Zhou, Shi, and Tu}]{wang2024gpt4video}
Zhanyu Wang, Longyue Wang, Zhen Zhao, Minghao Wu, Chenyang Lyu, Huayang Li, Deng Cai, Luping Zhou, Shuming Shi, and Zhaopeng Tu. 2024{\natexlab{e}}.
\newblock Gpt4video: A unified multimodal large language model for lnstruction-followed understanding and safety-aware generation.
\newblock In \emph{Proceedings of the 32nd ACM International Conference on Multimedia}, pages 3907--3916.

\bibitem[{Wei et~al.(2022)Wei, Wang, Schuurmans, Bosma, Xia, Chi, Le, Zhou et~al.}]{wei2022chainofthought}
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed~Chi, Quoc~V Le, Denny Zhou, and 1 others. 2022.
\newblock Chain-of-thought prompting elicits reasoning in large language models.
\newblock \emph{Advances in neural information processing systems}, 35:24824--24837.

\bibitem[{Weng et~al.(2024)Weng, Han, He, Chang, and Zhuang}]{weng2024longvlm}
Yuetian Weng, Mingfei Han, Haoyu He, Xiaojun Chang, and Bohan Zhuang. 2024.
\newblock Longvlm: Efficient long video understanding via large language models.
\newblock In \emph{European Conference on Computer Vision}, pages 453--470. Springer.

\bibitem[{Xu et~al.(2024)Xu, Wang, Chen, Yuan, Yuan, Liang, Chen, Dong, and Xiao}]{lifechoice}
Rui Xu, Xintao Wang, Jiangjie Chen, Siyu Yuan, Xinfeng Yuan, Jiaqing Liang, Zulong Chen, Xiaoqing Dong, and Yanghua Xiao. 2024.
\newblock Character is destiny: Can large language models simulate persona-driven decisions in role-playing?
\newblock \emph{arXiv e-prints}, pages arXiv--2404.

\bibitem[{Yang et~al.(2024)Yang, Chen, Li, Wang, and Yang}]{yang2024videoscene}
Zongxin Yang, Guikun Chen, Xiaodi Li, Wenguan Wang, and Yi~Yang. 2024.
\newblock Doraemongpt: toward understanding dynamic scenes with large language models (exemplified as a video agent).
\newblock In \emph{Proceedings of the 41st International Conference on Machine Learning}, pages 55976--55997.

\bibitem[{Zhang et~al.(2024)Zhang, Wu, Li, Li, Ma, Liu, and Li}]{LLava-video178k}
Yuanhan Zhang, Jinming Wu, Wei Li, Bo~Li, Zejun Ma, Ziwei Liu, and Chunyuan Li. 2024.
\newblock Video instruction tuning with synthetic data.
\newblock \emph{arXiv preprint arXiv:2410.02713}.

\bibitem[{Zhao et~al.(2023)Zhao, Zhou, Li, Tang, Wang, Hou, Min, Zhang, Zhang, Dong et~al.}]{llmsurvey}
Wayne~Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, and 1 others. 2023.
\newblock A survey of large language models.
\newblock \emph{arXiv preprint arXiv:2303.18223}, 1(2).

\bibitem[{Zhou et~al.(2024)Zhou, Chen, Wan, Wen, Song, Yu, Huang, Ke, Bi, Peng et~al.}]{zhou2024characterglm}
Jinfeng Zhou, Zhuang Chen, Dazhen Wan, Bosi Wen, Yi~Song, Jifan Yu, Yongkang Huang, Pei Ke, Guanqun Bi, Libiao Peng, and 1 others. 2024.
\newblock Characterglm: Customizing social characters with large language models.
\newblock In \emph{Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing: Industry Track}, pages 1457--1476.

\bibitem[{Zhou et~al.(2025)Zhou, Huang, Wen, Bi, Chen, Ke, Chen, Xiao, Peng, Tang et~al.}]{zhou2025characterbench}
Jinfeng Zhou, Yongkang Huang, Bosi Wen, Guanqun Bi, Yuxuan Chen, Pei Ke, Zhuang Chen, Xiyao Xiao, Libiao Peng, Kuntian Tang, and 1 others. 2025.
\newblock Characterbench: Benchmarking character customization of large language models.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, 24, pages 26101--26110.

\end{thebibliography}
