\begin{thebibliography}{65}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Albergo \& Vanden-Eijnden(2023)Albergo and Vanden-Eijnden]{albergo2023building}
Michael~Samuel Albergo and Eric Vanden-Eijnden.
\newblock Building normalizing flows with stochastic interpolants.
\newblock In \emph{ICLR}, 2023.

\bibitem[Avrahami et~al.(2025)Avrahami, Patashnik, Fried, Nemchinov, Aberman, Lischinski, and Cohen-Or]{avrahami2025stableflowvitallayers}
Omri Avrahami, Or~Patashnik, Ohad Fried, Egor Nemchinov, Kfir Aberman, Dani Lischinski, and Daniel Cohen-Or.
\newblock Stable flow: Vital layers for training-free image editing, 2025.
\newblock URL \url{https://arxiv.org/abs/2411.14430}.

\bibitem[Burgert et~al.(2025)Burgert, Xu, Xian, Pilarski, Clausen, He, Ma, Deng, Li, Mousavi, Ryoo, Debevec, and Yu]{gowiththeflow}
Ryan Burgert, Yuancheng Xu, Wenqi Xian, Oliver Pilarski, Pascal Clausen, Mingming He, Li~Ma, Yitong Deng, Lingxiao Li, Mohsen Mousavi, Michael Ryoo, Paul Debevec, and Ning Yu.
\newblock Go-with-the-flow: Motion-controllable video diffusion models using real-time warped noise.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pp.\  13--23, June 2025.

\bibitem[Chang et~al.(2024)Chang, Tang, Gross, and Azevedo]{howiwarpedyournoise}
Pascal Chang, Jingwei Tang, Markus Gross, and Vinicius~C Azevedo.
\newblock How i warped your noise: a temporally-correlated noise prior for diffusion models.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.

\bibitem[Chen et~al.(2025)Chen, Zhang, Tan, Xu, Luan, Guibas, Wetzstein, and Bi]{gmflow}
Hansheng Chen, Kai Zhang, Hao Tan, Zexiang Xu, Fujun Luan, Leonidas Guibas, Gordon Wetzstein, and Sai Bi.
\newblock Gaussian mixture flow matching models.
\newblock In \emph{ICML}, 2025.

\bibitem[Dalva et~al.(2024)Dalva, Venkatesh, and Yanardag]{dalva2024fluxspacedisentangledsemanticediting}
Yusuf Dalva, Kavana Venkatesh, and Pinar Yanardag.
\newblock Fluxspace: Disentangled semantic editing in rectified flow transformers, 2024.
\newblock URL \url{https://arxiv.org/abs/2412.09611}.

\bibitem[Do et~al.(2025)Do, Coeurjolly, Memari, and Bonneel]{do2025lineartimetransport}
Khoa Do, David Coeurjolly, Pooran Memari, and Nicolas Bonneel.
\newblock Linear-time transport with rectified flows.
\newblock \emph{ACM Trans. Graph.}, 44, Aug 2025.

\bibitem[Esser et~al.(2024)Esser, Kulal, Blattmann, Entezari, M\"{u}ller, Saini, Levi, Lorenz, Sauer, Boesel, Podell, Dockhorn, English, and Rombach]{sd3}
Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas M\"{u}ller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, Dustin Podell, Tim Dockhorn, Zion English, and Robin Rombach.
\newblock Scaling rectified flow transformers for high-resolution image synthesis.
\newblock In Ruslan Salakhutdinov, Zico Kolter, Katherine Heller, Adrian Weller, Nuria Oliver, Jonathan Scarlett, and Felix Berkenkamp (eds.), \emph{Proceedings of the 41st International Conference on Machine Learning}, volume 235 of \emph{Proceedings of Machine Learning Research}, pp.\  12606--12633. PMLR, 21--27 Jul 2024.
\newblock URL \url{https://proceedings.mlr.press/v235/esser24a.html}.

\bibitem[Fan et~al.(2025{\natexlab{a}})Fan, Si, Song, Yang, He, Zhuo, Huang, Dong, He, Pan, Wang, Jiang, Wang, Gao, Chen, Li, Lin, Qiao, and Liu]{vchitect2}
Weichen Fan, Chenyang Si, Junhao Song, Zhenyu Yang, Yinan He, Long Zhuo, Ziqi Huang, Ziyue Dong, Jingwen He, Dongwei Pan, Yi~Wang, Yuming Jiang, Yaohui Wang, Peng Gao, Xinyuan Chen, Hengjie Li, Dahua Lin, Yu~Qiao, and Ziwei Liu.
\newblock Vchitect-2.0: Parallel transformer for scaling up video diffusion models, 2025{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2501.08453}.

\bibitem[Fan et~al.(2025{\natexlab{b}})Fan, Bhattad, and Krishna]{videoshop}
Xiang Fan, Anand Bhattad, and Ranjay Krishna.
\newblock Videoshop: Localized semantic video editing with noise-extrapolated diffusion inversion.
\newblock In Ale{\v{s}} Leonardis, Elisa Ricci, Stefan Roth, Olga Russakovsky, Torsten Sattler, and G{\"u}l Varol (eds.), \emph{Computer Vision -- ECCV 2024}, pp.\  232--250, Cham, 2025{\natexlab{b}}. Springer Nature Switzerland.
\newblock ISBN 978-3-031-73254-6.

\bibitem[Feng et~al.(2025)Feng, Gao, Bao, Wang, Han, Zhang, Zhang, and Yao]{wave}
Yutang Feng, Sicheng Gao, Yuxiang Bao, Xiaodi Wang, Shumin Han, Juan Zhang, Baochang Zhang, and Angela Yao.
\newblock Wave: Warping ddim inversion features for zero-shot text-to-video editing.
\newblock In Ale{\v{s}} Leonardis, Elisa Ricci, Stefan Roth, Olga Russakovsky, Torsten Sattler, and G{\"u}l Varol (eds.), \emph{Computer Vision -- ECCV 2024}, pp.\  38--55, Cham, 2025. Springer Nature Switzerland.
\newblock ISBN 978-3-031-73116-7.

\bibitem[Gao et~al.(2025)Gao, Yang, Yao, and Hu]{unityindiversity}
Junyu Gao, Kunlin Yang, Xuan Yao, and Yufan Hu.
\newblock Unity in diversity: Video editing via gradient-latent purification.
\newblock In \emph{2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2025.

\bibitem[Gao et~al.(2024)Gao, Hoogeboom, Heek, Bortoli, Murphy, and Salimans]{gao2025diffusionmeetsflow}
Ruiqi Gao, Emiel Hoogeboom, Jonathan Heek, Valentin~De Bortoli, Kevin~P. Murphy, and Tim Salimans.
\newblock Diffusion meets flow matching: Two sides of the same coin, 2024.
\newblock URL \url{https://diffusionflow.github.io/}.

\bibitem[Guo et~al.(2024)Guo, Yang, Rao, Liang, Wang, Qiao, Agrawala, Lin, and Dai]{guo2024animatediff}
Yuwei Guo, Ceyuan Yang, Anyi Rao, Zhengyang Liang, Yaohui Wang, Yu~Qiao, Maneesh Agrawala, Dahua Lin, and Bo~Dai.
\newblock Animatediff: Animate your personalized text-to-image diffusion models without specific tuning.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.

\bibitem[Han et~al.(2024)Han, Jiang, Pan, Zhang, Mao, Xie, Liu, and Zhou]{ace}
Zhen Han, Zeyinzi Jiang, Yulin Pan, Jingfeng Zhang, Chaojie Mao, Chenwei Xie, Yu~Liu, and Jingren Zhou.
\newblock Ace: All-round creator and editor following instructions via diffusion transformer, 2024.
\newblock URL \url{https://arxiv.org/abs/2410.00086}.

\bibitem[Hertz et~al.(2023)Hertz, Mokady, Tenenbaum, Aberman, Pritch, and Cohen-or]{hertzprompt}
Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, and Daniel Cohen-or.
\newblock Prompt-to-prompt image editing with cross-attention control.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ddpm}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin (eds.), \emph{Advances in Neural Information Processing Systems}, volume~33, pp.\  6840--6851. Curran Associates, Inc., 2020.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf}.

\bibitem[Huang et~al.(2024)Huang, Xie, Wang, Yuan, Cun, Ge, Zhou, Dong, Huang, Zhang, and Shan]{smartedit}
Yuzhou Huang, Liangbin Xie, Xintao Wang, Ziyang Yuan, Xiaodong Cun, Yixiao Ge, Jiantao Zhou, Chao Dong, Rui Huang, Ruimao Zhang, and Ying Shan.
\newblock Smartedit: Exploring complex instruction-based image editing with multimodal large language models.
\newblock In \emph{2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pp.\  8362--8371, 2024.
\newblock \doi{10.1109/CVPR52733.2024.00799}.

\bibitem[Jeong et~al.(2025)Jeong, Chang, Park, and Ye]{dreammotion}
Hyeonho Jeong, Jinho Chang, Geon~Yeong Park, and Jong~Chul Ye.
\newblock Dreammotion: Space-time self-similar score distillation for zero-shot video editing.
\newblock In Ale{\v{s}} Leonardis, Elisa Ricci, Stefan Roth, Olga Russakovsky, Torsten Sattler, and G{\"u}l Varol (eds.), \emph{Computer Vision -- ECCV 2024}, pp.\  358--376, Cham, 2025. Springer Nature Switzerland.
\newblock ISBN 978-3-031-73404-5.

\bibitem[Jiang et~al.(2025)Jiang, Han, Mao, Zhang, Pan, and Liu]{vace}
Zeyinzi Jiang, Zhen Han, Chaojie Mao, Jingfeng Zhang, Yulin Pan, and Yu~Liu.
\newblock Vace: All-in-one video creation and editing, 2025.
\newblock URL \url{https://arxiv.org/abs/2503.07598}.

\bibitem[Kaplan et~al.(2020)Kaplan, McCandlish, Henighan, Brown, Chess, Child, Gray, Radford, Wu, and Amodei]{kaplan2020scalinglawsneurallanguage}
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom~B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.
\newblock Scaling laws for neural language models, 2020.
\newblock URL \url{https://arxiv.org/abs/2001.08361}.

\bibitem[Karras et~al.(2022)Karras, Aittala, Aila, and Laine]{edm}
Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine.
\newblock Elucidating the design space of diffusion-based generative models.
\newblock \emph{Advances in neural information processing systems}, 35:\penalty0 26565--26577, 2022.

\bibitem[Kong et~al.(2025)Kong, Tian, Zhang, Min, Dai, Zhou, Xiong, Li, Wu, Zhang, Wu, Lin, Yuan, Long, Wang, Wang, Li, Huang, Yang, Tan, Wang, Song, Bai, Wu, Xue, Wang, Wang, Liu, Li, Li, Wang, Yu, Deng, Li, Chen, Cui, Peng, Yu, He, Xu, Zhou, Xu, Tao, Lu, Liu, Zhou, Wang, Yang, Wang, Liu, Jiang, and Zhong]{hunyuanvideo}
Weijie Kong, Qi~Tian, Zijian Zhang, Rox Min, Zuozhuo Dai, Jin Zhou, Jiangfeng Xiong, Xin Li, Bo~Wu, Jianwei Zhang, Kathrina Wu, Qin Lin, Junkun Yuan, Yanxin Long, Aladdin Wang, Andong Wang, Changlin Li, Duojun Huang, Fang Yang, Hao Tan, Hongmei Wang, Jacob Song, Jiawang Bai, Jianbing Wu, Jinbao Xue, Joey Wang, Kai Wang, Mengyang Liu, Pengyu Li, Shuai Li, Weiyan Wang, Wenqing Yu, Xinchi Deng, Yang Li, Yi~Chen, Yutao Cui, Yuanbo Peng, Zhentao Yu, Zhiyu He, Zhiyong Xu, Zixiang Zhou, Zunnan Xu, Yangyu Tao, Qinglin Lu, Songtao Liu, Dax Zhou, Hongfa Wang, Yong Yang, Di~Wang, Yuhong Liu, Jie Jiang, and Caesar Zhong.
\newblock Hunyuanvideo: A systematic framework for large video generative models, 2025.
\newblock URL \url{https://arxiv.org/abs/2412.03603}.

\bibitem[Ku et~al.(2024)Ku, Wei, Ren, Yang, and Chen]{kuanyv2v}
Max Ku, Cong Wei, Weiming Ren, Huan Yang, and Wenhu Chen.
\newblock Anyv2v: A tuning-free framework for any video-to-video editing tasks.
\newblock \emph{Transactions on Machine Learning Research}, 2024.

\bibitem[Kulikov et~al.(2024)Kulikov, Kleiner, Huberman-Spiegelglas, and Michaeli]{kulikov2024floweditinversionfreetextbasedediting}
Vladimir Kulikov, Matan Kleiner, Inbar Huberman-Spiegelglas, and Tomer Michaeli.
\newblock Flowedit: Inversion-free text-based editing using pre-trained flow models, 2024.
\newblock URL \url{https://arxiv.org/abs/2412.08629}.

\bibitem[Lipman et~al.(2023)Lipman, Chen, Ben-Hamu, Nickel, and Le]{flowmatching}
Yaron Lipman, Ricky~TQ Chen, Heli Ben-Hamu, Maximilian Nickel, and Matthew Le.
\newblock Flow matching for generative modeling.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.

\bibitem[Liu et~al.(2023)Liu, Ning, Lin, Yang, and Wang]{omsdpm}
Enshu Liu, Xuefei Ning, Zinan Lin, Huazhong Yang, and Yu~Wang.
\newblock {OMS}-{DPM}: Optimizing the model schedule for diffusion probabilistic models.
\newblock In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett (eds.), \emph{Proceedings of the 40th International Conference on Machine Learning}, volume 202 of \emph{Proceedings of Machine Learning Research}, pp.\  21915--21936. PMLR, 23--29 Jul 2023.
\newblock URL \url{https://proceedings.mlr.press/v202/liu23ab.html}.

\bibitem[Liu et~al.(2025{\natexlab{a}})Liu, Zhang, Wang, Wei, Qiu, Zhao, Zhang, Ye, and Wan]{teacache}
Feng Liu, Shiwei Zhang, Xiaofeng Wang, Yujie Wei, Haonan Qiu, Yuzhong Zhao, Yingya Zhang, Qixiang Ye, and Fang Wan.
\newblock Timestep embedding tells: It's time to cache for video diffusion model, 2025{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2411.19108}.

\bibitem[Liu et~al.(2025{\natexlab{b}})Liu, Han, Xing, Yin, Wang, Cheng, Liao, Wang, Fu, Han, Li, Peng, Sun, Wu, Cai, Ge, Ming, Xia, Zeng, Zhu, Jiao, Zhang, Yu, and Jiang]{stepedit}
Shiyu Liu, Yucheng Han, Peng Xing, Fukun Yin, Rui Wang, Wei Cheng, Jiaqi Liao, Yingming Wang, Honghao Fu, Chunrui Han, Guopeng Li, Yuang Peng, Quan Sun, Jingwei Wu, Yan Cai, Zheng Ge, Ranchen Ming, Lei Xia, Xianfang Zeng, Yibo Zhu, Binxing Jiao, Xiangyu Zhang, Gang Yu, and Daxin Jiang.
\newblock Step1x-edit: A practical framework for general image editing, 2025{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2504.17761}.

\bibitem[Liu et~al.(2022)Liu, Gong, and Liu]{rectifiedflow}
Xingchao Liu, Chengyue Gong, and Qiang Liu.
\newblock Flow straight and fast: Learning to generate and transfer data with rectified flow, 2022.
\newblock URL \url{https://arxiv.org/abs/2209.03003}.

\bibitem[Mao et~al.(2025)Mao, Zhang, Pan, Jiang, Han, Liu, and Zhou]{acepp}
Chaojie Mao, Jingfeng Zhang, Yulin Pan, Zeyinzi Jiang, Zhen Han, Yu~Liu, and Jingren Zhou.
\newblock Ace++: Instruction-based image creation and editing via context-aware content filling, 2025.
\newblock URL \url{https://arxiv.org/abs/2501.02487}.

\bibitem[Meng et~al.(2022)Meng, He, Song, Song, Wu, Zhu, and Ermon]{meng2022sdedit}
Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and Stefano Ermon.
\newblock {SDE}dit: Guided image synthesis and editing with stochastic differential equations.
\newblock In \emph{ICLR}, 2022.

\bibitem[OpenAI(2025)]{gpt4oimg}
OpenAI.
\newblock Introducing 4o image generation, 2025.
\newblock URL \url{https://openai.com/index/introducing-4o-image-generation}.

\bibitem[Ouyang et~al.(2024)Ouyang, Dong, Yang, Si, and Pan]{i2vedit}
Wenqi Ouyang, Yi~Dong, Lei Yang, Jianlou Si, and Xingang Pan.
\newblock I2vedit: First-frame-guided video editing via image-to-video diffusion models.
\newblock In \emph{SIGGRAPH Asia 2024 Conference Papers}, SA '24, New York, NY, USA, 2024. Association for Computing Machinery.
\newblock ISBN 9798400711312.
\newblock \doi{10.1145/3680528.3687656}.
\newblock URL \url{https://doi.org/10.1145/3680528.3687656}.

\bibitem[Peebles \& Xie(2023)Peebles and Xie]{dit}
William Peebles and Saining Xie.
\newblock Scalable diffusion models with transformers.
\newblock In \emph{2023 IEEE/CVF International Conference on Computer Vision (ICCV)}, pp.\  4172--4182, 2023.
\newblock \doi{10.1109/ICCV51070.2023.00387}.

\bibitem[Peng et~al.(2025)Peng, Zheng, Shen, Young, Guo, Wang, Xu, Liu, Jiang, Li, Wang, Ye, Ren, Ma, Liang, Lian, Wu, Zhong, Li, Gong, Lei, Cheng, Zhang, Li, Zhang, Hu, Huang, Wang, Zhao, Wang, Wei, and You]{opensora2}
Xiangyu Peng, Zangwei Zheng, Chenhui Shen, Tom Young, Xinying Guo, Binluo Wang, Hang Xu, Hongxin Liu, Mingyan Jiang, Wenjun Li, Yuhui Wang, Anbang Ye, Gang Ren, Qianran Ma, Wanying Liang, Xiang Lian, Xiwen Wu, Yuting Zhong, Zhuangyan Li, Chaoyu Gong, Guojun Lei, Leijun Cheng, Limin Zhang, Minghao Li, Ruijie Zhang, Silan Hu, Shijie Huang, Xiaokang Wang, Yuanheng Zhao, Yuqi Wang, Ziang Wei, and Yang You.
\newblock Open-sora 2.0: Training a commercial-level video generation model in \$200k, 2025.
\newblock URL \url{https://arxiv.org/abs/2503.09642}.

\bibitem[Perazzi et~al.(2016)Perazzi, Pont-Tuset, McWilliams, Van~Gool, Gross, and Sorkine-Hornung]{davis}
F.~Perazzi, J.~Pont-Tuset, B.~McWilliams, L.~Van~Gool, M.~Gross, and A.~Sorkine-Hornung.
\newblock A benchmark dataset and evaluation methodology for video object segmentation.
\newblock In \emph{2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, pp.\  724--732, 2016.
\newblock \doi{10.1109/CVPR.2016.85}.

\bibitem[Poole et~al.(2023)Poole, Jain, Barron, and Mildenhall]{pooledreamfusion}
Ben Poole, Ajay Jain, Jonathan~T Barron, and Ben Mildenhall.
\newblock Dreamfusion: Text-to-3d using 2d diffusion.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, Krueger, and Sutskever]{clip}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever.
\newblock Learning transferable visual models from natural language supervision.
\newblock In Marina Meila and Tong Zhang (eds.), \emph{Proceedings of the 38th International Conference on Machine Learning}, volume 139 of \emph{Proceedings of Machine Learning Research}, pp.\  8748--8763. PMLR, 18--24 Jul 2021.
\newblock URL \url{https://proceedings.mlr.press/v139/radford21a.html}.

\bibitem[Ren et~al.(2025)Ren, Jiang, Zhang, Forchhammer, and Süsstrunk]{ren2025fdsfrequencyawaredenoisingscore}
Yufan Ren, Zicong Jiang, Tong Zhang, Søren Forchhammer, and Sabine Süsstrunk.
\newblock Fds: Frequency-aware denoising score for text-guided latent diffusion image editing, 2025.
\newblock URL \url{https://arxiv.org/abs/2503.19191}.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{ldm}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pp.\  10674--10685, 2022.
\newblock \doi{10.1109/CVPR52688.2022.01042}.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and Brox]{unet}
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In Nassir Navab, Joachim Hornegger, William~M. Wells, and Alejandro~F. Frangi (eds.), \emph{Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015}, pp.\  234--241, Cham, 2015. Springer International Publishing.
\newblock ISBN 978-3-319-24574-4.

\bibitem[Schuhmann et~al.(2022)Schuhmann, Beaumont, Vencu, Gordon, Wightman, Cherti, Coombes, Katta, Mullis, Wortsman, Schramowski, Kundurthy, Crowson, Schmidt, Kaczmarczyk, and Jitsev]{laion5b}
Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Wortsman, Patrick Schramowski, Srivatsa Kundurthy, Katherine Crowson, Ludwig Schmidt, Robert Kaczmarczyk, and Jenia Jitsev.
\newblock Laion-5b: An open large-scale dataset for training next generation image-text models.
\newblock In S.~Koyejo, S.~Mohamed, A.~Agarwal, D.~Belgrave, K.~Cho, and A.~Oh (eds.), \emph{Advances in Neural Information Processing Systems}, volume~35, pp.\  25278--25294. Curran Associates, Inc., 2022.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2022/file/a1859debfb3b59d094f3504d5ebb6c25-Paper-Datasets_and_Benchmarks.pdf}.

\bibitem[Shi et~al.(2024{\natexlab{a}})Shi, Huang, Wang, Bian, Li, Zhang, Zhang, Cheung, See, Qin, Dai, and Li]{motioni2v}
Xiaoyu Shi, Zhaoyang Huang, Fu-Yun Wang, Weikang Bian, Dasong Li, Yi~Zhang, Manyuan Zhang, Ka~Chun Cheung, Simon See, Hongwei Qin, Jifeng Dai, and Hongsheng Li.
\newblock Motion-i2v: Consistent and controllable image-to-video generation with explicit motion modeling.
\newblock In \emph{ACM SIGGRAPH 2024 Conference Papers}, SIGGRAPH '24, New York, NY, USA, 2024{\natexlab{a}}. Association for Computing Machinery.
\newblock ISBN 9798400705250.
\newblock \doi{10.1145/3641519.3657497}.
\newblock URL \url{https://doi.org/10.1145/3641519.3657497}.

\bibitem[Shi et~al.(2024{\natexlab{b}})Shi, Wang, and Huang]{seededit}
Yichun Shi, Peng Wang, and Weilin Huang.
\newblock Seededit: Align image re-generation to image editing, 2024{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2411.06686}.

\bibitem[Song et~al.(2021)Song, Meng, and Ermon]{ddim}
Jiaming Song, Chenlin Meng, and Stefano Ermon.
\newblock Denoising diffusion implicit models.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Song et~al.(2025)Song, Shin, Lee, Kim, and Kwak]{save}
Yeji Song, Wonsik Shin, Junsoo Lee, Jeesoo Kim, and Nojun Kwak.
\newblock Save: Protagonist diversification with structure agnostic video editing.
\newblock In Ale{\v{s}} Leonardis, Elisa Ricci, Stefan Roth, Olga Russakovsky, Torsten Sattler, and G{\"u}l Varol (eds.), \emph{Computer Vision -- ECCV 2024}, pp.\  41--57, Cham, 2025. Springer Nature Switzerland.
\newblock ISBN 978-3-031-72989-8.

\bibitem[Sun et~al.(2024)Sun, Tu, Liao, and Tao]{videoeditingsurvey}
Wenhao Sun, Rong-Cheng Tu, Jingyi Liao, and Dacheng Tao.
\newblock Diffusion model-based video editing: A survey, 2024.
\newblock URL \url{https://arxiv.org/abs/2407.07111}.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{attention2017}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N Gomez, \L~ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In I.~Guyon, U.~Von Luxburg, S.~Bengio, H.~Wallach, R.~Fergus, S.~Vishwanathan, and R.~Garnett (eds.), \emph{Advances in Neural Information Processing Systems}, volume~30. Curran Associates, Inc., 2017.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}.

\bibitem[Wan et~al.(2025)Wan, Wang, Ai, Wen, Mao, Xie, Chen, Yu, Zhao, Yang, Zeng, Wang, Zhang, Zhou, Wang, Chen, Zhu, Zhao, Yan, Huang, Feng, Zhang, Li, Wu, Chu, Feng, Zhang, Sun, Fang, Wang, Gui, Weng, Shen, Lin, Wang, Wang, Zhou, Wang, Shen, Yu, Shi, Huang, Xu, Kou, Lv, Li, Liu, Wang, Zhang, Huang, Li, Wu, Liu, Pan, Zheng, Hong, Shi, Feng, Jiang, Han, Wu, and Liu]{wan}
Team Wan, Ang Wang, Baole Ai, Bin Wen, Chaojie Mao, Chen-Wei Xie, Di~Chen, Feiwu Yu, Haiming Zhao, Jianxiao Yang, Jianyuan Zeng, Jiayu Wang, Jingfeng Zhang, Jingren Zhou, Jinkai Wang, Jixuan Chen, Kai Zhu, Kang Zhao, Keyu Yan, Lianghua Huang, Mengyang Feng, Ningyi Zhang, Pandeng Li, Pingyu Wu, Ruihang Chu, Ruili Feng, Shiwei Zhang, Siyang Sun, Tao Fang, Tianxing Wang, Tianyi Gui, Tingyu Weng, Tong Shen, Wei Lin, Wei Wang, Wei Wang, Wenmeng Zhou, Wente Wang, Wenting Shen, Wenyuan Yu, Xianzhong Shi, Xiaoming Huang, Xin Xu, Yan Kou, Yangyu Lv, Yifei Li, Yijing Liu, Yiming Wang, Yingya Zhang, Yitong Huang, Yong Li, You Wu, Yu~Liu, Yulin Pan, Yun Zheng, Yuntao Hong, Yupeng Shi, Yutong Feng, Zeyinzi Jiang, Zhen Han, Zhi-Fan Wu, and Ziyu Liu.
\newblock Wan: Open and advanced large-scale video generative models, 2025.
\newblock URL \url{https://arxiv.org/abs/2503.20314}.

\bibitem[Wang \& Vastola(2024)Wang and Vastola]{wang2024diffusionmodelsgenerateimages}
Binxu Wang and John~J. Vastola.
\newblock Diffusion models generate images like painters: an analytical theory of outline first, details later, 2024.
\newblock URL \url{https://arxiv.org/abs/2303.02490}.

\bibitem[Xiao et~al.(2024)Xiao, Wang, Zhou, Yuan, Xing, Yan, Li, Wang, Huang, and Liu]{omnigen}
Shitao Xiao, Yueze Wang, Junjie Zhou, Huaying Yuan, Xingrun Xing, Ruiran Yan, Chaofan Li, Shuting Wang, Tiejun Huang, and Zheng Liu.
\newblock Omnigen: Unified image generation, 2024.
\newblock URL \url{https://arxiv.org/abs/2409.11340}.

\bibitem[Xu et~al.(2024{\natexlab{a}})Xu, Zou, Huang, Chen, Liu, Cheng, Shi, and Huang]{easyanimate}
Jiaqi Xu, Xinyi Zou, Kunzhe Huang, Yunkuo Chen, Bo~Liu, MengLi Cheng, Xing Shi, and Jun Huang.
\newblock Easyanimate: A high-performance long video generation method based on transformer architecture, 2024{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2405.18991}.

\bibitem[Xu et~al.(2025)Xu, Jiang, Hu, Luo, He, Zhang, Wang, Wu, Ling, and Wang]{xu2025unveilinversioninvarianceflow}
Pengcheng Xu, Boyuan Jiang, Xiaobin Hu, Donghao Luo, Qingdong He, Jiangning Zhang, Chengjie Wang, Yunsheng Wu, Charles Ling, and Boyu Wang.
\newblock Unveil inversion and invariance in flow transformer for versatile image editing, 2025.
\newblock URL \url{https://arxiv.org/abs/2411.15843}.

\bibitem[Xu et~al.(2024{\natexlab{b}})Xu, Huang, Pan, Ma, and Chai]{infedit}
Sihan Xu, Yidong Huang, Jiayi Pan, Ziqiao Ma, and Joyce Chai.
\newblock Inversion-free image editing with language-guided diffusion models.
\newblock In \emph{2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pp.\  9454--9461, 2024{\natexlab{b}}.
\newblock \doi{10.1109/CVPR52733.2024.00903}.

\bibitem[Yan et~al.(2023{\natexlab{a}})Yan, Liew, Mai, Lin, and Feng]{magicprop}
Hanshu Yan, Jun~Hao Liew, Long Mai, Shanchuan Lin, and Jiashi Feng.
\newblock Magicprop: Diffusion-based video editing via motion-aware appearance propagation, 2023{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2309.00908}.

\bibitem[Yan et~al.(2023{\natexlab{b}})Yan, Brown, Abbeel, Girdhar, and Azadi]{moca}
Wilson Yan, Andrew Brown, Pieter Abbeel, Rohit Girdhar, and Samaneh Azadi.
\newblock Motion-conditioned image animation for video editing, 2023{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2311.18827}.

\bibitem[Yang et~al.(2025)Yang, Teng, Zheng, Ding, Huang, Xu, Yang, Hong, Zhang, Feng, Yin, Zhang, Wang, Cheng, Xu, Gu, Dong, and Tang]{cogvideox}
Zhuoyi Yang, Jiayan Teng, Wendi Zheng, Ming Ding, Shiyu Huang, Jiazheng Xu, Yuanming Yang, Wenyi Hong, Xiaohan Zhang, Guanyu Feng, Da~Yin, Yuxuan Zhang, Weihan Wang, Yean Cheng, Bin Xu, Xiaotao Gu, Yuxiao Dong, and Jie Tang.
\newblock Cogvideox: Text-to-video diffusion models with an expert transformer, 2025.
\newblock URL \url{https://arxiv.org/abs/2408.06072}.

\bibitem[Yatim et~al.(2025)Yatim, Fridman, Bar-Tal, and Dekel]{yatim2025dynvfxaugmentingrealvideos}
Danah Yatim, Rafail Fridman, Omer Bar-Tal, and Tali Dekel.
\newblock Dynvfx: Augmenting real videos with dynamic content, 2025.
\newblock URL \url{https://arxiv.org/abs/2502.03621}.

\bibitem[Yoon et~al.(2025)Yoon, Koo, Hong, and Yoo]{dni}
Sunjae Yoon, Gwanhyeong Koo, Ji~Woo Hong, and Chang~D. Yoo.
\newblock Dni: Dilutional noise initialization for diffusion video editing.
\newblock In Ale{\v{s}} Leonardis, Elisa Ricci, Stefan Roth, Olga Russakovsky, Torsten Sattler, and G{\"u}l Varol (eds.), \emph{Computer Vision -- ECCV 2024}, pp.\  180--195, Cham, 2025. Springer Nature Switzerland.
\newblock ISBN 978-3-031-73195-2.

\bibitem[Yu et~al.(2025)Yu, Chow, Yue, Pan, Wu, Wan, Li, Tang, Zhang, and Zhuang]{anyedit}
Qifan Yu, Wei Chow, Zhongqi Yue, Kaihang Pan, Yang Wu, Xiaoyang Wan, Juncheng Li, Siliang Tang, Hanwang Zhang, and Yueting Zhuang.
\newblock Anyedit: Mastering unified high-quality image editing for any idea, 2025.
\newblock URL \url{https://arxiv.org/abs/2411.15738}.

\bibitem[Zhang et~al.(2025)Zhang, Yu, Min, Xin, Wei, Shi, Huang, Kong, Xin, Jiang, Bahuguna, Chan, Hora, Yang, Liang, Bian, Liu, Valencia, Tredinick, Kozlov, Jiang, Huang, Chen, Liu, and Rao]{filmsurvey}
Ruihan Zhang, Borou Yu, Jiajian Min, Yetong Xin, Zheng Wei, Juncheng~Nemo Shi, Mingzhen Huang, Xianghao Kong, Nix~Liu Xin, Shanshan Jiang, Praagya Bahuguna, Mark Chan, Khushi Hora, Lijian Yang, Yongqi Liang, Runhe Bian, Yunlei Liu, Isabela~Campillo Valencia, Patricia~Morales Tredinick, Ilia Kozlov, Sijia Jiang, Peiwen Huang, Na~Chen, Xuanxuan Liu, and Anyi Rao.
\newblock Generative ai for film creation: A survey of recent advances, 2025.
\newblock URL \url{https://arxiv.org/abs/2504.08296}.

\bibitem[Zhao et~al.(2024)Zhao, Ma, Chen, Si, Wu, An, Yu, Zhang, Li, and Chang]{ultraedit}
Haozhe Zhao, Xiaojian Ma, Liang Chen, Shuzheng Si, Rujie Wu, Kaikai An, Peiyu Yu, Minjia Zhang, Qing Li, and Baobao Chang.
\newblock Ultraedit: Instruction-based fine-grained image editing at scale.
\newblock In A.~Globerson, L.~Mackey, D.~Belgrave, A.~Fan, U.~Paquet, J.~Tomczak, and C.~Zhang (eds.), \emph{Advances in Neural Information Processing Systems}, volume~37, pp.\  3058--3093. Curran Associates, Inc., 2024.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2024/file/05a30a0fc9e6bacdd3abd4ca8508a9e6-Paper-Datasets_and_Benchmarks_Track.pdf}.

\bibitem[Zhao et~al.(2023)Zhao, Bai, Rao, Zhou, and Lu]{unipc}
Wenliang Zhao, Lujia Bai, Yongming Rao, Jie Zhou, and Jiwen Lu.
\newblock Unipc: A unified predictor-corrector framework for fast sampling of diffusion models.
\newblock In A.~Oh, T.~Naumann, A.~Globerson, K.~Saenko, M.~Hardt, and S.~Levine (eds.), \emph{Advances in Neural Information Processing Systems}, volume~36, pp.\  49842--49869. Curran Associates, Inc., 2023.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2023/file/9c2aa1e456ea543997f6927295196381-Paper-Conference.pdf}.

\bibitem[Zhao et~al.(2025)Zhao, Jin, Wang, and You]{pab}
Xuanlei Zhao, Xiaolong Jin, Kai Wang, and Yang You.
\newblock Real-time video generation with pyramid attention broadcast, 2025.
\newblock URL \url{https://arxiv.org/abs/2408.12588}.

\end{thebibliography}
