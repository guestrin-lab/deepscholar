\section{Introduction}
\label{sec:intro}

Visual content editing aims at manipulating images and videos to align with the user's intention, offering endless possibilities in film production and creativity~\citep{filmsurvey}. Although significant progress has been made in the realm of image~\citep{smartedit, anyedit, ace, ultraedit, omnigen, seededit, acepp, stepedit, gpt4oimg}, video editing is still in its infancy due to the difficulty of maintaining spatiotemporal consistency, the lack of massive training data, and the huge computational cost~\citep{videoeditingsurvey}. Thus, transferring the strong editing capability of image editing models to the video domain by image-conditioned video editing serves as an ideal choice for creators to implement their ideas.

Most existing image-conditioned video editing methods either rely on the inversion of the diffusion process~\citep{ddim, edm} or require extensive optimization. The inversion process not only introduces a significant computational burden but is also inherently inaccurate~\citep{videoeditingsurvey}. To compensate for such error, a series of strategies have been introduced to enhance the texture and motion consistency, such as attention map manipulation~\citep{i2vedit} and motion embedding optimization~\citep{save}. Despite their effectiveness, these strategies are tailored for specific models, lacking the universality to adapt to other image-to-video (I2V) models. Optimizing either latents or model parameters~\citep{magicprop, motioni2v, moca, vace, dreammotion} requires extensive computational resources or data, which is not friendly for common users. In addition, it also lacks the flexibility to switch between various I2V models. With the rapid emergence of powerful flow-matching-based I2V models with different DiT-based architectures~\citep{wan, easyanimate, hunyuanvideo, cogvideox, opensora2, vchitect2, flowmatching, rectifiedflow, do2025lineartimetransport, dit}, a model-agnostic optimization-free editing paradigm is supposed to be promising to fully unleash the strong prior of these models with billions of parameters.

We introduce IF-V2V, an \underline{I}nversion-\underline{F}ree image-conditioned video editing method that can be applied to off-the-shelf flow-matching-based I2V models within acceptable computational overhead (\cref{fig:teaser}). It allows users to flexibly combine the capability of any black-box image editing methods and semi-black-box flow-matching-based I2V models with access to their input latents and denoising vectors. This paper primarily encompasses the following three technical contributions: \textbf{First}, to incorporate source video information into the denoising process without inversion, we introduce Vector Field Rectification with Sample Deviation (VFR-SD). This method modifies the vector field used in solving the target ordinary differential equation (ODE) by adding a deviation term.  Specifically, this deviation term leverages the difference between the ground truth sample and the predicted expectation of the source video distribution to direct the target denoising path to align with the source video sample. \textbf{Second}, to further enhance spatiotemporal consistency with the source video, we present Structure-and-Motion-Preserving Initialization (SMPI), which utilizes the motion cue of the source video to generate temporally correlated noise for initialization and meanwhile embeds the structural information into ODE initializations and reference conditions. \textbf{Third}, to minimize the additional computational cost for vector field rectification, we devise a Deviation Caching (D-Cache) mechanism to reuse the deviation term while preserving editing quality according to the variation pattern of the target denoising vector~\citep{teacache}. 

Extensive experiments demonstrate that IF-V2V achieves superior visual quality and consistency in image-conditioned video editing tasks with modest additional computational cost. Our method also outperforms previous approaches across diverse editing paradigms consistently. Thanks to the model-agnostic design, IF-V2V can effectively combine the capability of any state-of-the-art image editing and I2V models to support a variety of creative video editing tasks, demonstrating a strong potential to serve as a lightweight solution for creators to experiment with their innovative ideas.
