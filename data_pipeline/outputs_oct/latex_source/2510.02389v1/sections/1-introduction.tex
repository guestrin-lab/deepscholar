\section{Introduction}

% Software vulnerabilities are pervasive and consequential in our real-world. They come from design flaws, implementation mistakes, configuration or dependency disappear and unsafe defaults, and they can damage the ability, security and integrity of the code when deployed. Specifically for security related applications, once there is report or failure, the development team need to start with detection of the vulnerabilities, localization and patching them, then verify the patch works for this report in a short time limit. The speed and accuracy of these steps determines the cost of solve this failure and the longer time cost, the higher risk it brings to users.

Software vulnerabilities now occur at unprecedented scale and cost. In 2023, more than 29,000 Common Vulnerabilities and Exposures (CVEs) were recorded \cite{cve_details_2024}. In the first half of 2025, 1,732 data breaches were reported—an 11\% increase \cite{indusface_2024}. The economic toll is mounting: software supply-chain attacks are projected to cost the global economy 80.6 billion annually by 2026, up from 45.8 billion in 2023 \cite{darkreading_supply_chain}; some estimates put total damages at \$9.5 trillion in 2024 \cite{liu_makridis_galinkin_2024}. Critically, 14\% of breaches in 2024 began with vulnerability exploitation—nearly triple the prior year. Despite advances in automated vulnerability detection, effectiveness in localization remains underexplored \cite{zhang2024empirical}, leaving developers with coarse, file-level predictions while 32\% of critical vulnerabilities remain unpatched for over 180 days. These vulnerabilities are exploding in volume and growing ever more severe, driving escalating security and economic risks worldwide.

\textbf{Motivation.} The rise of Large Language Models (LLMs) has accelerated AI-driven automation across software development and cybersecurity \cite{zhang_et_al_2025}. From code assistants like \cite{github_copilot_2021} to automated security analysis and automation \cite{nunez2024autosafecoder}. LLMs show strong aptitude for understanding complex codebases and flagging potential issues \cite{divakaran2024llms}. This momentum naturally extends to vulnerability detection, spanning model-level approaches such as fine-tuning LLMs for classification—and agentic frameworks that harness LLM reasoning for automated analysis \cite{awesome_llm4cybersecurity_2024}. 

Yet today's LLM-based detection methods face practical barriers. Most operate at the function level, asking whether a fragment is vulnerable rather than pinpointing where the flaw lies \cite{zhang2024empirical}, \cite{10.1145/3715758}, yielding guidance too coarse for real remediation. Evaluations also rely heavily on lightweight, synthetic datasets that miss the complexity of production systems \cite{springer_vulnerability_analysis}.

This research–practice gap is most visible in vulnerability localization. While studies show promising results on isolated functions or snippets, engineers must navigate large repositories with cross-module dependencies and need line-level localization to craft minimal, targeted patches precision current methods rarely deliver. Moreover, artificial benchmarks obscure the true difficulty of project-level detection, where context spans multiple files and demands system-wide reasoning.

Given the surge in vulnerability reports outlined earlier, the field urgently needs approaches that close this reality gap: leveraging LLM automation while tackling project-scale challenges practitioners face daily. Only by embracing these real-world constraints can we convert the promise of LLM-assisted security into tools that meaningfully lighten the load on development teams.

% Large Language Models (LLMs) recently have shown strong ability in code comprehension and vulnerability localization. They can summarize the code across multiple files, understand the code content, and indicate the places it believes contains the vulnerabilities. In some cases, it can potentially help the developers to find out where we should apply a patch to fix the vulnerabilities. But turning from coarse "this file/function is suspicious" into precise "line-level is suspicious" localization in real-world, multiple files repositories remains difficult. In practice, developers need to know where to check and quickly apply a minimal patch to solve this failure, while a file or a function is not that sufficient to guide the developers and may lead to high false positives and waste of time to look into the details. Especially the vulnerabilities sometimes only takes a few lines to fix like the inputs or cross module interactions. So the accurate line level localization in real-world repository settings is still an open and practical challenge.

% We believe the gap is caused by three main reasons. One is, the industry and open source repositories always have data or control interact with many files, while putting all the related code into a single LLM's context without losing any important lines are really hard. second is, many detectors mainly care about the code chunks, but the runtime evidence like crash report, stack traces can provide more useful information. The prediction might be working but ungrounded. Third, some models are trained and aimed to classify files or functions, and not does not narrow down into specific lines or code chunks of the large repository. They generate the localization in one pass without considering the feedback, failing to mimics human debugging behaviors by iteratively reason through bugs.

To address these gaps, we introduce T2L (Trace-to-Line), which reframes vulnerability detection as a two-tier problem (a) coarse-grained detection - flagging suspicious code chunks and (b) fine-grained localization - pinpointing exact vulnerable lines. This separation enables systematic evaluation of LLM capabilities from repository-scale reasoning to human-expert precision.

\textbf{Contribution.} This work makes three contributions: \textbf{(1)} \textit{Task formulation.} We frame project-level vulnerability discovery as two structured tasks: chunk-level detection and line-level localization. AST-based chunking adapts large codebases to LLM context while preserving semantics, enabling refinement from coarse predictions to exact lines,bridging research setups and real-world needs for LLMs. \textbf{(2)} \textit{T2L-ARVO benchmark.} We present the first benchmark for agentic fine-grained localization, featuring 50 expert verified cases across five vulnerability types with balanced category distribution. \texttt{T2L-ARVO} enables realistic, project-scale evaluation of LLM-based systems. \textbf{(3)} \textit{T2L-Agent framework.} We propose a multi-agent system with the following innovation: (i) a Trace Analyzer (Agentic Trace Analyzer) integrating the ensemble of tools such as static analysis, sanitizers, and runtime monitoring for observability as human debuggers; (ii) a Proposal module (Divergence Tracing) that iteratively forms and tests vulnerability hypotheses; and (iii) a two-stage pipeline (Detection Refinement) that first detects coarse chunks and then verifies exact lines with runtime feedback.

\texttt{T2L-Agent} achieves up to \textbf{58\%} chunk-level detection and \textbf{54.8\%} exact line localization accuracy on \texttt{T2L-ARVO}, significantly reducing developer effort. Its iterative, feedback-driven workflow mirrors how engineers debug—combining reasoning with runtime evidence—while scaling effectively to large, real-world codebases through a lightweight agent architecture.

% \textbf{Contribution.} This work offers three main contributions: \textbf{(1)} Task formulation. We formalize project-level vulnerability localization as a structured task requiring both detection and localization. Our approach uses AST-based chunking to fit LLM context while preserving semantic coherence, then refines within LLM-selected views to exact lines, which bridges academic function-level evaluation and industrial line-level needs. \textbf{(2)} T2L-ARVO benchmark. We present the first benchmark tailored to agentic vulnerability localization, with 50 expert-verified cases spanning five vulnerability types and a balanced category distribution; this design enables rigorous evaluation of real-world OSS detection in the LLM era. \textbf{(3)} T2L Agent. We propose an automated Planner–Executor Agent architecture featuring: (i) an Agent Trace Analyzer (ATA) that integrates traditional tools such as static scanning, memory analysis and sanitizers to provide expert-level observability; (ii) a Vulnerability Proposal Design that generates multiple concurrent candidates via iterative hypothesis formation; and (iii) a two-stage detection refinement pipeline that performs coarse localization via AST chunking, followed by line-level verification with runtime evidence.

% T2L Agent consistently localizes vulnerable chunks with up to [x fill here]\% and often identifies [x fill here]\% exact lines on T2L-ARVO benchmark, substantially reducing developer effort versus existing approaches. Its iterative, feedback-driven workflow mirrors human debugging while leveraging LLM automation for scalable, project-level vulnerability localization.

% To address these gaps, we introduce T2L Agent (Trace-to-Line Agent), a real-world repository settings, multi-round and Planner-Executor framework. It integrates static code analysis with runtime output like sanitizer report which contains stack traces and multiple round LLM based reasoning, takes vulnerability localization as a planning and executing with feedback based process. This framework leads to higher precision and increased interpretability for vulnerability localization.

% Starting from a repository, the T2L Agent executes a multi-round localization loop. (1) It begins with broad localization likes modules or files, gradually narrows to code chunks and lines. (2) It collects runtime evidence by running sanitizer and GDB to form a crash log. and (3) It iteratively generates the location of the vulnerability and gradually narrows down to exact chunks or lines. Each round, the executor agent updates a feedback for whether find the vulnerability or not in this round, enables the planner agent to redirect in the following rounds. This loop turns long-context reasoning into targeted, feedback-driven search.

% Two design choices are key. Repository level chunking keeps the highly related code in the same chunk without exceeding the LLM's context limit by aligning chunks with module boundaries and dependency graphs. Crash log based narrowing takes the sanitizer report, stack traces as evidence to select and rerank locations. Together with delegation pipeline, these makes up to our agent that is robust to noisy static code cues and keep making progress even when early localizations are wrong.

% We evaluate our T2L Agent on the ARVO dataset[cite], which offers reproducible builds, recompilable, and automatically updating dataset of over 5,000 real-world vulnerabilities in open-source C/C++ projects. We select 50 projects across three levels of difficulty, report line level and chunk level localization accuracy. The results show that our T2L Agent consistently detect vulnerabilities code chunks and often localize the exact lines compared to the diff from ARVO dataset. So that can reduce the developers' effort to find the vulnerabilities code.

% This paper makes the following contributions:

% 1. We have line level vulnerabilities localization on repository setting projects with agentic, feedback driven reasoning and Planner-Executor framework, closing the gap between coarse detection and precise localization.

% 2. We propose T2L Agent, a Planner–Executor architecture, which combines repository level chunking, LLM planning, and crash log based localization to iteratively generate and rank candidates from chunks to lines just like human debugger.

% 3. We conduct experiments on ARVO with reproducible builds, and actual patch as localization label. Measure the performance of T2L Agent reliably across graded difficulty levels.
