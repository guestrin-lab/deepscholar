\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Angiulli(2018)]{angiulli2018behavior}
Fabrizio Angiulli.
\newblock On the behavior of intrinsically high-dimensional spaces: distances, direct and reverse nearest neighbors, and hubness.
\newblock \emph{Journal of Machine Learning Research}, 18\penalty0 (170):\penalty0 1--60, 2018.

\bibitem[Arthur \& Vassilvitskii(2007)Arthur and Vassilvitskii]{arthur2007kmeanspp}
David Arthur and Sergei Vassilvitskii.
\newblock k-means++: The advantages of careful seeding.
\newblock In \emph{Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms}, pp.\  1027--1035. Society for Industrial and Applied Mathematics, 2007.

\bibitem[Belkin \& Niyogi(2003)Belkin and Niyogi]{belkin2003laplacian}
Mikhail Belkin and Partha Niyogi.
\newblock Laplacian eigenmaps for dimensionality reduction and data representation.
\newblock \emph{Neural computation}, 15\penalty0 (6):\penalty0 1373--1396, 2003.

\bibitem[Beyer et~al.(1999)Beyer, Goldstein, Ramakrishnan, and Shaft]{beyer1999nearest}
Kevin Beyer, Jonathan Goldstein, Raghu Ramakrishnan, and Uri Shaft.
\newblock When is “nearest neighbor” meaningful?
\newblock In \emph{Database Theory—ICDT’99: 7th International Conference Jerusalem, Israel, January 10--12, 1999 Proceedings 7}, pp.\  217--235. Springer, 1999.

\bibitem[Brock(2018)]{brock2018large}
Andrew Brock.
\newblock Large scale gan training for high fidelity natural image synthesis.
\newblock \emph{arXiv preprint arXiv:1809.11096}, 2018.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 1877--1901, 2020.

\bibitem[Chen \& Li(2024)Chen and Li]{chen2024revisiting}
Wei Chen and Xiang Li.
\newblock Revisiting the manifold hypothesis in deep representational learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, volume~37, 2024.
\newblock (A representative recent work on manifold learning in deep networks.).

\bibitem[Cheng et~al.(2025)Cheng, Song, Xiao, Chen, Zhang, Sun, and Shan]{cheng2025tensorar}
Cheng Cheng, Lin Song, Yicheng Xiao, Yuxin Chen, Xuchong Zhang, Hongbin Sun, and Ying Shan.
\newblock Tensorar: Refinement is all you need in autoregressive image generation.
\newblock \emph{arXiv preprint arXiv:2505.16324}, 2025.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei]{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern recognition}, pp.\  248--255. Ieee, 2009.

\bibitem[Dhariwal \& Nichol(2021)Dhariwal and Nichol]{dhariwal2021diffusion}
Prafulla Dhariwal and Alexander Nichol.
\newblock Diffusion models beat gans on image synthesis.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 8780--8794, 2021.

\bibitem[Esser et~al.(2021)Esser, Rombach, and Ommer]{esser2021taming}
Patrick Esser, Robin Rombach, and Bjorn Ommer.
\newblock Taming transformers for high-resolution image synthesis.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  12873--12883, 2021.

\bibitem[Fan et~al.(2024)Fan, Li, Qin, Li, Sun, Rubinstein, Sun, He, and Tian]{fan2024fluid}
Lijie Fan, Tianhong Li, Siyang Qin, Yuanzhen Li, Chen Sun, Michael Rubinstein, Deqing Sun, Kaiming He, and Yonglong Tian.
\newblock Fluid: Scaling autoregressive text-to-image generative models with continuous tokens.
\newblock \emph{arXiv preprint arXiv:2410.13863}, 2024.

\bibitem[Guo et~al.(2025)Guo, Zhang, and Shieh]{guo2025improving}
Ziyao Guo, Kaipeng Zhang, and Michael~Qizhe Shieh.
\newblock Improving autoregressive image generation through coarse-to-fine token prediction.
\newblock \emph{arXiv preprint arXiv:2503.16194}, 2025.

\bibitem[Han et~al.(2024)Han, Liu, Jiang, Yan, Zhang, Yuan, Peng, and Liu]{han2024infinity}
Jian Han, Jinlai Liu, Yi~Jiang, Bin Yan, Yuqi Zhang, Zehuan Yuan, Bingyue Peng, and Xiaobing Liu.
\newblock Infinity: Scaling bitwise autoregressive modeling for high-resolution image synthesis.
\newblock \emph{arXiv preprint arXiv:2412.04431}, 2024.

\bibitem[Hatamizadeh et~al.(2024)Hatamizadeh, Song, Liu, Kautz, and Vahdat]{hatamizadeh2024diffit}
Ali Hatamizadeh, Jiaming Song, Guilin Liu, Jan Kautz, and Arash Vahdat.
\newblock Diffit: Diffusion vision transformers for image generation, 2024.
\newblock URL \url{https://arxiv.org/abs/2312.02139}.

\bibitem[Heusel et~al.(2018)Heusel, Ramsauer, Unterthiner, Nessler, and Hochreiter]{heusel2017gans}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash equilibrium, 2018.
\newblock URL \url{https://arxiv.org/abs/1706.08500}.

\bibitem[Hu et~al.(2025)Hu, Zhang, Yi, Weng, Wang, Zeng, Xue, and Ma]{hu2025improving}
Teng Hu, Jiangning Zhang, Ran Yi, Jieyu Weng, Yabiao Wang, Xianfang Zeng, Zhucun Xue, and Lizhuang Ma.
\newblock Improving autoregressive visual generation with cluster-oriented token prediction.
\newblock \emph{arXiv preprint arXiv:2501.00880}, 2025.

\bibitem[Huh et~al.(2023)Huh, Cheung, Agrawal, and Isola]{huh2023straightening}
Minyoung Huh, Brian Cheung, Pulkit Agrawal, and Phillip Isola.
\newblock Straightening out the straight-through estimator: Overcoming optimization challenges in vector quantized networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\  14096--14113. PMLR, 2023.

\bibitem[Kang et~al.(2023)Kang, Zhu, Zhang, Park, Shechtman, Paris, and Park]{kang2023scaling}
Minguk Kang, Jun-Yan Zhu, Richard Zhang, Jaesik Park, Eli Shechtman, Sylvain Paris, and Taesung Park.
\newblock Scaling up gans for text-to-image synthesis.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  10124--10134, 2023.

\bibitem[Kynkäänniemi et~al.(2019)Kynkäänniemi, Karras, Laine, Lehtinen, and Aila]{kynkaanniemi2019improved}
Tuomas Kynkäänniemi, Tero Karras, Samuli Laine, Jaakko Lehtinen, and Timo Aila.
\newblock Improved precision and recall metric for assessing generative models, 2019.
\newblock URL \url{https://arxiv.org/abs/1904.06991}.

\bibitem[Li et~al.(2023)Li, Liu, Wang, Qiu, Chen, Gao, and Zhou]{li2023resizing}
Lei Li, Tingting Liu, Chengyu Wang, Minghui Qiu, Cen Chen, Ming Gao, and Aoying Zhou.
\newblock Resizing codebook of vector quantization without retraining.
\newblock \emph{Multimedia Systems}, 29\penalty0 (3):\penalty0 1499--1512, 2023.

\bibitem[Li et~al.(2024)Li, Tian, Li, Deng, and He]{li2024autoregressive}
Tianhong Li, Yonglong Tian, He~Li, Mingyang Deng, and Kaiming He.
\newblock Autoregressive image generation without vector quantization.
\newblock \emph{Advances in Neural Information Processing Systems}, 37:\penalty0 56424--56445, 2024.

\bibitem[Lukasov{\'a}(1979)]{lukasova1979hierarchical}
Alena Lukasov{\'a}.
\newblock Hierarchical agglomerative clustering procedure.
\newblock \emph{Pattern Recognition}, 11\penalty0 (5-6):\penalty0 365--381, 1979.

\bibitem[Pang et~al.(2025)Pang, Zhang, Luan, Man, Tan, Zhang, Freeman, and Wang]{pang2025randardecoder}
Ziqi Pang, Tianyuan Zhang, Fujun Luan, Yunze Man, Hao Tan, Kai Zhang, William~T. Freeman, and Yu-Xiong Wang.
\newblock Randar: Decoder-only autoregressive visual generation in random orders, 2025.
\newblock URL \url{https://arxiv.org/abs/2412.01827}.

\bibitem[Peebles \& Xie(2023)Peebles and Xie]{peebles2023scalable}
William Peebles and Saining Xie.
\newblock Scalable diffusion models with transformers.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pp.\  4195--4205, 2023.

\bibitem[Ranzato et~al.(2015)Ranzato, Chopra, Auli, and Zaremba]{ranzato2015sequence}
Marc'Aurelio Ranzato, Sumit Chopra, Michael Auli, and Wojciech Zaremba.
\newblock Sequence level training with recurrent neural networks.
\newblock \emph{arXiv preprint arXiv:1511.06732}, 2015.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  10684--10695, 2022.

\bibitem[Salimans et~al.(2016)Salimans, Goodfellow, Zaremba, Cheung, Radford, and Chen]{salimans2016}
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi~Chen.
\newblock Improved techniques for training gans, 2016.
\newblock URL \url{https://arxiv.org/abs/1606.03498}.

\bibitem[Sun et~al.(2024)Sun, Jiang, Chen, Zhang, Peng, Luo, and Yuan]{sun2024autoregressive}
Peize Sun, Yi~Jiang, Shoufa Chen, Shilong Zhang, Bingyue Peng, Ping Luo, and Zehuan Yuan.
\newblock Autoregressive model beats diffusion: Llama for scalable image generation.
\newblock \emph{arXiv preprint arXiv:2406.06525}, 2024.

\bibitem[Tang et~al.(2025)Tang, Chu, Wang, Han, Wu, He, Zhang, Zhang, and Jia]{tang2025exploitingdiscriminativecodebookprior}
Longxiang Tang, Ruihang Chu, Xiang Wang, Yujin Han, Pingyu Wu, Chunming He, Yingya Zhang, Shiwei Zhang, and Jiaya Jia.
\newblock Exploiting discriminative codebook prior for autoregressive image generation, 2025.
\newblock URL \url{https://arxiv.org/abs/2508.10719}.

\bibitem[Tenenbaum et~al.(2000)Tenenbaum, De~Silva, and Langford]{tenenbaum2000global}
Joshua~B Tenenbaum, Vin De~Silva, and John~C Langford.
\newblock A global geometric framework for nonlinear dimensionality reduction.
\newblock \emph{Science}, 290\penalty0 (5500):\penalty0 2319--2323, 2000.

\bibitem[Tian et~al.(2024)Tian, Jiang, Yuan, Peng, and Wang]{tian2024visual}
Keyu Tian, Yi~Jiang, Zehuan Yuan, Bingyue Peng, and Liwei Wang.
\newblock Visual autoregressive modeling: Scalable image generation via next-scale prediction.
\newblock \emph{Advances in neural information processing systems}, 37:\penalty0 84839--84865, 2024.

\bibitem[Touvron et~al.(2023)Touvron, Lavril, Izacard, Martinet, Lachaux, Lacroix, Rozi{\`e}re, Goyal, Hambro, Azhar, et~al.]{touvron2023llama}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth{\'e}e Lacroix, Baptiste Rozi{\`e}re, Naman Goyal, Eric Hambro, Faisal Azhar, et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock \emph{arXiv preprint arXiv:2302.13971}, 2023.

\bibitem[Van Den~Oord et~al.(2017)Van Den~Oord, Vinyals, and Kavukcuoglu]{van2017neural}
Aaron Van Den~Oord, Oriol Vinyals, and Koray Kavukcuoglu.
\newblock Neural discrete representation learning.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Ward~Jr(1963)]{ward1963hierarchical}
Joe~H Ward~Jr.
\newblock Hierarchical grouping to optimize an objective function.
\newblock \emph{Journal of the American statistical association}, 58\penalty0 (301):\penalty0 236--244, 1963.

\bibitem[Wu et~al.(2025)Wu, Zhu, Liu, Tang, Yang, Peng, Zhai, Cao, and Zha]{wu2025alitok}
Pingyu Wu, Kai Zhu, Yu~Liu, Longxiang Tang, Jian Yang, Yansong Peng, Wei Zhai, Yang Cao, and Zheng-Jun Zha.
\newblock Alitok: Towards sequence modeling alignment between tokenizer and autoregressive model.
\newblock \emph{arXiv preprint arXiv:2506.05289}, 2025.

\bibitem[Xiong et~al.(2025)Xiong, Liew, Huang, Feng, and Liu]{xiong2025gigatok}
Tianwei Xiong, Jun~Hao Liew, Zilong Huang, Jiashi Feng, and Xihui Liu.
\newblock Gigatok: Scaling visual tokenizers to 3 billion parameters for autoregressive image generation.
\newblock \emph{arXiv preprint arXiv:2504.08736}, 2025.

\bibitem[Yu et~al.(2021)Yu, Li, Koh, Zhang, Pang, Qin, Ku, Xu, Baldridge, and Wu]{yu2021vector}
Jiahui Yu, Xin Li, Jing~Yu Koh, Han Zhang, Ruoming Pang, James Qin, Alexander Ku, Yuanzhong Xu, Jason Baldridge, and Yonghui Wu.
\newblock Vector-quantized image modeling with improved vqgan.
\newblock \emph{arXiv preprint arXiv:2110.04627}, 2021.

\bibitem[Zhang et~al.(2025)Zhang, Chen, He, and Zhuang]{zhang2025zipar}
Yifei Zhang, Feng Chen, Siyu He, and Biao Zhuang.
\newblock Zipar: Parallel autoregressive image generation through spatial locality, 2025.

\bibitem[Zheng \& Vedaldi(2023)Zheng and Vedaldi]{zheng2023online}
Chuanxia Zheng and Andrea Vedaldi.
\newblock Online clustered codebook.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  22798--22807, 2023.

\bibitem[Zhou et~al.(2024)Zhou, Yu, Babu, Tirumala, Yasunaga, Shamis, Kahn, Ma, Zettlemoyer, and Levy]{zhou2024transfusion}
Chunting Zhou, Lili Yu, Arun Babu, Kushal Tirumala, Michihiro Yasunaga, Leonid Shamis, Jacob Kahn, Xuezhe Ma, Luke Zettlemoyer, and Omer Levy.
\newblock Transfusion: Predict the next token and diffuse images with one multi-modal model.
\newblock \emph{arXiv preprint arXiv:2408.11039}, 2024.

\end{thebibliography}
