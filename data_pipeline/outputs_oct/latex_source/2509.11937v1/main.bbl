\begin{thebibliography}{25}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Auer et~al.(2024)Auer, Lysak, Nassar, Dolfi, Livathinos, Vagenas, Ramis, Omenetti, Lindlbauer, Dinkla, et~al.]{auer2024docling}
Auer, C., Lysak, M., Nassar, A., Dolfi, M., Livathinos, N., Vagenas, P., Ramis, C.~B., Omenetti, M., Lindlbauer, F., Dinkla, K., et~al.
\newblock Docling technical report.
\newblock \emph{arXiv preprint arXiv:2408.09869}, 2024.

\bibitem[Awadalla et~al.(2023)Awadalla, Gao, Gardner, Hessel, Hanafy, Zhu, Marathe, Bitton, Gadre, Sagawa, et~al.]{awadalla2023openflamingo}
Awadalla, A., Gao, I., Gardner, J., Hessel, J., Hanafy, Y., Zhu, W., Marathe, K., Bitton, Y., Gadre, S., Sagawa, S., et~al.
\newblock Openflamingo: An open-source framework for training large autoregressive vision-language models.
\newblock \emph{arXiv preprint arXiv:2308.01390}, 2023.

\bibitem[Chase(2022)]{Chase_LangChain_2022}
Chase, H.
\newblock {LangChain}.
\newblock \url{https://github.com/langchain-ai/langchain}, 2022.

\bibitem[CloudFiles(2025)]{pdfscloudfiles}
CloudFiles.
\newblock How many files are there in the world?, 2025.
\newblock URL \url{https://www.cloudfiles.io/blog/how-many-files-are-there-in-the-world}.

\bibitem[{Dask Development Team}(2016)]{dask}
{Dask Development Team}.
\newblock \emph{Dask: Library for dynamic task scheduling}, 2016.
\newblock URL \url{http://dask.pydata.org}.

\bibitem[Huang et~al.(2025)Huang, Yu, Ma, Zhong, Feng, Wang, Chen, Peng, Feng, Qin, et~al.]{huang2025survey}
Huang, L., Yu, W., Ma, W., Zhong, W., Feng, Z., Wang, H., Chen, Q., Peng, W., Feng, X., Qin, B., et~al.
\newblock A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions.
\newblock \emph{ACM Transactions on Information Systems}, 43\penalty0 (2):\penalty0 1--55, 2025.

\bibitem[Jin et~al.(2019)Jin, Dhingra, Liu, Cohen, and Lu]{jin2019pubmedqa}
Jin, Q., Dhingra, B., Liu, Z., Cohen, W., and Lu, X.
\newblock Pubmedqa: A dataset for biomedical research question answering.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)}, pp.\  2567--2577, 2019.

\bibitem[Li et~al.(2023)Li, Yin, Li, Chen, Wang, Ren, Li, Yang, Xu, Sun, Kong, and Liu]{li2023m3it}
Li, L., Yin, Y., Li, S., Chen, L., Wang, P., Ren, S., Li, M., Yang, Y., Xu, J., Sun, X., Kong, L., and Liu, Q.
\newblock M$^3$it: A large-scale dataset towards multi-modal multilingual instruction tuning.
\newblock \emph{arXiv preprint arXiv:2306.04387}, 2023.

\bibitem[Lin(2004)]{lin2004rouge}
Lin, C.-Y.
\newblock Rouge: A package for automatic evaluation of summaries.
\newblock In \emph{Proceedings of the Workshop on Text Summarization Branches Out (WAS 2004)}, pp.\  74--81, Barcelona, Spain, 2004. Association for Computational Linguistics.

\bibitem[Liu(2022)]{Liu_LlamaIndex_2022}
Liu, J.
\newblock Llamaindex.
\newblock \url{https://github.com/jerryjliu/llama_index}, 2022.
\newblock Version archived at Zenodo, doi:10.5281/zenodo.1234.

\bibitem[Mindee(2021)]{doctr2021}
Mindee.
\newblock doctr: Document text recognition.
\newblock \url{https://github.com/mindee/doctr}, 2021.

\bibitem[Navarro(2001)]{levenshtein}
Navarro, G.
\newblock A guided tour to approximate string matching.
\newblock \emph{ACM computing surveys (CSUR)}, 33\penalty0 (1):\penalty0 31--88, 2001.

\bibitem[OpenAI(2025)]{openai2025o3o4}
OpenAI.
\newblock Openai o3 and o4-mini system card.
\newblock \url{https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-and-o4-mini-system-card.pdf}, 2025.
\newblock Accessed: 2025-05-23.

\bibitem[Papineni et~al.(2002)Papineni, Roukos, Ward, and Zhu]{bleuscore}
Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J.
\newblock Bleu: a method for automatic evaluation of machine translation.
\newblock In \emph{Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL)}, pp.\  311--318, 2002.

\bibitem[Paruchuri \& Team(2025)Paruchuri and Team]{paruchuri2025surya}
Paruchuri, V. and Team, D.
\newblock Surya: A lightweight document ocr and analysis toolkit.
\newblock \url{https://github.com/VikParuchuri/surya}, 2025.
\newblock GitHub repository.

\bibitem[Penedo et~al.(2024)Penedo, Kydlíček, Cappelli, Sasko, and Wolf]{penedo2024datatrove}
Penedo, G., Kydlíček, H., Cappelli, A., Sasko, M., and Wolf, T.
\newblock Datatrove: large scale data processing, 2024.
\newblock URL \url{https://github.com/huggingface/datatrove}.

\bibitem[Pietsch et~al.(2019)Pietsch, Möller, Kostic, Risch, Pippi, Jobanputra, Zanzottera, Cerza, Blagojevic, Stadelmann, Soni, and Lee]{haystack2019}
Pietsch, M., Möller, T., Kostic, B., Risch, J., Pippi, M., Jobanputra, M., Zanzottera, S., Cerza, S., Blagojevic, V., Stadelmann, T., Soni, T., and Lee, S.
\newblock Haystack: the end-to-end nlp framework for pragmatic builders, 2019.
\newblock URL \url{https://github.com/deepset-ai/haystack}.
\newblock Accessed: 2025-05-26.

\bibitem[{Project Gutenberg}(1971)]{projectgutenberg}
{Project Gutenberg}.
\newblock Project gutenberg.
\newblock \url{https://www.gutenberg.org/}, 1971.
\newblock Accessed: 2025-05-26.

\bibitem[Radford et~al.(2023)Radford, Kim, Xu, Brockman, McLeavey, and Sutskever]{radford2023robust}
Radford, A., Kim, J.~W., Xu, T., Brockman, G., McLeavey, C., and Sutskever, I.
\newblock Robust speech recognition via large-scale weak supervision.
\newblock In \emph{International conference on machine learning}, pp.\  28492--28518. PMLR, 2023.

\bibitem[Sallinen et~al.(2025)Sallinen, Solergibert, Zhang, Boy{\'e}, Dupont-Roc, Theimer-Lienhard, Boisson, Bernath, Hadhri, Tran, et~al.]{sallinen2025llama}
Sallinen, A., Solergibert, A.-J., Zhang, M., Boy{\'e}, G., Dupont-Roc, M., Theimer-Lienhard, X., Boisson, E., Bernath, B., Hadhri, H., Tran, A., et~al.
\newblock Llama-3-meditron: An open-weight suite of medical llms based on llama-3.1.
\newblock In \emph{Workshop on Large Language Models and Generative AI for Health at AAAI 2025}, 2025.

\bibitem[Team(2024)]{nvingest}
Team, N. I.~D.
\newblock \emph{NVIDIA Ingest: An accelerated pipeline for document ingestion}, 2024.
\newblock URL \url{https://github.com/NVIDIA/nv-ingest}.

\bibitem[Unstract(2025)]{llmwhisperer2025}
Unstract.
\newblock Llmwhisperer.
\newblock \url{https://unstract.com/llmwhisperer/}, 2025.
\newblock Accessed: 2025-05-25.

\bibitem[{Unstructured-IO}(2025)]{unstructured2025}
{Unstructured-IO}.
\newblock Unstructured: Open-source pre-processing tools for unstructured data.
\newblock \url{https://github.com/Unstructured-IO/unstructured}, 2025.
\newblock Accessed: 2025-05-26.

\bibitem[Villalobos et~al.(2022)Villalobos, Ho, Sevilla, Besiroglu, Heim, and Hobbhahn]{villalobos2022}
Villalobos, P., Ho, A., Sevilla, J., Besiroglu, T., Heim, L., and Hobbhahn, M.
\newblock Will we run out of data? limits of {LLM} scaling based on human-generated data.
\newblock \emph{arXiv preprint arXiv:2211.04325}, 2022.
\newblock \doi{10.48550/arXiv.2211.04325}.
\newblock URL \url{https://arxiv.org/abs/2211.04325}.

\bibitem[Villalobos et~al.(2024)Villalobos, Ho, Sevilla, Besiroglu, Heim, and Hobbhahn]{llmdata2024}
Villalobos, P., Ho, A., Sevilla, J., Besiroglu, T., Heim, L., and Hobbhahn, M.
\newblock Will we run out of data? limits of {LLM} scaling based on human-generated data \;(v2, 2024 update).
\newblock \emph{arXiv preprint arXiv:2211.04325v2}, 2024.
\newblock \doi{10.48550/arXiv.2211.04325}.
\newblock URL \url{https://arxiv.org/abs/2211.04325v2}.
\newblock Version 2, revised 4 June 2024.

\end{thebibliography}
