\section{Related Work}
% % mention LLMWhisperer (this is not open-source and its paid, so our contribution here is easy)
% % doctr - they only do document parsing 
% % Surya - this one is the most relevant because we use it in our pipeline for PDFs intesively. The difference is we only reuse surya for PDFs and we offer native parallelization on multi-node multi-gpu systems in contrast

Large-scale transformation of unstructured documents into structured, machine‑readable format has attracted substantial attention. We group prior work into two strands: \textbf{(i)} document ingestion and parsing pipelines, and \textbf{(ii)} RAG frameworks. To our knowledge, neither line of work simultaneously offers the modality coverage and end‑to‑end throughput required for industrial‑ and small‑scale multimodal assistants that we target with \mmore{}.\\
\textbf{Document Ingestion Pipelines.} GPU‑accelerated microservice suites such as \textit{NV‑Ingest}~\cite{nvingest} convert PDFs and office documents into page‑level JSON enriched with text blocks, tables, and graphics, and can optionally export embeddings for downstream indexing. \textit{Docling}~\cite{auer2024docling} extends the modality set to spreadsheets, and other common formats, but executes primarily on a single node and therefore exhibits limited throughput in production settings. Classical OCR tools like \textit{doctr}~\cite{doctr2021} handle text detection and recognition but rely on external systems for layout, embeddings, and indexing. \textit{Surya}~\cite{paruchuri2025surya} adds multilingual OCR and layout analysis but lacks built-in multi-GPU or cluster parallelism. Commercial services such as \textit{LLMWhisperer}~\cite{llmwhisperer2025} offer similar functionality behind a paywall, which restricts reproducibility and hinders open experimentation. In contrast, \mmore{} combines extraction, transformation, embedding, and indexing into a single open‑source pipeline that natively parallelizes across multi‑node, multi‑GPU deployments. Moreover, \mmore{} uniquely handles audiovisual assets, enabling unified RAG over text, images, and time‑based media. \\
\textbf{RAG Frameworks.} Open‑source libraries such as \textit{LangChain}~\cite{Chase_LangChain_2022} and \textit{LlamaIndex}~\cite{Liu_LlamaIndex_2022} provide high-level abstractions for chunking, embedding, retrieval, and prompting. However, they rely on external loaders for modality‑specific parsing and give no guidance on efficient high-throughput ingestion. 
Several recent pipelines, such as \textit{Unstructured.io}~\cite{unstructured2025} and Haystack~\cite{haystack2019} for document parsing, or \textit{M3IT}~\cite{li2023m3it} and \textit{OpenFlamingo}~\cite{awadalla2023openflamingo} for multimodal model alignment, address specific components of this pipeline. Yet none provide an integrated, open-source framework that supports ingestion, transformation, and retrieval across heterogeneous, real-world file types at scale. 

\mmore{} combines a scalable ingestion layer with a task-agnostic retrieval API, unifying document processing and RAG tools to enable multimodal assistants from raw enterprise data in one library.
%%% vérifier les sourches encore

