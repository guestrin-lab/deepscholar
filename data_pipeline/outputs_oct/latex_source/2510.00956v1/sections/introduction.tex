% Network modeling and models (DQN, RN). Probably split in two.
Network modeling is crucial for reliable communication, traffic optimization, and network design. Traditional approaches, such as Discrete Event Simulation (DES), have been the standard for accurately modeling network behavior.
% \mpp{DES remains relevant for scenarios requiring high-fidelity simulations, such as detailed analyses of protocol behaviors or rare edge cases that are difficult to replicate in real-world settings.}
Tools like NS-3~\cite{Riley2010} and OMNeT++~\cite{Varga2019} simulate every network event. They provide highly detailed reconstructions of network dynamics but at a high computational cost, which limits scalability as networks grow.
Recent advancements in Machine Learning (ML) have introduced transformative possibilities for network modeling, exemplified by models such as MimicNet~\cite{10.1145/3452296.3472926}, DeepQueueNet~\cite{10.1145/3544216.3544248}, and the RouteNet~\cite{ferriolgalmés2022routenetfermi} family.
% have demonstrated the ability to approximate network behaviors with remarkable accuracy and fast inference times while requiring significantly less computational effort.
These innovations address the limitations of DES, enabling faster and more scalable network modeling at the price of a slight reduction in accuracy. 

% Issues of modeling real networks: where and how to build the training sets. Requirements in data variability.
% - ML works because it is data driven
% - This in turn requires A LOT of data

% The success of ML in network modeling arises from its data-driven nature, as models learn to approximate network behaviors by analyzing patterns in training datasets.
ML models learn to approximate network behavior accurately and (relatively) cheaply by analyzing traffic patterns in training datasets.
However, this reliance on data introduces significant challenges. To ensure accurate and reliable predictions, training datasets must meet three essential criteria: abundance, diversity, and completeness. Abundance is crucial to expose the model to a wide range of network conditions, enhancing its ability to generalize across scenarios. Diversity refers to the inclusion of a broad spectrum of real-world situations, including rare edge cases that deviate from typical network operations (e.g., highly congested links, heterogeneous traffic patterns, etc). Completeness ensures that all relevant factors influencing network behavior are captured, preventing critical variables from being overlooked.

Nevertheless, acquiring datasets that meet these criteria is commonly challenging. Real-world network data, while accurate, is costly to collect and often incomplete. Publicly available datasets frequently lack the diversity and edge-case scenarios required for robust model training. For instance, CAIDA's Anonymized Internet Traces~\cite{CAIDA} primarily focus on common traffic patterns, limiting their utility for scenarios involving atypical or highly variable network conditions. Testbed networks provide a controlled environment to generate data, but their deployment at scale is prohibitively expensive. These challenges hinder the development of high-quality ML models for real-world network applications.

% - Simulation is convenient (easy to set up, safe environment), but not enough since it can be inaccurate (reference to result) temporal cost.
Researchers often turn to network simulators to generate training datasets to mitigate data scarcity~\cite{10.1145/3452296.3472926, 10.1145/3544216.3544248, ferriolgalmés2022routenetfermi, li2024glancegraphbasedlearnabledigital}. Simulators offer a controlled and flexible environment for producing diverse and rare scenarios without the risks associated with live production networks. Conversely, generating simulated datasets is computationally expensive and often fails to capture the subtle nuances of real-world network dynamics. This arises from idealized assumptions in simulations and the proprietary nature of commercial network hardware. Consequently, ML models trained exclusively on simulated data exhibit reduced accuracy and reliability when deployed in production environments. This observation has been corroborated by other researchers~\cite{10635943} and by our findings in the evaluation (Table~\ref{tab:results}).

% A promising approach to address these limitations is transfer learning~\cite{10.5555/2998687.2998769, pmlr-v15-bengio11b}. It involves adapting a model trained on one domain and task (e.g., simulated data) to perform effectively in a related but distinct domain or task (e.g., real-world data). This process leverages the knowledge from the initial training phase and fine-tunes the model using a smaller, domain-specific dataset. This approach has proven impactful across multiple domains, 
% notably natural language processing~\cite{Weiss2016}.
% % ~\cite{Weiss2016}, more famously in natural language processing with the surge of genera pre-trained models ready to be later specialized to specific tasks~\cite{openai2024gpt4technicalreport}.
% Similarly, by applying transfer learning, we aim to benefit from a larger pool of training samples without affecting the resulting model's accuracy when predicting real-world behavior.


% % \textbf{FIXME: Emphasize more that we have a real-world network testbed (also at the abstract, this is not common at all and very positive towards acceptance)}.
% % \textbf{TODO: MENTION ROUTENET FERMI}
% This paper studies the viability of using simulated data to train ML models for real-world network behavior prediction. We propose a hybrid approach leveraging transfer learning to bridge the gap between simulation and real-world network environments. We train and evaluate our approach by combining simulated network scenarios with real ones (Figure~\ref{fig:transfer_learning_pipeline}). We use RouteNet-Fermi~\cite{ferriolgalmés2022routenetfermi}, a state-of-the-art ML network model, as our reference model in our comparison. However, we believe that our findings are generalizable to other ML-based solutions. We then use our configurable testbed network to record the real network scenarios. We find that, when done correctly, we increase the accuracy of the resulting model by up to 82\% relative to the version that only uses real-world network data. We also find that our approach is extremely data efficient: when using fine-tuning and having only 10 recorded network scenarios available, we are able to train a model with $37\%$ less error than without using simulated samples.

This paper studies the viability of using simulated data to train ML models for real-world network behavior prediction. We propose a hybrid approach leveraging transfer learning~\cite{10.5555/2998687.2998769, pmlr-v15-bengio11b} to bridge the gap between simulation and real-world network environments. This consists in training and evaluating our approach by combining simulated network scenarios with real ones (Figure~\ref{fig:transfer_learning_pipeline}). We use RouteNet-Fermi~\cite{ferriolgalmés2022routenetfermi}, a state-of-the-art ML network model, as our reference model in our comparison. However, we believe that our findings are generalizable to other ML-based solutions. We then use our configurable testbed network to record the real network scenarios. In our evaluation, we increase the accuracy of the resulting model by up to 88\% relative to the version that only uses real-world network data. We also find that our approach is extremely data efficient: limiting the training process to 10 recorded network scenarios, using fine-tuning results in a model with $37\%$ less error than when training from scratch.

The rest of the paper is structured as follows: Section~\ref{sec:background} provides an overview of transfer learning, highlighting its relevance to our approach and to RouteNet-Fermi, the ML network model used to evaluate it. Section~\ref{sec:problem_statement} describes the problem statement and introduces the proposed framework, whose details and implementation are then expanded in Section~\ref{sec:methodology_and_experimental_design}. Finally, Section~\ref{sec:evaluation} presents an evaluation of our approach, including key findings and insights.

