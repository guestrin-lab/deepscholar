% Explain environment/problem
% To address the problem of bridging the gap between simulated and real-world network data, we propose leveraging transfer learning with the RouteNet-Fermi model~\cite{ferriolgalmés2022routenetfermi}. Our approach involves two main components: (1) training the RouteNet-Fermi model on simulated data and (2) fine-tuning it with real-world network data. This methodology enables us to combine the broad generalization capabilities gained from simulation with real-world specificity.

Our approach involves two main components: (1) training the RouteNet-Fermi~\cite{ferriolgalmés2022routenetfermi} model on simulated data and (2) fine-tuning it with real-world network data. This methodology enables us to combine the broad generalization capabilities gained from simulation with real-world specificity.

\subsection{Model architecture}

We use a modified RouteNet-Fermi architecture to predict network performance metrics. The architecture can be decomposed into three main blocks:
\begin{enumerate}
    \item Encoding: Multi-layer perceptrons (MLPs) generate initial embeddings for network elements.
    \item Message Passing Algorithm (MPA): The embeddings are refined using the relationships between network elements by employing Gated Recurrent Units (GRU)~\cite{cho2014learningphraserepresentationsusing}.
    \item Readout: The final flow embeddings are used to predict performance metrics via an MLP.
\end{enumerate}

It should be noted that RouteNet-Fermi assumes stationary traffic, a condition that does not always apply to real-world network data. In turn, we adapt RouteNet-Fermi to non-stationary traffic by splitting network scenarios into temporal windows and predicting performance metrics for each window individually. This ensures the stationarity assumption applies only within shorter intervals, allowing the model to adapt to changing traffic conditions as in real-world scenarios.

Adapting the architecture requires two key modifications. First, the input features are adjusted to include window-specific attributes rather than global flow-level parameters. This includes features such as flow bandwidth and packet rate per window. Second, we introduce a GRU neural network during the MPA phase to capture inter-window dependencies. This mechanism updates queue embeddings in each window using those from the previous window, enabling the model to propagate temporal information. Overall, these measures aim to improve accuracy under non-stationary traffic conditions.

% \mpp{Adapting the architecture requires two key modifications. First, the input features are adjusted to include window-specific attributes, such as average bandwidth and packet rate within each temporal window. These attributes are crucial for capturing transient traffic dynamics in non-stationary network scenarios, where traffic conditions evolve over time. By focusing on shorter temporal intervals, the model can better track and respond to fluctuations in network performance, which static, aggregated metrics would miss.}

% \mpp{Second, to capture inter-window dependencies, we introduce a Gated Recurrent Unit (GRU) neural network during the Message Passing Algorithm (MPA) phase. The GRU is designed to retain information from previous windows and propagate it across the network, enabling the model to account for temporal patterns and trends. This enhancement allows the architecture to adapt to traffic changes over time, improving its predictive accuracy in real-world scenarios.}

% Types of TL used
\subsection{Manual transfer learning}
\label{sec:proposed_ft}
To summarize, we currently have an ML-model architecture, RouteNet-Fermi, a large dataset of simulated network scenarios, and a small dataset of real-world network scenarios. We propose using transfer learning to leverage the strengths of the simulated dataset while adapting the model to real-world conditions.
% \textbf{FIXME: This paragraph is redundant, I suggest to summarize it to 1 or 2 sentences} To summarize, we currently have an ML-model architecture, RouteNet-Fermi, and two datasets to work with. On one hand, we have a dataset made from real-world network scenarios, which is limited in size and variability, making it challenging to train a robust model directly. On the other, we have a dataset composed of simulated scenarios, that while abundant and diverse, result in sub-optimal models due to domain mismatch. To address this, we propose using transfer learning to leverage the strengths of the simulated dataset while adapting the model to real-world conditions, all without introducing excessive bias from the simulated samples.
% Reviewing Figure~\ref{fig:transfer_learning_pipeline}, our approach consists in transferring the weights from a pre-trained network model with the simulated data to act as a foundation for the network model for real-network data. By reusing the learned knowledge encoded in the pre-trained weights, the receiver model gains a significant advantage in adapting to the real-world environment with minimal data.
We start by training the network model with the simulated data to act as a foundation for the network model for real-network data. When fine-tuning, a critical decision is determining how to handle the weights of each block in the network.
Following the principles outlined in \cite{zeiler2013visualizingunderstandingconvolutionalnetworks}, we evaluate those configurations that adhere to the following guidelines:
\begin{itemize}
    \item Layer dependencies: We avoid configurations where a block is frozen or fine-tuned if preceded by a re-trained block. Otherwise, it would disrupt the natural flow of learned representations. We also avoid configurations where a block is frozen if preceded by a fine-tuned block.
    \item Trainable weights: We never freeze all blocks, as this would leave no trainable parameters for adaptation.
    \item Always transfer something: We never re-train all blocks, as it is equivalent to training the model from scratch.
\end{itemize}
% Following the principles outlined in \cite{zeiler2013visualizingunderstandingconvolutionalnetworks}, we evaluate those configurations that respect layer dependencies. That is, avoid configurations where a block is frozen or fine-tuned if preceded by a re-trained block as otherwise, it would disrupt the natural flow of learned representations. For the same reason we also avoid configurations where a block is frozen if preceded by a fine-tuned block.

The resulting testbed configurations are listed in Table~\ref{tab:results} in the evaluation. We split the network into blocks rather than individual layers to align with RouteNet-Fermi’s architecture. Unlike traditional NNs like MLPs, which are sequential, RouteNet-Fermi operates more like an ensemble of smaller NNs that work in parallel. For instance, the MLPs in the encoding block process individual network elements independently. Grouping these layers into blocks provides a structured approach to fine-tuning while ensuring that dependencies between blocks are respected. Furthermore, the shallow depth of the RouteNet-Fermi's internal NNs, with the deepest component being a 3-layered MLP, limits the benefit of fine-tuning individual layers.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\linewidth]{images/fine_tuning_example.pdf}
    \caption{Visual example of fine-tuning a RouteNet-Fermi~\cite{ferriolgalmés2022routenetfermi} model, where the Encoding is frozen, the MPA is fine-tuned, and the Readout is re-trained.}
    \label{fig:fine_tuning_example}
\end{figure}

In Figure~\ref{fig:fine_tuning_example}, we show an example of how the model can be fine-tuned. In this example, the chosen fine-tune configuration was to freeze the Encoding block, fine-tune the MPA block, and re-train the Readout block. As a result, we only transfer the Encoding and MPA weights from the donor model, while the Readout block's weights are randomly initialized as in traditional training. Then, during the fine-tuning training, the Encoding block is excluded so as not to modify its weights. Note that the fine-tuning training is otherwise similar to the original training process, but using the real-network samples and with a diminished learning rate ($\approx10\times$  smaller).

\subsection{Automated transfer learning}
\label{sec:automated_ft}

In addition to the previous manual configurations, we also test our approach using automated fine-tuning approaches from the state-of-the-art. These do not require manually deciding which blocks to freeze, fine-tune, or retrain, reducing trial-and-error:

\begin{itemize}
    \item Autofreeze~\cite{liu2021autofreeze}: This method consists of loading all donor weights and setting them as trainable. During training, blocks whose weight gradients fall under a threshold are frozen, allowing weights to be adjusted while minimizing computational costs.
    \item L2-SP~\cite{pmlr-v80-li18a}: This method consists of adding a regularization term in the loss function involving the L2-distance between the receiver and donor weights. This guides the learning of the receiver model and is more effective at avoiding overfitting than the standard L2 regularization.
    \item GTOT-Tuning~\cite{zhang2022fine}: A more advanced version of L2-SP meant for Graph Neural Networks (GNNs). Instead of comparing weights, it measures the differences between node embeddings after the MPA using the Masked Wasserstein Distance (MWD). The mask in the MWD allows it to incorporate relational information.
\end{itemize}

\subsection{Testbed}
\label{subsec:testbed}
\begin{figure}[t]
    \centering
    \includegraphics[width=0.90\linewidth]{images/testbed.pdf}
    \caption{Diagram summarizing the testbed's structure.}
    \label{fig:testbed}
\end{figure}

To collect real network samples, we use a custom testbed with up to 8 real routers and traffic generators connected via switches. VLAN-based configurations allow emulation of diverse network topologies. Links range from 1 to 40 Gbps to simulate modern network conditions. Traffic is generated using 2–8 servers running MGEN and Tcpreplay. An optical splitter enables passive traffic capture for analysis, ensuring low interference. Figure~\ref{fig:testbed} shows the testbed's structure.


% \begin{itemize}
%     \item The testbed comprises up to 8 Huawei NetEngine 8000 M1A routers, interconnected via two Huawei S5732-H48UM 2CC 5G Bundle switches. A third Cisco WS-C4506-E switch links the traffic generators to one of the router switches, enabling flexible traffic configurations.
%     \item Traffic is generated using 2 to 8 servers running the MGEN~\cite{MGEN} and Tcpreplay~\cite{Tcpreplay} software. These servers create traffic for each source/destination pair, allowing the testbed to replicate a variety of network topologies through VLAN-based routing paths.
%     \item An optical splitter duplicates both ingoing and outgoing traffic from the traffic generators to a packet capture server. This server processes the captured data for subsequent analysis. By using optical splitters, we minimize any potential impact on traffic transmission or recording accuracy, ensuring high-fidelity measurements.
%     \item The routers and traffic generators are connected to the switches using 1 Gbps links, representative of modern network conditions. To prevent bottlenecks in the testbed's control plane, higher-capacity links are employed: 10 Gbps links connect the traffic generator switch to one of the router switches, and two 40 Gbps links, configured in trunk mode, connect the two router switches.
% \end{itemize}