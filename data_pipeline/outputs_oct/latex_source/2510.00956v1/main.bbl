% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{Riley2010}
G.~F. Riley and T.~R. Henderson, ``The ns-3 network simulator,'' in \emph{Modeling and tools for network simulation}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2010, pp. 15--34.

\bibitem{Varga2019}
A.~Varga, ``A practical introduction to the omnet++ simulation framework,'' in \emph{Recent advances in network simulation: the OMNeT++ environment and its ecosystem}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2019, pp. 3--51.

\bibitem{10.1145/3452296.3472926}
Q.~Zhang, K.~K. Ng, C.~Kazer, S.~Yan, J.~Sedoc, and V.~Liu, ``Mimicnet: Fast performance estimates for data center networks with machine learning,'' in \emph{Proceedings of the 2021 ACM SIGCOMM 2021 Conference}, 2021, pp. 287--304.

\bibitem{10.1145/3544216.3544248}
Q.~Yang, X.~Peng, L.~Chen, L.~Liu, J.~Zhang, H.~Xu, B.~Li, and G.~Zhang, ``Deepqueuenet: Towards scalable and generalized network performance estimation with packet-level visibility,'' in \emph{Proceedings of the ACM SIGCOMM 2022 Conference}, 2022, pp. 441--457.

\bibitem{ferriolgalmés2022routenetfermi}
M.~Ferriol-Galmés \emph{et~al.}, ``Routenet-fermi: Network modeling with graph neural networks,'' 2022.

\bibitem{CAIDA}
\BIBentryALTinterwordspacing
``{The CAIDA Anonymized Internet Traces Dataset}.'' [Online]. Available: \url{https://www.caida.org/catalog/datasets/passive\_dataset}
\BIBentrySTDinterwordspacing

\bibitem{li2024glancegraphbasedlearnabledigital}
B.~Li \emph{et~al.}, ``Glance: graph-based learnable digital twin for communication networks,'' \emph{arXiv preprint arXiv:2408.09040}, 2024.

\bibitem{10635943}
K.~Hattori \emph{et~al.}, ``Meta learner-based transfer learning: Bridging simulation and actual router metrics,'' in \emph{2024 IEEE 25th International Conference on High Performance Switching and Routing (HPSR)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2024, pp. 203--208.

\bibitem{10.5555/2998687.2998769}
R.~Caruana, ``Learning many related tasks at the same time with backpropagation,'' in \emph{Proceedings of the 7th International Conference on Neural Information Processing Systems}, ser. NIPS'94.\hskip 1em plus 0.5em minus 0.4em\relax Cambridge, MA, USA: MIT Press, 1994, p. 657–664.

\bibitem{pmlr-v15-bengio11b}
Y.~Bengio \emph{et~al.}, ``Deep learners benefit more from out-of-distribution examples,'' in \emph{Proceedings of the fourteenth international conference on artificial intelligence and statistics}.\hskip 1em plus 0.5em minus 0.4em\relax JMLR Workshop and Conference Proceedings, 2011, pp. 164--172.

\bibitem{10.5555/2969033.2969197}
J.~Yosinski \emph{et~al.}, ``How transferable are features in deep neural networks?'' in \emph{Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 2}, ser. NIPS'14.\hskip 1em plus 0.5em minus 0.4em\relax Cambridge, MA, USA: MIT Press, 2014, p. 3320–3328.

\bibitem{zeiler2013visualizingunderstandingconvolutionalnetworks}
\BIBentryALTinterwordspacing
M.~D. Zeiler and R.~Fergus, ``Visualizing and understanding convolutional networks,'' 2013. [Online]. Available: \url{https://arxiv.org/abs/1311.2901}
\BIBentrySTDinterwordspacing

\bibitem{pmlr-v70-gilmer17a}
J.~Gilmer, S.~S. Schoenholz, P.~F. Riley, O.~Vinyals, and G.~E. Dahl, ``Neural message passing for quantum chemistry,'' in \emph{International conference on machine learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2017, pp. 1263--1272.

\bibitem{cho2014learningphraserepresentationsusing}
\BIBentryALTinterwordspacing
K.~Cho \emph{et~al.}, ``Learning phrase representations using rnn encoder-decoder for statistical machine translation,'' 2014. [Online]. Available: \url{https://arxiv.org/abs/1406.1078}
\BIBentrySTDinterwordspacing

\bibitem{liu2021autofreeze}
Y.~Liu, S.~Agarwal, and S.~Venkataraman, ``Autofreeze: Automatically freezing model blocks to accelerate fine-tuning,'' \emph{arXiv preprint arXiv:2102.01386}, 2021.

\bibitem{pmlr-v80-li18a}
\BIBentryALTinterwordspacing
X.~LI, Y.~Grandvalet, and F.~Davoine, ``Explicit inductive bias for transfer learning with convolutional networks,'' in \emph{Proceedings of the 35th International Conference on Machine Learning}, ser. Proceedings of Machine Learning Research, J.~Dy and A.~Krause, Eds., vol.~80.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 10--15 Jul 2018, pp. 2825--2834. [Online]. Available: \url{https://proceedings.mlr.press/v80/li18a.html}
\BIBentrySTDinterwordspacing

\bibitem{zhang2022fine}
J.~Zhang, X.~Xiao, L.-K. Huang, Y.~Rong, and Y.~Bian, ``Fine-tuning graph neural networks via graph topology induced optimal transport,'' \emph{arXiv preprint arXiv:2203.10453}, 2022.

\bibitem{10.5555/1267724.1267775}
K.~Cho, K.~Mitsuya, and A.~Kato, ``Traffic data repository at the wide project,'' in \emph{Proceedings of the Annual Conference on USENIX Annual Technical Conference}, ser. ATEC '00.\hskip 1em plus 0.5em minus 0.4em\relax USA: USENIX Association, 2000, p.~51.

\bibitem{wang2022xnet}
M.~Wang \emph{et~al.}, ``xnet: Improving expressiveness and granularity for network modeling with graph neural networks,'' in \emph{IEEE INFOCOM 2022-IEEE Conference on Computer Communications}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2022, pp. 2028--2037.

\bibitem{10.1145/3651890.3672243}
C.~Li, A.~Nasr-Esfahany, K.~Zhao, K.~Noorbakhsh, P.~Goyal, M.~Alizadeh, and T.~E. Anderson, ``m3: Accurate flow-level performance estimation using machine learning,'' in \emph{Proceedings of the ACM SIGCOMM 2024 Conference}, 2024, pp. 813--827.

\bibitem{8667446}
C.~Zhang \emph{et~al.}, ``Deep transfer learning for intelligent cellular traffic prediction based on cross-domain big data,'' \emph{IEEE Journal on Selected Areas in Communications}, vol.~37, no.~6, pp. 1389--1401, 2019.

\bibitem{MAHDAVI2022109542}
E.~Mahdavi \emph{et~al.}, ``Itl-ids: Incremental transfer learning for intrusion detection systems,'' \emph{Knowledge-based systems}, vol. 253, p. 109542, 2022.

\bibitem{8879693}
Y.~Shen \emph{et~al.}, ``Lorm: Learning to optimize for resource management in wireless networks with few training samples,'' \emph{IEEE Transactions on Wireless Communications}, vol.~19, no.~1, pp. 665--679, 2020.

\end{thebibliography}
