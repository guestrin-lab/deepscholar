% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{Edge-AI-Technology-Report}
\BIBentryALTinterwordspacing
Wevolver, ``2023 edge {AI} technology report,'' 2023. [Online]. Available:
  \url{https://www.wevolver.com/article/2023-edge-ai-technology-report}
\BIBentrySTDinterwordspacing

\bibitem{10843329}
W.~Fan, P.~Chen, X.~Chun, and Y.~Liu, ``{MADRL}-based model partitioning,
  aggregation control, and resource allocation for cloud-edge-device
  collaborative split federated learning,'' \emph{IEEE Transactions on Mobile
  Computing}, vol.~24, no.~6, pp. 5324--5341, May 2025.

\bibitem{10040976}
W.~Wu, M.~Li, K.~Qu, C.~Zhou, X.~Shen, W.~Zhuang, X.~Li, and W.~Shi, ``Split
  learning over wireless networks: Parallel design and resource management,''
  \emph{IEEE Journal on Selected Areas in Communications}, vol.~41, no.~4, pp.
  1051--1066, Feb. 2023.

\bibitem{wei2025pipeliningsplitlearningmultihop}
W.~Wei, Z.~Lin, T.~Li, X.~Li, and X.~Chen, ``Pipelining split learning in
  multi-hop edge networks,'' \emph{arXiv preprint arXiv:2505.04368}, May 2025.

\bibitem{ZW_spectrum}
Z.~Wang, K.~Huang, and Y.~C. Eldar, ``Spectrum breathing: Protecting
  over-the-air federated learning against interference,'' \emph{IEEE Trans.
  Wireless Commun.}, vol.~23, no.~8, pp. 10\,058--10\,071, 2024.

\bibitem{9944188}
W.~Wei, J.~Wang, Z.~Fang, J.~Chen, Y.~Ren, and Y.~Dong, ``{3U}: Joint design of
  {UAV-USV-UUV} networks for cooperative target hunting,'' \emph{IEEE
  Transactions on Vehicular Technology}, vol.~72, no.~3, pp. 4085--4090, Mar.
  2023.

\bibitem{9839238}
W.~Wei, J.~Wang, J.~Du, Z.~Fang, C.~Jiang, and Y.~Ren, ``Underwater
  differential game: Finite-time target hunting task with communication
  delay,'' in \emph{IEEE International Conference on Communications}, Seoul,
  Korea, May, 2022, pp. 3989--3994.

\bibitem{10298247}
W.~Wei, J.~Wang, J.~Du, Z.~Fang, Y.~Ren, and C.~L.~P. Chen, ``Differential
  game-based deep reinforcement learning in underwater target hunting task,''
  \emph{IEEE Transactions on Neural Networks and Learning Systems}, vol.~36,
  no.~1, pp. 462--474, Jan., 2025.

\bibitem{jetson-agx}
\BIBentryALTinterwordspacing
NVIDIA, ``{NVIDIA Jetson Xavier},'' 2019. [Online]. Available:
  \url{https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-xavier-series/}
\BIBentrySTDinterwordspacing

\bibitem{vepakomma2018split}
P.~Vepakomma, O.~Gupta, T.~Swedish, and R.~Raskar, ``{Split Learning for
  Health: Distributed Deep Learning Without Sharing Raw Patient Data},'' in
  \emph{ICLR workshop on AI for social good}, New Orleans, LA, USA, Apr. 2019,
  pp. 1--7.

\bibitem{lin2023split}
Z.~Lin, G.~Qu, X.~Chen, and K.~Huang, ``{Split Learning in 6G Edge Networks},''
  \emph{IEEE Wireless Communications}, vol.~31, no.~4, pp. 170--176, Aug. 2024.

\bibitem{10934144}
Z.~Yao, J.~Qi, Y.~Xu, Y.~Liao, H.~Xu, and L.~Wang, ``Pairingfl: Efficient
  federated learning with model splitting and client pairing,'' \emph{IEEE
  Transactions on Networking}, vol.~33, no.~4, pp. 1811--1825, May 2025.

\bibitem{lin2024efficient}
Z.~Lin, G.~Zhu, Y.~Deng, X.~Chen, Y.~Gao, K.~Huang, and Y.~Fang, ``Efficient
  parallel split learning over resource-constrained wireless edge networks,''
  \emph{IEEE Transactions on Mobile Computing}, vol.~23, no.~10, pp.
  9224--9239, 2024.

\bibitem{lin2025leo}
Z.~Lin, Y.~Zhang, Z.~Chen, Z.~Fang, C.~Wu, X.~Chen, Y.~Gao, and J.~Luo,
  ``Leo-split: A semi-supervised split learning framework over leo satellite
  networks,'' \emph{IEEE Transactions on Mobile Computing}, 2025.

\bibitem{9084352}
T.~Li, A.~K. Sahu, A.~Talwalkar, and V.~Smith, ``Federated learning:
  Challenges, methods, and future directions,'' \emph{IEEE Signal Processing
  Magazine}, vol.~37, no.~3, pp. 50--60, May 2020.

\bibitem{lin2024fedsn}
Z.~Lin, Z.~Chen, Z.~Fang, X.~Chen, X.~Wang, and Y.~Gao, ``Fedsn: A federated
  learning framework over heterogeneous leo satellite networks,'' \emph{IEEE
  Transactions on Mobile Computing}, 2024.

\bibitem{konevcny2016federated}
J.~Kone{\v{c}}n{\`y}, ``Federated learning: Strategies for improving
  communication efficiency,'' \emph{arXiv preprint arXiv:1610.05492}, 2016.

\bibitem{thapa2022splitfed}
C.~Thapa, P.~C.~M. Arachchige, S.~Camtepe, and L.~Sun, ``Splitfed: When
  federated learning meets split learning,'' in \emph{Proceedings of the AAAI
  Conference on Artificial Intelligence}, Vancouver, BC, Canada, Feb. 2022, pp.
  8485--8493.

\bibitem{lin2025hasfl}
Z.~Lin, Z.~Chen, X.~Chen, W.~Ni, and Y.~Gao, ``Hasfl: Heterogeneity-aware split
  federated learning over edge computing systems,'' \emph{arXiv preprint
  arXiv:2506.08426}, 2025.

\bibitem{9923620}
X.~Liu, Y.~Deng, and T.~Mahmoodi, ``Wireless distributed learning: A new hybrid
  split and federated learning approach,'' \emph{IEEE Transactions on Wireless
  Communications}, vol.~22, no.~4, pp. 2650--2665, Apr. 2023.

\bibitem{lin2025hsplitlora}
Z.~Lin, Y.~Zhang, Z.~Chen, Z.~Fang, X.~Chen, P.~Vepakomma, W.~Ni, J.~Luo, and
  Y.~Gao, ``Hsplitlora: A heterogeneous split parameter-efficient fine-tuning
  framework for large language models,'' \emph{arXiv preprint
  arXiv:2505.02795}, 2025.

\bibitem{9060868}
W.~Y.~B. Lim, N.~C. Luong, D.~T. Hoang, Y.~Jiao, Y.-C. Liang, Q.~Yang,
  D.~Niyato, and C.~Miao, ``Federated learning in mobile edge networks: A
  comprehensive survey,'' \emph{IEEE Communications Surveys \& Tutorials},
  vol.~22, no.~3, pp. 2031--2063, Apr. 2020.

\bibitem{10292582}
A.~Rodio, F.~Faticanti, O.~Marfoq, G.~Neglia, and E.~Leonardi, ``Federated
  learning under heterogeneous and correlated client availability,''
  \emph{IEEE/ACM Transactions on Networking}, vol.~32, no.~2, pp. 1451--1460,
  Apr. 2024.

\bibitem{chen2024fedmeld}
Q.~Chen, X.~Chen, and K.~Huang, ``Fedmeld: A model-dispersal federated learning
  framework for space-ground integrated networks,'' \emph{arXiv preprint
  arXiv:2412.17231}, Dec. 2024.

\bibitem{hu2024accelerating}
M.~Hu, J.~Zhang, X.~Wang, S.~Liu, and Z.~Lin, ``Accelerating federated learning
  with model segmentation for edge networks,'' \emph{IEEE Transactions on Green
  Communications and Networking}, 2024.

\bibitem{10095067}
Z.~H. Kafshgari, I.~V. Bajić, and P.~Saeedi, ``Smart split-federated learning
  over noisy channels for embryo image segmentation,'' in \emph{IEEE
  International Conference on Acoustics, Speech and Signal Processing}, Rhodes
  Island, Greece, Jun. 2023, pp. 1--5.

\bibitem{shiranthika2023splitfedresiliencepacketloss}
C.~Shiranthika, Z.~H. Kafshgari, P.~Saeedi, and I.~V. Bajić, ``{SplitFed}
  resilience to packet loss: Where to split, that is the question,'' in
  \emph{Medical Image Computing and Computer Assisted Intervention Workshops},
  Vancouver, BC, Canada, Dec. 2023, pp. 367--377.

\bibitem{mcmahan2017communication}
B.~McMahan, E.~Moore, D.~Ramage, S.~Hampson, and B.~A. y~Arcas,
  ``Communication-efficient learning of deep networks from decentralized
  data,'' in \emph{Artificial intelligence and statistics}, Florida, USA, Apr.
  2017, pp. 1273--1282.

\bibitem{10.5555/3546258.3546471}
J.~Wang and G.~Joshi, ``Cooperative {SGD}: a unified framework for the design
  and analysis of local-update sgd algorithms,'' \emph{Journal of Machine
  Learning Research}, vol.~22, no.~1, pp. 9709 -- 9758, Jan. 2021.

\bibitem{NEURIPS2018_3ec27c2c}
B.~E. Woodworth, J.~Wang, A.~Smith, B.~McMahan, and N.~Srebro, ``Graph oracle
  models, lower bounds, and gaps for parallel stochastic optimization,'' in
  \emph{Advances in Neural Information Processing Systems}, Montréal, Canada,
  Dec. 2018, pp. 1--11.

\bibitem{9261995}
C.~T. Dinh, N.~H. Tran, M.~N.~H. Nguyen, C.~S. Hong, W.~Bao, A.~Y. Zomaya, and
  V.~Gramoli, ``Federated learning over wireless networks: Convergence analysis
  and resource allocation,'' \emph{IEEE/ACM Transactions on Networking},
  vol.~29, no.~1, pp. 398--409, Feb. 2021.

\bibitem{cho2020clientselectionfederatedlearning}
Y.~J. Cho, J.~Wang, and G.~Joshi, ``Client selection in federated learning:
  Convergence analysis and power-of-choice selection strategies,'' \emph{arXiv
  preprint arXiv:2010.01243}, Oct. 2020.

\bibitem{chen2022optimalclientsamplingfederated}
W.~Chen, S.~Horvath, and P.~Richtarik, ``Optimal client sampling for federated
  learning,'' \emph{arXiv preprint arXiv:2010.13723}, Oct. 2022.

\bibitem{9904868}
E.~Rizk, S.~Vlaski, and A.~H. Sayed, ``Federated learning under importance
  sampling,'' \emph{IEEE Transactions on Signal Processing}, vol.~70, pp.
  5381--5396, Sep. 2022.

\bibitem{pmlr-v151-jee-cho22a}
Y.~Jee~Cho, J.~Wang, and G.~Joshi, ``Towards understanding biased client
  selection in federated learning,'' in \emph{Proceedings of International
  Conference on Artificial Intelligence and Statistics}, vol. 151.\hskip 1em
  plus 0.5em minus 0.4em\relax Virtual Conference: PMLR, Mar. 2022, pp.
  10\,351--10\,375.

\bibitem{fraboni2021clustered}
Y.~Fraboni, R.~Vidal, L.~Kameni, and M.~Lorenzi, ``Clustered sampling:
  Low-variance and improved representativity for clients selection in federated
  learning,'' in \emph{International Conference on Machine Learning}, Virtual,
  Jul. 2021, pp. 3407--3416.

\bibitem{NEURIPS2024_7886b9ba}
H.~Chen and H.~Vikalo, ``Heterogeneity-guided client sampling: Towards fast and
  efficient {Non-IID} federated learning,'' in \emph{Advances in Neural
  Information Processing Systems}, Vancouver, Canada, Dec. 2024, pp.
  65\,525--65\,561.

\bibitem{10.1109/INFOCOM48880.2022.9796935}
B.~Luo, W.~Xiao, S.~Wang, J.~Huang, and L.~Tassiulas, ``Tackling system and
  statistical heterogeneity for federated learning with adaptive client
  sampling,'' in \emph{IEEE Conference on Computer Communications}, London,
  United Kingdom, May 2022, pp. 1739--1748.

\bibitem{9810502}
A.~Sultana, M.~M. Haque, L.~Chen, F.~Xu, and X.~Yuan, ``Eiffel: Efficient and
  fair scheduling in adaptive federated learning,'' \emph{IEEE Transactions on
  Parallel and Distributed Systems}, vol.~33, no.~12, pp. 4282--4294, Jun.
  2022.

\bibitem{ZW2024ultra-LoLa}
Z.~Wang, A.~E. Kalør, Y.~Zhou, P.~Popovski, and K.~Huang, ``Ultra-low-latency
  edge inference for distributed sensing,'' \emph{IEEE Trans. Wireless
  Commun.}, 2024, early access, 2025.

\bibitem{zw2025AIoutage}
\BIBentryALTinterwordspacing
Z.~Wang, Q.~Zeng, H.~Zheng, and K.~Huang, ``Revisiting outage for edge
  inference systems,'' 2025. [Online]. Available:
  \url{https://arxiv.org/abs/2504.03686}
\BIBentrySTDinterwordspacing

\bibitem{lin2024adaptsfl}
Z.~Lin, G.~Qu, W.~Wei, X.~Chen, and K.~K. Leung, ``Adaptsfl: Adaptive split
  federated learning in resource-constrained edge networks,'' \emph{IEEE
  Transactions on Networking}, pp. 1--16, early access 2025.

\bibitem{10980018}
Z.~Lin, W.~Wei, Z.~Chen, C.-T. Lam, X.~Chen, Y.~Gao, and J.~Luo, ``Hierarchical
  split federated learning: Convergence analysis and system optimization,''
  \emph{IEEE Transactions on Mobile Computing}, vol.~24, no.~10, pp.
  9352--9367, Oct. 2025.

\bibitem{10304624}
C.~Xu, J.~Li, Y.~Liu, Y.~Ling, and M.~Wen, ``Accelerating split federated
  learning over wireless communication networks,'' \emph{IEEE Transactions on
  Wireless Communications}, vol.~23, no.~6, pp. 5587--5599, Jun. 2024.

\bibitem{10.1145/3460120.3485259}
D.~Pasquini, G.~Ateniese, and M.~Bernaschi, ``Unleashing the tiger: Inference
  attacks on split learning,'' in \emph{Proceedings of the 2021 ACM SIGSAC
  Conference on Computer and Communications Security}.\hskip 1em plus 0.5em
  minus 0.4em\relax New York, NY, USA: Association for Computing Machinery,
  Nov. 2021, pp. 2113--2129.

\bibitem{pmlr-v119-karimireddy20a}
S.~P. Karimireddy, S.~Kale, M.~Mohri, S.~Reddi, S.~Stich, and A.~T. Suresh,
  ``{SCAFFOLD}: Stochastic controlled averaging for federated learning,'' in
  \emph{International Conference on Machine Learning}, vol. 119.\hskip 1em plus
  0.5em minus 0.4em\relax Virtual: PMLR, Jul. 2020, pp. 5132--5143.

\bibitem{li2019convergence}
X.~Li, K.~Huang, W.~Yang, S.~Wang, and Z.~Zhang, ``On the convergence of fedavg
  on {Non-IID} data,'' in \emph{Proceedings of the International Conference on
  Learning Representation}, Addis Ababa, Ethiopia, Apr. 2020, pp. 1--11.

\bibitem{yang2021achieving}
H.~Yang, M.~Fang, and J.~Liu, ``Achieving linear speedup with partial worker
  participation in non-iid federated learning,'' in \emph{International
  Conference on Learning Representations}, Vienna, Austria, May 2021, pp.
  1--11.

\bibitem{10121038}
M.~F. Pervej, R.~Jin, and H.~Dai, ``Resource constrained vehicular edge
  federated learning with highly mobile connected vehicles,'' \emph{IEEE
  Journal on Selected Areas in Communications}, vol.~41, no.~6, pp. 1825--1844,
  May, 2023.

\bibitem{han2025convergenceanalysissplitfederated}
P.~Han, C.~Huang, G.~Tian, M.~Tang, and X.~Liu, ``Convergence analysis of split
  federated learning on heterogeneous data,'' \emph{arXiv preprint
  arXiv:2402.15166}, 2025.

\bibitem{pmlr-v162-gao22c}
H.~Gao, J.~Li, and H.~Huang, ``On the convergence of local stochastic
  compositional gradient descent with momentum,'' in \emph{Proceedings of
  International Conference on Machine Learning}, Baltimore, USA, Jul. 2022, pp.
  7017--7035.

\bibitem{yang2025optBS}
\BIBentryALTinterwordspacing
H.~Yang, Z.~Wang, and K.~Huang, ``Optimal batch-size control for low-latency
  federated learning with device heterogeneity,'' 2025. [Online]. Available:
  \url{https://arxiv.org/abs/2507.15601}
\BIBentrySTDinterwordspacing

\bibitem{10443546}
B.~Luo, W.~Xiao, S.~Wang, J.~Huang, and L.~Tassiulas, ``Adaptive heterogeneous
  client sampling for federated learning over wireless networks,'' \emph{IEEE
  Transactions on Mobile Computing}, vol.~23, no.~10, pp. 9663--9677, Oct.
  2024.

\bibitem{eiger1984bisection}
A.~Eiger, K.~Sikorski, and F.~Stenger, ``A bisection method for systems of
  nonlinear equations,'' \emph{ACM Transactions on Mathematical Software},
  vol.~10, no.~4, pp. 367--377, Dec. 1984.

\bibitem{cohen2017emnistextensionmnisthandwritten}
G.~Cohen, S.~Afshar, J.~Tapson, and A.~van Schaik, ``{EMNIST:} an extension of
  {MNIST} to handwritten letters,'' \emph{arXiv preprint arXiv:1702.05373},
  Mar. 2017.

\bibitem{lecun1998mnist}
Y.~Lecun, L.~Bottou, Y.~Bengio, and P.~Haffner, ``Gradient-based learning
  applied to document recognition,'' \emph{Proc. IEEE}, vol.~86, no.~11, pp.
  2278--2324, Nov. 1998.

\bibitem{he2015deepresiduallearningimage}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' in \emph{IEEE Conference on Computer Vision and Pattern
  Recognition}, Las Vegas, NV, USA, Dec. 2016, pp. 770--778.

\bibitem{zhang2025optimalheterogeneousclientsampling}
H.~Zhang, Z.~Gong, Z.~Li, M.~Siew, C.~Joe-Wong, and R.~El-Azouzi, ``Towards
  optimal heterogeneous client sampling in multi-model federated learning,''
  \emph{arXiv preprint arXiv:2504.05138}, Apr. 2025.

\bibitem{8664630}
S.~Wang, T.~Tuor, T.~Salonidis, K.~K. Leung, C.~Makaya, T.~He, and K.~Chan,
  ``Adaptive federated learning in resource constrained edge computing
  systems,'' \emph{IEEE Journal on Selected Areas in Communications}, vol.~37,
  no.~6, pp. 1205--1221, Jun. 2019.

\bibitem{10053757}
W.~J. Robinson~M., F.~Esposito, and M.~A. Zuluaga, ``{DTS}: A simulator to
  estimate the training time of distributed deep neural networks,'' in
  \emph{International Symposium on Modeling, Analysis, and Simulation of
  Computer and Telecommunication Systems}, Nice, France, Mar. 2023, pp. 17--24.

\bibitem{yoo2024modeling}
Y.~Yoo and S.~Jung, ``Modeling forecast errors for microgrid operation using
  {Gaussian } process regression,'' \emph{Scientific Reports}, vol.~14, no.~1,
  p. 2166, Jan. 2024.

\end{thebibliography}
