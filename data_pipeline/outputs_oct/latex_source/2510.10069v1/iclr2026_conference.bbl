\begin{thebibliography}{27}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Arandjelovic \& Zisserman(2017)Arandjelovic and Zisserman]{l3net}
Relja Arandjelovic and Andrew Zisserman.
\newblock Look, listen and learn.
\newblock In \emph{Proceedings of the IEEE international conference on computer vision}, pp.\  609--617, 2017.

\bibitem[Cai et~al.(2023)Cai, Ghosh, Stefanov, Dhall, Cai, Rezatofighi, Haffari, and Hayat]{marlin}
Zhixi Cai, Shreya Ghosh, Kalin Stefanov, Abhinav Dhall, Jianfei Cai, Hamid Rezatofighi, Reza Haffari, and Munawar Hayat.
\newblock Marlin: Masked autoencoder for facial video representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  1493--1504, 2023.

\bibitem[Chung \& Zisserman(2016)Chung and Zisserman]{syncnet}
Joon~Son Chung and Andrew Zisserman.
\newblock Out of time: automated lip sync in the wild.
\newblock In \emph{Asian conference on computer vision}, pp.\  251--263. Springer, 2016.

\bibitem[Cui et~al.(2025)Cui, Li, Zhan, Shang, Cheng, Ma, Mu, Zhou, Wang, and Zhu]{hallo3}
Jiahao Cui, Hui Li, Yun Zhan, Hanlin Shang, Kaihui Cheng, Yuqi Ma, Shan Mu, Hang Zhou, Jingdong Wang, and Siyu Zhu.
\newblock Hallo3: Highly dynamic and realistic portrait image animation with video diffusion transformer.
\newblock In \emph{Proceedings of the Computer Vision and Pattern Recognition Conference}, pp.\  21086--21095, 2025.

\bibitem[He et~al.(2022)He, Chen, Xie, Li, Doll{\'a}r, and Girshick]{mae}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  16000--16009, 2022.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and Hochreiter]{fid}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash equilibrium.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Jiang et~al.(2025)Jiang, Han, Mao, Zhang, Pan, and Liu]{vace}
Zeyinzi Jiang, Zhen Han, Chaojie Mao, Jingfeng Zhang, Yulin Pan, and Yu~Liu.
\newblock Vace: All-in-one video creation and editing.
\newblock \emph{arXiv preprint arXiv:2503.07598}, 2025.

\bibitem[Kadandale et~al.(2022)Kadandale, Montesinos, and Haro]{vocalist}
Venkatesh~S Kadandale, Juan~F Montesinos, and Gloria Haro.
\newblock Vocalist: An audio-visual synchronisation model for lips and voices.
\newblock \emph{arXiv preprint arXiv:2204.02090}, 2022.

\bibitem[Korbar et~al.(2019)Korbar, Tran, and Torresani]{scsampler}
Bruno Korbar, Du~Tran, and Lorenzo Torresani.
\newblock Scsampler: Sampling salient clips from video for efficient action recognition.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  6232--6242, 2019.

\bibitem[Li et~al.(2024)Li, Zhang, Xu, Lin, Xie, Feng, Peng, Chen, and Xing]{latentsync}
Chunyu Li, Chao Zhang, Weikai Xu, Jingyu Lin, Jinghui Xie, Weiguo Feng, Bingyue Peng, Cunjian Chen, and Weiwei Xing.
\newblock Latentsync: Taming audio-conditioned latent diffusion models for lip sync with syncnet supervision.
\newblock \emph{arXiv preprint arXiv:2412.09262}, 2024.

\bibitem[Livingstone \& Russo(2018)Livingstone and Russo]{ravdness}
Steven~R Livingstone and Frank~A Russo.
\newblock The ryerson audio-visual database of emotional speech and song (ravdess): A dynamic, multimodal set of facial and vocal expressions in north american english.
\newblock \emph{PloS one}, 13\penalty0 (5):\penalty0 e0196391, 2018.

\bibitem[Ma et~al.(2023)Ma, Haliassos, Fernandez-Lopez, Chen, Petridis, and Pantic]{autoavsr}
Pingchuan Ma, Alexandros Haliassos, Adriana Fernandez-Lopez, Honglie Chen, Stavros Petridis, and Maja Pantic.
\newblock Auto-avsr: Audio-visual speech recognition with automatic labels.
\newblock In \emph{ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pp.\  1--5. IEEE, 2023.

\bibitem[Morgado et~al.(2020)Morgado, Li, and Nvasconcelos]{avts}
Pedro Morgado, Yi~Li, and Nuno Nvasconcelos.
\newblock Learning representations from audio-visual spatial alignment.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 4733--4744, 2020.

\bibitem[Peebles \& Xie(2023)Peebles and Xie]{dit}
William Peebles and Saining Xie.
\newblock Scalable diffusion models with transformers.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pp.\  4195--4205, 2023.

\bibitem[Prajwal et~al.(2020)Prajwal, Mukhopadhyay, Namboodiri, and Jawahar]{wav2lip}
KR~Prajwal, Rudrabha Mukhopadhyay, Vinay~P Namboodiri, and CV~Jawahar.
\newblock A lip sync expert is all you need for speech to lip generation in the wild.
\newblock In \emph{Proceedings of the 28th ACM international conference on multimedia}, pp.\  484--492, 2020.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{clip}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{International conference on machine learning}, pp.\  8748--8763. PmLR, 2021.

\bibitem[Shi et~al.(2022)Shi, Hsu, Lakhotia, and Mohamed]{avhubert}
Bowen Shi, Wei-Ning Hsu, Kushal Lakhotia, and Abdelrahman Mohamed.
\newblock Learning audio-visual speech representation by masked multimodal cluster prediction.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Sun et~al.(2023)Sun, Lian, Liu, and Tao]{mae_dfer}
Licai Sun, Zheng Lian, Bin Liu, and Jianhua Tao.
\newblock Mae-dfer: Efficient masked autoencoder for self-supervised dynamic facial expression recognition.
\newblock In \emph{Proceedings of the 31st ACM International Conference on Multimedia}, pp.\  6110--6121, 2023.

\bibitem[Tong et~al.(2022)Tong, Song, Wang, and Wang]{videomae}
Zhan Tong, Yibing Song, Jue Wang, and Limin Wang.
\newblock Videomae: Masked autoencoders are data-efficient learners for self-supervised video pre-training.
\newblock \emph{Advances in neural information processing systems}, 35:\penalty0 10078--10093, 2022.

\bibitem[Unterthiner et~al.(2018)Unterthiner, Van~Steenkiste, Kurach, Marinier, Michalski, and Gelly]{fvd}
Thomas Unterthiner, Sjoerd Van~Steenkiste, Karol Kurach, Raphael Marinier, Marcin Michalski, and Sylvain Gelly.
\newblock Towards accurate generative models of video: A new metric \& challenges.
\newblock \emph{arXiv preprint arXiv:1812.01717}, 2018.

\bibitem[Wan et~al.(2025)Wan, Wang, Ai, Wen, Mao, Xie, Chen, Yu, Zhao, Yang, et~al.]{wan}
Team Wan, Ang Wang, Baole Ai, Bin Wen, Chaojie Mao, Chen-Wei Xie, Di~Chen, Feiwu Yu, Haiming Zhao, Jianxiao Yang, et~al.
\newblock Wan: Open and advanced large-scale video generative models.
\newblock \emph{arXiv preprint arXiv:2503.20314}, 2025.

\bibitem[Wang et~al.(2020)Wang, Wu, Song, Yang, Wu, Qian, He, Qiao, and Loy]{mead}
Kaisiyuan Wang, Qianyi Wu, Linsen Song, Zhuoqian Yang, Wayne Wu, Chen Qian, Ran He, Yu~Qiao, and Chen~Change Loy.
\newblock Mead: A large-scale audio-visual dataset for emotional talking-face generation.
\newblock In \emph{European conference on computer vision}, pp.\  700--717. Springer, 2020.

\bibitem[Xie et~al.(2022)Xie, Wang, Zhang, Dong, and Shan]{vfhq}
Liangbin Xie, Xintao Wang, Honglun Zhang, Chao Dong, and Ying Shan.
\newblock Vfhq: A high-quality dataset and benchmark for video face super-resolution.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  657--666, 2022.

\bibitem[Yu et~al.(2023)Yu, Zhu, Jiang, Loy, Cai, and Wu]{celebvtext}
Jianhui Yu, Hao Zhu, Liming Jiang, Chen~Change Loy, Weidong Cai, and Wayne Wu.
\newblock Celebv-text: A large-scale facial text-video dataset.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  14805--14814, 2023.

\bibitem[Zhang et~al.(2024)Zhang, Zhong, Liu, Chen, Wu, Zeng, Zhan, He, Huang, and Zhou]{musetalk}
Yue Zhang, Zhizhou Zhong, Minhao Liu, Zhaokang Chen, Bin Wu, Yubin Zeng, Chao Zhan, Yingjie He, Junxin Huang, and Wenjiang Zhou.
\newblock Musetalk: Real-time high-fidelity video dubbing via spatio-temporal sampling.
\newblock \emph{arXiv preprint arXiv:2410.10122}, 2024.

\bibitem[Zhang et~al.(2021)Zhang, Li, Ding, and Fan]{hdtf}
Zhimeng Zhang, Lincheng Li, Yu~Ding, and Changjie Fan.
\newblock Flow-guided one-shot talking face generation with a high-resolution audio-visual dataset.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  3661--3670, 2021.

\bibitem[Zhu et~al.(2022)Zhu, Wu, Zhu, Jiang, Tang, Zhang, Liu, and Loy]{celebvhq}
Hao Zhu, Wayne Wu, Wentao Zhu, Liming Jiang, Siwei Tang, Li~Zhang, Ziwei Liu, and Chen~Change Loy.
\newblock Celebv-hq: A large-scale video facial attributes dataset.
\newblock In \emph{European conference on computer vision}, pp.\  650--667. Springer, 2022.

\end{thebibliography}
