\appendix

\section{Ethics}\label{sec:appendix_ethics}
We have obtained ethical clearance from our university ethics board (UNSW Human Research Ethics Advisory Panel approval reference number iRECS5933) to report the measured cloud gaming session characteristics in an aggregated manner, by analyzing real-time network traffic at our partnered Internet service provider that exclusively hosts NVIDIA's GeForce NOW cloud gaming servers and offline logs.
All user identities are anonymous, and we have made no attempt to collect or reveal any personal information. Due to commercial confidentiality restrictions, we only report percentage values after aggregation instead of exact numbers from our field deployment.


\section{Data Availability}	\label{sec:data_availability}
Our ground-truth traffic traces (PCAP files) of cloud gaming sessions with their context labels (CSV files) that contain game titles, game genres, user platforms, streaming configurations and game activity stages, which are collected in our lab setup and described in \S\ref{sec:dataset}, are publicly shared with the research community via our university cloud drive. We also share a collection of supplementary preprocessing scripts in a GitHub repository. The public links to both the dataset and the scripts are available on our website \cite{lyu_dataset} under the ``Cloud Gaming'' category. 


\section{Additional Evaluation Results}\label{sec:additional_eval}
In this section, we present additional evaluation results on model selection and attribute importance for game title  (\S\ref{sec:additional_title_eval}) and gameplay activity pattern (\S\ref{sec:additional_pattern_eval}) classification.

\begin{figure}[h!]
    \centering
    \mbox{
    \hspace{-2mm}
        \subfigure[RF model.]{
        \includegraphics[width=0.33\columnwidth]{figures/hyperparameter_tuning_random_forest.pdf}
        }
        \hspace{-3mm}
        \subfigure[SVM model.]{
        \includegraphics[width=0.33\columnwidth]{figures/hyperparameter_tuning_svm.pdf}
        }
        \hspace{-3mm}
        \subfigure[KNN model.]{
        \includegraphics[width=0.33\columnwidth]{figures/hyperparameter_tuning_knn.pdf}
        }
    }
    \caption{Three models (\ie RF, SVM and KNN) are fine-tuned for their hyperparameters for game title classification, with the best accuracy achieved by the RF model.}
    \label{fig:game_title_hyperparameter_tuning}
\end{figure}

\subsection{Game Title Classification}\label{sec:additional_title_eval}
We trained and fine-tuned the hyperparameters of three models that are commonly used in traffic classification tasks, namely Random Forest (RF), Support Vector Machine (SVM) and K-Nearest-Neighbors (KNN). 
In Fig.\ref{fig:game_title_hyperparameter_tuning}, we show the accuracies of the three models for game title classification while tuning their two representative hyperparameters, including the number of trees and maximum tree depth for Random Forest, regularization parameter (C) and kernel type for SVM, and the number of neighbors and distance metric for KNN. The best hyperparameter combinations from each model are highlighted in red. The overall highest accuracy (\ie 95.2\%) was achieved from the Random Forest model with the number of trees set to 500 and the maximum tree depth between 10 and 30. In our deployment, we select a maximum tree depth of 10 as it reduces model complexity as well as the risk of overfitting. In comparison, the highest accuracy from SVM and KNN models after fine-tuning are 91.5\% and 81.4\%, respectively. The substantially lower performance of the KNN model might be due to the limitations of distance-based metrics in capturing the characteristics of high-dimensional attribute space.

\begin{figure}[h!]
    \centering
    \mbox{
    \hspace{-2mm}
        \subfigure[RF model.]{
        \includegraphics[width=0.33\columnwidth]{figures/game_stage_hyperparameter_tuning_random_forest.pdf}
        }
        \hspace{-3mm}
        \subfigure[SVM model.]{
        \includegraphics[width=0.33\columnwidth]{figures/game_stage_hyperparameter_tuning_svm.pdf}
        }
        \hspace{-3mm}
        \subfigure[KNN model.]{
        \includegraphics[width=0.33\columnwidth]{figures/game_stage_hyperparameter_tuning_knn.pdf}
        }
    }
    \caption{Three models (\ie RF, SVM and KNN) are fine-tuned for their hyperparameters for the classification of gameplay activity patterns, with the highest accuracy achieved by the RF model.}
    \label{fig:game_stage_hyperparameter_tuning}
\end{figure}

\subsection{Gameplay Activity Pattern Classification}   \label{sec:additional_pattern_eval}
Following the same model fine-tuning process as just described for game title classification, we show the accuracy of the three models with different hyperparameters in Fig.~\ref{fig:game_stage_hyperparameter_tuning}. Similarly, the highest accuracy of 96.5\% was achieved by the Random Forest model with the number of trees set to 100 and the maximum tree depth within the range of 10 and 30. We select a maximum tree depth of 10 in our deployment.
Due to the lower dimensionality of the attribute space, the SVM and KNN models demonstrate slightly lower accuracy compared to the Random Forest model, with their highest accuracy being 95.9\% and 93.7\%, respectively.

\begin{table}[h!]
	\centering
	\caption{Importance of the nine attributes (each representing a transition probability among the three types of player activity stages) in classifying gameplay activity patterns by the best-performing Random Forest model.}
	\small
	\begin{tabular}{|
    >{\columncolor[HTML]{C0C0C0}}l |l|l|l|}
    \hline
    \textbf{\diagbox{To}{From}}        & \cellcolor[HTML]{C0C0C0}\textbf{\coloractive{Active}} & \cellcolor[HTML]{C0C0C0}\textbf{\colorpassive{Passive}} & \cellcolor[HTML]{C0C0C0}\textbf{\coloridle{Idle}} \\ \hline
    \textbf{\coloractive{Active}}  & 0.022                                   & 0.009                                    & 0.018                                 \\ \hline
    \textbf{\colorpassive{Passive}} & 0.052                                   & 0.027                                    & 0.094                                 \\ \hline
    \textbf{\coloridle{Idle}}    & 0.167                                   & 0.022                                    & 0.026                                 \\ \hline
    \end{tabular}
	\label{tab:activity_pattern_feature_importance}
\end{table}

Table~\ref{tab:activity_pattern_feature_importance} shows the permutation importance of the nine attributes in classifying the gameplay activity pattern by our best-performing Random Forest model. Each of these attributes represents the probability of one possible stage transition.
All nine attributes have certain predictive power in classifying gameplay activity patterns. Among them, the attribute for transitions from active to idle stage has the highest importance.
