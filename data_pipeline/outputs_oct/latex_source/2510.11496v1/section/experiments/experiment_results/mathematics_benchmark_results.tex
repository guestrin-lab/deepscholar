\subsubsection{Evaluation Results}

\begin{table}[tb]
    \resizebox{1\textwidth}{!}{
    \centering
    \begin{tabular}{l|cccccccc|c}
        \hline
         Model &  \makecell{MMMU\\(val)} & \makecell{MMMU\\Pro} & \makecell{MathVista\\(mini)} & MathVision & \makecell{MathVerse\\(vision-only)} & \makecell{DynaMath\\(worst case)} & WeMath & LogicVista & Overall\\
         \hline
         Qwen2.5-VL-3B~\cite{bai2025qwen2_5}   & 51.2 & 30.9*& 60.9*& 18.8*& 25.7*& 11.0*& 23.2*& 35.1*& 32.1\\
         BlueLM-2.5-3B~\cite{xiong2025bluelm} & 47.5 & - & 70.8 & 28.5 & - & - & - &- & -\\
         BlueLM-2.5-3B-thinking~\cite{xiong2025bluelm} & 51.3 & - & 78.4 & 47.7 & - & - & - &- & -\\
         Qianfan-VL-3B~\cite{dong2025qianfan} & 46.4 & - & - & - & - & - & - &- & -\\
         Gemma3-4B~\cite{gemmateam2025gemma3} &  47.3 & 24.5*& 46.3 & 23.1*& 23.2*& 11.0*& 23.1*& 32.7*& 28.9\\
         Phi-3.5-Vision-4B~\cite{abdin2024phi3} &44.6 & 23.6*& 43.3 & 14.9*& 19.7*& 9.8*& 11.2*& 25.1*& 24.0\\
         Phi-4-Multimodal~\cite{abouelenin2025phi} &55.1& 38.5& 62.4& 19.7*& 22.0*& 13.0*& 19.2*& 35.6*& 33.2\\
         Ovis2-4B~\cite{lu2024ovis} &49.0 & 28.0*& 69.6 & 21.1*& 39.0*& 12.6*& 18.0*& 35.1*& 34.1\\
         MiniCPM-V-4-4B~\cite{yao2024minicpm} & 51.2 & 33.4*& 66.9 & 20.7 & 22.0*& 14.2* & 30.0*& 32.0*& 33.8\\
         R-4B-RL~\cite{jiang2025r} & 68.1 & 46.5 & 78.0 & 47.8 & 64.9 & \textbf{39.5} & 52.8 & \textbf{59.1} & 57.1\\
         InternVL3.5-4B~\cite{wang2025internvl3} & 66.6 & \textbf{53.5}*& 77.1 & \textbf{54.4} & 61.7 & 35.7 & 50.1 & 56.4 & 56.9\\
         \rowcolor{gray!15} AndesVL-4B-Instruct & 58.0 & 37.6 & 73.3 & 27.1 & 34.3 & 21.2 & 33.7 & 41.6 & 40.9\\
         \rowcolor{gray!15} AndesVL-4B-Thinking & \textbf{66.9} & 51.4 & \textbf{79.4} & 51.0 & \textbf{66.9} & 35.5 & \textbf{57.4} & 57.7 & \textbf{58.3} \\
         \hline
         Qwen2-VL-2B~\cite{wang2024qwen2vl} &  42.2 & 19.9*& 48.0 & 17.3*& 16.8*& 4.0*& 11.3*& 25.5*& 23.1 \\
         MiniCPM-V-2B~\cite{yao2024minicpm} &  38.2 & 20.8*& 39.8 & 15.0*& 16.8*& 2.8*& 6.3*& 26.6*& 20.8\\
         SAIL-VL-1.5-2B~\cite{dong2025scalable} &  46.7*& 23.6*& 67.3 &  18.0*& 21.7*& 8.6*& 16.5*& 33.8*& 29.5\\
         SAIL-VL2-2B~\cite{yin2025sail} &  47.7* & -& 71.1* &  23.4*& -& 10.2*& 22.7*& 36.2*& -\\
         SAIL-VL2-2B-Thinking~\cite{yin2025sail} &  - & -& 68.5* &  27.5*& -& 20.2*& 38.8*& 47.0*& -\\
        Ovis2-2B~\cite{lu2024ovis} &  45.6 & 23.8*& 64.1 & 17.6*& 30.7*& 10.0*& 10.4*& 33.6*& 29.5\\
         InternVL3-2B~\cite{zhu2025internvl3} &  43.2 & 26.9*& 57.0 & 19.5*& 21.8*& 14.6  & 22.4 & 47.7 & 31.6\\
         InternVL3.5-2B~\cite{wang2025internvl3} &  \textbf{59.0} & \textbf{42.6}*& 71.8 & \textbf{42.8} & 53.4 & \textbf{31.5}  & \textbf{48.5} & \textbf{49.4} & \textbf{49.9}\\
         \rowcolor{gray!15} AndesVL-2B-Instruct & 46.1 & 30.7 & 64.9 & 22.4 & 26.8 & 15.2 & 30.3 & 34.0 & 33.8 \\
         \rowcolor{gray!15} AndesVL-2B-Thinking & 52.1 & 37.3 & \textbf{73.3} & 35.2 & \textbf{54.8} & 27.5 & 41.1 & 44.3 & 45.7 \\
         \hline
         Ovis2-1B~\cite{lu2024ovis} &  36.1 & 20.9*& 59.4 & 16.0 & 23.9*& 2.8*& 9.6*& 26.0*& 24.3\\
         InternVL3-1B~\cite{zhu2025internvl3} & 43.4 & 20.1*& 45.8 & 18.8 & 18.7 & 5.8 & 13.4 & 29.8 & 24.5\\
         InternVL3.5-1B~\cite{wang2025internvl3} & \textbf{44.2} & 25.7*& 59.3 & \textbf{27.3} & 37.8 & \textbf{17.2} & 21.5 & 29.3 & 32.8\\
         \rowcolor{gray!15} AndesVL-1B-Instruct & 43.1 & 24.4 & 53.8 & 18.1 & 18.5 & 10.2 & 21.0 & 30.2 & 27.4 \\
         \rowcolor{gray!15} AndesVL-1B-Thinking & 44.0 & \textbf{27.9} & \textbf{66.4} & 23.5 & \textbf{45.1} & 11.6 & \textbf{33.9} & \textbf{34.0} & \textbf{35.8} \\
         \hline
         SmolVLM2-0.5B~\cite{marafioti2025smolvlm} &  34.1 & 14.7*& 37.5 & 13.2*& 14.0*& 3.2*& 7.2*& 23.5*& 18.4*\\
         \rowcolor{gray!15} AndesVL-0.6B-Instruct & 40.7 & \textbf{24.9} & 51.8 & \textbf{19.2} & 18.7 & 6.4 & 16.2 & \textbf{29.8} & 26.0 \\
         \rowcolor{gray!15} AndesVL-0.6B-Thinking & \textbf{43.3} & 24.3 & \textbf{54.9} & \textbf{19.2} & \textbf{34.0} & \textbf{7.0} & \textbf{22.8} & 29.3 & \textbf{29.4} \\
         \hline
    \end{tabular}}
    \caption{Comparison of reasoning and mathematical performance. The best results are marked in \textbf{bold}. Data marked with * are from our evaluation, while others are from their original papers or the OpenCompass leaderboard.}
    \label{tab:benchmark_math}
\end{table}

As shown in Table~\ref{tab:benchmark_math}, AndesVL-4B-Thinking achieves the highest overall score of 58.3 across various math and reasoning benchmarks among exiting models. Notably, AndesVL-4B exhibits considerable superiority over advanced models on the MathVista,  MathVerse and WeMath benchmarks. With an overall score of 45.7, the AndesVL-2B-Thinking model ranks second, performing very close to the top score of 49.9 in literature. Furthermore, the AndesVL's 1B and 0.6B Thinking models deliver dominant performance within their respective size groups, achieving top ranks not only overall but also on most individual benchmarks. 

These improvements over exiting models highlight the efficacy of our training strategy. Our approach enhances the visual-text joint reasoning ability by leveraging a large corpus of refined, long Chain-of-Thought (CoT) multimodal data in pre-training and through an intricately designed reinforcement learning process in post-training.

Collectively, these findings underscore AndesVLs' comprehensive capabilities in addressing multimodal mathematical problems, as well as reasoning challenges in scientific, engineering, and real-world contexts. 
