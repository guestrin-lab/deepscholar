\subsubsection{Evaluation Results}

\begin{table}
    \centering
    \resizebox{1\textwidth}{!}{
    \begin{tabular}{l|cccccc|c}
        \hline
         Model & Text-rich & \makecell{Reasoning\\\&Math} & Multi-image & \makecell{General\\VQA}  & Hallucination & Multilingual & Overall\\
         \hline
         Phi-3.5-Vision~\cite{abdin2024phi3}  & 65.8& 24.0& 36.8& 55.4& 63.9& 47.0& 48.8\\
         Phi-4-Multimodal~\cite{abouelenin2025phi}  & 81.2& 33.2& 42.4& 64.2& 66.0& 54.3& 56.9\\
         Gemma3-4B~\cite{gemmateam2025gemma3}  & 61.0& 28.9& 38.1& 57.8& 62.1& 52.4& 50.0\\
         Qwen2.5-VL-3B~\cite{bai2025qwen2_5} & 82.1& 32.1& 44.8& 62.2& 66.9& 58.9& 57.8\\
         Ovis2-4B~\cite{lu2024ovis}  & 85.1& 34.1& 45.6& 71.3& 73.2&63.4&62.1\\
         MiniCPM-V-4-4B~\cite{yao2024minicpm} & 82.4& 33.8& 59.1& 70.9& 69.3& 55.4&61.8\\
         R-4B-RL~\cite{jiang2025r} & - & 57.1 & - & -& -&- &-\\
         InternVL3.5-4B~\cite{wang2025internvl3} & 82.6& 56.9& 62.3& 72.8& 69.6& 62.1& 67.7\\
        \rowcolor{gray!15} AndesVL-4B-Instruct & 85.3& 42.1& 64.5& 72.7& 73.0& 64.6& 67.0\\
        \rowcolor{gray!15} AndesVL-4B-Thinking & \textbf{86.0}& \textbf{58.3}& \textbf{67.8}& \textbf{73.8}& \textbf{74.8}& \textbf{64.9}& \textbf{70.9}\\
         \hline
         Qwen2-VL-2B~\cite{wang2024qwen2vl}  & 75.8& 23.1& 49.7& 60.5& 66.1& 52.8& 54.7\\
         MiniCPM-V-2-2B~\cite{yao2024minicpm}  & 60.5& 20.8& 50.5&  53.5& 63.6& 40.2& 48.2\\
         SAIL-VL-1.5-2B~\cite{dong2025scalable}  & 82.1& 29.5& 55.6& 68.4& 70.5& 57.3& 60.6\\
         Ovis2-2B~\cite{lu2024ovis}  & 81.8& 29.5& 59.7& 67.2& 70.3& 58.0& 61.1\\
         InternVL3-2B~\cite{zhu2025internvl3} & 78.3& 31.6& 54.3& \textbf{69.4}& 67.9& 57.4& 59.8\\
         InternVL3.5-2B~\cite{wang2025internvl3} & 79.6& \textbf{49.9}& 56.6& 68.3& 70.5& 58.0& 63.8\\
         \rowcolor{gray!15} AndesVL-2B-Instruct & \textbf{82.4}& 33.8& 56.5& 66.1& 70.9& \textbf{60.3}& 61.7\\
         \rowcolor{gray!15} AndesVL-2B-Thinking & 81.3& 45.7& \textbf{59.8}& 68.3& \textbf{71.8}& 59.4& \textbf{64.4}\\
         \hline
         Ovis2-1B~\cite{lu2024ovis}  & 77.3& 24.3& 53.0& 59.5& 65.4& 52.4& 55.3\\
         InternVL3-1B~\cite{zhu2025internvl3}  & 71.2& 23.8& 47.8& 61.2& 65.4& 47.9& 52.9\\
         InternVL3.5-1B~\cite{wang2025internvl3}  & 73.5& 32.8& 52.2& 59.9& 65.4& 49.1& 55.5\\
         \rowcolor{gray!15} AndesVL-1B-Instruct  & 76.7& 27.4& 52.1& 60.7& 67.0&  53.3& 56.2\\
         \rowcolor{gray!15} AndesVL-1B-Thinking  & \textbf{77.4}& \textbf{35.8}& \textbf{54.3}&\textbf{ 63.4}& \textbf{67.4}& \textbf{54.1}& \textbf{58.8}\\
         \hline
         SmolVLM2-0.5B~\cite{marafioti2025smolvlm}  &55.5& 18.4& 42.0& 43.6& 54.4& 26.1& 40.0\\
         \rowcolor{gray!15} AndesVL-0.6B-Instruct & \textbf{73.5}  & 26.0 & 51.5 & 55.3  &  65.7 & \textbf{51.0} & 53.8\\
        \rowcolor{gray!15}  AndesVL-0.6B-Thinking & 73.3& \textbf{29.4}& \textbf{53.1}& \textbf{57.1}&  \textbf{65.9}& 49.7& \textbf{54.7}\\
         \hline
    \end{tabular}}
    \caption{The overall comparison of AndesVL with existing MLLMs on 32 benchmarks, which are grouped into 6 domains. The best results are marked in \textbf{bold}.}
    \label{tab:benchmark_all}
\end{table}

Table~\ref{tab:benchmark_all} summarizes the overall performance of various existing MLLMs across 32 benchmarks spanning six different categories: Text-rich, Reasoning \& Math, Multi-image, General VQA, Hallucination, and Multilingual. We compute the average scores, drawn from the models' original papers or the OpenCompass leaderboard~\cite{opencompass2023}, to represent their capabilities across specific domains and overall.

Our proposed AndesVL series substantially outperform existing models of similar sizes on multiple test sets, across all evaluated scales. These statistics highlight the effectiveness of our advanced training strategies and the quality of the training corpus utilized.

Specifically, across 32 benchmarks, the AndesVL-4B-Thinking model achieves an overall score of 70.9, outperforming the second-best model, InternVL3.5-4B~\cite{wang2025internvl3}, by a margin of 3.2 points. Across every multimodal task category, the AndesVL-4B-Thinking model secures a significant margin of 0.9 to 5.5 points, underscoring its universal superiority in diverse multimodal scenarios. AndesVL-4B-instruct also demonstrates remarkably strong performance across multiple vertical domains, especially on multilingual and multi-image tasks. 

At the 2B scale, the AndesVL-2B-Thinking model achieves the highest overall score of 64.4. It exhibits a clear advantage in multi-image understanding and hallucination mitigation over existing models, even surpassing some 4B-scale models. 

For even more compact and lightweight models, our proposed 1B and 0.6B models command a decisive advantage across all metrics, with their Thinking and Instruct versions occupying the top spots and suppressing other leading models in the literature. Notably, our 0.6B variants, the AndesVL-0.6B series, achieve a performance even comparable to existing 1B models, such as InternVL3.5-1B. 

Above results underscore the model's proficiency in addressing a wide range of real-world tasks that require multimodal perception, understanding, knowledge, and reasoning. Moreover, the diversity in our models' sizes, combined with their strong performance, enables them suitable for deployment in a wide range of mobile scenarios, including those with highly limited computing resources.
