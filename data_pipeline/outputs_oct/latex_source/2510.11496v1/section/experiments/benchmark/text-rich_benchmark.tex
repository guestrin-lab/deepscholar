\subsection{Text-rich Image Understanding}
\label{sec:exp_text-rich}
\subsubsection{Benchmarks}
In order to evaluate the OCR, chart, and document understanding capabilities of AndesVL, we perform assessments over a variety of text-rich datasets, including the following seven benchmarks. 

\textbf{AI2D}~\cite{kembhavi2016ai2d}: AI2D consists of visual questions based on elementary school science diagrams. The results of its test set with and without mask settings are reported.

\textbf{OCRBench}~\cite{liu2023ocrbench}: OCRBench evaluates the overall OCR capabilities of MLLMs across five tasks: text recognition, scene text VQA, document VQA, key information extraction, and handwritten math expression recognition.

\textbf{ChartQA}~\cite{masry2022chartqa}: ChartQA requires a model to comprehend charts and graphs visually. The average relaxed accuracy across both human and augmented test sets in ChartQA is taken as the evaluation metric.

\textbf{TextVQA}~\cite{singh2019textvqa}: TextVQA evaluates a model's capability on visual reasoning with visual context from texts within images. The accuracy in the validation set is reported.

\textbf{DocVQA}~\cite{mathew2021docvqa}: DocVQA requires a model to read, comprehend, and retrieve texts within document images to answer related questions. Performance is reported on the test set using the ANLS text similarity metric.

\textbf{InfoVQA}~\cite{mathew2022infographicvqa}: InfoVQA consists of various complex infographics that combine text, graphics, and visual elements in creative layouts. The ANLS similarity score computed on the test set is reported. 

\textbf{SEEDBench-2-Plus}~\cite{li2024seedbench2plus}: SEEDBench-2-Plus evaluates a model's multimodal capability on text-rich visual tasks across charts, maps, and webs. The average accuracy on this dataset is reported.

%\textbf{ChineseOCRBench}~\cite{chinese-ocr}: Focusing on the model's text comprehension capability in only the Chinese language, this set retrieves two Chinese subsets from the OCRBench set. The average score of two sets is reported. 