\begin{table*}[t!]
\centering
\renewcommand{\arraystretch}{0.95}
{\fontsize{7.5}{10}\selectfont 
\setlength\tabcolsep{1.5pt}
\newcommand{\MME}{\makecell{MME\\(sum)}}
\newcommand{\MMB}{\makecell{MMB\\(EN / CN)}}
\newcommand{\MMBV}{\makecell{MMBv1.1\\(EN)}}
\newcommand{\MMVet}{\makecell{MMVet\\(turbo)}}
\newcommand{\MMVetV}{\makecell{MMVetv2\\(0613)}}
\newcommand{\MMStar}{\makecell{MMStar}}
\newcommand{\POPE}{\makecell{POPE\\(avg)}}
\newcommand{\HallB}{\makecell{HallBench\\(avg)}}
\newcommand{\AMBER}{\makecell{AMBER\\(generative / discriminative / overall)}}
\newcommand{\ObjectHalBench}{\makecell{ObjectHal}}
\newcommand{\MMHal}{\makecell{MMHal\\(score)}}
\newcommand{\CRPE}{\makecell{CRPE\\(relation)}}
\begin{tabular}{l|ccccccc|ccccc}
Model Name                                & \MME   & \MMB        & \MMBV & \MMVet & \MMVetV & \MMStar & Overall & \HallB & \MMHal & \CRPE & \POPE & Overall \\
\hline
LLaVA-OneVision-0.5B~\cite{li2024llavaov} & 1438.0 & 61.6 / 55.5 & 59.6  & 32.2   & --      & 37.7    & --      & 27.9   & --     & --    & --    & --      \\
InternVL2-1B~\cite{chen2024far}           & 1794.4 & 65.4 / 60.7 & 61.6  & 32.7   & 36.1    & 45.7    & 51.7    & 34.0   & 2.25   & 57.5  & 87.3  & 45.3    \\
InternVL2.5-1B~\cite{chen2024expanding}   & 1950.5 & 70.7 / 66.3 & 68.4  & 48.8   & 43.2    & 50.1    & 58.9    & 39.0   & 2.49   & 60.9  & 89.9  & 48.1    \\
\rowcolor{gray!15}
InternVL3-1B                              & 1934.4 & 72.6 / 67.9 & 69.9  & 59.5   &  47.5   & 51.5    & 61.9    & 41.4   & 2.59   & 64.0  & 90.7  & 49.7    \\
Qwen2-VL-2B~\cite{wang2024qwen2vl}        & 1872.0 & 74.9 / 73.5 & 72.2  & 49.5   & --      & 48.0    & --      & 41.7   & --     & --    & --    & --      \\
Qwen2.5-VL-3B~\cite{bai2025qwen2}         &   2157 & 79.1 / 78.1 & 77.4  &  61.8  & --      & 55.9    & --      & 46.3   & --     & 73.6  & --    & --      \\
InternVL2-2B~\cite{chen2024far}           & 1876.8 & 73.2 / 70.9 & 70.2  & 39.5   & 39.6    & 50.1    & 58.0    & 37.9   & 2.52   & 66.3  & 88.3  & 48.8    \\
InternVL2.5-2B~\cite{chen2024expanding}   & 2138.2 & 74.7 / 71.9 & 72.2  & 60.8   & 52.3    & 53.7    & 65.3    & 42.6   & 2.94   & 70.2  & 90.6  & 51.6    \\
\rowcolor{gray!15}
InternVL3-2B                              & 2221.2 & 81.1 / 78.4 & 78.6  & 62.2   & 53.9    & 60.7    & 69.8    & 42.5   & 3.26   & 71.5  & 89.6  & 51.7    \\
\hline
Qwen2-VL-7B~\cite{wang2024qwen2vl}        & 2326.8 & 83.0 / 80.5 & 80.7  & 62.0   & --      & 60.7    & --      & 50.6   & 3.40   & 74.4  & 88.1  & 54.1    \\
Qwen2.5-VL-7B~\cite{bai2025qwen2}         & 2347   & 83.5 / 83.4 & 82.6  &  67.1  & --      & 63.9    & --      & 52.9   & --     & 76.4  & --    & --      \\
MiniCPM-V2.6~\cite{yao2024minicpm}        & 2348.4 & 81.5 / 79.3 & 78.0  & 60.0   & --      & 57.5    & --      & 48.1   & 3.60   & 75.2  & 87.3  & 53.6    \\
InternVL2-8B~\cite{chen2024far}           & 2210.3 & 81.7 / 81.2 & 79.5  & 54.2   & 52.3    & 62.0    & 69.2    & 45.2   & 3.33   & 75.8  & 86.9  & 52.8    \\
InternVL2.5-8B~\cite{chen2024expanding}   & 2344.1 & 84.6 / 82.6 & 83.2  & 62.8   & 58.1    & 62.8    & 73.2    & 50.1   & 3.65   & 78.4  & 90.6  & 55.7    \\
\rowcolor{gray!15}
InternVL3-8B                              & 2415.4 & 83.4 / 82.2 & 81.7  & 81.3   & 66.3    & 68.2    & 77.7    & 49.9   & 3.61   & 76.3  & 91.1  & 55.2    \\
\rowcolor{gray!15}
InternVL3-9B                              & 2372.8 & 83.4 / 82.2 & 81.7  & 76.2   & 65.4    & 66.3    & 76.3    & 51.2   & 3.47   & 75.0  & 90.4  & 55.0    \\
\rowcolor{gray!15}
InternVL3-14B                             & 2478.3 & 85.6 / 84.1 & 83.5  & 80.2   & 68.4    & 68.8    & 79.0    & 55.1   & 3.49   & 77.3  & 90.2  & 56.5    \\
\hline
InternVL-Chat-V1.5~\cite{chen2024far}     & 2194.2 & 82.2 / 82.0 & 80.3  & 61.5   & 51.5    & 57.3    & 69.7    & 50.3   & 3.11   & 75.4  & 88.4  & 54.3    \\
InternVL2-26B~\cite{chen2024far}          & 2260.7 & 83.4 / 82.0 & 81.5  & 62.1   & 57.2    & 61.2    & 71.8    & 50.7   & 3.55   & 75.6  & 88.0  & 54.5    \\
InternVL2.5-26B~\cite{chen2024expanding}  & 2373.3 & 85.4 / 85.5 & 84.2  & 65.0   & 60.8    & 66.5    & 75.2    & 55.0   & 3.70   & 79.1  & 90.6  & 57.1    \\
Cambrian-34B~\cite{tong2024cambrian}      & --     & 80.4 / 79.2 & 78.3  & 53.2   & --      & 54.2    & --      & 41.6   & --     & --    & --    & --      \\
InternVL2-40B~\cite{chen2024far}          & 2307.5 & 86.8 / 86.5 & 85.1  & 65.5   & 63.8    & 65.4    & 75.7    & 56.9   & 3.75   & 77.6  & 88.4  & 56.7    \\
InternVL2.5-38B~\cite{chen2024expanding}  & 2455.8 & 86.5 / 86.3 & 85.5  & 68.8   & 62.1    & 67.9    & 77.0    & 56.8   & 3.71   & 78.3  & 90.7  & 57.4    \\
\rowcolor{gray!15}
InternVL3-38B                             & 2523.6 & 87.6 / 86.8 & 86.9 & 83.9   & 69.6    & 71.5    & 81.5    & 57.1   & 3.77   & 77.1  & 90.6  & 57.1    \\
\hline
GPT-4V~\cite{gpt4v}                       & 1926.6 & 81.0 / 80.2 & 80.0  & 67.5   & 66.3    & 56.0    & 70.7    & 46.5   & --     & --    & --    & --      \\
GPT-4o-20240513~\cite{gpt4v}              & --     & 83.4 / 82.1 & 83.1  & 69.1   & 71.0    & 64.7    & --      & 55.0   & 4.00   & 76.6  & 86.9  & 55.6    \\
Claude-3-Opus~\cite{claude3series2024}    & 1586.8 & 63.3 / 59.2 & 60.1  & 51.7   & 55.8    & 45.7    & 55.5    & 37.8   & --     & --    & --    & --      \\
Claude-3.5-Sonnet~\cite{claude3series2024}& --     & 82.6 / 83.5 & 80.9  & 70.1   & 71.8    & 65.1    & --      & 55.5   & --     & --    & --    & --      \\
Gemini-1.5-Pro~\cite{reid2024gemini1_5}   & --     & 73.9 / 73.8 & 74.6  & 64.0   & 66.9    & 59.1    & --      & 45.6   & --     & --    & --    & --      \\
LLaVA-OneVision-72B~\cite{li2024llavaov}  & 2261.0 & 85.8 / 85.3 & 85.0  & 60.6   & --      & 65.8    & --      & 49.0   & --     & --    & --    & --      \\
Qwen2-VL-72B~\cite{wang2024qwen2vl}       & 2482.7 & 86.5 / 86.6 & 85.9  & 74.0   & 66.9    & 68.3    & 78.7    & 58.1   & --     & --    & --    & --      \\
Qwen2.5-VL-72B~\cite{bai2025qwen2}        & 2448.0 & 88.6 / 87.9 & 88.4  & 76.2   & --      & 70.8    & --      & 55.2   & --     & 79.2  & --    & --      \\
InternVL2-Llama3-76B~\cite{chen2024far}   & 2414.7 & 86.5 / 86.3 & 85.5  & 65.7   & 68.4    & 67.4    & 77.2    & 55.2   & 3.83   & 77.6  & 89.0  & 56.4    \\
InternVL2.5-78B~\cite{chen2024expanding}  & 2494.5 & 88.3 / 88.5 & 87.4  & 72.3   & 65.5    & 69.5    & 79.2    & 57.4   & 3.89   & 78.8  & 90.8  & 57.7    \\
\rowcolor{gray!15}
InternVL3-78B                             & 2549.8 & 89.0 / 88.7 & 87.7  & 81.3   & 70.0    & 72.5    & 82.0    & 59.1   & 3.85   & 79.2  & 90.3  & 58.1    \\
% \rowcolor{gray!15}
% InternVL2.5-Pro                           &        &             &       &        &         &         &         &        &        &       &       &         \\
\end{tabular}
}

\caption{\textbf{Comparison of comprehensive multimodal understanding and hallucination performance.}
Comprehensive multimodal benchmarks include MME~\cite{fu2023mme}, MMBench series~\cite{liu2023mmbench}, MMVet series~\cite{yu2023mmvet, yu2024mmvetv2}, and MMStar~\cite{chen2024mmstar}.
Hallucination benchmarks encompass HallusionBench~\cite{guan2023hallusionbench}, MMHal~\cite{sun2023aligning}, CRPE~\cite{wang2024allseeingv2}, and POPE~\cite{li2023pope}.
Part of the results are sourced from the benchmark papers and the OpenCompass leaderboard~\cite{opencompass2023}.
}
\label{tab:benchmark_multimodal_hallucination}
\end{table*}
