
% \begin{table*}[!t]
%     \caption{{Main results of CIBench.} Tool, Exe, Num, Text, and Vis denote the tool call rate, executable rate, numeric accuracy, text score, and visualization score respectively. {bold} denotes the best score among the same model scale. \textit{Average is the mean of Num, Text, and Vis in two modes.}}
%     \label{tab:main_results}
%     \setlength{\tabcolsep}{6pt}
%     \renewcommand{\arraystretch}{1.1}
%     \centering
%     \resizebox{\textwidth}{!}{%
%     \begin{tabular}{l|cccccc|cccccc|c}
%     \toprule
%     \multirow{2}{*}{{Model}} & \multicolumn{6}{c|}{{\textsc{English}}} & \multicolumn{6}{c|}{{\textsc{Chinese}}} & \multirow{2}{*}{AVG}} \\ 
%     % \cline{2-13}
%     % & \multicolumn{2}{c}{{\textsc{Round Overall}}}
%     \addlinespace[0.3pt]
%     & \small{Tool}} & \small{Exe}} & \small{Num}} & \small{Text}} & \small{Vis}} & \small{AVG}} & \small{Tool}} & \small{Exe}} & \small{Num}} & \small{Text}} & \small{Vis}} & \small{AVG}}  \\ \midrule %
%         % \multicolumn{8}{l}{{\textasciitilde7B}}  \\ \hline
% Llama2-7B   &   44.3   &   18.7   &   0.7   &   8.0   &   2.6   &   3.8   &   46.3   &   23.5   &   9.5   &   4.0   &   11.8   &   8.4   &   6.1   \\ 
% Yi-6B   &   84.7   &   50.0   &   10.9   &   33.0   &   36.5   &   26.8   &   88.1   &   46.8   &   9.5   &   23.9   &   29.2   &   20.9   &   23.8   \\ 
% ChatGLM3-6B   &   65.9   &   41.8   &   21.1   &   25.2   &   26.3   &   24.2   &   58.0   &   36.7   &   10.9   &   27.5   &   22.9   &   20.4   &   22.3   \\ 
% DeepSeek-7B   &   90.2   &   57.0   &   11.6   &   26.6   &   44.7   &   27.6   &   77.7   &   50.4   &   11.6   &   14.0   &   40.7   &   22.1   &   24.9   \\ 
% Vicuna-7B   &   88.5   &   50.4   &   15.7   &   35.6   &   32.6   &   28.0   &   87.2   &   55.5   &   8.8   &   26.1   &   19.5   &   18.1   &   23.0   \\ 
% Qwen-7B   &   99.8   &   72.5   &   21.1   &   65.9   &   45.5   &   44.2   &   94.5   &   57.4   &   15.7   &   23.1   &   30.9   &   23.2   &   33.7   \\ 
% Qwen1.5-7B   &   98.7   &   71.2   &   25.2   &   88.1   &   41.8   &   51.7   &   98.3   &   65.7   &   15.7   &   60.1   &   37.0   &   37.6   &   44.6   \\ 
% Mistral-7B   &   99.4   &   69.3   &   31.3   &   78.7   &   48.1   &   52.7   &   98.5   &   71.0   &   19.7   &   54.2   &   42.8   &   38.9   &   45.8   \\ 
% InternLM2-7B-SFT   &   99.2   &   73.4   &   36.0   &   62.5   &   44.8   &   47.8   &   99.6   &   67.0   &   20.4   &   30.9   &   49.3   &   33.5   &   40.7   \\ 
% InternLM2-7B   &   99.2   &   68.7   &   37.4   &   53.7   &   51.8   &   47.6   &   100.0   &   67.8   &   29.2   &   48.4   &   53.2   &   43.6   &   45.6   \\ \midrule 
% Llama2-13B   &   96.4   &   65.0   &   13.6   &   23.7   &   25.5   &   20.9   &   96.4   &   73.6   &   10.9   &   27.9   &   18.2   &   19.0   &   20.0   \\ 
% Vicuna-13B   &   88.9   &   62.9   &   12.2   &   74.2   &   40.1   &   42.2   &   92.5   &   65.5   &   15.0   &   52.9   &   45.9   &   37.9   &   40.0   \\ 
% Qwen-14B   &   90.2   &   70.4   &   33.3   &   65.7   &   54.7   &   51.2   &   93.6   &   71.4   &   34.0   &   52.3   &   54.3   &   46.9   &   49.1   \\ 
% Qwen1.5-14B   &   99.8   &   86.2   &   42.9   &   85.0   &   59.6   &   62.5   &   99.8   &   89.3   &   31.3   &   72.7   &   56.4   &   53.4   &   58.0   \\ 
% Mistral-8x7B   &   99.6   &   85.1   &   25.2   &   79.7   &   51.6   &   52.2   &   99.6   &   84.5   &   19.7   &   74.2   &   55.5   &   49.8   &   51.0   \\ 
% InternLM2-20B-SFT   &   99.2   &   85.9   &   38.1   &   75.5   &   52.7   &   55.4   &   99.4   &   82.3   &   29.9   &   63.1   &   55.7   &   49.6   &   52.5   \\ 
% InternLM2-20B   &   98.5   &   84.7   &   42.9   &   80.8   &   54.9   &   59.5   &   100.0   &   87.8   &   27.2   &   44.9   &   58.5   &   43.5   &   51.5   \\ \bottomrule 
% % Yi-34B   &   81.7   &   56.1   &   30.6   &   36.2   &   47.4   &   38.1   &   89.3   &   60.0   &   22.4   &   36.9   &   43.2   &   34.2   &   36.1   \\ 
% % Llama2-70B   &   99.1   &   66.8   &   18.4   &   37.0   &   34.2   &   29.9   &   98.7   &   67.0   &   15.0   &   37.3   &   31.2   &   27.8   &   28.8   \\ 
% % DeepSeek-67B   &   99.8   &   85.5   &   39.5   &   78.5   &   66.2   &   61.4   &   99.4   &   81.0   &   37.4   &   80.6   &   61.8   &   59.9   &   60.7   \\ 
% % Qwen-72B   &   99.4   &   85.3   &   45.6   &   77.5   &   65.8   &   63.0   &   91.4   &   73.1   &   30.6   &   27.9   &   45.2   &   34.6   &   48.8   \\ \midrule 
% % GPT-4-0613   &   99.6   &   98.3   &   50.3   &   85.0   &   75.0   &   70.1   &   98.1   &   95.5   &   45.6   &   81.4   &   74.7   &   67.2   &   68.7   \\  \bottomrule
%         % \multicolumn{8}{l}{{API}}  \\ \hline
%         % GPT-4-Turbo & 71.5  & 82.6  & 50.8  & 73.1  & 81.3  & 61.7  & 70.2  \\ 
%         % ChatGLM\_Pro & 99.1  & 72.8  & 42.3  & 45.1  & 42.6 & 100.0  & 58.8   & 45.7  & 62.4  & 39.0  & 46.2  \\ 
%         % Baichuan2\_Turbo & 88.1  & 68.6  & 39.9  & 51.7  & 38.8 & 100.0  & 61.0   & 51.5  & 70.8  & 36.4  & 48.2  \\ 
%         % % Claude-2 & 99.7  & 32.9  & 37.8  & 41.1  & 26.7 & 42.3  & 45.1   & 61.0  & {78.1}  & 59.7  & 50.7  \\ 
%         % Qwen-Max & 99.6  & 87.3  & 55.5  & 67.8  & 50.5  & 99.5  & 85.7  & {72.2}  & 71.5  & 58.9  & 62.7  \\ 
%         % GPT4-Turbo & 99.8  & 97.9  & 76.0  & 78.9  & 64.0 & 99.6  & 92.5  & 70.8  & 76.5  & 67.4  & 72.3  \\ \bottomrule
%         % GPT-4-0613 & 99.7  & 98.4  & 66.8  & 75.7  & 65.5 & 99.8  & 97.8  & 70.7  & 84.2  & 73.6  & 72.8  \\ \bottomrule
% \end{tabular}
% }
% \vspace{-1em}
% \end{table*}



\begin{table*}[!t]
    \setlength{\tabcolsep}{6pt}
    \renewcommand{\arraystretch}{1.1}
    \centering
    \resizebox{0.8\textwidth}{!}{%
    \begin{tabular}{l|c|ccc|ccc}
\multirow{2}{*}{model name} & \multirow{2}{*}{\#param}  & \multicolumn{3}{c|}{{T-Eval}} & \multicolumn{3}{c}{{CIBench}}\\ 
& & \small{English} & \small{Chinese} & \small{avg.} &  \small{English} & \small{Chinese} & \small{avg.}\\ 
\hline
% \multicolumn{7}{c}{\greencolor{\textit{ $\leq 7$B Models}}} \\ 
Llama2-7B-Chat   & 7B &   37.5 & 37.0 & 37.2 &   12.2   &   10.6   &   11.4   \\ 
Llama2-13B-Chat   & 13B &  48.7 & 44.9 & 46.8 &   20.0   &   12.3   &   16.1     \\ 

% Yi-6B   &   000 & 000 & 000 &   26.8   &   20.9   &   23.8   \\ 
% DeepSeek-7B   &   000 & 000 & 000 &   27.6   &   22.1   &   24.9   \\ 
% Vicuna-7B   &   000 & 000 & 000 &   28.0   &   18.1   &   23.0   \\
% Vicuna-13B   &   000 & 000 & 000 &   42.2   &   37.9   &   40.0   \\ 

% Baichuan2-7B-Chat &   58.5 & 53.7 &  &   28.0   &   18.1   &   23.0   \\
Qwen-7B-Chat   & 7B &  57.5 & 61.1 & 59.3 &   47.8   &   29.2   &   38.5     \\ 
Qwen-14B-Chat   & 14B &  63.6 & {{68.7}} & {{66.2}}  &   54.8   &   40.8   &   47.8   \\ 

Qwen1.5-7B-Chat   & 7B &  54.5 & 50.4 & 52.5 &   44.7   &   26.9   &   35.8   \\ 
Qwen1.5-14B-Chat   & 14B &  67.6 & 63.3 & 65.4 &   57.9   &   49.7   &   53.8   \\ 

Mistral-7B-Instruct-v0.2   & 7.3B &  39.3 & 38.7 & 39.0 &   47.6   &   38.0   &   42.8   \\ 
Mistral-8x7B-Instruct-v0.1   & 46.7B & 58.6 & 58.0 & 58.3 &   42.6   &   40.3   &   41.5   \\ 

ChatGLM3-6B   & 6.2B &  62.3 & 63.6 & 63.0 &   29.4   &   17.1   &   23.2   \\ 
\hline

% \multicolumn{7}{c}{\bluecolor{\textit{ $13 \sim 20$B Models}}} \\ 
\rowcolor{gray!15}
InternLM2-Chat-7B-SFT   & 7B &  64.1 & {66.8} & 65.5 &   52.1   &   27.8   &   39.9 \\ 
\rowcolor{gray!15}
InternLM2-Chat-7B   & 7B &  {{66.1}} & 65.4 & {65.8}  &   {{57.1}}   &   {{40.7}}   &   {{48.9}}     \\ 
\rowcolor{gray!15}
InternLM2-Chat-20B-SFT   & 20B &  64.7 & 64.1 & 64.4 &   49.0   &   43.7   &   46.4   \\ 
\rowcolor{gray!15}
InternLM2-Chat-20B   &  20B & {65.6} &  62.9 & 64.3 &   {{56.0}}   &   {{54.7}}   &   {{55.4}}   \\ 
% Yi-34B   &   81.7   &   56.1   &   30.6   &   36.2   &   47.4   &   38.1   &   89.3   &   60.0   &   22.4   &   36.9   &   43.2   &   34.2   &   36.1   \\ 
% Llama2-70B   &   99.1   &   66.8   &   18.4   &   37.0   &   34.2   &   29.9   &   98.7   &   67.0   &   15.0   &   37.3   &   31.2   &   27.8   &   28.8   \\ 
% DeepSeek-67B   &   99.8   &   85.5   &   39.5   &   78.5   &   66.2   &   61.4   &   99.4   &   81.0   &   37.4   &   80.6   &   61.8   &   59.9   &   60.7   \\ 
% Qwen-72B   &   99.4   &   85.3   &   45.6   &   77.5   &   65.8   &   63.0   &   91.4   &   73.1   &   30.6   &   27.9   &   45.2   &   34.6   &   48.8   \\ \midrule 
% GPT-4-0613   &   99.6   &   98.3   &   50.3   &   85.0   &   75.0   &   70.1   &   98.1   &   95.5   &   45.6   &   81.4   &   74.7   &   67.2   &   68.7   \\  \bottomrule
        % \multicolumn{8}{l}{{API}}  \\ \hline
        % GPT-4-Turbo & 71.5  & 82.6  & 50.8  & 73.1  & 81.3  & 61.7  & 70.2  \\ 
        % ChatGLM\_Pro & 99.1  & 72.8  & 42.3  & 45.1  & 42.6 & 100.0  & 58.8   & 45.7  & 62.4  & 39.0  & 46.2  \\ 
        % Baichuan2\_Turbo & 88.1  & 68.6  & 39.9  & 51.7  & 38.8 & 100.0  & 61.0   & 51.5  & 70.8  & 36.4  & 48.2  \\ 
        % % Claude-2 & 99.7  & 32.9  & 37.8  & 41.1  & 26.7 & 42.3  & 45.1   & 61.0  & {78.1}  & 59.7  & 50.7  \\ 
        % Qwen-Max & 99.6  & 87.3  & 55.5  & 67.8  & 50.5  & 99.5  & 85.7  & {72.2}  & 71.5  & 58.9  & 62.7  \\ 
        % GPT4-Turbo & 99.8  & 97.9  & 76.0  & 78.9  & 64.0 & 99.6  & 92.5  & 70.8  & 76.5  & 67.4  & 72.3  \\ \bottomrule
        % GPT-4-0613 & 99.7  & 98.4  & 66.8  & 75.7  & 65.5 & 99.8  & 97.8  & 70.7  & 84.2  & 73.6  & 72.8  \\ \bottomrule
\end{tabular}
}
\caption{\textbf{Results on T-Eval and CIBench.}}
\label{tab:cibench_teval}
\end{table*}