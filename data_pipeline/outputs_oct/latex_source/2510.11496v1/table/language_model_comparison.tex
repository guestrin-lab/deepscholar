\begin{table*}[!t]
\centering
\small
\renewcommand{\arraystretch}{0.95}
\setlength\tabcolsep{5pt}
{\fontsize{8}{10}\selectfont 
% \renewcommand{\arraystretch}{0.9}

\newcommand{\QwenOne}{\rotatebox{90}{\makecell{Qwen2.5-0.5B Chat}}}
\newcommand{\QwenTwo}{\rotatebox{90}{\makecell{Qwen2.5-1.5B Chat}}}
\newcommand{\QwenThree}{\rotatebox{90}{\makecell{Qwen2.5-7B Chat}}}
\newcommand{\QwenFour}{\rotatebox{90}{\makecell{Qwen2.5-14B Chat}}}
\newcommand{\QwenFive}{\rotatebox{90}{\makecell{Qwen2.5-32B Chat}}}
\newcommand{\QwenSix}{\rotatebox{90}{\makecell{Qwen2.5-72B Chat}}}

\newcommand{\InternVLThreeOne}{\rotatebox{90}{\makecell{InternVL3-1B}}}
\newcommand{\InternVLThreeTwo}{\rotatebox{90}{\makecell{InternVL3-2B}}}
\newcommand{\InternVLThreeThree}{\rotatebox{90}{\makecell{InternVL3-8B}}}
\newcommand{\InternVLThreeFour}{\rotatebox{90}{\makecell{InternVL3-9B}}}
\newcommand{\InternVLThreeFive}{\rotatebox{90}{\makecell{InternVL3-14B}}}
\newcommand{\InternVLThreeSix}{\rotatebox{90}{\makecell{InternVL3-38B}}}
\newcommand{\InternVLThreeSeven}{\rotatebox{90}{\makecell{InternVL3-78B}}}

% \begin{tabular}{l|rr|rr|rr|rr|rr|rr}
% Dataset                                                                & \QwenOne & \InternVLThreeOne & \QwenTwo & \InternVLThreeTwo & \QwenThree & \InternVLThreeThree & \QwenFour & \InternVLThreeFive & \QwenFive & \InternVLThreeSix & \QwenSix & \InternVLThreeSeven \\
% \midrule
% \begin{tabular}[c]{@{}l@{}}MMLU\\ 4d595a\end{tabular}             & 46.4         & 49.8         & 61.8         & 64.8         & 74.2       & 77.3         & 79.5        & 82.1          & 83.3        & 85.4          & 84.4        & 86.9          \\
% \begin{tabular}[c]{@{}l@{}}CMMLU\\ c13365\end{tabular}            & 47.2         & 56.7         & 62.9         & 72.2         & 78.8       & 84.4         & 82.6        & 85.8          & 85.8        & 88.7          & 87.4        & 89.9          \\
% \begin{tabular}[c]{@{}l@{}}C-Eval\\ 2daf24\end{tabular}           & 53.5         & 59.0         & 66.2         & 73.3         & 77.8       & 84.5         & 81.4        & 85.6          & 86.5        & 89.2          & 88.1        & 89.5          \\
% \begin{tabular}[c]{@{}l@{}}GAOKAO\\ 4c31db\end{tabular}           & 30.9         & 46.6         & 53.7         & 67.7         & 81.3       & 89.5         & 86.9        & 91.2          & 90.8        & 93.5          & 91.0        & 93.1          \\
% \midrule
% \begin{tabular}[c]{@{}l@{}}TriviaQA\\ 2121ce\end{tabular}         & 24.2         & 21.5         & 39.8         & 41.2         & 55.8       & 51.5         & 65.1        & 67.4          & 65.8        & 70.1          & 74.0        & 74.7          \\
% \begin{tabular}[c]{@{}l@{}}NaturalQuestions\\ 3dcea1\end{tabular} & 8.2          & 8.5          & 15.2         & 15.9         & 17.9       & 28.2         & 19.7        & 31.4          & 19.7        & 31.0          & 23.8        & 39.0          \\
% \begin{tabular}[c]{@{}l@{}}C3\\ 8c358f\end{tabular}               & 35.2         & 66.3         & 81.2         & 84.7         & 90.8       & 95.1         & 92.1        & 96.3          & 92.3        & 97.4          & 96.1        & 97.6          \\
% \begin{tabular}[c]{@{}l@{}}RACE-High\\ 69ee4f\end{tabular}        & 51.5         & 68.8         & 76.0         & 84.6         & 86.8       & 90.8         & 89.6        & 93.0          & 91.5        & 94.2          & 91.7        & 94.2          \\
% \midrule
% \begin{tabular}[c]{@{}l@{}}WinoGrande\\ b36770\end{tabular}       & 47.2         & 52.9         & 56.5         & 61.9         & 71.5       & 78.1         & 79.1        & 84.3          & 83.8        & 86.7          & 83.9        & 87.8          \\
% \begin{tabular}[c]{@{}l@{}}HellaSwag\\ e42710\end{tabular}        & 39.3         & 47.0         & 62.0         & 73.8         & 85.4       & 90.2         & 90.5        & 93.0          & 92.1        & 95.5          & 92.7        & 95.6          \\
% \begin{tabular}[c]{@{}l@{}}BBH\\ 5b92b0\end{tabular}              & 21.5         & 34.5         & 39.7         & 52.0         & 65.7       & 77.4         & 73.0        & 82.5          & 85.5        & 87.7          & 85.4        & 85.2          \\
% \midrule
% \begin{tabular}[c]{@{}l@{}}GSM8K\\ 1d7fe4\end{tabular}            & 39.0         & 47.2         & 61.6         & 72.5         & 80.1       & 83.1         & 82.4        & 88.4          & 84.7        & 89.7          & 88.2        & 90.5          \\
% \begin{tabular}[c]{@{}l@{}}MATH\\ 393424\end{tabular}             & 27.8         & 32.7         & 49.3         & 57.3         & 72.6       & 72.2         & 73.7        & 76.3          & 81.1        & 65.1          & 81.4        & 78.9          \\
% \begin{tabular}[c]{@{}l@{}}TheoremQA\\ 6f0af8\end{tabular}        & 12.3         & 12.9         & 14.4         & 15.6         & 20.1       & 25.5         & 18.5        & 24.1          & 21.9        & 18.9          & 22.9        & 30.4          \\
% \midrule
% \begin{tabular}[c]{@{}l@{}}HumanEval\\ 8e312c\end{tabular}        & 27.4         & 39.0         & 51.8         & 62.8         & 82.3       & 78.1         & 81.1        & 78.1          & 89.0        & 87.8          & 87.2        & 82.3          \\
% \begin{tabular}[c]{@{}l@{}}MBPP\\ a447ff\end{tabular}             & 38.5         & 47.5         & 51.4         & 60.7         & 74.3       & 69.3         & 76.7        & 75.1          & 83.7        & 77.4          & 86.8        & 76.7          \\
% \begin{tabular}[c]{@{}l@{}}MBPP-CN\\ 9114d5\end{tabular}          & 19.6         & 30.6         & 34.4         & 45.8         & 64.4       & 64.4         & 75.4        & 67.2          & 77.8        & 75.4          & 76.0        & 76.0          \\
% \midrule
% Avg.                                                                   & 33.5         & 42.4         & 51.6         & 59.2         & 69.4       & 72.9         & 73.4        & 76.6          & 77.4        & 78.4          & 78.9        & 80.5         
% \end{tabular}

\begin{tabular}{ll|rr|rr|rr|rr|rr|rr}
% Dataset          & Split       & Qwen2.5-0.5B & InternVL3-1B & Qwen2.5-1.5B & InternVL3-2B & Qwen2.5-7B & InternVL3-8B & Qwen2.5-14B & InternVL3-14B & Qwen2.5-32B & InternVL3-38B & Qwen2.5-72B & InternVL3-78B \\
Dataset                         &  Version                                       & \QwenOne & \InternVLThreeOne & \QwenTwo & \InternVLThreeTwo & \QwenThree & \InternVLThreeThree & \QwenFour & \InternVLThreeFive & \QwenFive & \InternVLThreeSix & \QwenSix & \InternVLThreeSeven \\
\midrule
MMLU             & 4d595a & 46.4         & 49.8         & 61.8         & 64.8         & 74.2       & 77.3         & 79.5        & 82.1          & 83.3        & 85.4          & 84.4        & 86.9          \\
CMMLU            & c13365 & 47.2         & 56.7         & 62.9         & 72.2         & 78.8       & 84.4         & 82.6        & 85.8          & 85.8        & 88.7          & 87.4        & 89.9          \\
C-Eval           & 2daf24 & 53.5         & 59.0         & 66.2         & 73.3         & 77.8       & 84.5         & 81.4        & 85.6          & 86.5        & 89.2          & 88.1        & 89.5          \\
GAOKAO           & 4c31db & 30.9         & 46.6         & 53.7         & 67.7         & 81.3       & 89.5         & 86.9        & 91.2          & 90.8        & 93.5          & 91.0        & 93.1          \\
\midrule
TriviaQA         & 2121ce & 24.2         & 21.5         & 39.8         & 41.2         & 55.8       & 51.5         & 65.1        & 67.4          & 65.8        & 70.1          & 74.0        & 74.7          \\
NaturalQuestions & 3dcea1 & 8.2          & 8.5          & 15.2         & 15.9         & 17.9       & 28.2         & 19.7        & 31.4          & 19.7        & 31.0          & 23.8        & 39.0          \\
C3               & 8c358f & 35.2         & 66.3         & 81.2         & 84.7         & 90.8       & 95.1         & 92.1        & 96.3          & 92.3        & 97.4          & 96.1        & 97.6          \\
RACE-High        & 69ee4f & 51.5         & 68.8         & 76.0         & 84.6         & 86.8       & 90.8         & 89.6        & 93.0          & 91.5        & 94.2          & 91.7        & 94.2          \\
\midrule
WinoGrande       & b36770 & 47.2         & 52.9         & 56.5         & 61.9         & 71.5       & 78.1         & 79.1        & 84.3          & 83.8        & 86.7          & 83.9        & 87.8          \\
HellaSwag        & e42710 & 39.3         & 47.0         & 62.0         & 73.8         & 85.4       & 90.2         & 90.5        & 93.0          & 92.1        & 95.5          & 92.7        & 95.6          \\
BBH              & 5b92b0 & 21.5         & 34.5         & 39.7         & 52.0         & 65.7       & 77.4         & 73.0        & 82.5          & 85.5        & 87.7          & 85.4        & 85.2          \\
\midrule
GSM8K            & 1d7fe4 & 39.0         & 47.2         & 61.6         & 72.5         & 80.1       & 83.1         & 82.4        & 88.4          & 84.7        & 89.7          & 88.2        & 90.5          \\
MATH             & 393424 & 27.8         & 32.7         & 49.3         & 57.3         & 72.6       & 72.2         & 73.7        & 76.3          & 81.1        & 72.2          & 81.4        & 78.9          \\
TheoremQA        & 6f0af8 & 12.3         & 12.9         & 14.4         & 15.6         & 20.1       & 25.5         & 18.5        & 24.1          & 21.9        & 18.9          & 22.9        & 30.4          \\
\midrule
HumanEval        & 8e312c & 27.4         & 39.0         & 51.8         & 62.8         & 82.3       & 78.1         & 81.1        & 78.1          & 89.0        & 87.8          & 87.2        & 82.3          \\
MBPP             & a447ff & 38.5         & 47.5         & 51.4         & 60.7         & 74.3       & 69.3         & 76.7        & 75.1          & 83.7        & 77.4          & 86.8        & 76.7          \\
MBPP-CN          & 9114d5 & 19.6         & 30.6         & 34.4         & 45.8         & 64.4       & 64.4         & 75.4        & 67.2          & 77.8        & 75.4          & 76.0        & 76.0          \\
\midrule
Overall             & -           & 33.5         & 42.4         & 51.6         & 59.2         & 69.4       & 72.9         & 73.4        & 76.6          & 77.4        & 78.9          & 78.9        & 80.5         
\end{tabular}
}
\caption{\textbf{Comparison of language model performance across multiple benchmarks.} These results were obtained using the OpenCompass toolkit. We compare InternVL3 with  Qwen2.5 Chat models, whose corresponding pre-trained base models are employed as the initialization of the language component in InternVL3.  Please note that the evaluation scores of the Qwen2.5 series may differ from those officially reported, as we have adopted the prompt versions provided in the table across all datasets for OpenCompass evaluation.}

\label{tab:language_model_comparison}
\end{table*}
