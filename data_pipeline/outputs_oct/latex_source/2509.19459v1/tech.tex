\section{\Tool}

This section discusses the key ideas behind our approach to
inserting flush and fence operations.

\subsection{Robustness\label{sec:discipline}}

\begin{figure}[!h]
\begin{subfigure}{0.24\textwidth}
{\scriptsize
  \begin{lstlisting}[xleftmargin=1.65cm]
    x = 1;
    y = 1;
  \end{lstlisting}
\caption{\label{fig:precrash}Pre-crash execution}
  }
\end{subfigure}
\begin{subfigure}{0.24\textwidth}
  {\scriptsize
  \begin{lstlisting}[xleftmargin=1.6cm]
    r1 = x;
    r2 = y;
  \end{lstlisting}
  }
  \caption{\label{fig:postcrash}Post-crash execution}
  \end{subfigure}
\caption{\label{fig:robustness}Assume $\code{x = y = 0}$ initially.  If the post-crash execution observes $\code{r2 = 1}$, strict persistency requires that $\code{r1 = 1}$.}
\vspace{-.3cm}
\end{figure}

Figure~\ref{fig:robustness} presents an example that illustrates the
requirements of strict persistency.  Strict persistency requires that
the persistency order for stores respects the happens-before relation.
This means that the store $\code{x = 1}$ must be persisted before the store $\code{y = 1}$, forbidding an execution in which $\code{r1 = 0}$ and $\code{r2 = 1}$.

It may initially appear that robustness would require placing flushes
after every memory access to PM.  However, robustness
only requires that the persistency order for stores respects the
happens-before relation when an execution can potentially observe a
violation of strict persistency.  For example if post-crash executions 
only read from $\code{y}$, then the program is robust even if 
$\code{y = 1}$ is made persistent while $\code{x = 1}$ is not.  This
observation is most relevant for newly created persistent objects
that have not yet become reachable from persistent
data structures.  Thus, it suffices to delay flushing stores to newly created
persistent objects until right before they are inserted into
persistent data structures.

We next present a sufficient set of requirements on flush and fence operations
to ensure robustness.  Figure~\ref{fig:discipline} presents a finite
state machine that captures how to check robustness for the x86-TSO persistency model.  We refer to a
state in this finite state machine
as an \textit{escape persistency state}.  The
finite state machine captures the set of legal transitions for cache
lines through escape persistency states.
If there is an object that is both escaped and non-clean and the program writes to an escaped object, then this is a \textit{robustness violation}.
A key insight is differentiating
between (1) memory locations that are \textit{captured} by the local
thread and thus stores to the memory location would not be visible if
the program crashed and (2) memory locations that
have \textit{escaped} to become reachable from the roots of persistent data structures, and thus stores would be visible if the program
crashed. With this distinction, captured objects do need to flushed according to the volatile order, because they cannot be read from in a post-crash execution.

\begin{figure}[!htbp]
\begin{center}
\includegraphics[scale=0.31]{figures/fsm}
\end{center}
\caption{Using Flush \& Drain Operations to Ensure Robustness\label{fig:discipline}}
\end{figure}

\noindent \textbf{Captured Objects:} Memory locations are captured
when there exists no path from the persistent data structure roots to
the memory location.  Stores to captured memory locations are not
visible after a crash, and thus it is safe to delay flushes
until immediately before the memory location escapes via insertion
into a persistent data structure.  This can have several
benefits---first, it becomes possible to use optimized flushes
like $\code{clflushopt}$ or $\code{clwb}$ on several
cache lines and amortize the cost of the fence operation across
multiple flushes.  Second, it is sufficient to handle
multiple stores to the same cache line with a single
flush.

\noindent \textbf{Escaped Objects:} Memory locations have escaped if
they are reachable from a persistent data structure.  Escaped memory
locations require a more expensive flush insertion approach.  If
consecutive stores happen to be to the same cache line, their
persistency order is enforced automatically due to cache coherence.
If they are to different cache lines, it is necessary to flush the
first store before performing the second store.

\begin{figure}[h]
\begin{subfigure}{0.24\textwidth}
{\scriptsize
\hspace{1.25cm} Thread 1:
\begin{lstlisting}[xleftmargin=1.7cm]
  x = 1;
  clflush(&x);
\end{lstlisting}  
\hspace{1.25cm} Thread 2:
\begin{lstlisting}[firstnumber=last, xleftmargin=1.7cm]
  r1 = x;
  y = r1;
\end{lstlisting}
\caption{\label{fig:rrprecrash}Pre-crash execution}
  }
\end{subfigure}
\begin{subfigure}{0.24\textwidth}
  {\scriptsize
  \begin{lstlisting}[xleftmargin=1.6cm]
    r2 = x;
    r3 = y;
  \end{lstlisting}
  }
  \caption{\label{fig:rrpostcrash}Post-crash execution}
  \end{subfigure}
\caption{\label{fig:racyreads}A non-robust program that is missing a flush on load. Assume that $\code{x = y = 0}$
initially and all accesses are atomic, it is possible that $\code{r2 = 0}$ and $\code{r3 = 1}$}
\end{figure}

Atomic loads require extra care to ensure robustness.  Consider the
example in Figure~\ref{fig:racyreads}.  If the pre-crash execution
crashes before the $\code{clflush}$ in Thread 1 completes,
but after the store to $\code{y}$ in Thread 2 has been made
persistent, it is possible for the post-crash execution to observe
$\code{r2 = 0}$ and $\code{r3 = 1}$, violating strict consistency.
Robustness in this case requires a $\code{clflush}$ to the
cache line of $\code{x}$ after Thread 2 reads from $\code{x}$.  This
example also has an implication for all stores to escaped memory
locations inside of critical sections---the store must be persisted
before the lock is released.

\subsection{Analyzing Robustness}

\begin{figure}[!h]
\begin{tabular}{c}
\begin{lstlisting}
struct Node {
  int data;
  struct Node * next;
};

struct Stack {
  struct Node * top;
};

void push(struct Stack *s, int val) { //s: <esc, clean>
  struct Node * head = s->top; /*@ \label{line:head}@*/
  struct Node * n = pmalloc(sizeof(struct Node));
  //n: <cap, <clean, clean>>
  n->data = val; /*@ \label{line:n-store1}@*/
  n->next = head; /*@ \label{line:n-store2}@*/
  //n: <cap, <dirty, dirty>>
  s->top = n; /*@ \label{line:commit-store}@*/
  //s: <esc, dirty>, n: <esc,<dirty, dirty>>
}
\end{lstlisting}
\end{tabular}
\caption{\label{fig:stack}A Persistent Stack. esc = escaped, cap = captured}
\end{figure}

We begin with an example to illustrate key concepts in our
approach to analyzing PM code.  Figure~\ref{fig:stack} presents a
single-threaded persistent stack.  The \code{push} method adds a new
value to the top of the stack.  It calls
\code{pmalloc} to allocate a new stack node, stores the value
\code{val} to the node, and updates the node's \code{next} field.
Then it flushes the new node and updates the top of the stack to
reference the new node.  Finally, it flushes the update to
the top of the stack.

In this example, the stack \code{s} and node \code{n} are persistent
variables and have one of the states in
Figure~\ref{fig:discipline}. We assume \code{s} and \code{n} are on
different cache lines.  The stack \code{s} is the root of the
persistent data structure and is escaped initially.  When the node
\code{n} is created, both of its fields have the state
$\tuple{\captured, \clean}$ initially.  Node \code{n} has the
state $\tuple{\captured, \dirty}$ for both fields after the stores at
lines~\ref{line:n-store1} and~\ref{line:n-store2}.  The commit store
at line~\ref{line:commit-store} makes \code{n} \escaped as \code{n} is
reachable from the persistent data structure root, and the state of
\code{s->top} transitions to $\tuple{\escaped, \dirty}$.  This is a
violation of robustness as both \code{n} and \code{s} are \escaped and
\dirty. Thus, we must insert a flush before
line~\ref{line:commit-store}.
 
\subsubsection{Basic Approach\label{sec:verification}}

We next discuss our approach to analyzing PM programs.  Our approach
builds on the finite state formulation for ensuring robustness from
Section~\ref{sec:discipline}.  Our analysis is structured as a
standard fixed-point dataflow analysis.  The basic idea is to use a
static analysis to compute at each program point a mapping from memory
locations to a set of potential escape persistency states.  The
transfer function implements the finite state machine from
Figure~\ref{fig:discipline}.  We apply this machine to each of the
potential escape persistency states for a given memory location to
generate a new output set of escape persistency states.

The analysis checks several correctness properties.  The first is that
the program does not take a forbidden transition that would violate
robustness such as having
multiple escaped and non-clean cache lines.  We compute summaries of
the effect of method calls by extending escape persistency states to
tracks the corresponding initial persistency states when the method
was first called.  When the analysis of the method is complete, the
static analysis has determined how the method changes each of the
possible escape persistency states.

Loads pose a challenge because they allow another thread
to observe a store before it is made persistent, and that thread may
later store a value that was derived from the value returned by the
load.  The later store can potentially be persisted before the initial
store, and thus a crash can leave the PM in an
inconsistent state.  For example, in Figure~\ref{fig:racyreads}, it is
possible for \code{y = r1} to be persisted before \code{x = 1}, and
then the post-crash execution would read \code{r2 = 0} and \code{r3 =
  1}.

This problem can be solved by inserting a flush 
immediately after every load, but this incurs an overhead.  We
consider two cases for loads:
\begin{enumerate}

\item {\bf Non-atomic Loads:} Here we assume programs are data race
  free, as they otherwise have undefined semantics in languages such
  as C/C++.  In the case of a non-atomic load, we require that
  non-atomic stores be persisted before any release operation such as
  an unlock operation.  Then there is no issue because store is
  persisted before its mutex is released and thus before it can be
  read.

\item {\bf Atomic Loads:} Atomic operations allow multiple threads to access memory
  without acquiring a lock.  As a result, we cannot assume the flush instruction after the corresponding store has completed before the atomic load.
  For atomic loads, we use
  FliT~\cite{flit} to ensure the corresponding store is flushed.  In
  the analysis, we address this issue by having atomic loads change
  the persistency state to dirty.  This forces the thread to flush the
  data before performing other visible stores.
  \end{enumerate}

\subsection{Detecting References to Persistent Memory}

\Tool uses a CFL-reachability-based alias analysis introduced by Zheng
and Rugina~\cite{cflalias} to distinguish PM locations from
non-persistent locations. First, the analysis requires a set of
user-configured PM allocators, and the pointers
returned by these allocators are identified as the initial set of PM
pointers. The aliases of known PM pointers are iteratively computed
and added to the set until a fixed point is reached. The
CFL-reachability-based formulation of the aliasing relation is precise
and enables a demand-driven algorithm, which finds all pointers that may
reach persistent memory. This helps \tool avoid analyzing
a large number of volatile memory pointers.

Our analysis is adapted from an existing
implementation from the LLVM-8 codebase~\cite{llvm-8} that computes
aliases between all pairs of pointers. We modified the analysis to
only explore aliases of PM pointers following the original
demand-driven formulation~\cite{cflalias}. We also added type-based
field-sensitivity to the analysis to track whether each offset of a
struct type is a PM pointer, and treat all objects of the same type
uniformly. This approach intentionally sacrifices some precision compared to
full field sensitivity because PM programs likely use
specialized data types for PM as we observe in the PM benchmarks.



\section{Intraprocedural Analysis\label{sec:intra}}

In this section, we first discuss the core intraprocedural analysis.
Later, in Section~\ref{sec:inter} we will extend this analysis to the
interprocedural context and to handle arrays.  The intraprocedural
part is implemented as a standard forward dataflow analysis.  The
algorithm maintains a program state at each instruction.

\subsection{Preliminaries\label{sec:prelim}}

The instructions that we analyze are atomic and non-atomic loads and stores, atomic RMWs,
assignments, and flushes and fences.  An object can occupy
multiple cache lines and thus an object reference $\aref \in \Refs$
can be used depending on the field to access one of several different
cache lines. Objects are by default not aligned to cache lines, and
thus the static analysis may not know whether two
different fields reside on the same cache line.  Thus, we model a
memory location $\mloc \in \Mlocs$ as the combination $\aloc =
\tuple{\aref, n} \in \ALoc$ of a reference (variable that references a memory location) $\aref \in \Refs$ and a
non-negative offset $n \in \mathbb{Z}^{0+}$ from that reference. 

We next describe our core analysis approach.  For each PM location,
our analysis must compute: (1) whether a reference to that memory
location may have escaped to PM, and (2) whether all
stores to the memory location have been flushed to PM.
Although the original finite state machine in
Figure~\ref{fig:discipline} combines both properties into a single
finite state machine, we separated the two properties into two finite
state machines to simplify the presentation.

Figure~\ref{fig:escfsm} presents a finite state machine that
captures whether a memory location has escaped at a given program
point, and Figure~\ref{fig:esclattice} presents a lattice for our
escape analysis.  We use an escape state $\estate \in \Estate$ to
represent one of the two escape values, $\{\captured, \escaped\}$,
from the escape analysis lattice. We use a may-escape analysis to
conservatively catch all cases where a reference might have escaped.
Thus, we have the \escaped value lower in the lattice, and a merge of
an \escaped value with a \captured value yields the \escaped
state.  The analysis computes a map $\EMap \subseteq \Refs \times
\Estate$ from memory locations to escape states at each point in the
program.  The meet operator $\sqcap: \Estate \times \Estate
\rightarrow \Estate$ is defined by $\estate_1 \sqcap \estate_2 =
\text{lower}(\estate_1, \estate_2)$, which returns the lower of the
two lattice values.  We write $\estate_1 \succeq \estate_2$ if
$\estate_1$ is higher than or equal to $\estate_2$ in the lattice.

\begin{figure}[!htbp]
\begin{subfigure}{.24\textwidth}
\vspace{-.7cm}
\begin{center}
\includegraphics[scale=0.35]{figures/escfsm}
\end{center}
\vspace{-.6cm}
\caption{Finite State Machine\label{fig:escfsm}}
\end{subfigure}
\begin{subfigure}{.24\textwidth}
\vspace{-.7cm}
\begin{center}
\includegraphics[scale=0.35]{figures/esclattice}
\end{center}
\vspace{-.6cm}
\caption{Lattice\label{fig:esclattice}}
\end{subfigure}
\caption{Lattice and FSM for Escape Analysis}
\end{figure}

Figure~\ref{fig:clfsm} presents a finite state machine that summarizes
the semantics for persistency state of a memory location, and
Figure~\ref{fig:cllattice} presents the corresponding lattice.
We use a persistency state $\pstate \in \Pstate$ to
represent one of the three persistency state values, $\{ \clean,
\clwb, \dirty \}$.  The lattice is ordered in this fashion, because we
need to know whether a memory location may require a fence 
(\clwb) or whether it may require a fence and flush
(\dirty).  For example, if a reference is \clean on one path to a node
and \clwb on a different path to the node, the analysis must
conservative assume it is \clwb at the merge point.

The core analysis computes a map $\PMap{} \subseteq \ALoc \times
\Pstate$ from memory locations to persistency states.  The meet
operator $\sqcap: \Pstate \times \Pstate \rightarrow \Pstate$ and the
ordering operator $\succeq$ for $\Pstate$ are defined similar to the
ones for $\Estate$.

\begin{figure}[!htbp]
\begin{subfigure}{.24\textwidth}
\vspace{-.2cm}
\begin{center}
\includegraphics[scale=0.35]{figures/clfsm}
\end{center}
\vspace{-.5cm}
\caption{Finite State Machine\label{fig:clfsm}}
\end{subfigure}
\begin{subfigure}{.24\textwidth}
\vspace{-.2cm}
\begin{center}
\includegraphics[scale=0.35]{figures/cllattice}
\end{center}
\vspace{-.5cm}
\caption{Lattice\label{fig:cllattice}}
\end{subfigure}
\caption{Lattice and FSM for Persistency State Analysis}
\end{figure}


\newcommand{\tspace}{\vspace{.01cm}}
\newcommand{\ispace}{\vspace{.1cm}}

\begin{figure}[!htb]
\scriptsize
\begin{tabular}{p{0.2\linewidth} | p{0.65\linewidth}}
  \code{statement} & {
  $\EMap' = (\EMap - \text{KILL} ) \cup \text{GEN}$
  }\ispace\\
  \hline \hline
  \tspace\code{y=x} & {\tspace$\begin{aligned}
  U =& \AliasMap(\code{x}) \cup \{ \code{y} \}\\
  \AliasMap' =& \{ \tuple{\aref, S} \mid \tuple{\aref,S} \in \AliasMap \wedge \aref \notin U \} \cup \\
  & \{ \tuple{\aref, U} \mid \aref \in U \} \\
  \text{GEN} =&\{ \tuple{\code{y}, \estate{}} \mid \tuple{\code{x}, \estate} \in \EMap{}\} \\
  \text{KILL} =&\{ \tuple{\code{y}, *} \mid \tuple{\code{x}, \estate} \in \EMap{}\} \\
  \end{aligned}$\ispace}\\
  \hline
  
  \tspace\code{*y=x} \linebreak or \linebreak \code{*y=\&x->f} & {\tspace$\begin{aligned}
  U =& \AliasMap(\code{x}) \\
  \text{GEN} =&\{ \tuple{\code{y}, \escaped} \mid \tuple{\code{x}, \estate} \in \EMap{} \wedge \aref \in U\} \\
  \text{KILL} =&\{ \tuple{\code{y}, *} \mid \tuple{\code{x}, \estate} \in \EMap{} \wedge \aref \in U\} \\
  \end{aligned}$\ispace}\\
  \hline

  \tspace\code{y=*x} & {\tspace$\begin{aligned}
  U =& \AliasMap(\code{y}) \setminus  \{ \code{y} \}\\
  \AliasMap' =& \{ \tuple{\aref, S} \mid \\
  & \tuple{\aref,S} \in \AliasMap \wedge r \notin \AliasMap(\code{y}) \} \cup \\
  & \{ \tuple{\code{y}, \{ \code{y} \}} \} \cup \{ \tuple{\aref, U} \mid \aref \in U \} \\
  \text{GEN} =& \{ \tuple{\code{y}, \escaped} \} \\
  \text{KILL} =& \{ \tuple{\code{y}, *} \}
  %\hspace{-1.6cm}\text{KILL} =& \{ \tuple{\code{y}, \estate} \mid \tuple{\code{y}, \estate} \in \EMap{} \}
  \end{aligned}$\ispace}\\

  \hline
\end{tabular}
\caption{Transfer Functions for Escape Analysis, where \code{x} and \code{y} point to PM locations\label{fig:esctransfer}}
\end{figure}
\begin{figure}[!htb]
\scriptsize
\begin{tabular}{p{0.2\linewidth} | p{0.65\linewidth}}
  \code{statement} & {$\begin{aligned} \PMap{}' = (\PMap{} - \text{KILL} ) \cup \text{GEN} \end{aligned}$\ispace}\\
  \hline \hline

  \tspace\code{x->f=v} & {\tspace$\begin{aligned}\hspace{-2.1cm}\text{GEN}=&\{\tuple{\tuple{\code{x}, \text{offset}(\code{f})},\dirty}\}\\
  \text{KILL} =& \{ \tuple{\tuple{\code{x}, \text{offset}(\code{f})},\text{*}}\}\end{aligned}$\ispace}\\
  \hline

  \tspace\code{y=x->f} \text{where \code{f} is an} \text{atomic field} & {\tspace$\begin{aligned}\hspace{-2.2cm}\text{GEN}=&\{\tuple{\tuple{\code{x}, \text{offset}(\code{f})},\dirty}\}\\
  \text{KILL} =& \{ \tuple{\tuple{\code{x}, \text{offset}(\code{f})},\text{*}}\}\end{aligned}$\ispace}\\
  \hline

  \tspace\code{flush(\&x->f)} & {\tspace$\begin{aligned}\hspace{-2.2cm}\text{GEN}=&\{\tuple{\tuple{\code{x}, \text{offset}(\code{f})},\clean}\}\\
  \text{KILL} =& \{ \tuple{\tuple{\code{x}, \text{offset}(\code{f})},\text{*}}\}\end{aligned}$\ispace}\\
  \hline

  \tspace\code{clwb(\&x->f)} & {\tspace$\begin{aligned}
  \text{GEN}=&\{ \tuple{\aloc, \clwb} \mid
  \tuple{\aloc, \dirty} \in \PMap{} \wedge \aloc = \tuple{\code{x}, \text{offset}(\code{f})}\}\\
  \text{KILL}=&\{ \tuple{\aloc, *} \mid
  \tuple{\aloc, \dirty} \in \PMap{} \wedge \aloc = \tuple{\code{x}, \text{offset}(\code{f})}\}\\
  \end{aligned}$\ispace}\\
  \hline

  \tspace\code{fence} & {\tspace$\begin{aligned}
  \text{GEN}=&\{ \tuple{\aloc, \clean} \mid \tuple{\aloc, \clwb} \in \PMap{} \}\\
  \text{KILL}=&\{ \tuple{\aloc, *} \mid \tuple{\aloc, \clwb} \in \PMap{} \}\\
  \end{aligned}$\ispace}\\
  \hline

  \end{tabular}
\caption{Transfer Functions for Persistency State Analysis\label{fig:perstransfer}}
\end{figure}



\subsection{Checking Whether Objects are Captured\label{sec:esctransfer}}

We take a simple approach to escape analysis
--- once a reference to a newly allocated struct or array is stored to
any place other than a variable, we assume it has escaped.  The key
ideas of the analysis are that a newly allocated object starts in the
captured state.  For example, the statement \code{x=new} would result
in the analysis computing that \code{x} is in the captured state at
the program point immediately after this statement.  This is stored in
the map $\EMap$.  The analysis then computes the sets of variables
that may reference the same object.  After the statement \code{x=new},
the analysis would compute that \code{x} is the only variable to
reference the memory it references.  The analysis stores this
information in the alias map $\AliasMap \subseteq \Refs \times
\mathbb{P}(\Refs)$ from references to their aliases, where
$\mathbb{P}(\Refs)$ denotes the power set of $\Refs$.  If the value in
a variable \code{x} is stored to some heap location, the variable
\code{x} and all variables that may reference the same heap location
are marked as $\escaped$.

Figure~\ref{fig:esctransfer} present the transfer functions of our escape analysis.  We use the form $\EMap' = (\EMap -
\text{KILL} ) \cup \text{GEN}$ and use the *
symbol to match arbitrary states. We next discuss the transfer functions for key statements:

\noindent {\bf Assignments:}
When there is an assignment 
\code{y=x}, we replace the alias set of \code{y} (and all other aliases of \code{x}) with the aliases of \code{x} plus \code{y} itself.
At the same time, we update $\EMap$ to assign \code{y} to have the same escape state as \code{x}.


\noindent {\bf Stores:} When a store 
\code{*y = x} or \code{*y = \&x->f} stores to the address \code{x}
or the address of one of its fields \code{\&x->f} to any location, we
consider \code{x} and its aliases as escaped.
As an example, line~\ref{line:commit-store} in
Figure~\ref{fig:stack} makes \code{n} \escaped.

\noindent {\bf Loads:} When a load \code{y =
  *x} reads from \code{x}, and \code{y} points to persistent
memory, the analysis marks \code{y} as \escaped as the loaded value comes from a dereference rather than directly from a variable. Since \code{y} is overwritten, we set the alias set of \code{y} to only include itself, and remove \code{y} from the alias sets of its previous aliases.  Note that since \code{y} is escaped, correct alias information is not necessary.

\subsection{Analyzing Persistency States}
We next describe our persistency state analysis.
Figure~\ref{fig:perstransfer} presents the transfer functions for the
persistency state analysis, where we assume \code{x} is a PM location.
We express transfer
functions using GEN and KILL sets. The reader may note that variables
may alias, but this analysis does not track aliasing information.  The
key observation is that aliasing does not violate soundness---it
simply means that the same variable that is used to perform a store
must be used to flush the value. The lack of must alias information
may result in false positives in cases where one alias is used to
perform a store and another is used to flush the store.  In
Figure~\ref{fig:perstransfer}, we use $\tuple{\code{x},
  \text{offset}(\code{f})}$ to denote the memory location of
\code{x->f}.

\noindent {\bf Store/Atomic Store:} When an atomic or non-atomic store
writes to a field \code{x->f}, the persistency state of \code{x->f}
(\ie $\tuple{\code{x}, \text{offset}(\code{f})}$) is updated as \dirty, indicating that the location needs to be flushed.

\noindent {\bf Atomic Load:} As we mentioned in
Section~\ref{sec:verification}, an atomic load changes the state of
the loaded variable or field to \dirty.  The analysis removes the
old persistency state of \code{x->f} and marks it as \dirty.

\noindent {\bf Atomic RMW:} An atomic RMW is a combination of a fence, an atomic
load, and an atomic store, so we apply the transfer functions for a fence, atomic load
and store in sequence.
 
An atomic CAS is an atomic RMW if successful and an fence and atomic load,
otherwise.  Since our transfer functions have the same effects when
storing to a field \code{x->f} and when performing an atomic load from
\code{x->f}, we consider atomic CASs the same as atomic
RMWs.

\noindent {\bf Flush:} When flushing the address of a field
\code{x->f} with the stronger \code{clflush}, the
persistency state of \code{x->f} becomes clean.  Flushing the address
of a field \code{x->f} with \code{clwb} or \code{clflushopt}
changes its state to \code{clwb} if it was \dirty,
indicating it will become \clean at the next fence.

\noindent {\bf Fence:} For fences, the transfer function
leaves the persistency states untouched unless they are
\clwb. The locations whose persistency states are \clwb
are changed to the \clean state.

\subsection{Intraprocedural Violation Detection\label{sec:intra-error}}

\Tool consider three categories of violations. The first two
categories are 1) unflushed PM locations at function exits; and 2) a
store to an escaped PM location when a different PM location is
already escaped and non-clean. The third category involving arrays
will be discussed in Sections~\ref{sec:array}.

The first category of violations is checked at function exits. When we
complete the analysis of a function, we get the program states at each
function exit and take a union of the states by using meet
operators. If the state of any PM location that is not a function
parameter or the return value is escaped and non-clean, we report it
as a violation.

The second category of errors is checked at every program point. If a
PM location is escaped and non-clean and we perform a store to an escape PM location,  this is a
violation.  To address violations involving multiple threads, when
there is an escaped and non-clean location, a release operation to a
non-PM location (atomic store release or unlock) is
reported as a violation.  Recall from Section~\ref{sec:prelim}, a PM
location $\aloc$ is a pair $\tuple{\aref, n}$ of a reference and an
offset from the reference, so an escaped PM object with two or more
fields being non-clean is also reported as a violation.

\section{Durability}
In addition to robustness violations, the first category of violation from the previous section also includes all durability bugs, i.e.
any escaped PM objects that is not made durable by the end of the program. This follows from a simple argument: 
 the only objects that may be escaped and non-clean are the return values and parameters of the top-level main function, but none of these
objects can be PM objects. 
\section{Interprocedural Analysis\label{sec:inter}}

In this section, we first discuss extending the core analysis to be
interprocedural.  Then we discuss how we detect bugs that involve
objects reachable from function parameters and bugs that involve
multiple functions.  Lastly, we describe our array support
and how we detect references to PM.


\subsection{Context Sensitivity}

We handle function calls in a context sensitive manner using function
summaries. Each function has a \textit{function summary table}
that maps calling contexts to summarized results.

For a function with $n$ parameters, its \textit{calling context} has
the form $C \in (\Estate \times \Pstate)^n$,  containing the abstract
escape and persistency states for each function parameter. To reduce
the possible number of calling contexts, for a function parameter with
$m$ fields, we collapse the $m$ persistency states to a single
abstract persistency state with the abstraction:
\begin{align*}
\textit{Abs}&(\tuple{\estate, \pstate_1, ..., \pstate_m}) = \tuple{\estate, \text{lowest}(\pstate_1, ..., \pstate_n)}
\end{align*}
In other words, we use a single state (the lowest one) for all fields of a given parameter. 

Each calling context is then mapped to a \textit{summarized result} in
the function summary table. For a function $F$ with $n$ parameters, a
summarized result for a calling context $C$ has the form
$R_{\tuple{F,C}} \in (\Estate \times \Pstate)^{n+1}$, containing
abstract states for each function parameter and the return value. The
last element may be ignored for functions with no return values. The
abstraction can be reverted to get back program states by
approximating every field with the same persistency state:
\begin{align*}
\textit{AbsRev}&(\tuple{\estate, \pstate}) = \tuple{\estate, (\pstate, ..., \pstate)}
\end{align*}
This allows summarized results to be used to update the program state
after a function call.

To extend our alias analysis to be interprocedural, we also store the
aliasing information between function parameters and the return value
to summarized results. The summarized result additionally uses a
\textit{markObjDirEsp} bit to record if there are any escaped objects
that become non-clean in the callee, potentially causing violations with
other escaped non-clean objects in the caller, but are not captured by
the summarized result because they become clean again before the
callee returns. These extensions are straightforward and are omitted in
the representation here.


The interprocedural analysis
uses a worklist algorithm operating on pairs $\tuple{F, C}$ of
function $F$ and calling context $C$.  The worklist initially includes
all functions with the calling contexts of all parameters having the
lowest state $\tuple{\captured, \clean}$. When we complete the
analysis of a function with a calling context, we update the function
summary table, and every time $F$'s summarized results are updated, we
push all callers of $F$ with their calling contexts to the worklist.

To speed up the convergence of the algorithm, we allow summarized
results for a function $F$ to be approximated from results for higher
contexts. For two calling context $C = \tuple{\tuple{\estate_1,
    \pstate_1}, ..., \tuple{\estate_n, \pstate_n}}$ and $C' =
\tuple{\tuple{\estate_1', \pstate_1'}, ..., \tuple{\estate_n',
    \pstate_n'}}$, we say that $C$ is higher than $C'$ if $\estate_i
\succeq \estate_i'$ and $\pstate_n \succeq \pstate_n'$ for all $i$.
The meet operator $\sqcap: (\Estate \times \Pstate)^{n+1} \rightarrow
(\Estate \times \Pstate)^{n+1}$ for summarized results is also defined
as a point-wise meet.  There are then three cases when processing a
pair $\tuple{F, C}$:

\begin{itemize}
  \item \textbf{Case 1:} If we have already analyzed $F$ with the
    calling context $C$, Then the summarized result $R_{\tuple{F,C}}$
    is used to approximate the state of the parameters and the return
    value of $F$ after the call site.

  \item \textbf{Case 2:} Otherwise, if we have only analyzed $F$ with
    calling contexts higher that $C$, we can take the summarized
    results $R_{\tuple{F, C'}}$ for all calling contexts $C'$ higher
    than $C$, and use the merged result of this set of summarized
    results via the meet operator as an approximation, and push the
    pair $\tuple{F,C}$ to the worklist. This choice ensures
    monotonicity when processing call sites and thus preserves the
    termination guarantee for dataflow analysis.

  \item \textbf{Case 3:} If we have not analyzed $F$ with $C$ or any calling context higher than $C$ before, we approximate all parameters and the return value of $F$ as having the state $\tuple{\captured, \clean}$ and push the pair $\tuple{F,C}$ to the worklist.
\end{itemize}

\iffalse
\begin{figure}[!h]
\begin{subfigure}{0.4\textwidth}
{\scriptsize
  \begin{lstlisting}
  void F(int &a) {
    a = 1; /*@\label{line:store-a}@*/
    flush(&a);
  }

  void main() {
    x = 1;
    F(y);
  }
\end{lstlisting}
\caption{A buggy execution\label{fig:buggy-execution}}
  }
\end{subfigure}
\begin{subfigure}{0.4\textwidth}
  {\scriptsize
  \begin{lstlisting}
  void F(int &a) {
    a = 1;
    flush(&a);
  }

  void main() {
    x = 1;
    F(x);
  }
  \end{lstlisting}
  }
\caption{A bug-free execution\label{fig:bug-free-execution}}
\end{subfigure}
\caption{Assume that $\code{x}$ and $\code{y}$ reside on different cache lines and are escaped and clean initially.}
\end{figure}
\fi



\subsection{Handling Arrays\label{sec:array}}
To handle arrays, we abstract
array writes as a pair of an array reference and an index.  Formally,
we model an array element $\aloc = \tuple{\aref, n} \in \ALoc_a$ as a
reference (variable) $\aref \in \Refs$ and a  index $n \in
\mathbb{Z}^{0+}$ from that reference.  We  abstract the array index
using the variable that provided the value for the array dereference
operation.  Thus, our abstraction is only able to track dirty array
elements as long as the original index variable exists.  To ensure
soundness, when a function writes to some PM array, we 
require the written element to be flushed before the function returns or the index variable is changed/lost.

We conservatively assume all array elements have escaped and only
compute a map $\PMap{a} \in \ALoc_a \times \Pstate$ from array
elements to persistency states. The transfer functions for the array persistency analysis can be straightforward obtained
from Figure~\ref{fig:perstransfer}
by replacing the addresses being stored to and loaded from
with the array index variable.
At a function exit, we report warnings if the map $\PMap{a}$
contains any element whose persistency state is not clean.

\subsection{Interprocedural Violation Detection\label{sec:inter-error}}

The robustness violation detection mechanism for interprocedural
analysis is the same as the intraprocedural one, except that
robustness violations that involve multiple functions are also
reported.  Our treatment of pointer arithmetic conservatively reports violations when there are stores to or loads from PM
addresses computed by pointer arithmetic.

\subsection{Relaxing Strict Persistency: An Escape Hatch\label{sec:escape_hatch}}

Robustness violations are not always bugs;  design patterns like
\textit{link-and-persist}~\cite{nvtraverse}, \textit{pointer
  tagging}~\cite{detectable2021li}, and checksums can cause false positives by allowing observable low-level robustness violations without compromising high-level safety.

For example, the RECIPE benchmarks 
sometimes use atomic loads to read data from an atomic variable
that is never mutated.  This is done because the data structure packs
both mutable and immutable state into the same atomic variable.
Flushing such loads can incur high
overheads.

PM programs sometimes
write data and a checksum, and then persist both the data and the
checksum.  When accessing the data, the PM program first verifies the
checksum before using the data.  While this pattern is safe, it can
yield executions that are not equivalent to any execution under strict
consistency and thus violate robustness.

\Tool provides strict persistency by default.  However, if the developer knows that it is safe to escape
from strict persistency, \tool provides annotations
to ignore blocks that are exempt from strict persistency.  When
applied to either a store or an atomic load, this annotation tells
\tool that no flush or fence operation is needed.

\subsection{Termination and Correctness}

All transfer functions in the analysis are monotonic and the lattices are of finite height.  Thus, the dataflow analysis  terminates.  \textbf{The appendix presents correctness proofs.}
