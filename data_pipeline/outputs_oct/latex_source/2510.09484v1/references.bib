@article{fairCRPS,
author = {Ferro, C. A. T.},
title = {Fair scores for ensemble forecasts},
journal = {Quarterly Journal of the Royal Meteorological Society},
volume = {140},
number = {683},
pages = {1917-1923},
keywords = {Brier score, continuous ranked probability score, scoring rules, forecast verification},
doi = {https://doi.org/10.1002/qj.2270},
url = {https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/qj.2270},
eprint = {https://rmets.onlinelibrary.wiley.com/doi/pdf/10.1002/qj.2270},
abstract = {Abstract The notion of fair scores for ensemble forecasts was introduced recently to reward ensembles with members that behave as though they and the verifying observation are sampled from the same distribution. In the case of forecasting binary outcomes, a characterization is given of a general class of fair scores for ensembles that are interpreted as random samples. This is also used to construct classes of fair scores for ensembles that forecast multicategory and continuous outcomes. The usual Brier, ranked probability and continuous ranked probability scores for ensemble forecasts are shown to be unfair, while adjusted versions of these scores are shown to be fair. A definition of fairness is also proposed for ensembles with members that are interpreted as being dependent and it is shown that fair scores exist only for some forms of dependence.},
year = {2014}
}

@misc{chen2021adaspeechadaptivetextspeech,
      title={AdaSpeech: Adaptive Text to Speech for Custom Voice}, 
      author={Mingjian Chen and Xu Tan and Bohan Li and Yanqing Liu and Tao Qin and Sheng Zhao and Tie-Yan Liu},
      year={2021},
      eprint={2103.00993},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2103.00993}, 
}

@article{zamo2018estimation,
  title = {Estimation of the Continuous Ranked Probability Score with Limited Information and Applications to Ensemble Weather Forecasts},
  author = {Zamo, Micka{\"e}l and Naveau, Philippe},
  journal = {Mathematical Geosciences},
  volume = {50},
  number = {2},
  pages = {209--234},
  year = {2018},
  publisher = {Springer}
}


@article{gneiting2007strictly,
  title = {Strictly proper scoring rules, prediction, and estimation},
  author = {Gneiting, Tilmann and Raftery, Adrian E.},
  journal = {Journal of the American Statistical Association},
  pages = {359--378},
  year = {2007},
  publisher = {Taylor \& Francis}
}


@misc{FGNalet2025skillfuljointprobabilisticweather,
      title={Skillful joint probabilistic weather forecasting from marginals}, 
      author={Ferran Alet and Ilan Price and Andrew El-Kadi and Dominic Masters and Stratis Markou and Tom R. Andersson and Jacklynn Stott and Remi Lam and Matthew Willson and Alvaro Sanchez-Gonzalez and Peter Battaglia},
      year={2025},
      eprint={2506.10772},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2506.10772}, 
}

@inproceedings{larsson2025diffusionlam,
  title={Diffusion-LAM: Probabilistic Limited Area Weather Forecasting with Diffusion},
  author={Larsson, Erik and Oskarsson, Joel and Landelius, Tomas and Lindsten, Fredrik},
  booktitle={ICLR 2025 Workshop on Tackling Climate Change with Machine Learning},
  url={https://www.climatechange.ai/papers/iclr2025/36},
  year={2025}
}


@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10012--10022},
  year={2021}
}

@article{AFNO,
  title={Adaptive fourier neural operators: Efficient token mixers for transformers},
  author={Guibas, John and Mardani, Morteza and Li, Zongyi and Tao, Andrew and Anandkumar, Anima and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:2111.13587},
  year={2021}
}

@misc{xu2024yinglongskillfulhighresolution,
      title={YingLong: Skillful High Resolution Regional Short Term Forecasting with Boundary Smoothing}, 
      author={Pengbo Xu and Tianyan Gao and Yu Wang and Junping Yin and Juan Zhang and Xiaogu Zheng and Zhimin Zhang and Xiaoguang Hu and Xiaoxu Chen},
      year={2024},
      eprint={2401.16254},
      archivePrefix={arXiv},
      primaryClass={physics.ao-ph},
      url={https://arxiv.org/abs/2401.16254}, 
}

@inproceedings{oskarsson2023graph-lam,
    title={Graph-based Neural Weather Prediction for Limited Area Modeling},
    author={Oskarsson, Joel and Landelius, Tomas and Lindsten, Fredrik},
    booktitle={NeurIPS 2023 Workshop on Tackling Climate Change with Machine Learning},
    year={2023}
}

@book{fundamentals_of_nwp,
  title={Fundamentals of numerical weather prediction},
  author={Coiffier, Jean},
  year={2011},
  publisher={Cambridge University Press},
  abstract={LAM offers the possibility to tailor models and run on higher resolution. Traditionally, weather models use large computing clusters, resulting in a high energy footprint.}
}

% Renewable energy
@article{ren_energy_future,
author = {Sweeney, Conor and Bessa, Ricardo J. and Browell, Jethro and Pinson, Pierre},
title = {The future of forecasting for renewable energy},
journal = {WIREs Energy and Environment},
volume = {9},
number = {2},
pages = {e365},
keywords = {business models, industry challenges, numerical weather prediction, renewable energy, statistical modelling},
doi = {https://doi.org/10.1002/wene.365},
url = {https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/wene.365},
eprint = {https://wires.onlinelibrary.wiley.com/doi/pdf/10.1002/wene.365},
abstract = {Abstract Forecasting for wind and solar renewable energy is becoming more important as the amount of energy generated from these sources increases. Forecast skill is improving, but so too is the way forecasts are being used. In this paper, we present a brief overview of the state-of-the-art of forecasting wind and solar energy. We describe approaches in statistical and physical modeling for time scales from minutes to days ahead, for both deterministic and probabilistic forecasting. Our focus changes then to consider the future of forecasting for renewable energy. We discuss recent advances which show potential for great improvement in forecast skill. Beyond the forecast itself, we consider new products which will be required to aid decision making subject to risk constraints. Future forecast products will need to include probabilistic information, but deliver it in a way tailored to the end user and their specific decision making problems. Businesses operating in this sector may see a change in business models as more people compete in this space, with different combinations of skills, data and modeling being required for different products. The transaction of data itself may change with the adoption of blockchain technology, which could allow providers and end users to interact in a trusted, yet decentralized way. Finally, we discuss new industry requirements and challenges for scenarios with high amounts of renewable energy. New forecasting products have the potential to model the impact of renewables on the power system, and aid dispatch tools in guaranteeing system security. This article is categorized under: Energy Infrastructure > Systems and Infrastructure Wind Power > Systems and Infrastructure Photovoltaics > Systems and Infrastructure},
year = {2020}
}

@article{SHARMA2014160,
title = {Leveraging weather forecasts in renewable energy systems},
journal = {Sustainable Computing: Informatics and Systems},
volume = {4},
number = {3},
pages = {160-171},
year = {2014},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2014.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S2210537914000407},
author = {Navin Sharma and Jeremy Gummeson and David Irwin and Ting Zhu and Prashant Shenoy},
keywords = {Energy harvesting, Weather forecast, Energy prediction, Green computing},
abstract = {Systems that harvest environmental energy must carefully regulate their usage to satisfy their demand. Regulating energy usage is challenging if a system's demands are not elastic, since it cannot precisely scale its usage to match its supply. Instead, the system must choose how to satisfy its demands based on its current energy reserves and predictions of its future energy supply. In this paper, we show that prediction strategies that use weather forecasts are more accurate than prediction strategies based on the past, and are capable of improving the performance of a variety of systems. We analyze weather forecast, observational, and energy harvesting data to formulate a model that translates a weather forecast to a solar or wind energy harvesting prediction, and quantify its accuracy. We then compare the performance of three types of energy harvesting systems—a lexicographically fair sensor network, an off-the-grid sensor testbed, and a solar-powered smart home—using prediction models based on both forecasts and the past. In each case, forecast-based predictions significantly improve system performance.}
}

@ARTICLE{ren_energy_pred,
  author={Andrade, José R. and Bessa, Ricardo J.},
  journal={IEEE Transactions on Sustainable Energy}, 
  title={Improving Renewable Energy Forecasting With a Grid of Numerical Weather Predictions}, 
  year={2017},
  volume={8},
  number={4},
  pages={1571-1580},
  abstract={In the last two decades, renewable energy forecasting progressed toward the development of advanced physical and statistical algorithms aiming at improving point and probabilistic forecast skill. This paper describes a forecasting framework to explore information from a grid of numerical weather predictions (NWP) applied to both wind and solar energy. The methodology combines the gradient boosting trees algorithm with feature engineering techniques that extract the maximum information from the NWP grid. Compared to a model that only considers one NWP point for a specific location, the results show an average point forecast improvement (in terms of mean absolute error) of 16.09% and 12.85% for solar and wind power, respectively. The probabilistic forecast improvement, in terms of continuous ranked probabilistic score, was 13.11% and 12.06%, respectively.},
  keywords={Wind forecasting;Wind power generation;Forecasting;Predictive models;Probabilistic logic;Solar energy;Wind energy;Feature engineering;forecasting;probabilistic;solar energy;spatial;temporal;wind energy;weather predictions},
  doi={10.1109/TSTE.2017.2694340},
  ISSN={1949-3037},
  month={Oct},}

%%%%

@article{arome_metcoop,
	title = {{AROME}-{MetCoOp}: A Nordic Convective-Scale Operational Weather Prediction Model},
	shorttitle = {{AROME}-{MetCoOp}},
	journaltitle = {Weather and Forecasting},
	journal = {Weather and Forecasting},
	author = {M\"{u}ller, Malte and Homleid, Mariken and Ivarsson, Karl-Ivar and K{\o}ltzow, Morten A. {\O} and Lindskog, Magnus and Midtb{\o}, Knut Helge and Andrae, Ulf and Aspelien, Trygve and Berggren, Lars and Bj{\o}rge, Dag and Dahlgren, Per and Kristiansen, J{\o}rn and Randriamampianina, Roger and Ridal, Martin and Vignes, Ole},
	date = {2017-04-01},
	year = {2017},
    publisher = {American Meteorological Society}
}

@article{yano2018scientific,
  title={Scientific challenges of convective-scale numerical weather prediction},
  author={Yano, Jun-Ichi and Ziemia{\'n}ski, Micha{\l} Z and Cullen, Mike and Termonia, Piet and Onvlee, Jeanette and Bengtsson, Lisa and Carrassi, Alberto and Davy, Richard and Deluca, Anna and Gray, Suzanne L and others},
  journal={Bulletin of the American Meteorological Society},
  volume={99},
  number={4},
  pages={699--710},
  year={2018},
  publisher={American Meteorological Society},
  abstract={Forecast uncertainty}
}

@article{leutbecher2008ensemble,
  title={Ensemble forecasting},
  author={Leutbecher, Martin and Palmer, Tim N},
  journal={Journal of computational physics},
  volume={227},
  number={7},
  pages={3515--3539},
  year={2008},
  publisher={Elsevier},
  abstract={Forecast uncertainty}
}


% Källor från Tomas
@misc{worldbank2023inclusive,
  title = {Designing Inclusive, Accessible Early Warning Systems: Good Practices and Entry Points},
  author = {{World Bank}},
  year = {2023},
  url = {https://documents1.worldbank.org/curated/en/099050123155016375/pdf/P1765160197f400b80947e0af8c48049151.pdf},
  note = {Accessed: 2025-01-23},
  abstract={Cheaper weather forecasts can make them available in less developed areas which can be heavily affected by extreme weather.}

}


@techreport{ipcc2023synthesis,
  author       = {{IPCC}},
  title        = {Climate change 2023: Synthesis report. Contribution of working groups I, II and III to the sixth assessment report of the intergovernmental panel on climate change},
  year         = {2023},
  institution  = {Intergovernmental Panel on Climate Change (IPCC)},
  type         = {Technical report},
  note         = {2023},
}

@misc{whitt2023economic,
  author       = {J. Whitt and S. Gordon},
  title        = {This is the economic cost of extreme weather},
  year         = {2023},
  howpublished = {In World Economic Forum Annual Meeting},
  month        = jan,
  url          = {https://www.weforum.org/agenda/2023/01/extreme-weather-economic-cost-wef23/},
  note         = {Accessed: 2025-01-23}
}

@inbook{astitha2023definition,
  author       = {M. Astitha and E. Nikolopoulos},
  title        = {Definition of extreme weather events (subchapter 1.1)},
  booktitle    = {Extreme Weather Forecasting},
  pages        = {1--7},
  publisher    = {Elsevier},
  year         = {2023}
}

@article{bauer2015quiet,
  author       = {P. Bauer and A. Thorpe and G. Brunet},
  title        = {The quiet revolution of numerical weather prediction},
  journal      = {Nature},
  year         = {2015}
}

@article{alley2019advances,
  author       = {R. B. Alley and others},
  title        = {Advances in weather prediction},
  journal      = {Science},
  volume       = {363},
  pages        = {342--344},
  year         = {2019},
  doi          = {10.1126/science.aav7274}
}

%%%%%%


% Ensembles through pertubations
@article{bulte2024uncertainty,
  title={Uncertainty quantification for data-driven weather models},
  author={B{\"u}lte, Christopher and Horat, Nina and Quinting, Julian and Lerch, Sebastian},
  journal={arXiv preprint arXiv:2403.13458},
  year={2024}
}

@inproceedings{graubner2022calibration,
  title={Calibration of large neural weather models},
  author={Graubner, Andre and Azizzadenesheli, Kamyar Kamyar and Pathak, Jaideep and Mardani, Morteza and Pritchard, Mike and Kashinath, Karthik and Anandkumar, Anima},
  booktitle={NeurIPS 2022 Workshop on Tackling Climate Change with Machine Learning},
  year={2022}
}

@article{chen2023fuxi,
  title={FuXi: A cascade machine learning forecasting system for 15-day global weather forecast},
  author={Chen, Lei and Zhong, Xiaohui and Zhang, Feng and Cheng, Yuan and Xu, Yinghui and Qi, Yuan and Li, Hao},
  journal={npj Climate and Atmospheric Science},
  volume={6},
  number={1},
  pages={190},
  year={2023},
  publisher={Nature Publishing Group UK London}
}
%%%%

@inproceedings{song2020score,
  title={Score-based generative modeling through stochastic differential equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{hersbach2020era5,
  title={The ERA5 global reanalysis},
  author={Hersbach, Hans and Bell, Bill and Berrisford, Paul and Hirahara, Shoji and Hor{\'a}nyi, Andr{\'a}s and Mu{\~n}oz-Sabater, Joaqu{\'\i}n and Nicolas, Julien and Peubey, Carole and Radu, Raluca and Schepers, Dinand and others},
  journal={Quarterly Journal of the Royal Meteorological Society},
  volume={146},
  number={730},
  pages={1999--2049},
  year={2020},
  publisher={Wiley Online Library}
}

@misc{shi2024codicastconditionaldiffusionmodel,
      title={CoDiCast: Conditional Diffusion Model for Weather Prediction with Uncertainty Quantification}, 
      author={Jimeng Shi and Bowen Jin and Jiawei Han and Giri Narasimhan},
      year={2024},
      eprint={2409.05975},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2409.05975}, 
}

@misc{andrae2024continuousensembleweatherforecasting,
      title={Continuous Ensemble Weather Forecasting with Diffusion models}, 
      author={Martin Andrae and Tomas Landelius and Joel Oskarsson and Fredrik Lindsten},
      year={2024},
      eprint={2410.05431},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.05431}, 
}

@misc{lang2024aifscrpsensembleforecastingusing,
      title={{AIFS-CRPS}: Ensemble forecasting using a model trained with a loss function based on the Continuous Ranked Probability Score}, 
      author={Simon Lang and Mihai Alexe and Mariana C. A. Clare and Christopher Roberts and Rilwan Adewoyin and Zied Ben Bouallègue and Matthew Chantry and Jesper Dramsch and Peter D. Dueben and Sara Hahner and Pedro Maciel and Ana Prieto-Nemesio and Cathal O'Brien and Florian Pinault and Jan Polster and Baudouin Raoult and Steffen Tietsche and Martin Leutbecher},
      year={2024},
      eprint={2412.15832},
      archivePrefix={arXiv},
      primaryClass={physics.ao-ph},
      url={https://arxiv.org/abs/2412.15832}, 
}

@article{SwinVRNN,
author = {Hu, Yuan and Chen, Lei and Wang, Zhibin and Li, Hao},
year = {2023},
month = {02},
pages = {},
title = {SwinVRNN: A Data‐Driven Ensemble Forecasting Model via Learned Distribution Perturbation},
volume = {15},
journal = {Journal of Advances in Modeling Earth Systems},
doi = {10.1029/2022MS003211}
}

@misc{noaa2025billiondollar,
  author       = {{NOAA NCEI}},
  title        = {U.S. Billion-Dollar Weather and Climate Disasters},
  year         = {2025},
  url          = {https://www.ncei.noaa.gov/access/billions/},
  doi          = {10.25921/stkw-7w73},
  note         = {Accessed: 2025-01-18}
}

@misc{stormCast,
      title={Kilometer-Scale Convection Allowing Model Emulation using Generative Diffusion Modeling}, 
      author={Jaideep Pathak and Yair Cohen and Piyush Garg and Peter Harrington and Noah Brenowitz and Dale Durran and Morteza Mardani and Arash Vahdat and Shaoming Xu and Karthik Kashinath and Michael Pritchard},
      year={2024},
      eprint={2408.10958},
      archivePrefix={arXiv},
      primaryClass={physics.ao-ph},
      url={https://arxiv.org/abs/2408.10958}, 
}

@inproceedings{
adamw,
title={Decoupled Weight Decay Regularization},
author={Ilya Loshchilov and Frank Hutter},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=Bkg6RiCqY7},
}

@article{fortin2014should,
  title={Why should ensemble spread match the RMSE of the ensemble mean?},
  author={Fortin, Vincent and Abaza, Mabrouk and Anctil, Francois and Turcotte, Raphael},
  journal={Journal of Hydrometeorology},
  volume={15},
  number={4},
  pages={1708--1713},
  year={2014},
  publisher={American Meteorological Society}
}

@misc{stretch_grid_norway,
      title={Regional data-driven weather modeling with a global stretched-grid}, 
      author={Thomas Nils Nipen and Håvard Homleid Haugen and Magnus Sikora Ingstad and Even Marius Nordhagen and Aram Farhad Shafiq Salihi and Paulina Tedesco and Ivar Ambjørn Seierstad and Jørn Kristiansen and Simon Lang and Mihai Alexe and Jesper Dramsch and Baudouin Raoult and Gert Mertes and Matthew Chantry},
      year={2024},
      eprint={2409.02891},
      archivePrefix={arXiv},
      primaryClass={physics.ao-ph},
      url={https://arxiv.org/abs/2409.02891}, 
}

@misc{hendrycks2023gaussianerrorlinearunits,
      title={Gaussian Error Linear Units (GELUs)}, 
      author={Dan Hendrycks and Kevin Gimpel},
      year={2023},
      eprint={1606.08415},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1606.08415}, 
}

@misc{mcnally2024datadrivenweatherforecasts,
      title={Data driven weather forecasts trained and initialised directly from observations}, 
      author={Anthony McNally and Christian Lessig and Peter Lean and Eulalie Boucher and Mihai Alexe and Ewan Pinnington and Matthew Chantry and Simon Lang and Chris Burrows and Marcin Chrust and Florian Pinault and Ethel Villeneuve and Niels Bormann and Sean Healy},
      year={2024},
      eprint={2407.15586},
      archivePrefix={arXiv},
      primaryClass={physics.ao-ph},
      url={https://arxiv.org/abs/2407.15586}, 
}

@InProceedings{bonev2023sfno,
    title={Spherical {F}ourier Neural Operators: Learning Stable Dynamics on the Sphere},
    author={Bonev, Boris and Kurth, Thorsten and Hundt, Christian and Pathak, Jaideep and Baust, Maximilian and Kashinath, Karthik and Anandkumar, Anima},
    booktitle={Proceedings of the 40th International Conference on Machine Learning},
    pages={2806--2823},
    year={2023},
    volume={202},
    series={Proceedings of Machine Learning Research},
    month={23--29 Jul},
    publisher={PMLR},
}

@article{pathak2022fourcastnet,
  title={Fourcastnet: A global data-driven high-resolution weather model using adaptive fourier neural operators},
  author={Pathak, Jaideep and Subramanian, Shashank and Harrington, Peter and Raja, Sanjeev and Chattopadhyay, Ashesh and Mardani, Morteza and Kurth, Thorsten and Hall, David and Li, Zongyi and Azizzadenesheli, Kamyar and Hassanzadeh, Pedram and Kashinath, Karthik and Anandkumar, Animashree},
  journal={arXiv preprint arXiv:2202.11214},
  year={2022}
}

@article{unet_weather,
author = {Weyn, Jonathan A. and Durran, Dale R. and Caruana, Rich},
title = {Improving Data-Driven Global Weather Prediction Using Deep Convolutional Neural Networks on a Cubed Sphere},
journal = {Journal of Advances in Modeling Earth Systems},
volume = {12},
number = {9},
pages = {e2020MS002109},
doi = {https://doi.org/10.1029/2020MS002109},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2020MS002109},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2020MS002109},
note = {e2020MS002109 10.1029/2020MS002109},
abstract = {Abstract We present a significantly improved data-driven global weather forecasting framework using a deep convolutional neural network (CNN) to forecast several basic atmospheric variables on a global grid. New developments in this framework include an off-line volume-conservative mapping to a cubed-sphere grid, improvements to the CNN architecture and the minimization of the loss function over multiple steps in a prediction sequence. The cubed-sphere remapping minimizes the distortion on the cube faces on which convolution operations are performed and provides natural boundary conditions for padding in the CNN. Our improved model produces weather forecasts that are indefinitely stable and produce realistic weather patterns at lead times of several weeks and longer. For short- to medium-range forecasting, our model significantly outperforms persistence, climatology, and a coarse-resolution dynamical numerical weather prediction (NWP) model. Unsurprisingly, our forecasts are worse than those from a high-resolution state-of-the-art operational NWP system. Our data-driven model is able to learn to forecast complex surface temperature patterns from few input atmospheric state variables. On annual time scales, our model produces a realistic seasonal cycle driven solely by the prescribed variation in top-of-atmosphere solar forcing. Although it currently does not compete with operational weather forecasting models, our data-driven CNN executes much faster than those models, suggesting that machine learning could prove to be a valuable tool for large-ensemble forecasting.},
year = {2020}
}

@misc{couairon2024archesweatherarchesweathergendeterministic,
      title={ArchesWeather \& ArchesWeatherGen: a deterministic and generative model for efficient ML weather forecasting}, 
      author={Guillaume Couairon and Renu Singh and Anastase Charantonis and Christian Lessig and Claire Monteleoni},
      year={2024},
      eprint={2412.12971},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2412.12971}, 
}

@inproceedings{
verma2024climode,
title={Clim{ODE}: Climate Forecasting With Physics-informed Neural {ODE}s},
author={Yogesh Verma and Markus Heinonen and Vikas Garg},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=xuY33XhEGR}
}


@ARTICLE{neuralGCM,
  title    = "Neural general circulation models for weather and climate",
  author   = "Kochkov, Dmitrii and Yuval, Janni and Langmore, Ian and Norgaard,
              Peter and Smith, Jamie and Mooers, Griffin and Kl{\"o}wer, Milan
              and Lottes, James and Rasp, Stephan and D{\"u}ben, Peter and
              Hatfield, Sam and Battaglia, Peter and Sanchez-Gonzalez, Alvaro
              and Willson, Matthew and Brenner, Michael P and Hoyer, Stephan",
  abstract = "General circulation models (GCMs) are the foundation of weather
              and climate prediction1,2. GCMs are physics-based simulators that
              combine a numerical solver for large-scale dynamics with tuned
              representations for small-scale processes such as cloud
              formation. Recently, machine-learning models trained on
              reanalysis data have achieved comparable or better skill than
              GCMs for deterministic weather forecasting3,4. However, these
              models have not demonstrated improved ensemble forecasts, or
              shown sufficient stability for long-term weather and climate
              simulations. Here we present a GCM that combines a differentiable
              solver for atmospheric dynamics with machine-learning components
              and show that it can generate forecasts of deterministic weather,
              ensemble weather and climate on par with the best
              machine-learning and physics-based methods. NeuralGCM is
              competitive with machine-learning models for one- to ten-day
              forecasts, and with the European Centre for Medium-Range Weather
              Forecasts ensemble prediction for one- to fifteen-day forecasts.
              With prescribed sea surface temperature, NeuralGCM can accurately
              track climate metrics for multiple decades, and climate forecasts
              with 140-kilometre resolution show emergent phenomena such as
              realistic frequency and trajectories of tropical cyclones. For
              both weather and climate, our approach offers orders of magnitude
              computational savings over conventional GCMs, although our model
              does not extrapolate to substantially different future climates.
              Our results show that end-to-end deep learning is compatible with
              tasks performed by conventional GCMs and can enhance the
              large-scale physical simulations that are essential for
              understanding and predicting the Earth system.",
  journal  = "Nature",
  volume   =  632,
  number   =  8027,
  pages    = "1060--1066",
  month    =  aug,
  year     =  2024
}


@misc{lang2024aifsecmwfsdatadriven,
      title={{AIFS -- ECMWF}'s data-driven forecasting system}, 
      author={Simon Lang and Mihai Alexe and Matthew Chantry and Jesper Dramsch and Florian Pinault and Baudouin Raoult and Mariana C. A. Clare and Christian Lessig and Michael Maier-Gerber and Linus Magnusson and Zied Ben Bouallègue and Ana Prieto Nemesio and Peter D. Dueben and Andrew Brown and Florian Pappenberger and Florence Rabier},
      year={2024},
      eprint={2406.01465},
      archivePrefix={arXiv},
      primaryClass={physics.ao-ph},
      url={https://arxiv.org/abs/2406.01465}, 
}

@misc{keisler2022forecastingglobalweathergraph,
      title={Forecasting Global Weather with Graph Neural Networks}, 
      author={Ryan Keisler},
      year={2022},
      eprint={2202.07575},
      archivePrefix={arXiv},
      primaryClass={physics.ao-ph},
      url={https://arxiv.org/abs/2202.07575}, 
}

@article{pangu,
  title={Accurate medium-range global weather forecasting with 3D neural networks},
  author={Bi, Kaifeng and Xie, Lingxi and Zhang, Hengheng and Chen, Xin and Gu, Xiaotao and Tian, Qi},
  journal={Nature},
  volume={619},
  number={7970},
  pages={533--538},
  year={2023},
  publisher={Nature Publishing Group}
}

@article{graphcast,
  title={Learning skillful medium-range global weather forecasting},
  author={Lam, Remi and Sanchez-Gonzalez, Alvaro and Willson, Matthew and Wirnsberger, Peter and Fortunato, Meire and Alet, Ferran and Ravuri, Suman and Ewalds, Timo and Eaton-Rosen, Zach and Hu, Weihua and others},
  journal={Science},
  volume={382},
  number={6677},
  pages={1416--1421},
  year={2023},
  publisher={American Association for the Advancement of Science}
}

@misc{siddiqui2024exploringdesignspacedeeplearningbased,
      title={Exploring the design space of deep-learning-based weather forecasting systems}, 
      author={Shoaib Ahmed Siddiqui and Jean Kossaifi and Boris Bonev and Christopher Choy and Jan Kautz and David Krueger and Kamyar Azizzadenesheli},
      year={2024},
      eprint={2410.07472},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.07472}, 
}

@article{NWP,
author = {Bauer, Peter and Thorpe, Alan and Brunet, Gilbert},
year = {2015},
month = {09},
pages = {47-55},
title = {The quiet revolution of numerical weather prediction},
volume = {525},
journal = {Nature},
doi = {10.1038/nature14956}
}

@misc{SiLU,
      title={Sigmoid-Weighted Linear Units for Neural Network Function Approximation in Reinforcement Learning}, 
      author={Stefan Elfwing and Eiji Uchibe and Kenji Doya},
      year={2017},
      eprint={1702.03118},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1702.03118}, 
}

@misc{rasp2023weatherbench,
      title={WeatherBench 2: A benchmark for the next generation of data-driven global weather models}, 
      author={Stephan Rasp and Stephan Hoyer and Alexander Merose and Ian Langmore and Peter Battaglia and Tyler Russel and Alvaro Sanchez-Gonzalez and Vivian Yang and Rob Carver and Shreya Agrawal and Matthew Chantry and Zied Ben Bouallegue and Peter Dueben and Carla Bromberg and Jared Sisk and Luke Barrington and Aaron Bell and Fei Sha},
      year={2023},
      eprint={2308.15560},
      archivePrefix={arXiv},
      primaryClass={physics.ao-ph}
}

@article{gencast,
  title={Probabilistic weather forecasting with machine learning},
  author={Price, Ilan and Sanchez-Gonzalez, Alvaro and Alet, Ferran and Andersson, Tom R and El-Kadi, Andrew and Masters, Dominic and Ewalds, Timo and Stott, Jacklynn and Mohamed, Shakir and Battaglia, Peter and others},
  journal={Nature},
  volume={637},
  number={8044},
  pages={84--90},
  year={2025},
  publisher={Nature Publishing Group}
}

@inproceedings{oskarsson2024probabilistic,
  title = {Probabilistic Weather Forecasting with Hierarchical Graph Neural Networks},
  author = {Oskarsson, Joel and Landelius, Tomas and Deisenroth, Marc Peter and Lindsten, Fredrik},
  year = {2024},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {37},
}

@inproceedings{
karras2022elucidating,
title={Elucidating the Design Space of Diffusion-Based Generative Models},
author={Tero Karras and Miika Aittala and Timo Aila and Samuli Laine},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=k7FuTOWMOc7}
}

@InProceedings{UNET_Original,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}

@article{prob_fc_scoring_rules,
	title = {Probabilistic Forecasting with Generative Networks via Scoring Rule Minimization},
	volume = {25},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v25/23-0038.html},
	abstract = {Probabilistic forecasting relies on past observations to provide a probability distribution for a future outcome, which is often evaluated against the realization using a scoring rule. Here, we perform probabilistic forecasting with generative neural networks, which parametrize distributions on high-dimensional spaces by transforming draws from a latent variable. Generative networks are typically trained in an adversarial framework. In contrast, we propose to train generative networks to minimize a predictive-sequential (or prequential) scoring rule on a recorded temporal sequence of the phenomenon of interest, which is appealing as it corresponds to the way forecasting systems are routinely evaluated. Adversarial-free minimization is possible for some scoring rules; hence, our framework avoids the cumbersome hyperparameter tuning and uncertainty underestimation due to unstable adversarial training, thus unlocking reliable use of generative networks in probabilistic forecasting. Further, we prove consistency of the minimizer of our objective with dependent data, while adversarial training assumes independence. We perform simulation studies on two chaotic dynamical models and a benchmark data set of global weather observations; for this last example, we define scoring rules for spatial data by drawing from the relevant literature. Our method outperforms state-of-the-art adversarial approaches, especially in probabilistic calibration, while requiring less hyperparameter tuning.},
	pages = {1--64},
	number = {45},
	journaltitle = {Journal of Machine Learning Research},
	author = {Pacchiardi, Lorenzo and Adewoyin, Rilwan A. and Dueben, Peter and Dutta, Ritabrata},
	urldate = {2024-05-15},
	year = {2024},
	file = {Full Text PDF:/home/joel/Zotero/storage/ZM3XWVT2/Pacchiardi et al. - 2024 - Probabilistic Forecasting with Generative Networks.pdf:application/pdf;Source Code:/home/joel/Zotero/storage/R298DX2J/GenerativeNetworksScoringRulesProbabilisticForecasting.html:text/html},
}

@misc{lang_multi-scale,
	title = {A multi-scale loss formulation for learning a probabilistic model with proper score optimisation},
	url = {http://arxiv.org/abs/2506.10868},
	doi = {10.48550/arXiv.2506.10868},
	abstract = {We assess the impact of a multi-scale loss formulation for training probabilistic machine-learned weather forecasting models. The multi-scale loss is tested in {AIFS}-{CRPS}, a machine-learned weather forecasting model developed at the European Centre for Medium-Range Weather Forecasts ({ECMWF}). {AIFS}-{CRPS} is trained by directly optimising the almost fair continuous ranked probability score ({afCRPS}). The multi-scale loss better constrains small scale variability without negatively impacting forecast skill. This opens up promising directions for future work in scale-aware model training.},
	number = {{arXiv}:2506.10868},
	publisher = {{arXiv}},
	author = {Lang, Simon and Leutbecher, Martin and Maciel, Pedro},
	urldate = {2025-06-13},
	year = {2025},
	eprinttype = {arxiv},
	eprint = {2506.10868 [physics]},
	keywords = {Computer Science - Artificial Intelligence, Physics - Atmospheric and Oceanic Physics},
	file = {Preprint PDF:/home/joel/Zotero/storage/E934T26C/Lang et al. - 2025 - A multi-scale loss formulation for learning a prob.pdf:application/pdf;Snapshot:/home/joel/Zotero/storage/5YY9E4JB/2506.html:text/html},
}

@misc{fourcastnet3,
	title = {{FourCastNet} 3: A geometric approach to probabilistic machine-learning weather forecasting at scale},
	url = {http://arxiv.org/abs/2507.12144},
	doi = {10.48550/arXiv.2507.12144},
	shorttitle = {{FourCastNet} 3},
	abstract = {{FourCastNet} 3 advances global weather modeling by implementing a scalable, geometric machine learning ({ML}) approach to probabilistic ensemble forecasting. The approach is designed to respect spherical geometry and to accurately model the spatially correlated probabilistic nature of the problem, resulting in stable spectra and realistic dynamics across multiple scales. {FourCastNet} 3 delivers forecasting accuracy that surpasses leading conventional ensemble models and rivals the best diffusion-based methods, while producing forecasts 8 to 60 times faster than these approaches. In contrast to other {ML} approaches, {FourCastNet} 3 demonstrates excellent probabilistic calibration and retains realistic spectra, even at extended lead times of up to 60 days. All of these advances are realized using a purely convolutional neural network architecture tailored for spherical geometry. Scalable and efficient large-scale training on 1024 {GPUs} and more is enabled by a novel training paradigm for combined model- and data-parallelism, inspired by domain decomposition methods in classical numerical models. Additionally, {FourCastNet} 3 enables rapid inference on a single {GPU}, producing a 90-day global forecast at 0.25°, 6-hourly resolution in under 20 seconds. Its computational efficiency, medium-range probabilistic skill, spectral fidelity, and rollout stability at subseasonal timescales make it a strong candidate for improving meteorological forecasting and early warning systems through large ensemble predictions.},
	number = {{arXiv}:2507.12144},
	publisher = {{arXiv}},
	author = {Bonev, Boris and Kurth, Thorsten and Mahesh, Ankur and Bisson, Mauro and Kossaifi, Jean and Kashinath, Karthik and Anandkumar, Anima and Collins, William D. and Pritchard, Michael S. and Keller, Alexander},
	urldate = {2025-08-19},
	year = {2025},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2507.12144 [cs]},
	keywords = {Computer Science - Machine Learning, Physics - Atmospheric and Oceanic Physics},
	file = {Bonev et al. - 2025 - FourCastNet 3 A geometric approach to probabilist.pdf:/home/joel/Zotero/storage/6KDZDRQ9/Bonev et al. - 2025 - FourCastNet 3 A geometric approach to probabilist.pdf:application/pdf},
}

@inproceedings{disconets,
	title = {{DISCO} Nets : {DISsimilarity} {COefficients} Networks},
	volume = {29},
	url = {https://papers.nips.cc/paper_files/paper/2016/hash/c0e190d8267e36708f955d7ab048990d-Abstract.html},
	shorttitle = {{DISCO} Nets},
	abstract = {We present a new type of probabilistic model which we call {DISsimilarity} {COefficient} Networks ({DISCO} Nets). {DISCO} Nets allow us to efficiently sample from a posterior distribution parametrised by a neural network. During training, {DISCO} Nets are learned by minimising the dissimilarity coefficient between the true distribution and the estimated distribution. This allows us to tailor the training to the loss related to the task at hand. We empirically show that (i) by modeling uncertainty on the output value, {DISCO} Nets outperform equivalent non-probabilistic predictive networks and (ii) {DISCO} Nets accurately model the uncertainty of the output, outperforming existing probabilistic models based on deep neural networks.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Bouchacourt, Diane and Mudigonda, Pawan K and Nowozin, Sebastian},
	year = {2016},
	file = {Full Text PDF:/home/joel/Zotero/storage/XA4AH98S/Bouchacourt et al. - 2016 - DISCO Nets  DISsimilarity COefficients Networks.pdf:application/pdf},
}

@article{atmorep,
  title={AtmoRep: A stochastic model of atmosphere dynamics using large scale representation learning},
  author={Lessig, Christian and Luise, Ilaria and Gong, Bing and Langguth, Michael and Stadtler, Scarlet and Schultz, Martin},
  journal={arXiv preprint arXiv:2308.13280},
  year={2023}
}

@article{hrrrcast,
  title={{HRRRCast}: a data-driven emulator for regional weather forecasting at convection allowing scales},
  author={Abdi, Daniel and Jankov, Isidora and Madden, Paul and Vargas, Vanderlei and Smith, Timothy A and Frolov, Sergey and Flora, Montgomery and Potvin, Corey},
  journal={arXiv preprint arXiv:2507.05658},
  year={2025}
}
