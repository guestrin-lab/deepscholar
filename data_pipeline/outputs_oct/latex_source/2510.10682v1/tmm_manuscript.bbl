% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{de2016online}
R.~De~Geest, E.~Gavves, A.~Ghodrati, Z.~Li, C.~Snoek, and T.~Tuytelaars, ``Online action detection,'' in \emph{Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part V 14}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2016, pp. 269--284.

\bibitem{kitani2012activity}
K.~M. Kitani, B.~D. Ziebart, J.~A. Bagnell, and M.~Hebert, ``Activity forecasting,'' in \emph{Computer Vision--ECCV 2012: 12th European Conference on Computer Vision, Florence, Italy, October 7-13, 2012, Proceedings, Part IV 12}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2012, pp. 201--214.

\bibitem{li2024adaptive}
Q.~Li, G.~Zu, H.~Xu, J.~Kong, Y.~Zhang, and J.~Wang, ``An adaptive dual selective transformer for temporal action localization,'' \emph{IEEE Transactions on Multimedia}, 2024.

\bibitem{xia2023exploring}
K.~Xia, L.~Wang, Y.~Shen, S.~Zhou, G.~Hua, and W.~Tang, ``Exploring action centers for temporal action localization,'' \emph{IEEE Transactions on Multimedia}, vol.~25, pp. 9425--9436, 2023.

\bibitem{song2018temporal}
H.~Song, X.~Wu, B.~Zhu, Y.~Wu, M.~Chen, and Y.~Jia, ``Temporal action localization in untrimmed videos using action pattern trees,'' \emph{IEEE transactions on multimedia}, vol.~21, no.~3, pp. 717--730, 2018.

\bibitem{li2021restep}
Y.~Li, P.~Wang, and C.-Y. Chan, ``Restep into the future: relational spatio-temporal learning for multi-person action forecasting,'' \emph{IEEE Transactions on Multimedia}, vol.~25, pp. 1954--1963, 2021.

\bibitem{liu2023hcm}
S.~Liu, J.~Cheng, Z.~Xia, Z.~Xi, Q.~Hou, and Z.~Dong, ``Hcm: Online action detection with hard video clip mining,'' \emph{IEEE Transactions on Multimedia}, vol.~26, pp. 3626--3639, 2023.

\bibitem{schacter2007remembering}
D.~L. Schacter, D.~R. Addis, and R.~L. Buckner, ``Remembering the past to imagine the future: the prospective brain,'' \emph{Nature reviews neuroscience}, vol.~8, no.~9, pp. 657--661, 2007.

\bibitem{xu2021long}
M.~Xu, Y.~Xiong, H.~Chen, X.~Li, W.~Xia, Z.~Tu, and S.~Soatto, ``Long short-term transformer for online action detection,'' \emph{Advances in Neural Information Processing Systems}, vol.~34, pp. 1086--1099, 2021.

\bibitem{chen2022gatehub}
J.~Chen, G.~Mittal, Y.~Yu, Y.~Kong, and M.~Chen, ``Gatehub: Gated history unit with background suppression for online action detection,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022, pp. 19\,925--19\,934.

\bibitem{zhao2022real}
Y.~Zhao and P.~Kr{\"a}henb{\"u}hl, ``Real-time online video detection with temporal smoothing transformers,'' in \emph{European Conference on Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2022, pp. 485--502.

\bibitem{girdhar2021anticipative}
R.~Girdhar and K.~Grauman, ``Anticipative video transformer,'' in \emph{Proceedings of the IEEE/CVF international conference on computer vision}, 2021, pp. 13\,505--13\,515.

\bibitem{zhao2023learning}
Y.~Zhao, I.~Misra, P.~Kr{\"a}henb{\"u}hl, and R.~Girdhar, ``Learning video representations from large language models,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2023, pp. 6586--6597.

\bibitem{gong2019exploiting}
L.~Gong and Q.~Cheng, ``Exploiting edge features for graph neural networks,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2019, pp. 9211--9219.

\bibitem{song2021learning}
S.~Song, Z.~Shao, S.~Jaiswal, L.~Shen, M.~Valstar, and H.~Gunes, ``Learning graph representation of person-specific cognitive processes from audio-visual behaviours for automatic personality recognition,'' \emph{arXiv preprint arXiv:2110.13570}, 2021.

\bibitem{deo2017learning}
N.~Deo and M.~M. Trivedi, ``Learning and predicting on-road pedestrian behavior around vehicles,'' in \emph{2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2017, pp. 1--6.

\bibitem{xu2019temporal}
M.~Xu, M.~Gao, Y.-T. Chen, L.~S. Davis, and D.~J. Crandall, ``Temporal recurrent networks for online action detection,'' in \emph{Proceedings of the IEEE/CVF international conference on computer vision}, 2019, pp. 5532--5541.

\bibitem{eun2020learning}
H.~Eun, J.~Moon, J.~Park, C.~Jung, and C.~Kim, ``Learning to discriminate information for online action detection,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2020, pp. 809--818.

\bibitem{cho2014learning}
K.~Cho, B.~Van~Merri{\"e}nboer, C.~Gulcehre, D.~Bahdanau, F.~Bougares, H.~Schwenk, and Y.~Bengio, ``Learning phrase representations using rnn encoder-decoder for statistical machine translation,'' \emph{arXiv preprint arXiv:1406.1078}, 2014.

\bibitem{zhao2022progressive}
P.~Zhao, L.~Xie, J.~Wang, Y.~Zhang, and Q.~Tian, ``Progressive privileged knowledge distillation for online action detection,'' \emph{Pattern Recognition}, vol. 129, p. 108741, 2022.

\bibitem{vaswani2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez, {\L}.~Kaiser, and I.~Polosukhin, ``Attention is all you need,'' \emph{Advances in neural information processing systems}, vol.~30, 2017.

\bibitem{wang2021oadtr}
X.~Wang, S.~Zhang, Z.~Qing, Y.~Shao, Z.~Zuo, C.~Gao, and N.~Sang, ``Oadtr: Online action detection with transformers,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2021, pp. 7565--7575.

\bibitem{yang2022colar}
L.~Yang, J.~Han, and D.~Zhang, ``Colar: Effective and efficient online action detection by consulting exemplars,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2022, pp. 3160--3169.

\bibitem{furnari2020rolling}
A.~Furnari and G.~M. Farinella, ``Rolling-unrolling lstms for action anticipation from first-person video,'' \emph{IEEE transactions on pattern analysis and machine intelligence}, vol.~43, no.~11, pp. 4021--4036, 2020.

\bibitem{qi2021self}
Z.~Qi, S.~Wang, C.~Su, L.~Su, Q.~Huang, and Q.~Tian, ``Self-regulated learning for egocentric video activity anticipation,'' \emph{IEEE transactions on pattern analysis and machine intelligence}, vol.~45, no.~6, pp. 6715--6730, 2021.

\bibitem{liu2022hybrid}
T.~Liu and K.-M. Lam, ``A hybrid egocentric activity anticipation framework via memory-augmented recurrent and one-shot representation forecasting,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022, pp. 13\,904--13\,913.

\bibitem{osman2021slowfast}
N.~Osman, G.~Camporese, P.~Coscia, and L.~Ballan, ``Slowfast rolling-unrolling lstms for action anticipation in egocentric videos,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2021, pp. 3437--3445.

\bibitem{roy2024interaction}
D.~Roy, R.~Rajendiran, and B.~Fernando, ``Interaction region visual transformer for egocentric action anticipation,'' in \emph{Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, 2024, pp. 6740--6750.

\bibitem{huang2022learning}
Z.~Huang, J.~Chen, J.~Zhang, and H.~Shan, ``Learning representation for clustering via prototype scattering and positive sampling,'' \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, vol.~45, no.~6, pp. 7509--7524, 2022.

\bibitem{dempster1977maximum}
A.~P. Dempster, N.~M. Laird, and D.~B. Rubin, ``Maximum likelihood from incomplete data via the em algorithm,'' \emph{Journal of the royal statistical society: series B (methodological)}, vol.~39, no.~1, pp. 1--22, 1977.

\bibitem{bresson2017residual}
X.~Bresson and T.~Laurent, ``Residual gated graph convnets,'' \emph{arXiv preprint arXiv:1711.07553}, 2017.

\bibitem{damen2022rescaling}
D.~Damen, H.~Doughty, G.~M. Farinella, A.~Furnari, E.~Kazakos, J.~Ma, D.~Moltisanti, J.~Munro, T.~Perrett, W.~Price \emph{et~al.}, ``Rescaling egocentric vision: Collection, pipeline and challenges for epic-kitchens-100,'' \emph{International Journal of Computer Vision}, pp. 1--23, 2022.

\bibitem{jiang2014thumos}
Y.-G. Jiang, J.~Liu, A.~R. Zamir, G.~Toderici, I.~Laptev, M.~Shah, and R.~Sukthankar, ``Thumos challenge: Action recognition with a large number of classes,'' 2014.

\bibitem{zhou2024smc}
F.~Zhou, Z.~Jiang, H.~Zhou, and X.~Li, ``Smc-nca: Semantic-guided multi-level contrast for semi-supervised temporal action segmentation,'' \emph{IEEE Transactions on Multimedia}, 2024.

\bibitem{guo2024uncertainty}
H.~Guo, N.~Agarwal, S.-Y. Lo, K.~Lee, and Q.~Ji, ``Uncertainty-aware action decoupling transformer for action anticipation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2024, pp. 18\,644--18\,654.

\bibitem{wang2023memory}
J.~Wang, G.~Chen, Y.~Huang, L.~Wang, and T.~Lu, ``Memory-and-anticipation transformer for online action understanding,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2023, pp. 13\,824--13\,835.

\bibitem{furnari2019would}
A.~Furnari and G.~M. Farinella, ``What would you expect? anticipating egocentric actions with rolling-unrolling lstms and modality attention,'' in \emph{Proceedings of the IEEE/CVF International conference on computer vision}, 2019, pp. 6252--6261.

\bibitem{wu2022memvit}
C.-Y. Wu, Y.~Li, K.~Mangalam, H.~Fan, B.~Xiong, J.~Malik, and C.~Feichtenhofer, ``Memvit: Memory-augmented multiscale vision transformer for efficient long-term video recognition,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022, pp. 13\,587--13\,597.

\bibitem{diko2024semantically}
A.~Diko, D.~Avola, B.~Prenkaj, F.~Fontana, and L.~Cinque, ``Semantically guided representation learning for action anticipation,'' in \emph{European Conference on Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2024, pp. 448--466.

\bibitem{xie2024towards}
Z.~Xie, Y.~Shi, K.~Wu, Y.~Cheng, and D.~Guo, ``Towards understanding future: Consistency guided probabilistic modeling for action anticipation,'' in \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, vol.~38, no.~6, 2024, pp. 6243--6251.

\bibitem{gao2017red}
J.~Gao, Z.~Yang, and R.~Nevatia, ``Red: Reinforced encoder-decoder networks for action anticipation,'' \emph{arXiv preprint arXiv:1707.04818}, 2017.

\bibitem{wang2021long}
X.~Wang, S.~Zhang, Z.~Qing, Y.~Shao, Z.~Zuo, C.~Gao, and N.~Sang, ``Long shortterm transformer for online action detection,'' in \emph{ICCV}, vol.~2, no.~5, 2021, p.~7.

\bibitem{foo2024action}
L.~G. Foo, T.~Li, H.~Rahmani, and J.~Liu, ``Action detection via an image diffusion process,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2024, pp. 18\,351--18\,361.

\bibitem{wang2024contextdet}
N.~Wang, Y.~Xiao, X.~Peng, X.~Chang, X.~Wang, and D.~Fang, ``Contextdet: Temporal action detection with adaptive context aggregation,'' \emph{arXiv preprint arXiv:2410.15279}, 2024.

\end{thebibliography}
