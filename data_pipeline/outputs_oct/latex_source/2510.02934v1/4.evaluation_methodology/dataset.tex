\subsection{Dataset Construction}

\label{sec:dataset_construction}
To evaluate the performance of \tool and the baselines, we construct an experimental dataset from several popular benchmarks, including \textit{HumanEval}~\cite{HumanEval}, \textit{MBPP}~\cite{MBPP}, \textit{DevEval}~\cite{li-etal-2024-deveval}, \textit{SecurityEval}~\cite{SecurityEval}, \textit{CWEval}~\cite{Cweval}, \textit{CODEGUARD+}~\cite{CODEGUARD+}, and \textit{SALLM}~\cite{Sallm}.
For each task in these benchmarks, we employed each studied code LLMs to generate 10 candidate solutions.
 
In particular, HumanEval, MBPP, and DevEval focus on functional correctness and are therefore used to construct datasets for evaluating compilability and functionality. The remaining benchmarks are specifically designed to assess security correctness, focusing on identifying potential vulnerabilities in generated code.
%
Following the procedures established in the prior work~\cite{openia}, the benchmark guidelines, and our criteria defined in Sec.\ref{sec:problem_formulation}, we assign correctness labels to each generated solution as follows:
\begin{itemize}
    \item \textit{Compilability}: A solution is labeled \textit{correct} if it is successfully executed by the Python 3 interpreter; otherwise, it is labeled \textit{incorrect}.
    \item \textit{Functionality}: A solution is labeled \textit{correct} if it passes all provided test cases for the corresponding task; otherwise, \textit{incorrect}.
    \item \textit{Security}: A solution is labeled \textit{correct} if it passes all checks from two widely used static analyzers, Bandit~\cite{bandit} and CodeQL~\cite{codeql}; otherwise, \textit{incorrect}.
\end{itemize}
%
%
Table~\ref{tab:dataset_com_func} and Table~\ref{tab:dataset_security} summarize the numbers of correct and incorrect code generated by each studied model for the given benchmarks and criteria.
%
%
The complete dataset, including generated code, the corresponding internal representations extracted from the studied code LLMs, and their correctness labels, could be found on our website~\cite{website}.


\input{tables/tab_dataset_com_func}
\input{tables/tab_dataset_security}