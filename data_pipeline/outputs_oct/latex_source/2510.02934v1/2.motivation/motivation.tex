\subsection{Motivation}

\begin{figure}
\centering
\begin{subfigure}{\columnwidth}
\centering
\includegraphics[width=1\columnwidth]{images/motivation_Deepseek.png}
\caption{\deepseek}
\label{fig:motivation_deepseek}
\end{subfigure}\\
\begin{subfigure}{\columnwidth}
\centering
\includegraphics[width=1\columnwidth]{images/motivation_CodeLlama.png}
\caption{\codellama}
\label{fig:motivation_codellama}
\end{subfigure}\\
\begin{subfigure}{\columnwidth}
\centering
\includegraphics[width=1\columnwidth]{images/motivation_MagicCoder.png}
\caption{\magiccoder}
\label{fig:motivation_magiccoder}
\end{subfigure}

\caption{The performance in F1-score of functionality assessment using internal states from different tokens and layers across various code LLMs}
\label{fig:motivation}
\end{figure}


Inspired by the procedure in \openia~\cite{openia}, we conducted an empirical study to assess the functional correctness of code generated by \deepseek-6.7B, \codellama-7B, and \magiccoder-7B using their internal representations. 
%
For HumanEval~\cite{HumanEval} and MBPP~\cite{MBPP} benchmarks, we employed each studied model to generate 10 solutions per task.
%
The functional correctness of each solution is determined by using the provided test cases; these resulting datasets are summarized in Table~\ref{tab:preliminary_data_summarize}. 
%

\input{tables/tab_preliminary_study}

For each code LLM, we trained a probing classifier on its internal representations extracted from different layers and token positions during code generation for MBPP tasks. 
%
The classifier was subsequently evaluated on its ability to predict the correctness of the solutions for HumanEval tasks. In this experiment, representations were extracted from four specific token positions: \texttt{first token} and \texttt{last token} (marking the start and end of the full generated sequence), and \texttt{first code token} and \texttt{last code token} (marking the start and end of the code snippet itself).


Figure~\ref{fig:motivation} shows the performance of probing classifiers using internal representations from various layers and token positions for the studied model. 
%
The results reveal a key challenge: \textbf{\textit{the code correctness assessment performance varies significantly across models, layers, and token positions}}. 
%   

First, the choice of token position plays a crucial role in the predictive performance of internal representations, with notable variation across models.
%
%
For instance, in \deepseek and \magiccoder, the highest performance is achieved using the internal representations of the \texttt{last token}, while in \codellama, the best results are observed from the hidden states of the \texttt{last code token}. Conversely, the representations at \texttt{first token}, while being the least informative for both \deepseek and \codellama, provide comparatively strong signals in \magiccoder.

Moreover, the predictive performance varies significantly across layers, even for the same token position. 
%
In \magiccoder, the performance improves with layer depth, i.e., the F1-score for the \texttt{last token} at the \texttt{final layer} reaches 0.69, which is 40\% higher than that at the \texttt{first layer}. 
%
In contrast, \deepseek exhibits remarkably stable performance across layers, maintaining a high F1-score for the \texttt{last token} representations.
%
\codellama shows highly inconsistent patterns. For the \texttt{last token}, better performance is observed at \texttt{early and middle layers}, while for the \texttt{last code token}, the best F1-scores are achieved using representations from the \texttt{middle and final layers}.

These findings suggest that the optimal internal representations for code correctness assessment are highly model-dependent, with the most effective layers and token positions varying significantly across models.
%
In other words, \textit{no single layer or token position consistently captures correctness signals across all models}.
%
This highlights the need for a general solution that can \textbf{\textit{dynamically and automatically select the most informative internal states}}, enabling reliable correctness assessment in a model-agnostic manner.