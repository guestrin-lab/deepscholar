\begin{thebibliography}{10}
\expandafter\ifx\csname url\endcsname\relax
  \def\url#1{\texttt{#1}}\fi
\expandafter\ifx\csname urlprefix\endcsname\relax\def\urlprefix{URL }\fi
\expandafter\ifx\csname href\endcsname\relax
  \def\href#1#2{#2} \def\path#1{#1}\fi

\bibitem{HumanEval}
M.~Chen, J.~Tworek, H.~Jun, Q.~Yuan, H.~P. d.~O. Pinto, J.~Kaplan, H.~Edwards, Y.~Burda, N.~Joseph, G.~Brockman, et~al., Evaluating large language models trained on code, arXiv preprint arXiv:2107.03374.

\bibitem{rambo}
T.-D. Bui, D.-T. Luu-Van, T.-P. Nguyen, T.-T. Nguyen, S.~Nguyen, H.~D. Vo, Rambo: Enhancing rag-based repository-level method body completion, arXiv preprint arXiv:2409.15204.

\bibitem{zhang2023repocoder}
F.~Zhang, B.~Chen, Y.~Zhang, J.~Keung, J.~Liu, D.~Zan, Y.~Mao, J.-G. Lou, W.~Chen, Repocoder: Repository-level code completion through iterative retrieval and generation, in: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, 2023, pp. 2471--2484.

\bibitem{zheng2025towards}
Z.~Zheng, K.~Ning, Q.~Zhong, J.~Chen, W.~Chen, L.~Guo, W.~Wang, Y.~Wang, Towards an understanding of large language models in software engineering tasks, Empirical Software Engineering 30~(2) (2025) 50.

\bibitem{dai2025comprehensive}
S.-C. Dai, J.~Xu, G.~Tao, A comprehensive study of llm secure code generation, arXiv preprint arXiv:2503.15554.

\bibitem{github_copilot}
\href{https://github.com/features/copilot}{Github copilot}.
\newline\urlprefix\url{https://github.com/features/copilot}

\bibitem{codegeex2}
\href{https://github.com/zai-org/CodeGeeX2}{Codegeex2}.
\newline\urlprefix\url{https://github.com/zai-org/CodeGeeX2}

\bibitem{deepseek-coder}
DeepSeek, Deepseek coder: Let the code write itself, \url{https://github.com/deepseek-ai/DeepSeek-Coder} (2023).

\bibitem{codellama}
B.~Roziere, J.~Gehring, F.~Gloeckle, S.~Sootla, I.~Gat, X.~E. Tan, Y.~Adi, J.~Liu, T.~Remez, J.~Rapin, et~al., Code llama: Open foundation models for code, arXiv preprint arXiv:2308.12950.

\bibitem{MBPP}
J.~Austin, A.~Odena, M.~Nye, M.~Bosma, H.~Michalewski, D.~Dohan, E.~Jiang, C.~Cai, M.~Terry, Q.~Le, et~al., Program synthesis with large language models, arXiv preprint arXiv:2108.07732.

\bibitem{liu2023your}
J.~Liu, C.~S. Xia, Y.~Wang, L.~Zhang, Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation, Advances in Neural Information Processing Systems 36 (2023) 21558--21572.

\bibitem{li-etal-2024-deveval}
J.~Li, G.~Li, Y.~Zhao, Y.~Li, H.~Liu, H.~Zhu, L.~Wang, K.~Liu, Z.~Fang, L.~Wang, J.~Ding, X.~Zhang, Y.~Zhu, Y.~Dong, Z.~Jin, B.~Li, F.~Huang, Y.~Li, B.~Gu, M.~Yang, \href{https://aclanthology.org/2024.findings-acl.214/}{{D}ev{E}val: A manually-annotated code generation benchmark aligned with real-world code repositories}, in: L.-W. Ku, A.~Martins, V.~Srikumar (Eds.), Findings of the Association for Computational Linguistics: ACL 2024, Association for Computational Linguistics, Bangkok, Thailand, 2024, pp. 3603--3614.
\newblock \href {http://dx.doi.org/10.18653/v1/2024.findings-acl.214} {\path{doi:10.18653/v1/2024.findings-acl.214}}.
\newline\urlprefix\url{https://aclanthology.org/2024.findings-acl.214/}

\bibitem{perry2023users}
N.~Perry, M.~Srivastava, D.~Kumar, D.~Boneh, Do users write more insecure code with ai assistants?, in: Proceedings of the 2023 ACM SIGSAC conference on computer and communications security, 2023, pp. 2785--2799.

\bibitem{liu2024no}
Z.~Liu, Y.~Tang, X.~Luo, Y.~Zhou, L.~F. Zhang, No need to lift a finger anymore? assessing the quality of code generation by chatgpt, IEEE Transactions on Software Engineering 50~(6) (2024) 1548--1584.

\bibitem{tihanyi2025secure}
N.~Tihanyi, T.~Bisztray, M.~A. Ferrag, R.~Jain, L.~C. Cordeiro, How secure is ai-generated code: A large-scale comparison of large language models, Empirical Software Engineering 30~(2) (2025) 47.

\bibitem{msr2023-prem-llm-code-bugs}
K.~Jesse, T.~Ahmed, P.~T. Devanbu, E.~Morgan, Large language models and simple, stupid bugs, in: 2023 IEEE/ACM 20th International Conference on Mining Software Repositories (MSR), IEEE, 2023, pp. 563--575.

\bibitem{llm-code-bugs1}
F.~Tambon, A.~M. Dakhel, A.~Nikanjam, F.~Khomh, M.~C. Desmarais, G.~Antoniol, Bugs in large language models generated code, arXiv preprint arXiv:2403.08937.

\bibitem{code-quality-chagpt}
Z.~Liu, Y.~Tang, X.~Luo, Y.~Zhou, L.~F. Zhang, No need to lift a finger anymore? assessing the quality of code generation by chatgpt, IEEE Transactions on Software Engineering.

\bibitem{evaluating-chatgpt}
J.~Liu, C.~S. Xia, Y.~Wang, L.~Zhang, Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation, Advances in Neural Information Processing Systems 36.

\bibitem{survey_3}
H.~Krasner, The cost of poor software quality in the us: a 2022 report, Consortium for Information and Software Quality (CISQ).

\bibitem{survey-icse24}
J.~T. Liang, C.~Yang, B.~A. Myers, A large-scale survey on the usability of ai programming assistants: Successes and challenges, in: Proceedings of the 46th IEEE/ACM International Conference on Software Engineering, 2024, pp. 1--13.

\bibitem{expectation}
P.~Vaithilingam, T.~Zhang, E.~L. Glassman, Expectation vs. experience: Evaluating the usability of code generation tools powered by large language models, in: Chi conference on human factors in computing systems extended abstracts, 2022, pp. 1--7.

\bibitem{embedding_emse22}
Z.~Ding, H.~Li, W.~Shang, T.-H.~P. Chen, Can pre-trained code embeddings improve model performance? revisiting the use of code embeddings in software engineering tasks, Empirical Software Engineering 27~(3) (2022) 1--38.

\bibitem{opt-pretrained-model}
Y.~Zhao, L.~Gong, Z.~Huang, Y.~Wang, M.~Wei, F.~Wu, Coding-ptms: How to find optimal code pre-trained models for code embedding in vulnerability detection?, in: Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering, 2024, pp. 1732--1744.

\bibitem{pretrained-survey}
C.~Niu, C.~Li, B.~Luo, V.~Ng, Deep learning meets software engineering: A survey on pre-trained models of source code, in: Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, {IJCAI-22}, 2022, pp. 5546--5555.

\bibitem{codebert}
Z.~Feng, D.~Guo, D.~Tang, N.~Duan, X.~Feng, M.~Gong, L.~Shou, B.~Qin, T.~Liu, D.~Jiang, M.~Zhou, {C}ode{BERT}: A pre-trained model for programming and natural languages, in: Findings of the Association for Computational Linguistics: EMNLP 2020, Association for Computational Linguistics, Online, 2020, pp. 1536--1547.

\bibitem{codet5}
Y.~Wang, W.~Wang, S.~Joty, S.~C. Hoi, Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation, in: Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 2021, pp. 8696--8708.

\bibitem{openia}
Correctness assessment of code generated by large language models using internal representations, Journal of Systems and Software 230 (2025) 112570.
\newblock \href {http://dx.doi.org/https://doi.org/10.1016/j.jss.2025.112570} {\path{doi:https://doi.org/10.1016/j.jss.2025.112570}}.

\bibitem{internal-state-2}
Z.~Ji, D.~Chen, E.~Ishii, S.~Cahyawijaya, Y.~Bang, B.~Wilie, P.~Fung, Llm internal states reveal hallucination risk faced with a query, in: Proceedings of the 7th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP, 2024, pp. 88--104.

\bibitem{inner-working}
J.~Ferrando, G.~Sarti, A.~Bisazza, M.~R. Costa-juss{\`a}, A primer on the inner workings of transformer-based language models, arXiv preprint arXiv:2405.00208.

\bibitem{probing}
S.~Zhao, T.~Nguyen, A.~Grover, Probing the decision boundaries of in-context learning in large language models, Advances in Neural Information Processing Systems 37 (2024) 130408--130432.

\bibitem{internal-state}
A.~Azaria, T.~Mitchell, The internal state of an llm knows when it’s lying, in: Findings of the Association for Computational Linguistics: EMNLP 2023, 2023, pp. 967--976.

\bibitem{inside}
C.~Chen, K.~Liu, Z.~Chen, Y.~Gu, Y.~Wu, M.~Tao, Z.~Fu, J.~Ye, Inside: Llms' internal states retain the power of hallucination detection, arXiv preprint arXiv:2402.03744.

\bibitem{floridi2020gpt}
L.~Floridi, M.~Chiriatti, Gpt-3: Its nature, scope, limits, and consequences, Minds and machines 30~(4) (2020) 681--694.

\bibitem{anil2023palm}
R.~Anil, A.~M. Dai, O.~Firat, M.~Johnson, D.~Lepikhin, A.~Passos, S.~Shakeri, E.~Taropa, P.~Bailey, Z.~Chen, et~al., Palm 2 technical report, arXiv preprint arXiv:2305.10403.

\bibitem{touvron2023llama}
H.~Touvron, T.~Lavril, G.~Izacard, X.~Martinet, M.-A. Lachaux, T.~Lacroix, B.~Rozi{\`e}re, N.~Goyal, E.~Hambro, F.~Azhar, et~al., Llama: Open and efficient foundation language models, arXiv preprint arXiv:2302.13971.

\bibitem{minaee2024large}
S.~Minaee, T.~Mikolov, N.~Nikzad, M.~Chenaghlu, R.~Socher, X.~Amatriain, J.~Gao, Large language models: A survey, arXiv preprint arXiv:2402.06196.

\bibitem{ji2024zero}
B.~Ji, X.~Duan, Y.~Zhang, K.~Wu, M.~Zhang, Zero-shot prompting for llm-based machine translation using in-domain target sentences, IEEE/ACM Transactions on Audio, Speech, and Language Processing.

\bibitem{zhang2025systematic}
H.~Zhang, P.~S. Yu, J.~Zhang, A systematic survey of text summarization: From statistical methods to large language models, ACM Computing Surveys 57~(11) (2025) 1--41.

\bibitem{li2024flexkbqa}
Z.~Li, S.~Fan, Y.~Gu, X.~Li, Z.~Duan, B.~Dong, N.~Liu, J.~Wang, Flexkbqa: A flexible llm-powered framework for few-shot knowledge base question answering, in: Proceedings of the AAAI conference on artificial intelligence, Vol.~38, 2024, pp. 18608--18616.

\bibitem{magicoder}
Y.~Wei, Z.~Wang, J.~Liu, Y.~Ding, L.~Zhang, Magicoder: Source code is all you need, arXiv preprint arXiv:2312.02120.

\bibitem{wang2025can}
R.~Wang, J.~Guo, C.~Gao, G.~Fan, C.~Y. Chong, X.~Xia, Can llms replace human evaluators? an empirical study of llm-as-a-judge in software engineering, Proceedings of the ACM on Software Engineering 2~(ISSTA) (2025) 1955--1977.

\bibitem{bui2024rambo}
T.-D. Bui, D.-T. Luu-Van, T.-P. Nguyen, T.-T. Nguyen, S.~Nguyen, H.~D. Vo, Rambo: Enhancing rag-based repository-level method body completion, arXiv preprint arXiv:2409.15204.

\bibitem{chen2024chatunitest}
Y.~Chen, Z.~Hu, C.~Zhi, J.~Han, S.~Deng, J.~Yin, Chatunitest: A framework for llm-based test generation, in: Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering, 2024, pp. 572--576.

\bibitem{zhang2025llm}
Z.~Zhang, C.~Wang, Y.~Wang, E.~Shi, Y.~Ma, W.~Zhong, J.~Chen, M.~Mao, Z.~Zheng, Llm hallucinations in practical code generation: Phenomena, mechanism, and mitigation, Proceedings of the ACM on Software Engineering 2~(ISSTA) (2025) 481--503.

\bibitem{llmcheck}
G.~Sriramanan, S.~Bharti, V.~S. Sadasivan, S.~Saha, P.~Kattakinda, S.~Feizi, Llm-check: Investigating detection of hallucinations in large language models, Advances in Neural Information Processing Systems 37 (2024) 34188--34216.

\bibitem{zhang2025icr}
Z.~Zhang, X.~Hu, H.~Zhang, J.~Zhang, X.~Wan, Icr probe: Tracking hidden state dynamics for reliable hallucination detection in llms, arXiv preprint arXiv:2507.16488.

\bibitem{al2011software}
A.~B. Al-Badareen, M.~H. Selamat, M.~A.~Jabar, J.~Din, S.~Turaev, Software quality models: A comparative study, in: International Conference on Software Engineering and Computer Systems, Springer, 2011, pp. 46--55.

\bibitem{yin2024characterizing}
F.~Yin, J.~Srinivasa, K.-W. Chang, Characterizing truthfulness in large language model generations with local intrinsic dimension, in: Proceedings of the 41st International Conference on Machine Learning, 2024, pp. 57069--57084.

\bibitem{snyder2024early}
B.~Snyder, M.~Moisescu, M.~B. Zafar, On early detection of hallucinations in factual question answering, in: Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, 2024, pp. 2721--2732.

\bibitem{SecurityEval}
M.~L. Siddiq, J.~C. Santos, Securityeval dataset: mining vulnerability examples to evaluate machine learning-based code generation techniques, in: Proceedings of the 1st International Workshop on Mining Software Repositories Applications for Privacy and Security, 2022, pp. 29--33.

\bibitem{Cweval}
J.~Peng, L.~Cui, K.~Huang, J.~Yang, B.~Ray, Cweval: Outcome-driven evaluation on functionality and security of llm code generation, in: 2025 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code), IEEE, 2025, pp. 33--40.

\bibitem{CODEGUARD+}
Y.~Fu, E.~Baker, Y.~Ding, Y.~Chen, Constrained decoding for secure code generation, arXiv preprint arXiv:2405.00218.

\bibitem{Sallm}
M.~L. Siddiq, J.~C. da~Silva~Santos, S.~Devareddy, A.~Muller, Sallm: Security assessment of generated code, in: Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering Workshops, 2024, pp. 54--65.

\bibitem{bandit}
\href{https://bandit.readthedocs.io/en/latest/}{Bandit}.
\newline\urlprefix\url{https://bandit.readthedocs.io/en/latest/}

\bibitem{codeql}
\href{https://codeql.github.com}{Codeql}.
\newline\urlprefix\url{https://codeql.github.com}

\bibitem{website}
T.~T. Vu, T.-D. Bui, T.-T. Nguyen, S.~Nguyen, D.~H. Vo, \href{https://github.com/iSE-UET-VNU/AUTOPROBE}{Model-agnostic correctness assessment for llm-generated code via dynamic internal representation selection}.
\newline\urlprefix\url{https://github.com/iSE-UET-VNU/AUTOPROBE}

\bibitem{codegemma}
C.~Team, H.~Zhao, J.~Hui, J.~Howland, N.~Nguyen, S.~Zuo, A.~Hu, C.~A. Choquette-Choo, J.~Shen, J.~Kelley, et~al., Codegemma: Open code models based on gemma, arXiv preprint arXiv:2406.11409.

\bibitem{lookback}
Y.-S. Chuang, L.~Qiu, C.-Y. Hsieh, R.~Krishna, Y.~Kim, J.~Glass, Lookback lens: Detecting and mitigating contextual hallucinations in large language models using only attention maps, in: Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, 2024, pp. 1419--1436.

\bibitem{cubert}
A.~Kanade, P.~Maniatis, G.~Balakrishnan, K.~Shi, Learning and evaluating contextual embedding of source code, in: Proceedings of the 37th International Conference on Machine Learning, ICML'20, JMLR.org, 2020.

\bibitem{jiang2024tracing}
J.~Jiang, J.~Zhou, Z.~Zhu, Tracing representation progression: Analyzing and enhancing layer-wise similarity, arXiv preprint arXiv:2406.14479.

\bibitem{wei2023empirical}
F.~Wei, R.~Keeling, N.~Huber-Fliflet, J.~Zhang, A.~Dabrowski, J.~Yang, Q.~Mao, H.~Qin, Empirical study of llm fine-tuning for text classification in legal document review, in: 2023 IEEE international conference on big data (BigData), IEEE, 2023, pp. 2786--2792.

\bibitem{zhang2025teleclass}
Y.~Zhang, R.~Yang, X.~Xu, R.~Li, J.~Xiao, J.~Shen, J.~Han, Teleclass: Taxonomy enrichment and llm-enhanced hierarchical text classification with minimal supervision, in: Proceedings of the ACM on Web Conference 2025, 2025, pp. 2032--2042.

\bibitem{zhang2024vision}
J.~Zhang, J.~Huang, S.~Jin, S.~Lu, Vision-language models for vision tasks: A survey, IEEE transactions on pattern analysis and machine intelligence 46~(8) (2024) 5625--5644.

\bibitem{chen2024vitamin}
J.~Chen, Q.~Yu, X.~Shen, A.~Yuille, L.-C. Chen, Vitamin: Designing scalable vision models in the vision-language era, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2024, pp. 12954--12966.

\bibitem{mu2024clarifygpt}
F.~Mu, L.~Shi, S.~Wang, Z.~Yu, B.~Zhang, C.~Wang, S.~Liu, Q.~Wang, Clarifygpt: A framework for enhancing llm-based code generation via requirements clarification, Proceedings of the ACM on Software Engineering 1~(FSE) (2024) 2332--2354.

\bibitem{wang2024hits}
Z.~Wang, K.~Liu, G.~Li, Z.~Jin, Hits: High-coverage llm-based unit test generation via method slicing, in: Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering, 2024, pp. 1258--1268.

\bibitem{sun2024source}
W.~Sun, Y.~Miao, Y.~Li, H.~Zhang, C.~Fang, Y.~Liu, G.~Deng, Y.~Liu, Z.~Chen, Source code summarization in the era of large language models, in: 2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE), IEEE Computer Society, 2024, pp. 419--431.

\bibitem{jin2023inferfix}
M.~Jin, S.~Shahriar, M.~Tufano, X.~Shi, S.~Lu, N.~Sundaresan, A.~Svyatkovskiy, Inferfix: End-to-end program repair with llms, in: Proceedings of the 31st ACM joint european software engineering conference and symposium on the foundations of software engineering, 2023, pp. 1646--1656.

\bibitem{liu2024exploring}
F.~Liu, Y.~Liu, L.~Shi, H.~Huang, R.~Wang, Z.~Yang, L.~Zhang, Z.~Li, Y.~Ma, Exploring and evaluating hallucinations in llm-powered code generation, arXiv preprint arXiv:2404.00971.

\bibitem{wang2025towards}
Z.~Wang, Z.~Zhou, D.~Song, Y.~Huang, S.~Chen, L.~Ma, T.~Zhang, Towards understanding the characteristics of code generation errors made by large language models, in: 2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE), IEEE Computer Society, 2025, pp. 717--717.

\bibitem{manakul2023selfcheckgpt}
P.~Manakul, A.~Liusie, M.~Gales, Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models, in: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, 2023, pp. 9004--9017.

\bibitem{huang2025survey}
L.~Huang, W.~Yu, W.~Ma, W.~Zhong, Z.~Feng, H.~Wang, Q.~Chen, W.~Peng, X.~Feng, B.~Qin, et~al., A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions, ACM Transactions on Information Systems 43~(2) (2025) 1--55.

\bibitem{farquhar2024detecting}
S.~Farquhar, J.~Kossen, L.~Kuhn, Y.~Gal, Detecting hallucinations in large language models using semantic entropy, Nature 630~(8017) (2024) 625--630.

\bibitem{zhang2024self}
X.~Zhang, B.~Peng, Y.~Tian, J.~Zhou, L.~Jin, L.~Song, H.~Mi, H.~Meng, Self-alignment for factuality: Mitigating hallucinations in llms via self-evaluation, in: Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2024, pp. 1946--1965.

\bibitem{zhang2024knowhalu}
J.~Zhang, C.~Xu, Y.~Gai, F.~Lecue, D.~Song, B.~Li, Knowhalu: Hallucination detection via multi-form knowledge based factual checking, arXiv preprint arXiv:2404.02935.

\bibitem{zhou2021detecting}
C.~Zhou, G.~Neubig, J.~Gu, M.~Diab, F.~Guzm{\'a}n, L.~Zettlemoyer, M.~Ghazvininejad, Detecting hallucinated content in conditional neural sequence generation, in: Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, 2021, pp. 1393--1404.

\bibitem{huang2023look}
Y.~Huang, J.~Song, Z.~Wang, S.~Zhao, H.~Chen, F.~Juefei-Xu, L.~Ma, Look before you leap: An exploratory study of uncertainty measurement for large language models, arXiv preprint arXiv:2307.10236.

\bibitem{augenstein2024factuality}
I.~Augenstein, T.~Baldwin, M.~Cha, T.~Chakraborty, G.~L. Ciampaglia, D.~Corney, R.~DiResta, E.~Ferrara, S.~Hale, A.~Halevy, et~al., Factuality challenges in the era of large language models and opportunities for fact-checking, Nature Machine Intelligence 6~(8) (2024) 852--863.

\bibitem{hu2024knowledge}
X.~Hu, D.~Ru, L.~Qiu, Q.~Guo, T.~Zhang, Y.~Xu, Y.~Luo, P.~Liu, Y.~Zhang, Z.~Zhang, Knowledge-centric hallucination detection, in: Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, 2024, pp. 6953--6975.

\bibitem{factoscope}
J.~He, Y.~Gong, Z.~Lin, Y.~Zhao, K.~Chen, et~al., Llm factoscope: Uncovering llms’ factual discernment through measuring inner states, in: Findings of the Association for Computational Linguistics ACL 2024, 2024, pp. 10218--10230.

\bibitem{croft2021empirical}
R.~Croft, D.~Newlands, Z.~Chen, M.~A. Babar, An empirical study of rule-based and learning-based approaches for static application security testing, in: Proceedings of the 15th ACM/IEEE international symposium on empirical software engineering and measurement (ESEM), 2021, pp. 1--12.

\bibitem{zhang2020graph}
J.~Zhang, H.~Zhang, C.~Xia, L.~Sun, Graph-bert: Only attention is needed for learning graph representations, arXiv preprint arXiv:2001.05140.

\bibitem{ivdetect}
Y.~Li, S.~Wang, T.~N. Nguyen, Vulnerability detection with fine-grained interpretations, in: Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, 2021, pp. 292--303.

\bibitem{COSTA}
T.-T. Nguyen, H.~D. Vo, Context-based statement-level vulnerability localization, Information and Software Technology 169 (2024) 107406.

\bibitem{velvet}
Y.~Ding, S.~Suneja, Y.~Zheng, J.~Laredo, A.~Morari, G.~Kaiser, B.~Ray, Velvet: a novel ensemble learning approach to automatically locate vulnerable statements, in: 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering, IEEE, 2022, pp. 959--970.

\bibitem{linevd}
D.~Hin, A.~Kan, H.~Chen, M.~A. Babar, Linevd: Statement-level vulnerability detection using graph neural networks, in: {IEEE/ACM} 19th International Conference on Mining Software Repositories, {MSR} 2022, Pittsburgh, PA, USA, May 23-24, 2022, {IEEE}, 2022, pp. 596--607.

\bibitem{linevul}
M.~Fu, C.~Tantithamthavorn, Linevul: A transformer-based line-level vulnerability prediction, in: 2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR), IEEE Computer Society, Los Alamitos, CA, USA, 2022, pp. 608--620.

\bibitem{lost-at-c}
G.~Sandoval, H.~Pearce, T.~Nys, R.~Karri, S.~Garg, B.~Dolan-Gavitt, Lost at c: A user study on the security implications of large language model code assistants, in: 32nd USENIX Security Symposium (USENIX Security 23), 2023, pp. 2205--2222.

\bibitem{empirical-study-2}
D.~Song, Z.~Zhou, Z.~Wang, Y.~Huang, S.~Chen, B.~Kou, L.~Ma, T.~Zhang, An empirical study of code generation errors made by large language models, in: 7th Annual Symposium on Machine Programming, 2023.

\bibitem{llm-gen-code-emp-study}
A.~Mohsin, H.~Janicke, A.~Wood, I.~H. Sarker, L.~Maglaras, N.~Janjua, Can we trust large language models generated code? a framework for in-context learning, security patterns, and code evaluations across diverse llms, arXiv preprint arXiv:2406.12513.

\bibitem{calibration}
C.~Spiess, D.~Gros, K.~S. Pai, M.~Pradel, M.~R.~I. Rabin, A.~Alipour, S.~Jha, P.~Devanbu, T.~Ahmed, Calibration and correctness of language models for code, arXiv preprint arXiv:2402.02047.

\bibitem{vulnerabilities-copilot}
Y.~Fu, P.~Liang, A.~Tahir, Z.~Li, M.~Shahin, J.~Yu, J.~Chen, Security weaknesses of copilot generated code in github, arXiv preprint arXiv:2310.02059.

\bibitem{llm-security-guard}
A.~Kavian, M.~M. Pourhashem~Kallehbasti, S.~Kazemi, E.~Firouzi, M.~Ghafari, Llm security guard for code, in: Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering, 2024, pp. 600--603.

\bibitem{autosafecoder}
A.~Nunez, N.~T. Islam, S.~K. Jha, P.~Najafirad, Autosafecoder: A multi-agent framework for securing llm code generation through static analysis and fuzz testing, arXiv preprint arXiv:2409.10737.

\end{thebibliography}
