\begin{thebibliography}{22}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Joi()]{JointQuestionnaire}
{WVS Database}.
\newblock URL \url{https://www.worldvaluessurvey.org/WVSEVSjoint2017.jsp}.
\newblock [https://www.worldvaluessurvey.org/WVSEVSjoint2017.jsp].

\bibitem[Pol()]{PoliticalCompassTest}
{The Political Compass}.
\newblock URL \url{https://www.politicalcompass.org/test}.
\newblock [https://www.politicalcompass.org/test].

\bibitem[Advisor and Lohmann(2024)]{GoodmanFacultyAdvisor2024}
Neomi Goodman~Faculty Advisor and Professor~Susanne Lohmann.
\newblock How harmful is the political bias in chatgpt?
\newblock Technical report, 2024.

\bibitem[Faulborn et~al.(2025)Faulborn, Sen, Pellert, Spitz, and Garcia]{Faulborn2025}
Mats Faulborn, Indira Sen, Max Pellert, Andreas Spitz, and David Garcia.
\newblock Only a little to the left: A theory-grounded measure of political bias in large language models.
\newblock 7 2025.
\newblock URL \url{http://arxiv.org/abs/2503.16148}.

\bibitem[Feng et~al.(2023)Feng, Park, Liu, and Tsvetkov]{feng-etal-2023-pretraining}
Shangbin Feng, Chan~Young Park, Yuhan Liu, and Yulia Tsvetkov.
\newblock From pretraining data to language models to downstream tasks: Tracking the trails of political biases leading to unfair {NLP} models.
\newblock In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki, editors, \emph{Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 11737--11762, Toronto, Canada, July 2023. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2023.acl-long.656}.
\newblock URL \url{https://aclanthology.org/2023.acl-long.656/}.

\bibitem[Fisher et~al.(2025)Fisher, Feng, Aron, Richardson, Choi, Fisher, Pan, Tsvetkov, and Reinecke]{Fisher2025}
Jillian Fisher, Shangbin Feng, Robert Aron, Thomas Richardson, Yejin Choi, Daniel~W Fisher, Jennifer Pan, Yulia Tsvetkov, and Katharina Reinecke.
\newblock Biased llms can influence political decision-making.
\newblock In \emph{Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 6559--6607. Association for Computational Linguistics, 2025.
\newblock \doi{10.18653/v1/2025.acl-long.328}.

\bibitem[Gallegos et~al.(2024)Gallegos, Rossi, Barrow, Tanjim, Kim, Dernoncourt, Yu, Zhang, and Ahmed]{Gallegos2024}
Isabel~O. Gallegos, Ryan~A. Rossi, Joe Barrow, Md~Mehrab Tanjim, Sungchul Kim, Franck Dernoncourt, Tong Yu, Ruiyi Zhang, and Nesreen~K. Ahmed.
\newblock Bias and fairness in large language models: A survey.
\newblock \emph{Computational Linguistics}, 50:\penalty0 1097--1179, 9 2024.
\newblock ISSN 0891-2017.
\newblock \doi{10.1162/coli_a_00524}.

\bibitem[Messer(2025)]{Messer2025}
Uwe Messer.
\newblock How do people react to political bias in generative artificial intelligence (ai)?
\newblock \emph{Computers in Human Behavior: Artificial Humans}, 3:\penalty0 100108, 3 2025.
\newblock ISSN 29498821.
\newblock \doi{10.1016/j.chbah.2024.100108}.

\bibitem[Motoki et~al.(2025)Motoki, Neto, and Rangel]{Motoki2025}
Fabio Y~S Motoki, Valdemar~Pinho Neto, and Victor Rangel.
\newblock Assessing political bias and value misalignment in generative artificial intelligence.
\newblock 2025.
\newblock \doi{10.7910/DVN/VZ}.
\newblock URL \url{https://doi.org/10.7910/DVN/VZ}.

\bibitem[Nawale et~al.(2025)Nawale, Khan, D, Gupta, Pruthi, and Khapra]{nawale2025fairitalesevaluationfairness}
Janki~Atul Nawale, Mohammed Safi Ur~Rahman Khan, Janani D, Mansi Gupta, Danish Pruthi, and Mitesh~M. Khapra.
\newblock Fairi tales: Evaluation of fairness in indian contexts with a focus on bias and stereotypes, 2025.
\newblock URL \url{https://arxiv.org/abs/2506.23111}.

\bibitem[Peng et~al.(2024)Peng, Yang, Lee, Li, Chu, Lin, and Liu]{Peng2024}
Tai-Quan Peng, Kaiqi Yang, Sanguk Lee, Hang Li, Yucheng Chu, Yuping Lin, and Hui Liu.
\newblock Beyond partisan leaning: A comparative analysis of political bias in large language models llms and political bias.
\newblock Technical report, 2024.

\bibitem[Ranjan et~al.(2024)Ranjan, Gupta, and Singh]{ranjan2024comprehensivesurveybiasllms}
Rajesh Ranjan, Shailja Gupta, and Surya~Narayan Singh.
\newblock A comprehensive survey of bias in llms: Current landscape and future directions, 2024.
\newblock URL \url{https://arxiv.org/abs/2409.16430}.

\bibitem[Rettenberger et~al.(2025)Rettenberger, Reischl, and Schutera]{Rettenberger2025}
Luca Rettenberger, Markus Reischl, and Mark Schutera.
\newblock Assessing political bias in large language models.
\newblock \emph{Journal of Computational Social Science}, 8:\penalty0 42, 5 2025.
\newblock ISSN 2432-2717.
\newblock \doi{10.1007/s42001-025-00376-w}.

\bibitem[Rotaru et~al.(2024)Rotaru, Anagnoste, and Oancea]{Rotaru2024}
George-Cristinel Rotaru, Sorin Anagnoste, and Vasile-Marian Oancea.
\newblock How artificial intelligence can influence elections: Analyzing the large language models (llms) political bias.
\newblock \emph{Proceedings of the International Conference on Business Excellence}, 18:\penalty0 1882--1891, 6 2024.
\newblock \doi{10.2478/picbe-2024-0158}.

\bibitem[Rozado(2023)]{Rozado2023}
David Rozado.
\newblock The political biases of chatgpt.
\newblock \emph{Social Sciences}, 12, 2023.
\newblock ISSN 2076-0760.
\newblock \doi{10.3390/socsci12030148}.
\newblock URL \url{https://www.mdpi.com/2076-0760/12/3/148}.

\bibitem[Rozado(2025)]{rozado2025measuringpoliticalpreferencesai}
David Rozado.
\newblock Measuring political preferences in ai systems: An integrative approach, 2025.
\newblock URL \url{https://arxiv.org/abs/2503.10649}.

\bibitem[Röttger et~al.(2024)Röttger, Hofmann, Pyatkin, Hinck, Kirk, Schütze, and Hovy]{röttger2024politicalcompassspinningarrow}
Paul Röttger, Valentin Hofmann, Valentina Pyatkin, Musashi Hinck, Hannah~Rose Kirk, Hinrich Schütze, and Dirk Hovy.
\newblock Political compass or spinning arrow? towards more meaningful evaluations for values and opinions in large language models, 2024.
\newblock URL \url{https://arxiv.org/abs/2402.16786}.

\bibitem[Saito et~al.(2025)Saito, Sohn, Lee, and Ushiku]{saito2025answerinvestigatingpositionalbias}
Kuniaki Saito, Kihyuk Sohn, Chen-Yu Lee, and Yoshitaka Ushiku.
\newblock Where is the answer? investigating positional bias in language model knowledge extraction, 2025.
\newblock URL \url{https://arxiv.org/abs/2402.12170}.

\bibitem[Wang et~al.(2025)Wang, Zhang, Li, Huang, Han, Ji, Kakade, Peng, and Ji]{wang2025eliminatingpositionbiaslanguage}
Ziqi Wang, Hanlin Zhang, Xiner Li, Kuan-Hao Huang, Chi Han, Shuiwang Ji, Sham~M. Kakade, Hao Peng, and Heng Ji.
\newblock Eliminating position bias of language models: A mechanistic approach, 2025.
\newblock URL \url{https://arxiv.org/abs/2407.01100}.

\bibitem[Wright et~al.(2024)Wright, Arora, Borenstein, Yadav, Belongie, and Augenstein]{wright-etal-2024-llm}
Dustin Wright, Arnav Arora, Nadav Borenstein, Srishti Yadav, Serge Belongie, and Isabelle Augenstein.
\newblock {LLM} tropes: Revealing fine-grained values and opinions in large language models.
\newblock In Yaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen, editors, \emph{Findings of the Association for Computational Linguistics: EMNLP 2024}, pages 17085--17112, Miami, Florida, USA, November 2024. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2024.findings-emnlp.995}.
\newblock URL \url{https://aclanthology.org/2024.findings-emnlp.995/}.

\bibitem[Yang and Menczer(2025)]{Yangetal}
Kai-Cheng Yang and Filippo Menczer.
\newblock Accuracy and political bias of news source credibility ratings by large language models.
\newblock In \emph{Proceedings of the 17th ACM Web Science Conference 2025}, Websci '25, page 127–137, New York, NY, USA, 2025. Association for Computing Machinery.
\newblock ISBN 9798400714832.
\newblock \doi{10.1145/3717867.3717903}.
\newblock URL \url{https://doi.org/10.1145/3717867.3717903}.

\bibitem[Yuksel et~al.(2025)Yuksel, Catalbas, and Oc]{yuksel2025languagedependentpoliticalbiasai}
Dogus Yuksel, Mehmet~Cem Catalbas, and Bora Oc.
\newblock Language-dependent political bias in ai: A study of chatgpt and gemini, 2025.
\newblock URL \url{https://arxiv.org/abs/2504.06436}.

\end{thebibliography}
