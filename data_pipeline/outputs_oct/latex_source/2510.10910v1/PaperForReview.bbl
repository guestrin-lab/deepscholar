\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{chen2024diffute}
Haoxing Chen, Zhuoer Xu, Zhangxuan Gu, Yaohui Li, Changhua Meng, Huijia Zhu, Weiqiang Wang, et~al.
\newblock Diffute: Universal text editing diffusion model.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{chen2024textdiffuser}
Jingye Chen, Yupan Huang, Tengchao Lv, Lei Cui, Qifeng Chen, and Furu Wei.
\newblock Textdiffuser: Diffusion models as text painters.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{chung2024style}
Jiwoo Chung, Sangeek Hyun, and Jae-Pil Heo.
\newblock Style injection in diffusion: A training-free approach for adapting large-scale diffusion models for style transfer.
\newblock In {\em Proc. of IEEE Computer Vision and Pattern Recognition}, pages 8795--8805, 2024.

\bibitem{deng2022stytr2}
Yingying Deng, Fan Tang, Weiming Dong, Chongyang Ma, Xingjia Pan, Lei Wang, and Changsheng Xu.
\newblock Stytr2: Image style transfer with transformers.
\newblock In {\em Proc. of IEEE Computer Vision and Pattern Recognition}, pages 11326--11336, 2022.

\bibitem{fang2025recognition}
Zhengyao Fang, Pengyuan Lyu, Jingjing Wu, Chengquan Zhang, Jun Yu, Guangming Lu, and Wenjie Pei.
\newblock Recognition-synergistic scene text editing.
\newblock In {\em Proc. of IEEE Computer Vision and Pattern Recognition}, pages 13104--13113, 2025.

\bibitem{gatys2016image}
Leon~A Gatys, Alexander~S Ecker, and Matthias Bethge.
\newblock Image style transfer using convolutional neural networks.
\newblock In {\em Proc. of IEEE Computer Vision and Pattern Recognition}, pages 2414--2423, 2016.

\bibitem{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock {\em Advances in Neural Information Processing Systems}, 27, 2014.

\bibitem{huang2025attenst}
Bo Huang, Wenlun Xu, Qizhuo Han, Haodong Jing, and Ying Li.
\newblock Attenst: A training-free attention-driven style transfer framework with pre-trained diffusion models.
\newblock {\em arXiv preprint arXiv:2503.07307}, 2025.

\bibitem{huang2024diffstyler}
Nisha Huang, Yuxin Zhang, Fan Tang, Chongyang Ma, Haibin Huang, Weiming Dong, and Changsheng Xu.
\newblock Diffstyler: Controllable dual diffusion for text-driven image stylization.
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems}, 2024.

\bibitem{huang2017arbitrary}
Xun Huang and Serge Belongie.
\newblock Arbitrary style transfer in real-time with adaptive instance normalization.
\newblock In {\em Proc. of IEEE Computer Vision and Pattern Recognition}, pages 1501--1510, 2017.

\bibitem{ji2023improving}
Jiabao Ji, Guanhua Zhang, Zhaowen Wang, Bairu Hou, Zhifei Zhang, Brian Price, and Shiyu Chang.
\newblock Improving diffusion models for scene text editing with dual encoders.
\newblock {\em arXiv preprint arXiv:2304.05568}, 2023.

\bibitem{jiang2024diffartist}
Ruixiang Jiang and Changwen Chen.
\newblock Diffartist: Towards structure and appearance controllable image stylization.
\newblock {\em arXiv preprint arXiv:2407.15842}, 2024.

\bibitem{karras2019style}
Tero Karras, Samuli Laine, and Timo Aila.
\newblock A style-based generator architecture for generative adversarial networks.
\newblock In {\em Proc. of IEEE Computer Vision and Pattern Recognition}, pages 4401--4410, 2019.

\bibitem{krishnan2023textstylebrush}
Praveen Krishnan, Rama Kovvuri, Guan Pang, Boris Vassilev, and Tal Hassner.
\newblock Textstylebrush: Transfer of text aesthetics from a single example.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}, 2023.

\bibitem{kwon2022clipstyler}
Gihyun Kwon and Jong~Chul Ye.
\newblock Clipstyler: Image style transfer with a single text condition.
\newblock In {\em Proc. of IEEE Computer Vision and Pattern Recognition}, pages 18062--18071, 2022.

\bibitem{labs2025flux}
Black~Forest Labs, Stephen Batifol, Andreas Blattmann, Frederic Boesel, Saksham Consul, Cyril Diagne, Tim Dockhorn, Jack English, Zion English, Patrick Esser, et~al.
\newblock Flux. 1 kontext: Flow matching for in-context image generation and editing in latent space.
\newblock {\em arXiv preprint arXiv:2506.15742}, 2025.

\bibitem{levin2025differential}
Eran Levin and Ohad Fried.
\newblock Differential diffusion: Giving each pixel its strength.
\newblock In {\em Computer Graphics Forum}, page e70040. Wiley Online Library, 2025.

\bibitem{luo2022siman}
Canjie Luo, Lianwen Jin, and Jingdong Chen.
\newblock Siman: exploring self-supervised representation learning of scene text via similarity-aware normalization.
\newblock In {\em Proc. of IEEE Computer Vision and Pattern Recognition}, pages 1039--1048, 2022.

\bibitem{ma2023glyphdraw}
Jian Ma, Mingjun Zhao, Chen Chen, Ruichen Wang, Di Niu, Haonan Lu, and Xiaodong Lin.
\newblock Glyphdraw: Learning to draw chinese characters in image synthesis models coherently.
\newblock {\em arXiv preprint arXiv:2303.17870}, 2023.

\bibitem{qu2023exploring}
Yadong Qu, Qingfeng Tan, Hongtao Xie, Jianjun Xu, Yuxin Wang, and Yongdong Zhang.
\newblock Exploring stroke-level modifications for scene text editing.
\newblock In {\em Proceedings of the AAAI Conference on Artificial Intelligence}, volume~37, pages 2119--2127, 2023.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In {\em Proc. of the International Conference on Machine Learning}, pages 8748--8763, 2021.

\bibitem{roy2020stefann}
Prasun Roy, Saumik Bhattacharya, Subhankar Ghosh, and Umapada Pal.
\newblock Stefann: scene text editor using font adaptive neural network.
\newblock In {\em Proc. of IEEE Computer Vision and Pattern Recognition}, pages 13228--13237, 2020.

\bibitem{si2024freeu}
Chenyang Si, Ziqi Huang, Yuming Jiang, and Ziwei Liu.
\newblock Freeu: Free lunch in diffusion u-net.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 4733--4743, 2024.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem{wang2025glyphmastero}
Tong Wang, Ting Liu, Xiaochao Qu, Chengjing Wu, Luoqi Liu, and Xiaolin Hu.
\newblock Glyphmastero: A glyph encoder for high-fidelity scene text editing.
\newblock In {\em Proc. of IEEE Computer Vision and Pattern Recognition}, pages 28523--28532, 2025.

\bibitem{wang2023stylediffusion}
Zhizhong Wang, Lei Zhao, and Wei Xing.
\newblock Stylediffusion: Controllable disentangled style transfer via diffusion models.
\newblock In {\em Proc. of IEEE Computer Vision and Pattern Recognition}, pages 7677--7689, 2023.

\bibitem{wu2019editing}
Liang Wu, Chengquan Zhang, Jiaming Liu, Junyu Han, Jingtuo Liu, Errui Ding, and Xiang Bai.
\newblock Editing text in the wild.
\newblock In {\em Proc. of ACM International Conference Multimedia}, pages 1500--1508, 2019.

\bibitem{yang2020swaptext}
Qiangpeng Yang, Jun Huang, and Wei Lin.
\newblock Swaptext: Image based texts transfer in scenes.
\newblock In {\em Proc. of IEEE Computer Vision and Pattern Recognition}, pages 14700--14709, 2020.

\bibitem{yang2023zero}
Serin Yang, Hyunmin Hwang, and Jong~Chul Ye.
\newblock Zero-shot contrastive loss for text-guided diffusion image style transfer.
\newblock In {\em Proc. of IEEE International Conference on Computer Vision}, pages 22873--22882, 2023.

\bibitem{yang2024glyphcontrol}
Yukang Yang, Dongnan Gui, Yuhui Yuan, Weicong Liang, Haisong Ding, Han Hu, and Kai Chen.
\newblock Glyphcontrol: Glyph conditional control for visual text generation.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{yuan2024font}
Honghui Yuan and Keiji Yanai.
\newblock Font style translation in scene text images with clipstyler.
\newblock In {\em International Conference on Pattern Recognition}, pages 105--121. Springer, 2024.

\bibitem{zeng2024textctrl}
Weichao Zeng, Yan Shu, Zhenhang Li, Dongbao Yang, and Yu Zhou.
\newblock Textctrl: Diffusion-based scene text editing with prior guidance control.
\newblock {\em Advances in Neural Information Processing Systems}, 37:138569--138594, 2024.

\bibitem{zhang2024choose}
Boqiang Zhang, Hongtao Xie, Zuan Gao, and Yuxin Wang.
\newblock Choose what you need: Disentangled representation learning for scene text recognition removal and editing.
\newblock In {\em Proc. of IEEE Computer Vision and Pattern Recognition}, pages 28358--28368, 2024.

\bibitem{zhang2023inversion}
Yuxin Zhang, Nisha Huang, Fan Tang, Haibin Huang, Chongyang Ma, Weiming Dong, and Changsheng Xu.
\newblock Inversion-based style transfer with diffusion models.
\newblock In {\em Proc. of IEEE Computer Vision and Pattern Recognition}, pages 10146--10156, 2023.

\end{thebibliography}
