\begin{table}[t]
\small
\centering
\setlength{\tabcolsep}{4pt}
\renewcommand\arraystretch{1.2}
    \centering\small
      \caption{\textbf{
  Comparison of different approaches in protein question answering
  } ``Fun.'', ``Des.'', ``Dom.'', and ``Cat.'' denote the 4 protein-oriented tasks in the Mol-Instructions dataset~\cite{fang2023mol}: protein function prediction (Fun.), general textual description generation (Des.), domain/motif recognition (Dom.), and catalytic activity prediction (Cat.). $\Delta$ \textit{Gain} shows the percentage performance increase. $\diamondsuit$ indicates LLMs augmented with our adaptive context construction method. Metric: ROUGE-L.
  }
  \vspace{\baselineskip}
    \begin{tabular}{l|c|c|c@{\hspace{8pt}}c@{\hspace{8pt}}c@{\hspace{8pt}}c@{\hspace{8pt}}c}
\hline

\hline

\hline

\hline
        \multirow{2}{*}{\bf Model}& \multirow{2}{*}{\bf ProtDescribe
} &  \multicolumn{1}{c|}{ \bf Protein2Text-
}&\multicolumn{5}{c}{\bf Mol-Instructions}  \\
          & & \bf QA & Func. & Desc.
 & Dom. & Cat. & \bf Avg.  \\ 
\hline
\rowcolor{gray!20}
        \textit{Fine-tuned LLM} &&&&&&&\\
        BioT5+~\cite{pei2023biot5} & 9.97 & 6.96 & 2.92 & 6.22 & 2.37 & 2.87 & 3.60 \\
        ProLLaMA-7B~\cite{lv2025prollama}& 12.77 & 10.09 & 16.89 & 15.34 & 15.85 & 19.32 & 16.85 \\
\hline
\rowcolor{gray!20} 
        \textit{Frozen LLM} &&&&&&&\\
        Qwen2.5-3B~\cite{qwen2.5} & 18.45 & 23.21 & 18.91 & 17.18 & 18.01 & 20.05 & 18.54 \\
        \rowcolor[HTML]{E6F7FF}
        Qwen2.5-3B~\cite{qwen2.5} $\diamondsuit$& 27.32 & 28.66 & 22.05 & 22.23 & 25.14 & 15.96 & 21.35\\
        $\Delta$ \it Gain & \bf {\color[HTML]{006400} +8.87} & \bf {\color[HTML]{006400} +5.45} & & & & & \bf {\color[HTML]{006400} +2.81}\\
        Mistral-7B-Instruct-v0.3~\cite{chaplot2023albert} & 15.02 & 20.97 & 17.05 & 18.59 & 14.95 & 18.07 & 17.17\\
        \rowcolor[HTML]{E6F7FF}
        Mistral-7B-Instruct-v0.3~\cite{chaplot2023albert} $\diamondsuit$ & 29.39 & 28.59 & 15.77 &22.72 & 17.46 & 21.20 & 19.29\\
        $\Delta$ \it Gain & \bf {\color[HTML]{006400} +14.37} & \bf {\color[HTML]{006400} +7.62} & & & & & \bf {\color[HTML]{006400} +2.12}\\
        Qwen3-14B~\cite{qwen3technicalreport} &  23.20 & 21.02 & 15.80  &  12.75 & 15.81 & 14.06 & 14.61 \\
        \rowcolor[HTML]{E6F7FF}
        Qwen3-14B~\cite{qwen3technicalreport} $\diamondsuit$ &  35.53 & 25.93 & 20.17 & 17.37 & 18.47 & 23.25 & 19.82\\
        $\Delta$ \it Gain & \bf {\color[HTML]{006400}+12.33} & \bf {\color[HTML]{006400} +4.91 } & & & & & \bf {\color[HTML]{006400} +5.21}\\
        % Llama-3.3-70B-Instruct\\
        % \rowcolor[HTML]{E6F7FF}
        % Llama-3.3-70B-Instruct $\diamondsuit$\\
        % $\Delta$ \it Gain & \bf {\color[HTML]{006400}+} & \bf {\color[HTML]{006400} + } & & & & & \bf {\color[HTML]{006400} +}\\
        kimi-k2~\cite{team2025kimi} & 26.74 & 17.33 & 12.60 &12.36 & 10.32 & 15.97 & 12.81 \\
        \rowcolor[HTML]{E6F7FF}
        kimi-k2~\cite{team2025kimi} $\diamondsuit$ & 35.91 & 21.04 & 14.47 & 14.97 & 15.68 & 17.02 & 15.54\\
        $\Delta$ \it Gain & \bf {\color[HTML]{006400} +9.17} & \bf {\color[HTML]{006400} +3.71} & & & & & \bf {\color[HTML]{006400} +2.72}\\
        GPT-4o~\cite{openai2024gpt4} & 18.29 &20.84 & 16.89 & 14.50 & 16.74 & 20.00 & 17.03\\
        \rowcolor[HTML]{E6F7FF}
        GPT-4o~\cite{openai2024gpt4} $\diamondsuit$ &35.53 & 26.86 & 20.24 & 19.23 & 17.46 & 22.61 & 19.89\\
        $\Delta$ \it Gain & \bf {\color[HTML]{006400} +17.22} & \bf {\color[HTML]{006400} +6.02} & & & & & \bf {\color[HTML]{006400} +2.85}\\
        \cline{1-4}
\hline

\hline

\hline

\hline
    \end{tabular}
    
    \label{tab:main}
\end{table}