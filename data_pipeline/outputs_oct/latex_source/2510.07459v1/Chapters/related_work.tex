\section{Related Work}
\label{related_work}
\textbf{MoE Models}
The pursuit of increasingly capable and adaptable artificial intelligence systems has led to the development of sophisticated architectural paradigms, among which the Mixture-of-Experts (MoE) stands out. MoE is an architectural concept that adaptively combines predictions from multiple specialized neural modules, often sharing a common architecture, through a learned gating mechanism. This paradigm allows for a dynamic allocation of computational resources, enabling models to specialize on different sub-problems or data modalities. Early implementations of MoE \citep{jacobs1991adaptive} focused on ensemble learning (ensemble MoE), where multiple models (experts) contributed to a final prediction. More recently, MoE layers have been seamlessly integrated within larger neural architectures, with experts operating in latent domains (latent MoE)  \citep{shazeer2017outrageously,fedus2022switch}. This integration has proven particularly impactful in the realm of large language models (LLMs), where MoE layers have been instrumental in scaling models to unprecedented sizes while managing computational costs \citep{lepikhin2020gshard, jiang2024mixtral, dai2024deepseekmoe}. By selectively activating only a subset of experts for each input token, MoEs enable models with vast numbers of parameters to achieve high performance without incurring the prohibitive inference costs of densely activated large models.
Despite  their contribution and adoption, both ensemble and latent MoE architectures typically output point estimates, both at the level of the individual expert and at the level of the overall model. This limits the ability to quantify uncertainty which is important for 
decision-making. 
Few works have explored uncertainty estimation for MoE architectures  
(see e.g. \cite{pavlitska2025moeuncertainty,zhang2023mofme}).
In this work, we focus on ensemble MoE architectures, as uncertainty quantification is more directly applicable for decision making and interpretability. 
In our method, we view the experts of the MoE model as an ensemble of models that can be used to extract both aleatoric and epistemic uncertainties.

\textbf{Uncertainty Estimation for Regression Tasks.} Deep learning regression models are increasingly required not only to provide accurate point estimates but also to quantify predictive uncertainty. A large body of research has focused on Bayesian neural networks, which place distributions over weights and approximate posterior inference using variational methods or Monte Carlo dropout, thereby producing predictive intervals \citep{gal2016dropout}. Another line of work employs ensembles of neural networks to capture both aleatoric and epistemic uncertainties, with randomized initialization or bootstrapped training providing diverse predictions \citep{lakshminarayanan2017simple}. More recently, post-hoc calibration techniques have been proposed, adapting classification-oriented approaches such as temperature scaling to regression settings, for instance by optimizing proper scoring rules or variance scaling factors \citep{kuleshov2018accurate}. Beyond probabilistic calibration, conformal prediction (CP) methods have gained attention due to their finite-sample coverage guarantees under minimal distributional assumptions. CP can be applied to regression to produce instance-dependent prediction intervals with guaranteed coverage, and has been extended to handle asymmetric intervals, distribution shift, and multi-target regression \citep{vovk2005algorithmic,romano2019conformalized}. 

\textbf{Time Series Forecasting and Uncertainty Estimation.} Time series forecasting is a critical discipline in machine learning and statistics, focusing on predicting future values from a sequence of historical data points ordered by time. This field has wide-ranging applications, including financial market analysis, energy consumption forecasting, weather prediction, and medical prognosis. Traditional statistical methods, such as Autoregressive Integrated Moving Average (ARIMA) and Exponential Smoothing, have been foundational. However, their effectiveness is often limited by their assumption of linearity and their inability to capture complex, non-linear dependencies. More recently, deep learning models, employing  Transformers \citep{Yuqietal-2023-PatchTST,autoformer,reformer}, Multi-Layer Perceptrons (MLPs) \citep{wang2024timemixer, dlinear}, and Convolutional Neural Networks (CNNs) \citep{wu2023timesnet}, were shown to be effective in modeling temporal dynamics and long-range dependencies \citep{wang2024deep,time_series_survey,xwang2024deep}. The ability to quantify the uncertainty of a forecast, rather than providing just a single point estimate, is of paramount importance.  Uncertainty quantification provides a confidence interval for the prediction, which is crucial for risk management and informed decision-making. Some recent works have introduced uncertainty estimation to time series forecasting (see e.g. \cite{cini2025corel, wu2025eci}).
Given its wide-ranging applications, the importance of reporting uncertainty, and its challenging nature, time series forecasting serves as a highly suitable domain to evaluate the performance of MoGU. 

