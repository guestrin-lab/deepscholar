\section{Introduction}
\label{sec:intro}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figs/fig_immer_demo.pdf}
    \caption{Comparison between (a) classical IR that acquires on-axis data in controlled setups with dedicated sensors, and (b) immersive IR that acquires off-axis data in open scenes with VR headsets. Examples are from CASIA-IrisV4~\cite{casia-iris-v4} and ImmerIris.}
    \label{fig:immer-demo}
    \vspace{-3mm}
\end{figure}

% Iris recognition is a long-standing biometric technique that identifies persons by comparing the unique texture patterns of their irises. The iris is a thin, circular structure in the human eye that regulates the amount of light reaching the retina. Its texture, readily capturable in ocular images, is randomly formed, highly distinctive, and relatively stable over time, making iris secure and accurate for personal identification. In recent years, with the rise of egocentric applications such as augmented reality (AR) and virtual reality (VR), IR has gained renewed prominence, as irises can be seamlessly captured through home electronics like VR headsets, offering convenience in scenarios such as login and e-pay. We refer to this emerging scenario as \textit{immersive IR}, to distinguish it from classical IR in controlled setups. \Cref{fig:immer-demo} compares the acquisition scenario and example images between two setups.

Iris recognition is a long-standing biometric technique that identifies persons by the unique patterns of their irises. The iris is a thin, circular structure in the human eye that regulates the amount of light reaching the retina. Its texture, being randomly formed, highly distinctive, and relatively stable over time, provides a secure and accurate basis for personal identification. \textit{Classical} iris recognition (\cref{fig:immer-demo}(a)) has long been employed in sensitive applications such as access control. More recently, with the rise of egocentric applications such as augmented reality (AR) and virtual reality (VR), \textit{immersive} iris recognition (\cref{fig:immer-demo}(b)) has gained renewed prominence, as irises can be conveniently acquired through consumer electronics such as VR headsets to enable seamless use in tasks like login and e-payment.

Immersive and classical iris recognition differ most clearly in how data are acquired. Classical iris recognition is a controlled setup that uses specialized frontal cameras to capture on-axis images under full user cooperation. In contrast, the immersive setup places cameras at a tilt on headsets due to hardware design and user experience, producing off-axis images. Acquisition also takes place in open scenes, where environments vary and non-expert users cooperate less consistently. Together, off-axis and open-scene acquisition give rise to 3 distinctive challenges: 1) \textit{Perspective distortion}, where tilted camera-eye geometries make the circular iris appear elliptical and stretch local textures; (2) \textit{Quality degradation}, where the absence of control in device calibration and user cooperation can yield flawed samples, \eg, occlusions when eyes are not fully opened; and 3) \textit{Intra-class variation}, which arises from environmental and behavioral changes in such as illumination and gaze direction. Data scarcity has long been a barrier for iris recognition research, with most existing datasets proprietary or small in scale. For immersive iris recognition, which is still an emerging topic, datasets capturing these challenges are even scarcer.

% Immersive and classic iris recognition differ fundamentally in data acquisition. Classic iris recognition, as a controlled setup, uses frontal cameras to capture on-axis iris images under full user cooperation. By contrast, the immersive setup employs tilt-placed headset cameras to avoid obstructing the display, producing off-axis images, and acquisition often takes place in open scenes where environments vary and non-expert users cannot be expected to cooperate consistently. Off-axis and open-scene acquisition therefore introduce 3 distinctive challenges: 1) \textit{Perspective distortion}, where tilted camera-eye geometries cause circular irises to appear elliptical and local textures to be unevenly stretched; 2) \textit{Quality degradation}, as casual wearing or calibration often produce defocused images, while inconsistent cooperation can lead to partial occlusions from eyelids or eyelashes; and (3) \textit{Intra-class variation}, where environmental and behavioral factors such as illumination changes and gaze direction shifts can induce substantial variations. Data scarcity has long been a barrier for iris recognition research, with most existing datasets being proprietary or small in scale. For immersive iris recognition, this issue is even more pronounced.


% Iris recognition is a long-standing biometric technique that identifies persons by the unique texture patterns of their irises. The iris is a thin, circular structure in the human eye that regulates the amount of light reaching the retina. Its texture, being randomly formed, highly distinctive, and relatively stable over time, is secure and accurate for personal identification. \textit{Classic} iris recognition (\cref{fig:immer-demo}(a)) has long been employed in sensitive applications such as access control, where a dedicated frontal camera captures on-axis iris images under controlled setups with full user cooperation. More recently, with the rise of egocentric applications such as augmented reality (AR) and virtual reality (VR), \textit{immersive} iris recognition (\cref{fig:immer-demo}(b)) has gained renewed prominence, as irises are captured through consumer VR headsets for convenient login and e-payment. Unlike the classic setting, headset cameras are usually tilt-placed to avoid obstructing the display, producing off-axis images, and acquisition occurs in open scenes where environments vary and users, being non-experts, cannot be expected to cooperate in a controlled manner.

% Data scarcity has long been a critical barrier for iris recognition research. In classical settings, collecting data requires costly specialized devices, hence existing datasets are mostly proprietary or small in scale. For immersive iris recognition, the problem is even more pronounced due to 3 distinctive challenges of open-scene iris acquisition: 1) \textit{Off-axis distortion.} VR/AR headsets typically capture tilted or off-axis ocular images, where perspective distortion, \eg, the circular iris appearing elliptical and local textures being unevenly stretched, can undermine the geometric consistency of iris textures. 2) \textit{Quality degradation.} As largely self-service devices without professional calibration, VR/AR headsets yield image quality that varies considerably with user cooperation. 3) \textit{Intra-class variation.} Environmental and behavioral factors introduce substantial variations such as pupil size changes from illumination and angle changes from gaze points. As immersive IR is relatively recent, datasets capturing these challenges remain scarce.

To addresses data scarcity, this paper presents ImmerIris, a large-scale immersive iris dataset collected in open scenes using VR headsets. It consists of 564 subjects and 499,791 ocular images. To our knowledge, it is the largest public dataset to date and among the first to target off-axis acquisition. Based on it, we establish a comprehensive set of test protocols to assess recognition performance under varying acquisition constraints and challenging factors, and provide a benchmark for state-of-the-art (SOTA) methods. We believe this dataset and benchmark will largely promote research on immersive iris recognition.

The past decade has also witnessed significant advances in recognition methodologies. Most SOTAs build on Daugman's seminal work~\cite{daugman2009iris}, where a normalization stage first aligns and unwraps ocular images into a rectangular strip of normalized texture. Features are then extracted, either by hand-crafted filters or deep neural networks (DNN), to generate identity-discriminative templates. These methods have achieved remarkable success in controlled setups. 

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figs/fig_intro_comp.png}
    \caption{Comparison between SOTAs and our normalization-free paradigm on a classical iris recognition benchmark~\cite{casia-iris-v4} and on ImmerIris protocols of increasing difficulty. Larger (1 - FRR@FAR) indicates better performance. SOTAs perform well under controlled setups but drop on ImmerIris, whereas our paradigm consistently outperforms them.}
    \label{fig:intro-comp}
    \vspace{-3mm}
\end{figure}

When it comes to immersive iris recognition, however, SOTAs perform poorly on open-scene, off-axis data. To illustrate, we evaluate models trained on their respective datasets over a classical iris recognition benchmark~\cite{casia-iris-v4} and 4 increasingly difficult test protocols of our ImmerIris. \Cref{fig:intro-comp} shows a sharp increase in false rejection rates (FRR), which reveals a substantial performance drop. We primarily attribute the gap of SOTAs to their reliance on fallible preprocessing, \ie, normalization. While normalization unifies ocular images into comparable iris textures and was valuable in the early years when feature extraction techniques were primitive, it requires precise segmentation and parameterization of the iris region, which become highly unreliable under distortion and degradation. In other words, we think that normalization is non-intuitive for end-to-end recognition and may no longer represent the optimal paradigm.

To improve immersive recognition performance, we propose a reframed paradigm that waives normalization and directly learns from ocular images with minimal adjustment. Concretely, we crop the iris region with a robustly obtained bounding box, to preserve both iris texture and contextual cues. For feature extraction, we inherit the proven practice of modern face recognition systems, whose success lies not in dedicated preprocessing but in robust extractors and discriminative objectives. As shown in~\cref{fig:intro-comp} and later in~\cref{sec:benchmark}, this simple yet natural design performs surprisingly well in immersive scenarios, consistently outperforming normalization-based SOTAs. We believe this paradigm points to a promising direction for future improvement.


% Iris recognition (IR) is a long-standing biometric technique that identifies persons by comparing the unique texture patterns of their irises. The iris is a thin, circular structure in the human eye that regulates the amount of light reaching the retina. Its texture, readily capturable in ocular images, is randomly formed, highly distinctive, and relatively stable over time, making IR more secure and accurate for personal identification than other biometric modalities (\eg, face). While classical IR systems capture iris using specialized hardware under controlled setups, with the rise of egocentric applications such as augmented reality (AR) and virtual reality (VR), immersive IR, capturing irises seamlessly via general-purpose devices like VR headsets, is gaining emerging prominence.

% Data scarcity has long been a crucial barrier for IR research. Collecting iris data in classical IR requires costly specialized cameras and labor-intensive cooperation from subjects, and existing datasets are mostly proprietary or small in scale. Moreover, in immersive IR, images are acquired in open scenes, where both the subject and the device are under only mild control. Compared to classical IR, this introduces three unique challenges in its iris data, that is rarely studied: 1) \textit{Off-axis distortion.} VR/AR headsets typically capture tilted or off-axis ocular images, where perspective distortion, \eg, the circular iris appearing elliptical and local textures being unevenly stretched, can undermine the geometric consistency assumed in controlled IR. 2) \textit{Quality degradation.} As largely self-service devices without professional calibration, VR/AR headsets produce image quality that depends on user cooperation and thus varies considerably. 3) \textit{Intra-class variation.} Environmental and behavioral factors introduce substantial intra-class variation, such as pupil size changes from illumination and viewing angle changes from varying gaze points. Relative immersive IR data is therefore unseen or even scarce.

% Moreover, they differ from irises captured by immersive devices in two key aspects: (1) they are typically collected under controlled setups, carefully managed of conditions to minimize variations such as pupil dilation, gaze direction, and partial occlusion by eyelids or eyelashes, whereas immersive devices capture irises largely in the wild and thus exhibit rich variations; and (2) they are predominantly on-axis, meaning cameras are placed in front of the eyes without tilt, while immersive devices usually place cameras at oblique angles, producing tilted or off-axis images. These differences, as illustrated in Fig. X, further intensify data scarcity for immersive IR. % Figure X compares existing datasets and iris data in immersive scenarios.

% Moreover, they bear two critical differences from iris data in immersive scenarios
%  The challenge is further intensified for immersive IR, as existing datasets differ from irises captured by immersive devices in two key aspects:

% This paper address this issue by presenting ImmerIris, a large-scale iris dataset collected for immersive IR in open scene using VR headsets. It includes 564 subjects and 499,791 ocular images. To our knowledge, it is the largest public IR dataset to date and among the first to focus on off-axis acquisition. The dataset provides rich intra-class variation and supports open-set evaluation. Based on ImmerIris, we establish a comprehensive set of test protocols to evaluate IR performance under different acquisition flexibilities and on most challenging factors. We also provide a benchmark of SOTAs. We believe this dataset and benchmark will foster more effective research on immersive IR. 

% 要先说方法再说data scarcity，因为“模型需要训练”是需要data的逻辑前提？也不一定
% The past decade has witnessed significant advances in IR techniques. Most state-of-the-arts (SOTA) initially follow the seminal preprocessing pipeline by Daugman, which segments irises from ocular images and normalizes them into uniform, rectangular shape. Then, training-free methods transform the normalized irises using hand-crafted feature extractors into binary sequences, known as iris codes, and perform matching via bit-wise distance (Fig. X(a)), while learning-based methods employ deep neural networks (DNN) to hierarchically extract discriminative features as comparable identity embeddings (Fig. X(b)). % These approaches exhibit strong performance in closed-scene IR scenarios, where ocular images are captured using specialized hardware under controlled setups.

%   training-free methods transform the normalized irises using hand-crafted feature extractors into binary sequences, known as iris codes, and perform matching via bit-wise distance (Fig. X(a)), while learning-based methods employ deep neural networks (DNN) to hierarchically extract discriminative features as comparable identity embeddings (Fig. X(b)). % These approaches exhibit strong performance in closed-scene IR scenarios, where ocular images are captured using specialized hardware under controlled setups.

% When it comes to immersive IR, however, we find SOTAs perform poorly on open-scene, off-axis data. To illustrate, we evaluate SOTA models' performance, trained on respective datasets, on a classical IR dataset~\cite{casia-iris-v4} and 4 test protocols of increasing difficulty of our ImmerIris. In Fig. 1, we observe a sharp increase in false rejection rate (FRR) therefore a significant downgrade in performance. We attribute the performance gap of SOTAs on immersive IR  to their reliance to the fallible preprocessing of ocular images, \ie, normalization. The normalization turns ocular images into unified iris textures that facilitates feature extraction, especially helpful when extraction techniques were relatively primitive in the early years. It however requires sophisticated segmentation and parameterization of iris region, which are extra challenging for iris images captured with distortion and degradations. In other words, we find normalization is non-intuitive for end-to-end IR and is becoming a technical debt.

%  We attribute the performance gap of SOTAs to the above mentioned unique challenges of immersive IR, more specifically, to several key challenging factors, \eg, occlusion from eyelid and eyelash that obfuscate iris textures, and the variation of pupil size and gaze angles that potentially break the consistency in normalized irises.

% While SOTAs achieve strong performance on on-axis datasets, we find that they perform poorly on open-scene, off-axis data. To illustrate, we first train SOTA models on an open-source on-axis dataset, CASIA-T, and evaluate them on both its test set and on ImmerIris. As shown in Fig. 1(a–b), these methods recognize on-axis irises reliably but suffer a significant performance drop on off-axis samples. This suggests that off-axis data exhibit inherently different characteristics and pose new challenges for IR. We further control for domain shift by both training and testing SOTAs on ImmerIris, where the training subset is sampled to match the size of CASIA-T. Though SOTAs perform better under this off-axis training-and-testing setting (Fig. 1(c)), there remains a substantial gap compared to the on-axis setting. Detailed discussions and quantitative results are provided in Sec. X. These findings highlight the need for new IR methodologies tailored to open-scene, off-axis conditions.

% We attribute the performance gap of existing SOTAs to two major factors. First, open-scene iris data present substantial challenges due to 1) pupil dilation, gaze angle variation, and illumination variations, 2) artifacts such as occlusion, as well as 3) tilt and perspective distortion caused by off-axis imaging. Second, most SOTAs heavily depend on preprocessing steps (e.g., iris segmentation and normalization), which are highly sensitive to off-axis distortions and often lead to severe performance degradation.

% To address the limitation of sophisticated and error-prone preprocessing, we propose an alternative recognition paradigm that treats the iris holistically. Specifically, we localize the iris region within ocular images and feed the cropped bounding boxes into a CNN without further normalization. Leveraging advanced deep recognition models and discriminative objectives mimicked from face recognition (e.g., ResNet with ArcFace loss), this approach can learn robust and identity-discriminative feature templates while being more resilient to challenging imaging conditions. We adopt this paradigm as the baseline in our benchmark.


Overall, this paper makes three main contributions:
\begin{enumerate}
\item We introduce ImmerIris, a large-scale and open-scene dataset for immersive iris recognition.
\item We establish a comprehensive benchmark dedicated to immersive iris recognition. Results show that SOTAs cannot be readily transferred to this setup.
\item We identify the primary limitation of SOTAs as their reliance on fallible normalization, and propose a simple yet effective normalization-free paradigm that significantly improves performance.  
\end{enumerate}


% Conventional IR systems typically rely on commercial off-the-shelf (COTS) hardware, which requires users to pause and gaze at designated sensors. More recently, IR has gained popularity with the rise of egocentric applications such as augmented reality (AR) and virtual reality (VR), where ocular images can be conveniently collected through head-mounted devices such as the HoloLens or Vision Pro.
% Driven by the rise of egocentric applications, recent years have witnessed a broadening of IR's applicability, evolving from controlled settings that required users to pause-and-gaze into specialized hardware, to open-scene applications enabled by general-purpose devices such as augmented reality (AR) and virtual reality (VR) headsets.
%While conventional IR systems typically rely on specialized hardware and controlled setups, recent advances have broadened its applicability, enabling in-the-wild recognition using general-purpose immersive devices such as augmented reality (AR) and virtual reality (VR) headsets.
% A key feature of interest of IR is iris's collectability. While conventional IR systems typically rely on specialized hardware and controlled setups to capture iris, emerging egocentric applications such as augmented reality (AR) and virtual reality (VR) has fostered the in-the-wild iris collection using general-purpose immersive devices, \eg, VR headsets. 

% A crucial barrier for IR research remains unsettled is the scarcity of data. As iris data is more difficult to collect than other biometric modalities (\eg, face), current datasets are rarely open-source and generatively small in scale. They are also typically collected in controlled enviroments where 

% Data scarcity has long been a major barrier for IR research. As collecting iris data requires costly specialized cameras and labor-intensive cooperation from subjects, existing datasets are often proprietary or small in scale. Moreover, existing datasets bare two critical limitations for being used in immersive scenarios: First, most existing iris datasets are designed for controlled environments, where acquisition conditions can be carefully managed to substantially reduce variations such as pupil dilation, gaze direction, and partial occlusion by eyelids or eyelashes. However, in immersive scenarios, irises are largely captured in the wild, which requires IR systems to be established on richly varied datasets to achieve robustness. Second, most existing dataset are captured on-axis, meaning the cameras are positioned directly in front of the eyes without tilt. By contrast, in VR/AR devices, cameras are placed at oblique angles, and the captured images are typically tilted or off-axis, which causes unique difficulties in such as iris normalization. 
% Data scarcity has long been a major barrier for IR research. Unlike other image datasets, ocular images cannot be casually crawled from the web but require explicit cooperation from subjects, which is costly and labor-intensive. As a result, existing datasets are often proprietary or small in scale. Moreover, they bare two critical limitations: % 此外，它们还有两个重要的局限（in variation and format），限制了它们在VR/AR场景下的应用。
 %In particular, existing datasets commonly suffer from several limitations: they are rarely open-source or generally small in scale; they are typically collected in controlled environments where samples are relatively clean and lack intra-class variation; and most of them are on-axis, meaning the sensors are positioned directly in front of the eyes without tilt. By contrast, in VR/AR devices, sensors are placed at oblique angles, and the captured images are typically tilted or off-axis.
% Data scarcity has long been a crucial barrier for IR research. In particular, existing datasets commonly suffer from several limitations: they are rarely open-source or generally small in scale; they are typically collected in controlled environments where samples are relatively clean and lack intra-class variation; and most of them are on-axis, meaning the sensors are positioned directly in front of the eyes without tilt. By contrast, in VR/AR devices, sensors are placed at oblique angles, and the captured images are typically tilted or off-axis.
