\begin{thebibliography}{68}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Barron et~al.(2021)Barron, Mildenhall, Tancik, Hedman, Martin-Brualla,
  and Srinivasan]{barron2021mip}
Jonathan~T Barron, Ben Mildenhall, Matthew Tancik, Peter Hedman, Ricardo
  Martin-Brualla, and Pratul~P Srinivasan.
\newblock Mip-nerf: A multiscale representation for anti-aliasing neural
  radiance fields.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pp.\  5855--5864, 2021.

\bibitem[Barron et~al.(2022)Barron, Mildenhall, Verbin, Srinivasan, and
  Hedman]{barron2022mip}
Jonathan~T Barron, Ben Mildenhall, Dor Verbin, Pratul~P Srinivasan, and Peter
  Hedman.
\newblock Mip-nerf 360: Unbounded anti-aliased neural radiance fields.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  5470--5479, 2022.

\bibitem[Barron et~al.(2023)Barron, Mildenhall, Verbin, Srinivasan, and
  Hedman]{barron2023zip}
Jonathan~T Barron, Ben Mildenhall, Dor Verbin, Pratul~P Srinivasan, and Peter
  Hedman.
\newblock Zip-nerf: Anti-aliased grid-based neural radiance fields.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  19697--19705, 2023.

\bibitem[Battaglia et~al.(2018)Battaglia, Hamrick, Bapst, Sanchez-Gonzalez,
  Zambaldi, Malinowski, Tacchetti, Raposo, Santoro, Faulkner,
  et~al.]{battaglia2018relational}
Peter~W Battaglia, Jessica~B Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez,
  Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam
  Santoro, Ryan Faulkner, et~al.
\newblock Relational inductive biases, deep learning, and graph networks.
\newblock \emph{arXiv preprint arXiv:1806.01261}, 2018.

\bibitem[Blattmann et~al.(2023)Blattmann, Dockhorn, Kulal, Mendelevitch,
  Kilian, Lorenz, Levi, English, Voleti, Letts, et~al.]{blattmann2023stable}
Andreas Blattmann, Tim Dockhorn, Sumith Kulal, Daniel Mendelevitch, Maciej
  Kilian, Dominik Lorenz, Yam Levi, Zion English, Vikram Voleti, Adam Letts,
  et~al.
\newblock Stable video diffusion: Scaling latent video diffusion models to
  large datasets.
\newblock \emph{arXiv preprint arXiv:2311.15127}, 2023.

\bibitem[Brooks et~al.(2023)Brooks, Holynski, and
  Efros]{brooks2023instructpix2pix}
Tim Brooks, Aleksander Holynski, and Alexei~A Efros.
\newblock Instructpix2pix: Learning to follow image editing instructions.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  18392--18402, 2023.

\bibitem[Chang et~al.(2023)Chang, Weng, Zhang, Li, Li, and Shi]{chang2023coins}
Zheng Chang, Shuchen Weng, Peixuan Zhang, Yu~Li, Si~Li, and Boxin Shi.
\newblock L-coins: Language-based colorization with instance awareness.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  19221--19230, 2023.

\bibitem[Chen et~al.(2022)Chen, Xu, Geiger, Yu, and Su]{chen2022tensorf}
Anpei Chen, Zexiang Xu, Andreas Geiger, Jingyi Yu, and Hao Su.
\newblock Tensorf: Tensorial radiance fields.
\newblock In \emph{European conference on computer vision}, pp.\  333--350.
  Springer, 2022.

\bibitem[Chen et~al.(2024{\natexlab{a}})Chen, Tao, Zhang, Wang, Li, Ye, Wang,
  Hu, and Savvides]{chen2024conv}
Hao Chen, Ran Tao, Han Zhang, Yidong Wang, Xiang Li, Wei Ye, Jindong Wang,
  Guosheng Hu, and Marios Savvides.
\newblock Conv-adapter: Exploring parameter efficient transfer learning for
  convnets.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  1551--1561, 2024{\natexlab{a}}.

\bibitem[Chen et~al.(2024{\natexlab{b}})Chen, Chen, Zhang, Wang, Yang, Wang,
  Cai, Yang, Liu, and Lin]{chen2024gaussianeditor}
Yiwen Chen, Zilong Chen, Chi Zhang, Feng Wang, Xiaofeng Yang, Yikai Wang,
  Zhongang Cai, Lei Yang, Huaping Liu, and Guosheng Lin.
\newblock Gaussianeditor: Swift and controllable 3d editing with gaussian
  splatting.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  21476--21485, 2024{\natexlab{b}}.

\bibitem[Cheng et~al.(2024{\natexlab{a}})Cheng, Long, Yang, Yao, Yin, Ma, Wang,
  and Chen]{cheng2024gaussianpro}
Kai Cheng, Xiaoxiao Long, Kaizhi Yang, Yao Yao, Wei Yin, Yuexin Ma, Wenping
  Wang, and Xuejin Chen.
\newblock Gaussianpro: 3d gaussian splatting with progressive propagation.
\newblock In \emph{Forty-first International Conference on Machine Learning},
  2024{\natexlab{a}}.

\bibitem[Cheng et~al.(2024{\natexlab{b}})Cheng, Wan, Weng, Zhu, Chang, and
  Shi]{cheng2024colorizing}
Yean Cheng, Renjie Wan, Shuchen Weng, Chengxuan Zhu, Yakun Chang, and Boxin
  Shi.
\newblock Colorizing monochromatic radiance fields.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~38, pp.\  1317--1325, 2024{\natexlab{b}}.

\bibitem[Dhiman et~al.(2023)Dhiman, Srinath, Sarkar, Boregowda, and
  Babu]{dhiman2023corf}
Ankit Dhiman, R~Srinath, Srinjay Sarkar, Lokesh~R Boregowda, and R~Venkatesh
  Babu.
\newblock Corf: Colorizing radiance fields using knowledge distillation.
\newblock \emph{arXiv preprint arXiv:2309.07668}, 2023.

\bibitem[Duan et~al.(2024)Duan, Wei, Dai, He, Chen, and Chen]{duan20244d}
Yuanxing Duan, Fangyin Wei, Qiyu Dai, Yuhang He, Wenzheng Chen, and Baoquan
  Chen.
\newblock 4d-rotor gaussian splatting: towards efficient novel view synthesis
  for dynamic scenes.
\newblock In \emph{ACM SIGGRAPH 2024 Conference Papers}, pp.\  1--11, 2024.

\bibitem[Fang et~al.(2022)Fang, Yi, Wang, Xie, Zhang, Liu, Nie{\ss}ner, and
  Tian]{fang2022fast}
Jiemin Fang, Taoran Yi, Xinggang Wang, Lingxi Xie, Xiaopeng Zhang, Wenyu Liu,
  Matthias Nie{\ss}ner, and Qi~Tian.
\newblock Fast dynamic radiance fields with time-aware neural voxels.
\newblock In \emph{SIGGRAPH Asia 2022 Conference Papers}, pp.\  1--9, 2022.

\bibitem[Fridovich-Keil et~al.(2022)Fridovich-Keil, Yu, Tancik, Chen, Recht,
  and Kanazawa]{fridovich2022plenoxels}
Sara Fridovich-Keil, Alex Yu, Matthew Tancik, Qinhong Chen, Benjamin Recht, and
  Angjoo Kanazawa.
\newblock Plenoxels: Radiance fields without neural networks.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  5501--5510, 2022.

\bibitem[Garbin et~al.(2021)Garbin, Kowalski, Johnson, Shotton, and
  Valentin]{garbin2021fastnerf}
Stephan~J Garbin, Marek Kowalski, Matthew Johnson, Jamie Shotton, and Julien
  Valentin.
\newblock Fastnerf: High-fidelity neural rendering at 200fps.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pp.\  14346--14355, 2021.

\bibitem[Guo et~al.(2023)Guo, Sun, Dai, Chen, Ye, Tan, Ding, Zhang, and
  Wang]{guo2023forward}
Xiang Guo, Jiadai Sun, Yuchao Dai, Guanying Chen, Xiaoqing Ye, Xiao Tan, Errui
  Ding, Yumeng Zhang, and Jingdong Wang.
\newblock Forward flow for novel view synthesis of dynamic scenes.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  16022--16033, 2023.

\bibitem[Hasler \& Suesstrunk(2003)Hasler and Suesstrunk]{hasler2003measuring}
David Hasler and Sabine~E Suesstrunk.
\newblock Measuring colorfulness in natural images.
\newblock In \emph{Human vision and electronic imaging VIII}, volume 5007, pp.\
   87--95. SPIE, 2003.

\bibitem[He et~al.(2018)He, Chen, Liao, Sander, and Yuan]{he2018deep}
Mingming He, Dongdong Chen, Jing Liao, Pedro~V Sander, and Lu~Yuan.
\newblock Deep exemplar-based colorization.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 37\penalty0 (4):\penalty0
  1--16, 2018.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and
  Hochreiter]{heusel2017gans}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp
  Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash
  equilibrium.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Huang et~al.(2022)Huang, Zhao, and Liao]{huang2022unicolor}
Zhitong Huang, Nanxuan Zhao, and Jing Liao.
\newblock Unicolor: A unified framework for multi-modal colorization with
  transformer.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 41\penalty0 (6):\penalty0
  1--16, 2022.

\bibitem[Iizuka et~al.(2016)Iizuka, Simo-Serra, and Ishikawa]{iizuka2016let}
Satoshi Iizuka, Edgar Simo-Serra, and Hiroshi Ishikawa.
\newblock Let there be color! joint end-to-end learning of global and local
  image priors for automatic image colorization with simultaneous
  classification.
\newblock \emph{ACM Transactions on Graphics (ToG)}, 35\penalty0 (4):\penalty0
  1--11, 2016.

\bibitem[Ji et~al.(2022)Ji, Jiang, Luo, Tao, Chu, Xie, Wang, and
  Tai]{ji2022colorformer}
Xiaozhong Ji, Boyuan Jiang, Donghao Luo, Guangpin Tao, Wenqing Chu, Zhifeng
  Xie, Chengjie Wang, and Ying Tai.
\newblock Colorformer: Image colorization via color memory assisted
  hybrid-attention transformer.
\newblock In \emph{European Conference on Computer Vision}, pp.\  20--36.
  Springer, 2022.

\bibitem[Kang et~al.(2023)Kang, Yang, Ouyang, Ren, Li, and
  Xie]{kang2023ddcolor}
Xiaoyang Kang, Tao Yang, Wenqi Ouyang, Peiran Ren, Lingzhi Li, and Xuansong
  Xie.
\newblock Ddcolor: Towards photo-realistic image colorization via dual
  decoders.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pp.\  328--338, 2023.

\bibitem[Kerbl et~al.(2023)Kerbl, Kopanas, Leimk{\"u}hler, and
  Drettakis]{kerbl20233d}
Bernhard Kerbl, Georgios Kopanas, Thomas Leimk{\"u}hler, and George Drettakis.
\newblock 3d gaussian splatting for real-time radiance field rendering.
\newblock \emph{ACM Trans. Graph.}, 42\penalty0 (4):\penalty0 139--1, 2023.

\bibitem[Kim et~al.(2022)Kim, Kang, Kim, Lee, Kim, Kim, Baek, and
  Cho]{kim2022bigcolor}
Geonung Kim, Kyoungkook Kang, Seongtae Kim, Hwayoon Lee, Sehoon Kim, Jonghyun
  Kim, Seung-Hwan Baek, and Sunghyun Cho.
\newblock Bigcolor: Colorization using a generative color prior for natural
  images.
\newblock In \emph{European Conference on Computer Vision}, pp.\  350--366.
  Springer, 2022.

\bibitem[Kirillov et~al.(2023)Kirillov, Mintun, Ravi, Mao, Rolland, Gustafson,
  Xiao, Whitehead, Berg, Lo, et~al.]{kirillov2023segment}
Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura
  Gustafson, Tete Xiao, Spencer Whitehead, Alexander~C Berg, Wan-Yen Lo, et~al.
\newblock Segment anything.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pp.\  4015--4026, 2023.

\bibitem[Li et~al.(2024{\natexlab{a}})Li, Zhao, Wang, and Lin]{li2024towards}
Jiaxing Li, Hongbo Zhao, Yijun Wang, and Jianxin Lin.
\newblock Towards photorealistic video colorization via gated color-guided
  image diffusion models.
\newblock In \emph{Proceedings of the 32nd ACM International Conference on
  Multimedia}, pp.\  10891--10900, 2024{\natexlab{a}}.

\bibitem[Li et~al.(2022)Li, Slavcheva, Zollhoefer, Green, Lassner, Kim,
  Schmidt, Lovegrove, Goesele, Newcombe, et~al.]{li2022neural}
Tianye Li, Mira Slavcheva, Michael Zollhoefer, Simon Green, Christoph Lassner,
  Changil Kim, Tanner Schmidt, Steven Lovegrove, Michael Goesele, Richard
  Newcombe, et~al.
\newblock Neural 3d video synthesis from multi-view video.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  5521--5531, 2022.

\bibitem[Li et~al.(2024{\natexlab{b}})Li, Chen, Li, and Xu]{li2024spacetime}
Zhan Li, Zhang Chen, Zhong Li, and Yi~Xu.
\newblock Spacetime gaussian feature splatting for real-time dynamic view
  synthesis.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  8508--8520, 2024{\natexlab{b}}.

\bibitem[Liang et~al.(2024)Liang, Li, Zhou, Li, and Loy]{liang2024control}
Zhexin Liang, Zhaochen Li, Shangchen Zhou, Chongyi Li, and Chen~Change Loy.
\newblock Control color: Multimodal diffusion-based interactive image
  colorization.
\newblock \emph{arXiv preprint arXiv:2402.10855}, 2024.

\bibitem[Liao et~al.(2024)Liao, He, Yuan, and Zhang]{liao2024gbc}
Jiecheng Liao, Shi He, Yichen Yuan, and Hui Zhang.
\newblock Gbc: Gaussian-based colorization and super-resolution for 3d
  reconstruction.
\newblock In \emph{The 19th ACM SIGGRAPH International Conference on
  Virtual-Reality Continuum and its Applications in Industry}, pp.\  1--9,
  2024.

\bibitem[Liu et~al.(2023{\natexlab{a}})Liu, Li, Wu, and Lee]{liu2023visual}
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong~Jae Lee.
\newblock Visual instruction tuning.
\newblock \emph{Advances in neural information processing systems},
  36:\penalty0 34892--34916, 2023{\natexlab{a}}.

\bibitem[Liu et~al.(2024)Liu, Xue, Luo, Tan, and Yi]{liu2024genn2n}
Xiangyue Liu, Han Xue, Kunming Luo, Ping Tan, and Li~Yi.
\newblock Genn2n: Generative nerf2nerf translation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  5105--5114, 2024.

\bibitem[Liu et~al.(2023{\natexlab{b}})Liu, Gao, Meuleman, Tseng, Saraf, Kim,
  Chuang, Kopf, and Huang]{liu2023robust}
Yu-Lun Liu, Chen Gao, Andreas Meuleman, Hung-Yu Tseng, Ayush Saraf, Changil
  Kim, Yung-Yu Chuang, Johannes Kopf, and Jia-Bin Huang.
\newblock Robust dynamic radiance fields.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  13--23, 2023{\natexlab{b}}.

\bibitem[Lu et~al.(2024)Lu, Yu, Xu, Xiangli, Wang, Lin, and
  Dai]{lu2024scaffold}
Tao Lu, Mulin Yu, Linning Xu, Yuanbo Xiangli, Limin Wang, Dahua Lin, and
  Bo~Dai.
\newblock Scaffold-gs: Structured 3d gaussians for view-adaptive rendering.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  20654--20664, 2024.

\bibitem[Mildenhall et~al.(2019)Mildenhall, Srinivasan, Ortiz-Cayon, Kalantari,
  Ramamoorthi, Ng, and Kar]{mildenhall2019local}
Ben Mildenhall, Pratul~P Srinivasan, Rodrigo Ortiz-Cayon, Nima~Khademi
  Kalantari, Ravi Ramamoorthi, Ren Ng, and Abhishek Kar.
\newblock Local light field fusion: Practical view synthesis with prescriptive
  sampling guidelines.
\newblock \emph{ACM Transactions on Graphics (ToG)}, 38\penalty0 (4):\penalty0
  1--14, 2019.

\bibitem[Mildenhall et~al.(2021)Mildenhall, Srinivasan, Tancik, Barron,
  Ramamoorthi, and Ng]{mildenhall2021nerf}
Ben Mildenhall, Pratul~P Srinivasan, Matthew Tancik, Jonathan~T Barron, Ravi
  Ramamoorthi, and Ren Ng.
\newblock Nerf: Representing scenes as neural radiance fields for view
  synthesis.
\newblock \emph{Communications of the ACM}, 65\penalty0 (1):\penalty0 99--106,
  2021.

\bibitem[Mou et~al.(2024)Mou, Chen, and Wang]{mou2024instruct}
Linzhan Mou, Jun-Kun Chen, and Yu-Xiong Wang.
\newblock Instruct 4d-to-4d: Editing 4d scenes as pseudo-3d scenes using 2d
  diffusion.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  20176--20185, 2024.

\bibitem[M{\"u}ller et~al.(2022)M{\"u}ller, Evans, Schied, and
  Keller]{muller2022instant}
Thomas M{\"u}ller, Alex Evans, Christoph Schied, and Alexander Keller.
\newblock Instant neural graphics primitives with a multiresolution hash
  encoding.
\newblock \emph{ACM transactions on graphics (TOG)}, 41\penalty0 (4):\penalty0
  1--15, 2022.

\bibitem[Neyshabur et~al.(2017)Neyshabur, Bhojanapalli, McAllester, and
  Srebro]{neyshabur2017exploring}
Behnam Neyshabur, Srinadh Bhojanapalli, David McAllester, and Nati Srebro.
\newblock Exploring generalization in deep learning.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Park et~al.(2021{\natexlab{a}})Park, Sinha, Barron, Bouaziz, Goldman,
  Seitz, and Martin-Brualla]{park2021nerfies}
Keunhong Park, Utkarsh Sinha, Jonathan~T Barron, Sofien Bouaziz, Dan~B Goldman,
  Steven~M Seitz, and Ricardo Martin-Brualla.
\newblock Nerfies: Deformable neural radiance fields.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pp.\  5865--5874, 2021{\natexlab{a}}.

\bibitem[Park et~al.(2021{\natexlab{b}})Park, Sinha, Hedman, Barron, Bouaziz,
  Goldman, Martin-Brualla, and Seitz]{park2021hypernerf}
Keunhong Park, Utkarsh Sinha, Peter Hedman, Jonathan~T Barron, Sofien Bouaziz,
  Dan~B Goldman, Ricardo Martin-Brualla, and Steven~M Seitz.
\newblock Hypernerf: A higher-dimensional representation for topologically
  varying neural radiance fields.
\newblock \emph{arXiv preprint arXiv:2106.13228}, 2021{\natexlab{b}}.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{International conference on machine learning}, pp.\
  8748--8763. PmLR, 2021.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and
  Ommer]{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj√∂rn
  Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  10684--10695, 2022.

\bibitem[Shao et~al.(2023)Shao, Zheng, Tu, Liu, Zhang, and
  Liu]{shao2023tensor4d}
Ruizhi Shao, Zerong Zheng, Hanzhang Tu, Boning Liu, Hongwen Zhang, and Yebin
  Liu.
\newblock Tensor4d: Efficient neural 4d decomposition for high-fidelity dynamic
  reconstruction and rendering.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  16632--16642, 2023.

\bibitem[Shen et~al.(2024)Shen, Cai, Yin, M{\"u}ller, Li, Wang, Chen, and
  Wang]{shen2024gim}
Xuelun Shen, Zhipeng Cai, Wei Yin, Matthias M{\"u}ller, Zijun Li, Kaixuan Wang,
  Xiaozhi Chen, and Cheng Wang.
\newblock Gim: Learning generalizable image matcher from internet videos.
\newblock \emph{arXiv preprint arXiv:2402.11095}, 2024.

\bibitem[Simard et~al.(2003)Simard, Steinkraus, and Platt]{simard2003best}
Patrice~Y Simard, David Steinkraus, and John~C Platt.
\newblock Best practices for convolutional neural networks applied to visual
  document analysis.
\newblock In \emph{ICDAR}. IEEE, 2003.

\bibitem[Song et~al.(2023)Song, Chen, Li, Chen, Chen, Yuan, Xu, and
  Geiger]{song2023nerfplayer}
Liangchen Song, Anpei Chen, Zhong Li, Zhang Chen, Lele Chen, Junsong Yuan,
  Yi~Xu, and Andreas Geiger.
\newblock Nerfplayer: A streamable dynamic scene representation with decomposed
  neural radiance fields.
\newblock \emph{IEEE Transactions on Visualization and Computer Graphics},
  29\penalty0 (5):\penalty0 2732--2742, 2023.

\bibitem[Verbin et~al.(2022)Verbin, Hedman, Mildenhall, Zickler, Barron, and
  Srinivasan]{verbin2022ref}
Dor Verbin, Peter Hedman, Ben Mildenhall, Todd Zickler, Jonathan~T Barron, and
  Pratul~P Srinivasan.
\newblock Ref-nerf: Structured view-dependent appearance for neural radiance
  fields.
\newblock In \emph{2022 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pp.\  5481--5490. IEEE, 2022.

\bibitem[Wang et~al.(2023)Wang, Chen, Wang, Song, and Liu]{wang2023masked}
Feng Wang, Zilong Chen, Guokang Wang, Yafei Song, and Huaping Liu.
\newblock Masked space-time hash encoding for efficient dynamic scene
  reconstruction.
\newblock \emph{Advances in neural information processing systems},
  36:\penalty0 70497--70510, 2023.

\bibitem[Wang et~al.(2025)Wang, Zhang, Zhang, Lu, and Song]{wang2025consistent}
Han Wang, Yuang Zhang, Yuhong Zhang, Lingxiao Lu, and Li~Song.
\newblock Consistent video colorization via palette guidance.
\newblock \emph{arXiv preprint arXiv:2501.19331}, 2025.

\bibitem[Weng et~al.(2022)Weng, Wu, Chang, Tang, Li, and Shi]{weng2022code}
Shuchen Weng, Hao Wu, Zheng Chang, Jiajun Tang, Si~Li, and Boxin Shi.
\newblock L-code: Language-based colorization using color-object decoupled
  conditions.
\newblock In \emph{Proceedings of the AAAI conference on artificial
  intelligence}, volume~36, pp.\  2677--2684, 2022.

\bibitem[Weng et~al.(2023)Weng, Zhang, Li, Li, Shi, et~al.]{weng2023cad}
Shuchen Weng, Peixuan Zhang, Yu~Li, Si~Li, Boxin Shi, et~al.
\newblock L-cad: Language-based colorization with any-level descriptions using
  diffusion priors.
\newblock \emph{Advances in Neural Information Processing Systems},
  36:\penalty0 77174--77186, 2023.

\bibitem[Wu et~al.(2024)Wu, Yi, Fang, Xie, Zhang, Wei, Liu, Tian, and
  Wang]{wu20244d}
Guanjun Wu, Taoran Yi, Jiemin Fang, Lingxi Xie, Xiaopeng Zhang, Wei Wei, Wenyu
  Liu, Qi~Tian, and Xinggang Wang.
\newblock 4d gaussian splatting for real-time dynamic scene rendering.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  20310--20320, 2024.

\bibitem[Wu et~al.(2021)Wu, Wang, Li, Zhang, Zhao, and Shan]{wu2021towards}
Yanze Wu, Xintao Wang, Yu~Li, Honglun Zhang, Xun Zhao, and Ying Shan.
\newblock Towards vivid and diverse image colorization with generative color
  prior.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pp.\  14377--14386, 2021.

\bibitem[Yan et~al.(2024)Yan, Peng, Tang, and Wang]{yan20244d}
Jinbo Yan, Rui Peng, Luyang Tang, and Ronggang Wang.
\newblock 4d gaussian splatting with scale-aware residual field and adaptive
  optimization for real-time rendering of temporally complex dynamic scenes.
\newblock In \emph{Proceedings of the 32nd ACM International Conference on
  Multimedia}, pp.\  7871--7880, 2024.

\bibitem[Yang et~al.(2024{\natexlab{a}})Yang, Dong, Tang, and
  Pan]{yang2024colormnet}
Yixin Yang, Jiangxin Dong, Jinhui Tang, and Jinshan Pan.
\newblock Colormnet: A memory-based deep spatial-temporal feature propagation
  network for video colorization.
\newblock In \emph{European Conference on Computer Vision}, pp.\  336--352.
  Springer, 2024{\natexlab{a}}.

\bibitem[Yang et~al.(2024{\natexlab{b}})Yang, Pan, Peng, Du, Tao, and
  Tang]{yang2024bistnet}
Yixin Yang, Jinshan Pan, Zhongzheng Peng, Xiaoyu Du, Zhulin Tao, and Jinhui
  Tang.
\newblock Bistnet: Semantic image prior guided bidirectional temporal feature
  fusion for deep exemplar-based video colorization.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2024{\natexlab{b}}.

\bibitem[Yang et~al.(2023)Yang, Yang, Pan, and Zhang]{yang2023real}
Zeyu Yang, Hongye Yang, Zijie Pan, and Li~Zhang.
\newblock Real-time photorealistic dynamic scene representation and rendering
  with 4d gaussian splatting.
\newblock \emph{arXiv preprint arXiv:2310.10642}, 2023.

\bibitem[Yang et~al.(2024{\natexlab{c}})Yang, Gao, Zhou, Jiao, Zhang, and
  Jin]{yang2024deformable}
Ziyi Yang, Xinyu Gao, Wen Zhou, Shaohui Jiao, Yuqing Zhang, and Xiaogang Jin.
\newblock Deformable 3d gaussians for high-fidelity monocular dynamic scene
  reconstruction.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  20331--20341, 2024{\natexlab{c}}.

\bibitem[Yu et~al.(2024)Yu, Chen, Huang, Sattler, and Geiger]{yu2024mip}
Zehao Yu, Anpei Chen, Binbin Huang, Torsten Sattler, and Andreas Geiger.
\newblock Mip-splatting: Alias-free 3d gaussian splatting.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  19447--19456, 2024.

\bibitem[Zabari et~al.(2023)Zabari, Azulay, Gorkor, Halperin, and
  Fried]{zabari2023diffusing}
Nir Zabari, Aharon Azulay, Alexey Gorkor, Tavi Halperin, and Ohad Fried.
\newblock Diffusing colors: Image colorization with text guided diffusion.
\newblock In \emph{SIGGRAPH Asia 2023 Conference Papers}, pp.\  1--11, 2023.

\bibitem[Zhang et~al.(2017)Zhang, Zhu, Isola, Geng, Lin, Yu, and
  Efros]{zhang2017real}
Richard Zhang, Jun-Yan Zhu, Phillip Isola, Xinyang Geng, Angela~S Lin, Tianhe
  Yu, and Alexei~A Efros.
\newblock Real-time user-guided image colorization with learned deep priors.
\newblock \emph{arXiv preprint arXiv:1705.02999}, 2017.

\bibitem[Zhang et~al.(2023)Zhang, He, Xing, Yao, and Jia]{zhang2023ref}
Yuechen Zhang, Zexin He, Jinbo Xing, Xufeng Yao, and Jiaya Jia.
\newblock Ref-npr: Reference-based non-photorealistic radiance fields for
  controllable scene stylization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  4242--4251, 2023.

\bibitem[Zhao et~al.(2021)Zhao, Wu, Liu, and He]{zhao2021color2embed}
Hengyuan Zhao, Wenhao Wu, Yihao Liu, and Dongliang He.
\newblock Color2embed: Fast exemplar-based image colorization using color
  embeddings.
\newblock \emph{arXiv preprint arXiv:2106.08017}, 2021.

\bibitem[Zhou et~al.(2025)Zhou, Gao, Voleti, Vasishta, Yao, Boss, Torr,
  Rupprecht, and Jampani]{zhou2025stable}
Jensen~(Jinghao) Zhou, Hang Gao, Vikram Voleti, Aaryaman Vasishta, Chun-Han
  Yao, Mark Boss, Philip Torr, Christian Rupprecht, and Varun Jampani.
\newblock Stable virtual camera: Generative view synthesis with diffusion
  models.
\newblock \emph{arXiv preprint arXiv:2503.14489}, 2025.

\end{thebibliography}
