\section{User Evaluation}
\label{sec:evaluation}

\subsection{Methodology}
The evaluation study consisted of two phases: a familiarity session and a main study session. These were designed to introduce participants to the Tranquil Loom VR app and explore their experiences using it in a workplace setting.  \revision{The sessions were held in a quiet and spacious room to ensure minimal distractions, located in the city center to ensure accessibility to knowledge workers employed in nearby offices. We kept the familiarity session to 20 minutes and the main session to an hour so participants could join without interfering with their workday (even during lunch). If a participant needed a shorter session or more flexibility, we adjusted to fit their schedule.} We used a mixed-methods approach, collecting quantitative and qualitative data to understand participants' experiences with the VR app. Our institution's ethics board approved the study. 
\smallskip

\noindent\textbf{Procedure and Data Collection.} The first session was designed to familiarize participants with the Tranquil Loom app. This helped reduce potential barriers related to hardware discomfort or interface unfamiliarity before the main study and avoided any biases introduced due to the novelty effect. Upon arrival, participants signed informed consent and completed a demographics survey, which also included the Satisfaction with Life Scale (SwLS) questionnaire. A researcher introduced the VR headset and walked participants through how to use the app. Participants could ask questions and learn to use the experience in a low-pressure setting. 

Participants then booked a 1-hour timeslot within three days, during work hours, for the main study. At the start of the session, they completed two state well-being questionnaires: the State-Trait Anxiety Inventory (STAI-S) \cite{julian_measures_2011}, which measures current anxiety across 20 items (4-point scale), and the State Mindfulness Scale (SMS) \cite{ruimi_state_2022}, a 21-item tool (5-point scale) assessing present-moment awareness of bodily and mental states. Participants then used the app independently. Sessions were unstructured, with participants free to explore as they wished. Researchers gently concluded sessions exceeding 20 minutes to respect work schedules. Screen recordings captured navigation and feature usage, while researchers took observational notes on behavior and comments.

After the session, participants completed STAI-S and SMS again, along with the short form of the User Experience Questionnaire (UEQ-S) \cite{schrepp_applying_2014} and the User Engagement Scale (UES) \cite{obrien_development_2010}. UEQ-S measures usability and enjoyment via paired attributes on a 7-point scale (-3 to +3); UES evaluates engagement, satisfaction, and immersion across 30 items on a 5-point scale. Finally, participants took part in a 30-40 minute semi-structured interview. These explored their impressions of the app and broader reflections on the usefulness, limitations, and workplace role of VR for well-being. Participants were also asked about when and why they might use or avoid VR, how AI could be integrated meaningfully, and what features would help align such tools with their routines.
\smallskip

\noindent\textbf{Participants.}
We recruited 35 knowledge workers (PS1-PS35) via mailing lists and personal networks. These participants did not overlap with those in Phase 1. They were employed across a range of sectors, including academia, software development, engineering, design, finance, healthcare, administration, and human resources. All held primarily sedentary roles (5+ hours/day) and reported no history of VR-induced motion sickness. Ages ranged from 21 to 59.5 years ($\mu$ = 33.36, $\sigma$ = 9.45); 18 identified as women and 17 as men. Nationalities included British, Greek, Russian, Cypriot, Zimbabwean, Czech, Portuguese, and Canadian. In terms of education, 6 held a doctorate degree, 16 a master’s degree, 7 an undergraduate degree, and 2 had other qualifications. Participants described a range of short break activities during the workday, most commonly walking, socializing, or using digital devices. After work, they supported their well-being through personal strategies such as exercise, meditation, stretching, or occasional workouts.
Participants reported mixed experience with VR. The most common pattern was occasional use (n = 15), followed by never having used VR (n = 9), and yearly use (n = 5). A few used VR more frequently: monthly (n = 2), weekly (n = 1), or daily (n = 3). SwLS scores ranged from 10 to 26, with an average score of 20.91 ($\sigma$ = 3.27), indicating moderate overall satisfaction.
\smallskip

\noindent\textbf{Data Analysis.} For the quantitative analysis, we conducted descriptive and inferential statistical analyses to evaluate the effects of the app. First, we calculated summary statistics ($\mu$, $\sigma$, minimum, and maximum values) for our outcome variables, including the UEQ-S and the four subscales of UES (Attractiveness, Perspicuity, Efficiency, and Dependability). To examine pre-post differences, we conducted normality tests using the Shapiro-Wilk test on each pair of ``before'' and ``after'' measures, including STAI-S and SMS questionnaires. 

For the qualitative analysis, all interviews were audio-recorded and then transcribed with \url{rev.com}. Transcripts were then reviewed to make sure there were no discrepancies. The cleaned interview and observational data were qualitatively analyzed using thematic analysis~\cite{braun_using_2006}. We employed an iterative open-ended coding process, identifying data patterns related to our RQs. 
First, two researchers read the interview transcripts to re-familiarize themselves with the data. Then, during a discussion session, the research team reflected on the data and agreed on the key points for analysis. Following this, the interviews were split between the two researchers and coded using \url{Atlas.ti}, Code examples included: \textit{`non-goal oriented play', `customization', `familiarity over novelty', and ' visiting familiar places'}. Observational data from the notes during the VR sessions and from screen recordings were used to provide additional context.
 Over the course of the analysis stage, the two researchers had regular meetings to reflect on their codes and iteratively identify data patterns, gradually determining which patterns were most useful for becoming overarching themes, how they may be combined according to shared meanings, and which parts of the data could be discarded. Disagreements were resolved through successive rounds of synchronous review. In addition, discussions with the wider research team helped ensure that the final themes accurately captured the participants' experiences. Through the iterative process, we identified 4 overarching themes in relation to our RQs.
\smallskip

\subsection{Results}

\begin{figure}
    \centering
    \includegraphics[width=0.48\textwidth]{figures/stai_sms_boxplots.png}
    \caption{Boxplot comparisons of self-reported anxiety and mindfulness scores before and after using the app. The left panel shows a reduction in anxiety (STAI-S) from before to after the intervention. The right panel displays increases across all three dimensions of state mindfulness: overall awareness, mental engagement, and bodily presence (SMS subscales).}
    \label{fig:before-after-questionnaire}
\end{figure}
\subsubsection{Quantitative}
To assess the impact of the app on users' anxiety and mindfulness, we conducted paired-sample t-tests comparing scores before and after use; Shapiro-Wilk test showed normality across all our variables ($p$ $>$ .05). We found statistically significant improvements across all four outcomes (Figure~\ref{fig:before-after-questionnaire}). There was a significant reduction in anxiety levels as measured by $STAI-S$ ($t(34) = 4.88, p < .001$). Similarly, significant increases were observed in state mindfulness, with $SMS_{Overall}$ (t(34) = -6.70, $p < .001$), $SMS_{Mind}$ ($t(34) = -6.42, p < .001$), and $SMS_{Body}$ ($t(34) = -6.14, p < .001$).

To evaluate user perceptions of the app itself, we analyzed the responses to the UEQ-S and UES questionnaires. On the UEQ-S, the overall user experience was positive ($\mu$ = 1.73, $\sigma$ = 0.84). The UE scores further confirmed positive evaluations across dimensions: Focused Attention ($\mu$ = 3.89, $\sigma$ = 0.87), Perceived Usability ($\mu$ = 3.83, $\sigma$ = 0.81), Aesthetic Elements ($\mu$ = 3.96, $\sigma$ = 0.76), and Reward Factor ($\mu$ = 4.13, $\sigma$ = 0.54). 

\begin{table}[t!]
\centering
\footnotesize
\caption{Time participants spent in each scene ($\mu$ and $\sigma$ in seconds).}
\begin{tabular}{l c c}
\hline
\textbf{Scene} & \textbf{Mean Duration (s)} & \textbf{SD (s)} \\
\hline
Forest Stretching & 236.82 & 102.85 \\
Forest Exploration & 201.43 & 97.92 \\
Snow Exploration & 200.68 & 128.10 \\
Beach Stretching & 199.29 & 95.88 \\
Snow Stretching & 182.00 & 81.77 \\
Forest Meditation & 172.00 & 56.69 \\
Abstract Meditation & 143.23 & 72.36 \\
Beach Meditation & 116.50 & 47.32 \\
Abstract Exploration & 83.35 & 58.57 \\
\hline
\end{tabular}
\label{tab:scene_engagement}
\end{table}


To explore the effect of Loomi's LLM-powered recommendations on participants’ behavior within the VR experience, we analyzed scene-level interaction data. Each of the 12 available scenes (across four environments and three activity types) was paired with a binary indicator of whether it was accessed through an LLM suggestion. We excluded scenes where participants spent less than 30 seconds to focus on meaningful engagement. The results showed that participants spent, on average, 166.50 seconds in scenes they entered via an LLM recommendation, compared to 166.31 seconds in scenes they entered independently. This negligible difference suggests that while LLMs were used to guide scene selection, they had limited influence on how long participants remained engaged once in the scene. These findings indicate that momentary engagement may be more influenced by intrinsic scene qualities or personal preferences than by whether the scene was AI-recommended.



% Correlate the questionnaires metrics (physical / meditation vs SMS) -> calculate the improvements -> calculate changes in the metrics with ANOVA forest activity/ stretching activity was more correlated / helped more interesting etc
% }

% \todo{Marios to update} To explore the effect of large language model (LLM) recommendations on participants' behavior within the VR experience, we analyzed scene-level interaction data. For each of the 12 available scenes (across four environments and three activity types), we recorded whether the participant followed the LLM’s recommendation (1 = yes, 0 = no) and how long they remained in that scene. On average, participants spent substantially more time in scenes they accessed via an LLM recommendation (M = 161.07 seconds) compared to those they entered independently (M = 62.55 seconds), indicating a potential influence of AI-driven guidance on user engagement. Correlational analyses between recommendation use and scene duration revealed moderate to strong positive relationships in several cases, including Snow Stretching (r = .67), Abstract Meditation (r = .57), and Forest Stretching (r = .44), suggesting that participants who followed recommendations tended to engage longer in those scenes. These findings highlight the role of LLMs in shaping exploratory behavior and supporting deeper immersion in well-being-oriented environments.


% \todo{Marios to update} We also examined participants’ overall engagement across the 12 available scenes, irrespective of whether the scene was recommended by the LLM. The most visited and time-intensive scenes were Snow Exploration ($\mu$ = 143.63 seconds), Beach Exploration ($\mu$ = 123.60 seconds), and Forest Exploration ($\mu$ = 121.14 seconds), indicating a strong preference for free-roaming activities. Among exercise-based scenes, Beach Stretching ($\mu$ = 79.71 seconds) and Forest Stretching ($\mu$ = 74.43 seconds) were the most engaging, while meditation scenes such as Forest Meditation ($\mu$ = 24.86 seconds) and Abstract Stretching ($\mu$ = 29.86 seconds) received less attention overall. These results suggest that participants were more drawn to exploratory experiences, with nature-themed environments offering the highest levels of sustained engagement.





We also examined participants' overall engagement across the 12 available scenes, irrespective of whether the scene was recommended by the LLM (Table~\ref{tab:scene_engagement}). The most popular environment-activity combo was Forest Stretching ($\mu$ = 236.82s), while the least popular was Abstract Exploration ($\mu$ = 83.35s).

% To focus on meaningful engagement, we excluded visits where participants spent less than 30 seconds. The most time-intensive scenes were Forest Stretching ($\mu$ = 236.82s), Forest Exploration ($\mu$ = 201.43s), and Snow Exploration ($\mu$ = 200.68s), suggesting a strong interest in both movement-based and exploratory experiences. Among exercise-based scenes, Beach Stretching ($\mu$ = 199.29s) and Snow Stretching ($\mu$ = 182.00s) were also highly engaging. Interestingly, even some meditation scenes such as Forest Meditation ($\mu$ = 172.00s) and Abstract Meditation ($\mu$ = 143.23s) attracted sustained attention. In contrast, scenes such as Abstract Exploration ($\mu$ = 83.35s) and Beach Meditation ($\mu$ = 116.50s) were used for shorter durations. These results suggest participants were drawn to immersive and nature-themed environments, particularly those that supported active or contemplative engagement.


% Additionally, we explored the average times our participants spent in each activity independent to the scene (e.g., beach, forest, snow, abstract). We found that the most popular activity was stretching ($\mu = 192.43 s$), followed by exploration ($\mu = 165.2 s$), and meditation ($\mu = 138.92 s$).

% \todo{DONE. report result: average out all activities independent to the scene (e.g., beach stretching, forest stretching...) say which activity is the most popular} 
\smallskip

\subsubsection{Qualitative}

% \noindent \textbf{VR for well-being is not a one size fits all recipe.}
% Our 
% Aligning with our findings from the formative study as well as previous literature, our results indicated that knowledge workers face a variety of well-being challenges and needs, which in turn influenced their preferences regarding the use of VR to meet them. 16 of our participants directly talked about the sedentary nature of knowledge work, which was seen as unhealthy and uncomfortable, often leading to lack of movement, which in turn causes physical discomfort and pain (PS15, PS6). PS15 explained \textit{``The biggest issue I have is that most of the time I have to sit in front of the computer, so I end up visiting the physiotherapist who has to fix my back. I have back pain, neck pain or I might get pains on my arms because of using the mouse''.} The workload and focus required by knowledge work exacerbates this as it can be difficult for individuals to take sufficient breaks and move around during the workday (PS33, PS20). Moreover, mentally knowledge workers face challenges like stress (PS23, NN06, PS30, PS13), burnout (PS4), emotional strain (PS8), lack of motivation (PS6, PS4), and difficulty maintaining work-life balance (LI67, IA11), often intensified by high cognitive demands (PS20 PS25, le07) and tight deadlines (PS23, NN06, PS30, PS13). IA11 noted that such challenges lead to \textit{''Need to for decompressing when I go to at home. I don't want to do anything, just the tasks necessary to survive the rest the day and I end up not doing anything for myself''.}

% \begin{itemize}

% \item people have different needs but also different ways of relaxing
% \item seen by our data by the diversity of preferences our participants had and the ways they prefered interacting with the app both in terms of environments and what to do in them 
% \item talk about flexibility of interaction and ambiguity in design
% \item we opted for relaxing activities but also people asked for activites to get out ther annoyance for example 
% \end{itemize}

\noindent\textbf{VR as a ``drop-in'' Well-being Tool.} Our participants saw potential for VR at work as a drop-in well-being tool, to be used opportunistically rather than through scheduled sessions, supporting the findings of our formative study. 13 of our participants mentioned that for such a tool to be meaningful, it should be readily available without requiring extensive setup (PS3) or booking systems (PS9), catering to the unpredictable nature of work pressures. PS1 elaborated \textit{``I could see it being a drop-in thing. Booking presumes that you can plan for stresses at work, which most of the time doesn't really work that way. If my neck felt stiff after a long meeting, I might drop by and see if there's an available headset to use''.} PS24 and PS1 suggested that a dedicated space with enough headsets would support this kind of spontaneous use.

Moreover, our participants reiterated the need for diverse experiences that are suitable for short breaks between 5 and 20 minutes. The three activities we provided were seen as appropriate for this timeframe. Providing a means for quick stress relief or mental reset could help employees return to their tasks feeling more creative and focused. PS30 described \textit{``having this as a solution could even decrease the breaks because you take one break and it helps you relax and be more productive''.} Nevertheless, PS8 pointed out that for this to happen it is important for the experience to allow users to quickly detach from their surroundings: \textit{``the virtual environment should help you disconnect from the real world fast and be in a state that you forget where you are and you're fully engaged''.} PS12 and PS10, suggested usage limits were seen as a way to prevent overuse by employees. PS3 and PS10 explained that exiting the experience is as important; any type of time limit should be implemented in a way that takes the user smoothly out of the experience. Having a timer abruptly run out might undo the relaxation effect. 
\smallskip

\noindent \textbf{VR for Escaping the Office.}
Participants often described VR as a potential supplement or alternative, not a replacement, for real-life breaks or social interactions. PS5 explained \textit{``fundamentally it is there not to replace social breaks or any type of break, it is there as a thing that you can go for five minutes when you're feeling overworked''.} For VR to be considered a meaningful alternative, it had to offer something distinct from a typical 5 to10 minute off-screen break as PS16 pointed out: \textit{`` it should offer a different experience at what you do in your typical breaks at work, [...] an escape, an addition''.} Many valued VR for its ability to transport them away from the immediate work context. PS8 explained \textit{`` when you want to take a break and disconnect from everything it can help you. It gives you the chance to be in an environment that it's not easy to do in real world''.}  The included environments were found sufficient in creating a sense of disconnection from reality, which, according to PS5, could help \textit{``people who struggle to meditate with their eyes closed focus on the environment and in turn on the meditation''.}

Sound was consistently brought up as a crucial element in increasing the effectiveness of VR well-being experiences, with 12 participants pointing out that it was one of the main elements that helped them detach. Participants noted that realistic and soothing sounds, such as birds in a forest or the ocean at a beach, contributed significantly to the feeling of ``being there''. PS27 described that the audio \textit{``helped you get into the environment and live the present moment'',} and PS15 further noted that it helped them  \textit{``feel present in every scene''.}  Nevertheless, responses to sound were subjective. Wind in the snow scene, for example, was relaxing for some (PS14) and distracting for others (PS32). Similarly, the mellow music in the abstract scene was disliked by PS10, describing it as one of the main things they did not like about the experience, while for others like PS5, it was the main thing that kept them in that scene and helped them detach. PS5 spent an extensive amount of time in the abstract environment because they enjoyed combining the sound with the 'simplistic' environment. They explained \textit{``in everyday life the frequency of the change of the images that we have in front of us is so high. So, visually, I feel that I cannot find comfort in the environment. Whereas with the sound, I feel that the information is less, and I could focus on that''.} Lastly, participants also commented on the guided meditation. While Loomi's AI-generated voice was generally well-received, several wanted a slower pace.
\smallskip

\noindent\textbf{VR for Playful Well-being.} Activities that encouraged play and curiosity without causing stress were seen as a way of relieving stress and injecting fun into the workday. This allowed employees to mentally detach from work pressures (even momentarily) and \textit{``return back feeling refreshed and energized''.} as PS35 described. During the sessions, we observed our participants engaging in unplanned playful behaviors, often triggered by their curiosity to discover the environment. For example, participants tried to run on the water, knock on doors, or gather flowers. Such interactions provided a sense of fun and escape, according to PS32 and PS22. Even if they were not practically possible, the potential of their existence triggered participants' curiosity.  Exploration mode was particularly valued. PS26 described it as `fascinating', prompting them to \textit{``want to explore around and look at the entire landscape''}, while PS23 reflected that exploration \textit{`` taps into a primitive human need, wakes up the child inside us and their curiosity''} and helped them momentarily reconnect with themselves during a busy workday.

Although some participants like PS12 appreciated the passive nature of exploration as it allowed them to simply \textit{``to look around and absorb what is happening''}, others felt it lacked meaningful interaction besides moving (PS3). Suggestions to enrich the experience included non-goal-oriented interactions such as the ability to fly (PS3, PS4), going underwater (PS11), entering houses (PS12), picking up flowers (PS32), or looking for and finding animals (PS22, PS11, PS25, PS6). PS11 suggested \textit{``it would be nice to look for animals based on where the sounds are coming from. That would grab my attention and make me more focused''.} Easter eggs were also commonly requested as a way to make exploration more fun. As PS13 put it \textit{``I would have liked to explore more things, like finding Easter eggs or something different to spark my curiosity''.}

Beyond unstructured play, several participants suggested various game elements and play features that are more structured.  These included tasks like finding hidden items, collecting objects, or reaching locations (PS33, PS8). PS33 proposed \textit{``you could have points of reference, find that in the environment or try and look for or gather stuff, meaning in a forest environment you could collect flowers''.} Other suggestions included mini-games like fishing with scoring (PS20) or competitive challenges among employees, such as exercise-based leaderboards (PS3) and treasure hunts (PS33). Goals were seen as adding a sense of accomplishment and encouraging engagement. However, not all participants welcomed gamification. PS8 cautioned against overloading the experience with tasks that might feel like work or added pressure during a break. The key would be to find a balance where gamification enhances engagement without detracting from the primary goal of supporting well-being, as PS2 explained \textit{``It helps to have 5, 10 minutes of fun [...]. Maybe a fun mini-game. Not stressful one''}.


% \todo{Write about ai generated environments to keep things interesting. }


% \begin{itemize}
% \item Play whether structured or unstructured emerged during the interactions
% \item Participant asked for gamification
% \item but they also asked for non-goal oriented play. 
% \item Experiences that trigger curiosity / (e.g animal finding and so on and focus the attention)
% \end{itemize}
\smallskip
\noindent \textbf{AI for Personalizing the Experience.} \revision{The use of AI at the start of the app to prompt emotional reflection received mixed reactions. While some participants appreciated it as a gentle nudge, others found it unhelpful or overly simplistic.}

\revision{On the positive side, participants valued how the assistant helped reduce overthinking or offered helpful framing. \revision{PS21 used the AI to guide their experience, while PS14 shared: \textit{``It gives you an answer based on what you could do so you don't have to think [...] It directs you to the correct path''.}} Even participants who did not rely on the suggestions still found value in the option. \revision{As PS20 put it, \textit{``It [the AI] provides you guidance [...] but I don't know if it's necessarily helpful as I still went where I wanted to''.}}} \revision{Beyond the current implementation, many participants envisioned richer uses of AI. \revision{PS30 and PS25 imagined Loomi as a personal coach that adapts to their preferences over time. PS30 noted, \textit{``[AI could] learn from the way you use the app and guide you there''.} Others suggested tracking wellness progress (e.g.,  mood or performance). PS25 imagined Loomi offering summaries or posture feedback, while PS27 proposed real-time support: \textit{``If the app understands you're having difficulty, I can ask it, and the answer would come''.}} Participants also envisioned generative personalization, where the AI dynamically creates activities and environments. \revision{PS1 imagined conversations with Loomi leading to customized meditation or yoga based on how they felt that day. PS27 emphasized: \textit{``If I'm going to use it on an everyday basis, I would like different yoga options based on what I need''.} PS4 proposed scene variability: \textit{``It could generate the world [...] so it's different every time''.} PS33 added, \textit{``It could generate a cat doing funny things [...]. Something that cheers you up. Something that could be more like a mood booster''.}}}

\revision{On the negative side, several participants reported either not noticing the AI at all (PS8, PS32) or finding it too generic (PS22) or unnecessary (PS3). \revision{A key issue was the text-based interface. PS3 found it cognitively demanding during already overloaded workdays, proposing \textit{``Maybe a voice would have made me notice it more. The text didn't grab my attention''.}} Participants advocated for multimodal interactions (e.g., voice and embodied avatars) to make Loomi feel more engaging. \revision{PS20 suggested a playful character; PS23 imagined venting frustrations: \textit{`` I've been in front of my computer since 7:00 AM, so I don't want to see any more text. I want to talk to someone, want a voice.[...] If this is meant to help me relax, I think that a conversation could be helpful''.}}} \revision{While participants recognized the value of personalization, they also expressed strong reservations about the risks of integrating AI into well-being tools, particularly in workplace contexts. Trust emerged as a major concern. PS7 noted: \textit{``You don't know if the recommendation is good or not. So it's up to you to decide based on how much you trust it''.} PS8 proposed evaluating outcomes: \textit{``If it asks you whether you feel better after, it builds trust with AI tools''.} Participants also raised privacy concerns, especially if users began confiding in Loomi as they might with a therapist. \revision{PS1 warned: \textit{``If it gets to a point where people share intimate details, then the data becomes a big problem''.}} The workplace setting heightened these anxieties. \revision{PS3 shared: \textit{``If you want to complain about something at work and that is later used against you, it's a problem''.}} The possibility of data being used for targeted advertising or surveillance raised further ethical flags. Participants felt this tension between personalization and anonymity must be carefully managed. PS1 proposed a compromise: input data should be used in the moment but not stored (or reused) to train AI models.}

% \subsection{Limitations and Future Work}
% \revision{Phase 2 of our work has seven major limitations. Firstly, the deployment was limited in duration and scope, taking place in a specific workspace setting with relatively short, one-off sessions. The reliance on a tethered VR setup may have reduced ease of use and does not reflect the typical experience of using standalone headsets in office settings. Although the app included low-effort physical activities, it did not support full-body movement or a wider range of interaction styles, which may limit its appeal for some users. While users could choose from multiple activities, only one could be accessed per session, requiring a return to the main menu to switch. The participant group was again largely comfortable with digital tools, which may not represent the broader working population. The AI assistant provided static, one-time suggestions and did not adapt over time, limiting its role in personalisation and long-term support. Finally, the system did not introduce new technological features or interaction techniques. This was intentional: the focus of our work was not on technological novelty, but on exploring how existing immersive tools can be used in practical, meaningful ways to support well-being at work.
% Future studies should explore longer-term deployments to understand sustained use, particularly with adaptive or context-aware systems. Testing in varied work settings with standalone devices would offer more realistic insights into everyday integration. Including less tech-confident users and enabling smoother transitions between activity types could help create more inclusive and flexible VR well-being tools.}
% Based on the design requirements established in the formative study, we used AI at the start of the app to prompt users into emotional reflection as well as a recommender tool that helps users decide which part of the app they would like to use, based on the challenge they faced recently. This type of implementation received mixed perceptions from our participants. \revision{Some, like PS21, used AI to help them decide where to go and reduce overthinking. SH01 explained \textit{``It gives you an answer based on what you could do so you don't have to think [...] It directs you to the correct path''.}. Other participants did not notice it (AZ99, RA10, li67) or found its usage unnecessary, limited (IS11), or too generic (IKO2). Some participants like PS20 did use it and saw what the GPT recommended, but they still preferred to follow their own preferences: \textit{``I mean it [the AI] provides you guidance on what to experience from the other staff, but I don't know if it's necessarily helpful as I still went where i wanted to''.}} 

% \revision{Moreover, another common reason for participants ultimately not using the AI was the text-based interaction, which was found to be too bothersome and required too much focus (NN06, IA11). Participants such as RA11, IA11, OS02, and GE10 strongly expressed a desire for voice commands and auditory feedback from the AI rather than text. They suggested that if Loomi interacted with them via voice, then perhaps they would have paid more attention to it. IA11 elaborated \textit{``Maybe a voice would have made me notice it more, listen and pay more attention. The text did not grab my attention''.}  Others took it a step further and suggested giving a body to the AI to enhance the connection with the user. PS20 suggested having an actual avatar or playful character for the AI: \textit{``you need to be able to [...] converse with the AI. And maybe you can have an actual avatar or a playful character for the AI and do more interactions. In that case, it could have more value''.} Users like AR08 described that if the AI has a form of interaction beyond text, it could be easily used by them to perhaps vent frustrations like they would do to a therapist. GE10 elaborated \textit{``Could it be interactive in the sense that if I'm feeling something at a specific moment during my experience, I can share it with the AI?. Maybe the reason I decided to use this app is because I got frustrated with a colleague, and I want to tell someone what happened, and I want to share that because I want to, not necessarily because I want to be told how to handle it. I want to let it out. So could that be a good usage of it?''} The same user goes on to explain why voice would be the best in such a situation \textit{`` Because I've been in front of my computer since 7:00 AM, so I don't want to see any more text or type. I want to talk to someone, want a voice. You know what I mean? If this is meant to help me relax, I think that a conversation could also be very, very helpful''.}}

% \revision{Nevertheless, although participants had mixed feelings about the current implementation of AI within the app, its presence enabled them to envision other ways of using AI within VR apps for well-being, and they saw a lot of potential in enabling personalization and customization of the experience while still allowing for agency. Some participants, such as PS30  and PS25, envisioned AI being used as a personal coach, learning from user behavior, performance, and preferences as well as through conversations to offer more tailored recommendations for activities or environments. According to IS08 AI could \textit{`` Learn from the way you use the app and tries through the app to understand what actually helps you and guide you there''.}. This could also include tracking personal metrics such as yoga performance and mood changes according to RA11 to help users keep a record of their progress and work towards their wellness goals. However, participants like SH01 suggested that since the app is about well-being, tracking progress should be only when the user opts in, as \textit{``it could become obsessive and I would want to reach a certain level and stuff like that which would take away from stress reduction''.} In addition, participants proposed that the AI could also provide guidance within activities such as real-time yoga posture correction or information about completed sessions and muscle improvements. NI09 explained  \textit {``If it's based on AI and the app understands that you're having difficulty with something, I can just ask it and the answer would come to me. For example, with the yoga poses, it could give me an indication of the way I need to change my hands''.} AZ05 further added \textit{``Maybe it could also give some sort of information when you have completed this session. It could tell you if your muscles are working better or so. Something more to give what you've done value. So maybe some side notes''.}}

% \revision{Moreover, participants imagined AI  dynamically generating such activities. According to PS3 and PS1, through free-flowing conversations with an AI assistant, similar to a therapist or advisor, AI could customize activities or content based on a user's stated feelings, such as custom meditation or yoga sessions. This would not only enable personalization based on the users' context but also make the app more interesting and useful in the long term, with activities not becoming repetitive. NI09 elaborated \textit{``Maybe it [AI] can build the meditation based on the needs of the user instead of being the same for every single user. That would help or have different options like a calmness meditation and meditation for security, a meditation session for different aspects that a worker can go through while working. [...] The same goes for yoga. At the moment, it does help to calm down, but you can't do that every single time. I mean, if I'm going to use it on an everyday basis, I would like different options of yoga exercises based on what I need that day''.}. Taking it a step further, participants also proposed that the AI could generate dynamic and varied environments or spawn objects within scenes, making each experience unique and preventing boredom. AA11 described \textit{``It could be used to generate part of the world [...] Or generate the word to spawn things in the scene, so it's different every time''}.  ML02 further suggested \textit{``It could generate a cat in the environment doing funny things so you can change your mood. Something like that. Something that cheers you up. Something that could be more like a mood booster''.}}

% \revision{Despite the potential they saw, users also raised several concerns about AI in VR wellness apps. A significant concern was the lack of trust in AI as it is known to make mistakes, especially in complex applications (MP70, OD01).  PS7 elaborated on this by explaining \textit{``You have some recommendation. You don't know if the recommendation is good or not. So it's up to you to decide if you're going to follow the AI based on how much you trust it''.} For this reason, participants highlighted the importance of safeguarding and building trust with the AI, especially when it comes to wellness context, where the potential for pre-trained models to offer problematic or even dangerous advice (e.g., related to self-harm) was also highlighted. To combat this, participants felt it was important to evaluate the recommendations provided by AI.  PS8 suggested that this would also help build trust between the user and the technology \textit{``I never blindly trust AI because it also makes mistakes. If I ask something about my well-being, it gives me some recommendations, and I follow them. It's a bit of blind trust. But if there is a way to subjectively evaluate the experience after you finish, for example, if it asks you whether you feel better after the recommendation, it would be an additional proof of building trust with using AI tools in general''.} even though participants stated that an app targeted towards well-being at the workplace should not track progress as its success would lie in whether it makes you feel better at the moment, they saw potential in using AI to reflect on the experience by asking them simple questions like 'Did you feel better after today's session'.}

% \revision{In addition, throughout our study, privacy and ethical considerations came up with participants talking about the fact that they are not particularly concerned about the safety of their data as long as it is covered by standard protocols such as GDPR. However, if the app used AI, then the data and what participants share become a more important point of concern. IH10 said \textit{``if you get to a point where it's advanced enough that the person treats the AI as a therapist and that it's telling them intimate details of their life, then the data would become a big problem''.} Participants worried about how employers might use the content of conversations with an AI. For instance, PS3 explained \textit{It could be an issue if it(data) is stored and used against you.[...] It's a matter of how it is then accessed by the employer. If you are having conversations with AI and you want to complain about something that happened at work and blow off some steam, and then that is still later used against you by someone, it's a problem''.} Furthermore, PS25 talked about how custom input data could also be used for target advertising, similarly to how social media conversations are used, which would be quite problematic. Such concerns raised a tension between participants' desire for personalized experiences based on their feelings, which would require sensitive input of information data tracking, and the need for anonymity and privacy within a workplace well-being tool. PS1 suggested that this could be resolved by input being transient, i.e, just used in the moment, rather than used to train the AI to personalize the experience long term. }

% \todo{Add something about biofeedback and biometric data and talk about papers like Deep VR - people didn't really think biofeedback is needed to evaluate VR application}



% \begin{itemize}
% \item Nevertheless during the interveiws participants reported that they didn't find the way we implemented AI useful however they saw potential in using it. - we used the AI as a form of personalisation through recommendation -> they saw what was being recommended but they wanted to follow their own preference. they prefered it as a personal coach tool. 
% \item main concerns were text but also the choices we had
% \item AI as a recommendation tool
% \item AI as personalisation tool 
% \item AI as a therapist / someone to vent to
% \item AI as a games companion
% \item Ai can be used to keep things interesting
% \item Personalisation - data collection for that 
% \end{itemize}

% \noindent \textbf{What to measure, how to measure it and how to evaluate the experience}
% \begin{itemize}
% \item Ethics where do they come in?
% \item well-being is subjective / we don't really need biometric data to measure if we feel better / track progress.
% \end{itemize}
