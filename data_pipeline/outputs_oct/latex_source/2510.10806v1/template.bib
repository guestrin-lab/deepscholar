@article{jin2024large,
  title={Large language models on graphs: A comprehensive survey},
  author={Jin, Bowen and Liu, Gang and Han, Chi and Jiang, Meng and Ji, Heng and Han, Jiawei},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2024},
  publisher={IEEE}
},

@article{xypolopoulos2024graph,
  title={Graph linearization methods for reasoning on graphs with large language models},
  author={Xypolopoulos, Christos and Shang, Guokan and Fei, Xiao and Nikolentzos, Giannis and Abdine, Hadi and Evdaimon, Iakovos and Chatzianastasis, Michail and Stamou, Giorgos and Vazirgiannis, Michalis},
  journal={arXiv preprint arXiv:2410.19494},
  year={2024}
},

@article{wang2023can,
  title={Can language models solve graph problems in natural language?},
  author={Wang, Heng and Feng, Shangbin and He, Tianxing and Tan, Zhaoxuan and Han, Xiaochuang and Tsvetkov, Yulia},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={30840--30861},
  year={2023}
},

@inproceedings{sarthi2024raptor,
  title={Raptor: Recursive abstractive processing for tree-organized retrieval},
  author={Sarthi, Parth and Abdullah, Salman and Tuli, Aditi and Khanna, Shubh and Goldie, Anna and Manning, Christopher D},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
},

@article{liu2024graphcoder,
  title={Graphcoder: Enhancing repository-level code completion via code context graph-based retrieval and language model},
  author={Liu, Wei and Yu, Ailun and Zan, Daoguang and Shen, Bo and Zhang, Wei and Zhao, Haiyan and Jin, Zhi and Wang, Qianxiang},
  journal={arXiv preprint arXiv:2406.07003},
  year={2024}
},

@article{fatemi2023talk,
  title={Talk like a graph: Encoding graphs for large language models},
  author={Fatemi, Bahare and Halcrow, Jonathan and Perozzi, Bryan},
  journal={arXiv preprint arXiv:2310.04560},
  year={2023}
},

@article{li2024can,
  title={Can large language models analyze graphs like professionals? a benchmark, datasets and models},
  author={Li, Xin and Chen, Weize and Chu, Qizhi and Li, Haopeng and Sun, Zhaojun and Li, Ran and Qian, Chen and Wei, Yiwei and Shi, Chuan and Liu, Zhiyuan and others},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={141045--141070},
  year={2024}
},

@article{he2024g,
  title={G-retriever: Retrieval-augmented generation for textual graph understanding and question answering},
  author={He, Xiaoxin and Tian, Yijun and Sun, Yifei and Chawla, Nitesh and Laurent, Thomas and LeCun, Yann and Bresson, Xavier and Hooi, Bryan},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={132876--132907},
  year={2024}
},

@article{li2024simple,
  title={Simple is effective: The roles of graphs and large language models in knowledge-graph-based retrieval-augmented generation},
  author={Li, Mufei and Miao, Siqi and Li, Pan},
  journal={arXiv preprint arXiv:2410.20724},
  year={2024}
},

@article{edge2024local,
  title={From local to global: A graph rag approach to query-focused summarization},
  author={Edge, Darren and Trinh, Ha and Cheng, Newman and Bradley, Joshua and Chao, Alex and Mody, Apurva and Truitt, Steven and Metropolitansky, Dasha and Ness, Robert Osazuwa and Larson, Jonathan},
  journal={arXiv preprint arXiv:2404.16130},
  year={2024}
},

@article{levy2025more,
  title={More Documents, Same Length: Isolating the Challenge of Multiple Documents in RAG},
  author={Levy, Shahar and Mazor, Nir and Shalmon, Lihi and Hassid, Michael and Stanovsky, Gabriel},
  journal={arXiv preprint arXiv:2503.04388},
  year={2025}
},

@article{warfield2024vector,
  title   = {Do Vector Databases Lose Accuracy at Scale?},
  author  = {Warfield, Daniel and Fletcher, Benjamin},
  journal = {EyeLevel.ai Blog},
  year    = {2024},
  month   = {October},
  url     = {https://www.eyelevel.ai/post/do-vector-databases-lose-accuracy-at-scale}
},

@article{jiang2024longrag,
  title={Longrag: Enhancing retrieval-augmented generation with long-context llms},
  author={Jiang, Ziyan and Ma, Xueguang and Chen, Wenhu},
  journal={arXiv preprint arXiv:2406.15319},
  year={2024}
},

@article{deng2023implicit,
  title={Implicit chain of thought reasoning via knowledge distillation},
  author={Deng, Yuntian and Prasad, Kiran and Fernandez, Roland and Smolensky, Paul and Chaudhary, Vishrav and Shieber, Stuart},
  journal={arXiv preprint arXiv:2311.01460},
  year={2023}
},

@inproceedings{wang2023explicit,
  title={Explicit and implicit knowledge distillation via unlabeled data},
  author={Wang, Yuzheng and Ge, Zuhao and Chen, Zhaoyu and Liu, Xian and Ma, Chuangjia and Sun, Yunquan and Qi, Lizhe},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
},

@article{li2024direct,
  title={Direct preference knowledge distillation for large language models},
  author={Li, Yixing and Gu, Yuxian and Dong, Li and Wang, Dequan and Cheng, Yu and Wei, Furu},
  journal={arXiv preprint arXiv:2406.19774},
  year={2024}
},

@article{dong2022survey,
  title={A survey on in-context learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Ma, Jingyuan and Li, Rui and Xia, Heming and Xu, Jingjing and Wu, Zhiyong and Liu, Tianyu and others},
  journal={arXiv preprint arXiv:2301.00234},
  year={2022}
},

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
},

@article{gao2023retrieval,
  title={Retrieval-augmented generation for large language models: A survey},
  author={Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yixin and Sun, Jiawei and Wang, Haofen and Wang, Haofen},
  journal={arXiv preprint arXiv:2312.10997},
  volume={2},
  number={1},
  year={2023}
},

@inproceedings{ren2024survey,
  title={A survey of large language models for graphs},
  author={Ren, Xubin and Tang, Jiabin and Yin, Dawei and Chawla, Nitesh and Huang, Chao},
  booktitle={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={6616--6626},
  year={2024}
},

@inproceedings{shi2023large,
  title={Large language models can be easily distracted by irrelevant context},
  author={Shi, Freda and Chen, Xinyun and Misra, Kanishka and Scales, Nathan and Dohan, David and Chi, Ed H and Sch{\"a}rli, Nathanael and Zhou, Denny},
  booktitle={International Conference on Machine Learning},
  pages={31210--31227},
  year={2023},
  organization={PMLR}
}