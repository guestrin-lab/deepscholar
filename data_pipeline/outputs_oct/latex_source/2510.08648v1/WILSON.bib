@inproceedings{ribeiro2020checklist,
  title       = {CheckList: A Behavioral Testing Framework for NLP},
  author      = {Ribeiro, Marco Tulio and Wu, Tongshuang and Guestrin, Carlos and Singh, Sameer},
  booktitle   = {ACL},
  year        = {2020},
  pages       = {4902--4912}
}

@inproceedings{goel2021robustgym,
  title       = {Robustness Gym: Unifying the NLP Evaluation Landscape},
  author      = {Goel, Karan and Rajani, Nazneen Fatema and Reif, Emily and others},
  booktitle   = {ACL (System Demonstrations)},
  year        = {2021},
  pages       = {42--55}
}

@inproceedings{ankner2021varrename,
  title       = {Transformer Models Should Be Invariant to Variable Renaming},
  author      =  {Ankner, Zachary and others},
  booktitle   = {ICLR Workshop},
  year        = {2021}
}

@misc{wang2022recoderobustnessevaluationcode,
      title={ReCode: Robustness Evaluation of Code Generation Models}, 
      author={Shiqi Wang and Zheng Li and Haifeng Qian and Chenghao Yang and more},
      year={2022},
      eprint={2212.10264},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2212.10264}, 
}



@inproceedings{chen2018tvm,
  title       = {Optimizing {DNN} Computation with {TVM}},
  author      = {Chen, Tianqi and others},
  booktitle   = {OSDI},
  year        = {2018}
}

@book{higham2002accuracy,
  title       = {Accuracy and Stability of Numerical Algorithms},
  author      = {Higham, Nicholas J.},
  publisher   = {SIAM},
  edition     = {2},
  year        = {2002}
}

@inproceedings{cohen2016groupcnn,
  title       = {Group Equivariant Convolutional Networks},
  author      = {Cohen, Taco and Welling, Max},
  booktitle   = {ICML},
  year        = {2016}
}

@inproceedings{cohen2017steerable,
  title       = {Steerable {CNN}s},
  author      = {Cohen, Taco and Welling, Max},
  booktitle   = {ICLR},
  year        = {2017}
}
@article{bronstein2021geometric,
  title       = {Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges},
  author      = {Bronstein, Michael M. and Bruna, Joan and Cohen, Taco and Veli{\v{c}}kovi{\'c}, Petar},
  journal     = {Proceedings of the IEEE},
  volume      = {109},
  number      = {5},
  pages       = {899--919},
  year        = {2021}
}

@inproceedings{vaswani2017attention,
  title       = {Attention Is All You Need},
  author      = {Vaswani, Ashish and Shazeer, Noam and others},
  booktitle   = {NeurIPS},
  year        = {2017}
}

@inproceedings{shaw2018relative,
  title       = {Self-Attention with Relative Position Representations},
  author      = {Shaw, Peter and Uszkoreit, Jakob and Vaswani, Ashish},
  booktitle   = {NAACL},
  year        = {2018}
}

@article{su2021rope,
  title       = {RoFormer: Enhanced Transformer with Rotary Position Embedding},
  author      = {Su, Jianlin and Lu, Yu and Pan, Shengfeng and Wen, Bo and Liu, Yunfeng},
  journal     = {arXiv preprint arXiv:2104.09864},
  year        = {2021}
}

@article{press2021alibi,
  title       = {Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation},
  author      = {Press, Ofir and Smith, Noah A. and Levy, Mike},
  journal     = {arXiv preprint arXiv:2108.12409},
  year        = {2021}
}

@article{chen2023positioninterp,
  title       = {Extending Context Window of Large Language Models via Positional Interpolation},
  author = {Chen, Shouyuan and Wong, Sherman and Chen, Liangjian and Tian, Yuandong},
  journal     = {arXiv preprint arXiv:2306.15595},
  year        = {2023}
}

@article{ding2024longrope,
  title   = {LongRoPE: Extending {LLM} Context Window Beyond 2 Million Tokens},
  author  = {Ding, Yiran and others},
  journal = {arXiv preprint arXiv:2404.13760},
  year    = {2024}
}

@inproceedings{peng2024yarn,
title={Ya{RN}: Efficient Context Window Extension of Large Language Models},
author={Bowen Peng and Jeffrey Quesnelle and Honglu Fan and Enrico Shippole},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=wHBfxhZu1u}
}

@inproceedings{raghu2017svcca,
  title       = {SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability},
  author      = {Raghu, Maithra and Gilmer, Justin and Yosinski, Jason and Sohl-Dickstein, Jascha},
  booktitle   = {NeurIPS},
  year        = {2017}
}

@inproceedings{kornblith2019cka,
  title       = {Similarity of Neural Network Representations Revisited},
  author      = {Kornblith, Simon and Norouzi, Mohammad and Lee, Honglak and Hinton, Geoffrey},
  booktitle   = {ICML},
  year        = {2019}
}

@inproceedings{hewitt2019designing,
  title       = {Designing and Interpreting Probes with Control Tasks},
  author      = {Hewitt, John and Liang, Percy},
  booktitle   = {EMNLP},
  year        = {2019}
}

@article{elhage2021mathematical,
  title   = {A Mathematical Framework for Transformer Circuits},
  author  = {Elhage, Nelson and Nanda, Neel and more},
  journal = {Anthropic},
  year    = {2021},
  url     = {https://transformer-circuits.pub/2021/framework/index.html}
}

@inproceedings{nanda2023progress,
title={Progress measures for grokking via mechanistic interpretability},
author={Neel Nanda and Lawrence Chan and more},
booktitle={ICLR},
year={2023},
url={https://openreview.net/forum?id=9XFSbDPmdW}
}

@inproceedings{
zhang2024towards,
title={Towards Best Practices of Activation Patching in Language Models: Metrics and Methods},
author={Fred Zhang and Neel Nanda},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=Hf17y6u9BC}
}

@article{ni2015ricci,
  title       = {Ricci Curvature of Markov Chains on Graphs},
  author      = {Ni, Chien-Chun and Lin, Yu-Yao and Gao, Jie and Gu, Xianfeng David},
  journal     = {Journal of Graph Theory},
  volume      = {83},
  number      = {2},
  pages       = {160--178},
  year        = {2015}
}

@article{samal2018forman,
  title       = {Comparative Analysis of Two Discretizations of Ricci Curvature on Biological Networks},
  author      = {Samal, Areejit and Sreejith, Rinoj and Gu, Xianfeng David and Liu, Shi and Saucan, Emil and Jost, J{\"u}rgen},
  journal     = {Scientific Reports},
  volume      = {8},
  number      = {1},
  pages       = {8650},
  year        = {2018}
}

@misc{chang2025UCCT,
      title={The Unified Cognitive Consciousness Theory for Language Models: Anchoring Semantics, Thresholds of Activation, and Emergent Reasoning}, 
      author={Edward Y. Chang and Zeyneb N. Kaya and Ethan Chang},
      year={2025},
      eprint={2506.02139},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2506.02139}, 
}

@book{hornjohnson2013matrixanalysis,
  title        = {Matrix Analysis},
  author       = {Horn, Roger A. and Johnson, Charles R.},
  edition      = {2},
  year         = {2013},
  publisher    = {Cambridge University Press},
  address      = {Cambridge, UK},
  isbn         = {978-0521548236}
}

@article{hutchinson1989stochastic,
  title   = {A stochastic estimator of the trace of the influence matrix for Laplacian smoothing splines},
  author  = {Hutchinson, Michael F.},
  journal = {Communications in Statistics -- Simulation and Computation},
  volume  = {18},
  number  = {3},
  pages   = {1059--1076},
  year    = {1989},
  publisher = {Taylor \& Francis},
  doi     = {10.1080/03610918908812806}
}

@article{avron2011randomized,
  title   = {Randomized algorithms for estimating the trace of an implicit symmetric positive semidefinite matrix},
  author  = {Avron, Haim and Toledo, Sivan},
  journal = {Journal of the ACM},
  volume  = {58},
  number  = {2},
  pages   = {8:1--8:34},
  year    = {2011},
  doi     = {10.1145/1944345.1944349}
}

@article{hsu2012tail,
  title   = {A tail inequality for quadratic forms of subgaussian random vectors},
  author  = {Hsu, Daniel and Kakade, Sham M. and Zhang, Tong},
  journal = {Electronic Communications in Probability},
  volume  = {17},
  number  = {52},
  pages   = {1--6},
  year    = {2012},
  doi     = {10.1214/ECP.v17-2079}
}

@article{rudelson2013hansonwright,
  title   = {Hanson--Wright inequality and sub-Gaussian concentration},
  author  = {Rudelson, Mark and Vershynin, Roman},
  journal = {Electronic Communications in Probability},
  volume  = {18},
  number  = {82},
  pages   = {1--9},
  year    = {2013},
  doi     = {10.1214/ECP.v18-2865}
}

@misc{cuconasu2025rags,
      title={Do RAG Systems Really Suffer From Positional Bias?}, 
      author={Florin Cuconasu and Simone Filice and Guy Horowitz and Yoelle Maarek and Fabrizio Silvestri},
      year={2025},
      eprint={2505.15561},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.15561}, 
}


@article{liu2023lostmiddle,
  title     = {Lost in the Middle: How Language Models Use Long Contexts},
  author    = {Liu, Nelson F. and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
  journal   = {arXiv preprint arXiv:2307.03172},
  year      = {2023},
  url       = {https://arxiv.org/abs/2307.03172}
}

@article{chen2024premiseorder,
  title     = {Premise Order Matters in Reasoning with Large Language Models},
  author    = {Chen, Xin and Xu, Haiyang and Zhao, Wayne and et al.},
  journal   = {arXiv preprint arXiv:2402.08939},
  year      = {2024},
  url       = {https://arxiv.org/abs/2402.08939}
}


@inproceedings{zhang2024compensateposbias,
  title     = {Can We Instruct LLMs to Compensate for Position Bias?},
  author    = {Zhang, Ming and Sun, Yutong and Xu, Yichong and Cai, Deng and Wang, Yizhou and Zhang, Yue},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2024},
  year      = {2024},
  publisher = {ACL},
  url       = {https://aclanthology.org/2024.findings-emnlp.732/}
}

@article{liang2022helm,
  title     = {Holistic Evaluation of Language Models},
  author    = {Liang, Percy and others},
  journal   = {arXiv preprint arXiv:2211.09110},
  year      = {2022},
  url       = {https://arxiv.org/abs/2211.09110}
}

@inproceedings{kiela2021dynabench,
  title     = {Dynabench: Rethinking Benchmarking in NLP},
  author    = {Kiela, Douwe and Bartolo, Max and Nie, Yixin and others},
  booktitle = {Proceedings of the 2021 Conference of the North American Chapter of the ACL},
  year      = {2021},
  publisher = {ACL},
  url       = {https://aclanthology.org/2021.naacl-main.324/}
}

@article{ahrens2020reprod,
  title     = {Algorithms for Efficient Reproducible Floating Point Summation},
  author    = {Ahrens, Willow and Demmel, James and Nguyen, Hong Diep},
  journal   = {ACM Transactions on Mathematical Software},
  year      = {2020},
  volume    = {46},
  number    = {3},
  pages     = {1--49},
  doi       = {10.1145/3389360}
}

@article{ollivier2007markov,
  title     = {Ricci Curvature of Markov Chains on Metric Spaces},
  author    = {Ollivier, Yann},
  journal   = {C. R. Acad. Sci. Paris, Ser. I},
  year      = {2007},
  volume    = {345},
  number    = {11},
  pages     = {643--646},
  doi       = {10.1016/j.crma.2007.10.041}
}

@inproceedings{WeiCoT2022,
author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed H. and Le, Quoc V. and Zhou, Denny},
title = {Chain-of-thought prompting elicits reasoning in large language models},
year = {2022},
isbn = {9781713871088},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We explore how generating a chain of thought—a series of intermediate reasoning steps—significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain-of-thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting.Experiments on three large language models show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a PaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.},
booktitle = {Proceedings of the 36th International Conference on Neural Information Processing Systems},
articleno = {1800},
numpages = {14},
location = {New Orleans, LA, USA},
series = {NIPS '22}
}

@inproceedings{lewis2020retrieval,
  title={Retrieval-Augmented Generation for Knowledge-Intensive {NLP} Tasks},
  author={Lewis, Patrick and Perez, Ethan and more},
  booktitle={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020},
}
