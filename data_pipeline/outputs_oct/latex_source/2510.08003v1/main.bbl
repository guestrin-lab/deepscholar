\begin{thebibliography}{77}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Anwaar et~al.(2020)Anwaar, Labintcev, and Kleinsteuber]{Anwaar2020CompositionalLO}
Muhammad~Umer Anwaar, Egor Labintcev, and Martin Kleinsteuber.
\newblock Compositional learning of image-text query for image retrieval.
\newblock \emph{2021 IEEE Winter Conference on Applications of Computer Vision (WACV)}, pages 1139--1148, 2020.

\bibitem[Anwaar et~al.(2021)Anwaar, Labintcev, and Kleinsteuber]{anwaar2021compositional}
Muhammad~Umer Anwaar, Egor Labintcev, and Martin Kleinsteuber.
\newblock Compositional learning of image-text query for image retrieval.
\newblock In \emph{Proceedings of the IEEE/CVF Winter conference on Applications of Computer Vision}, pages 1140--1149, 2021.

\bibitem[Bai et~al.(2023{\natexlab{a}})Bai, Bai, Yang, Wang, Tan, Wang, Lin, Zhou, and Zhou]{bai2023qwen}
Jinze Bai, Shuai Bai, Shusheng Yang, Shijie Wang, Sinan Tan, Peng Wang, Junyang Lin, Chang Zhou, and Jingren Zhou.
\newblock Qwen-vl: A frontier large vision-language model with versatile abilities.
\newblock \emph{arXiv preprint arXiv:2308.12966}, 2023{\natexlab{a}}.

\bibitem[Bai et~al.(2025)Bai, Chen, Liu, Wang, Ge, Song, Dang, Wang, Wang, Tang, et~al.]{bai2025qwen2}
Shuai Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Sibo Song, Kai Dang, Peng Wang, Shijie Wang, Jun Tang, et~al.
\newblock Qwen2. 5-vl technical report.
\newblock \emph{arXiv preprint arXiv:2502.13923}, 2025.

\bibitem[Bai et~al.(2023{\natexlab{b}})Bai, Xu, Liu, Khan, Khan, Zuo, Goh, and Feng]{bai2023sentence}
Yang Bai, Xinxing Xu, Yong Liu, Salman Khan, Fahad Khan, Wangmeng Zuo, Rick Siow~Mong Goh, and Chun-Mei Feng.
\newblock Sentence-level prompts benefit composed image retrieval.
\newblock \emph{arXiv preprint arXiv:2310.05473}, 2023{\natexlab{b}}.

\bibitem[Baldrati et~al.(2023{\natexlab{a}})Baldrati, Agnolucci, Bertini, and Bimbo]{Baldrati2023ZeroShotCI}
Alberto Baldrati, Lorenzo Agnolucci, Marco Bertini, and A. Bimbo.
\newblock Zero-shot composed image retrieval with textual inversion.
\newblock \emph{2023 IEEE/CVF International Conference on Computer Vision (ICCV)}, pages 15292--15301, 2023{\natexlab{a}}.

\bibitem[Baldrati et~al.(2023{\natexlab{b}})Baldrati, Agnolucci, Bertini, and Del~Bimbo]{baldrati2023zero}
Alberto Baldrati, Lorenzo Agnolucci, Marco Bertini, and Alberto Del~Bimbo.
\newblock Zero-shot composed image retrieval with textual inversion.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 15338--15347, 2023{\natexlab{b}}.

\bibitem[Bi et~al.(2024)Bi, Chen, Chen, Chen, Dai, Deng, Ding, Dong, Du, Fu, et~al.]{bi2024deepseek}
Xiao Bi, Deli Chen, Guanting Chen, Shanhuang Chen, Damai Dai, Chengqi Deng, Honghui Ding, Kai Dong, Qiushi Du, Zhe Fu, et~al.
\newblock Deepseek llm: Scaling open-source language models with longtermism.
\newblock \emph{arXiv preprint arXiv:2401.02954}, 2024.

\bibitem[Cesista(2024)]{Cesista2024MultimodalSG}
Franz~Louis Cesista.
\newblock Multimodal structured generation: Cvpr's 2nd mmfm challenge technical report.
\newblock \emph{ArXiv}, abs/2406.11403, 2024.

\bibitem[Chen et~al.(2024{\natexlab{a}})Chen, Chen, Zhang, Wang, Liu, Zhou, Zhang, Wan, Zhou, and Sun]{chen2024mllm}
Dongping Chen, Ruoxi Chen, Shilin Zhang, Yaochen Wang, Yinuo Liu, Huichi Zhou, Qihui Zhang, Yao Wan, Pan Zhou, and Lichao Sun.
\newblock Mllm-as-a-judge: Assessing multimodal llm-as-a-judge with vision-language benchmark.
\newblock In \emph{Forty-first International Conference on Machine Learning}, 2024{\natexlab{a}}.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Gong, and Bazzani]{Chen_2020_CVPR}
Yanbei Chen, Shaogang Gong, and Loris Bazzani.
\newblock Image search with text feedback by visiolinguistic attention learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Gong, and Bazzani]{chen2020image}
Yanbei Chen, Shaogang Gong, and Loris Bazzani.
\newblock Image search with text feedback by visiolinguistic attention learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 3001--3011, 2020{\natexlab{b}}.

\bibitem[Chen et~al.(2022)Chen, Zheng, Ji, Qu, and Chua]{Chen2022ComposedIR}
Yiyang Chen, Zhedong Zheng, Wei Ji, Leigang Qu, and Tat-Seng Chua.
\newblock Composed image retrieval with text feedback via multi-grained uncertainty regularization.
\newblock \emph{ArXiv}, abs/2211.07394, 2022.

\bibitem[Chen et~al.(2024{\natexlab{b}})Chen, Zhong, He, Peng, Zhou, and Cheng]{chen2024fashionern}
Yanzhe Chen, Huasong Zhong, Xiangteng He, Yuxin Peng, Jiahuan Zhou, and Lele Cheng.
\newblock Fashionern: enhance-and-refine network for composed fashion image retrieval.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, pages 1228--1236, 2024{\natexlab{b}}.

\bibitem[Chiang et~al.(2023)Chiang, Li, Lin, Sheng, Wu, Zhang, Zheng, Zhuang, Zhuang, Gonzalez, et~al.]{chiang2023vicuna}
Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph~E Gonzalez, et~al.
\newblock Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality.
\newblock \emph{See https://vicuna. lmsys. org (accessed 14 April 2023)}, 2\penalty0 (3):\penalty0 6, 2023.

\bibitem[Chu et~al.(2023)Chu, Chen, Chen, Yu, He, Wang, Peng, Liu, Qin, and Liu]{Chu2023NavigateTE}
Zheng Chu, Jingchang Chen, Qianglong Chen, Weijiang Yu, Tao He, Haotian Wang, Weihua Peng, Ming Liu, Bing Qin, and Ting Liu.
\newblock Navigate through enigmatic labyrinth a survey of chain of thought reasoning: Advances, frontiers and future.
\newblock In \emph{Annual Meeting of the Association for Computational Linguistics}, 2023.

\bibitem[Gal et~al.(2022)Gal, Alaluf, Atzmon, Patashnik, Bermano, Chechik, and Cohen-Or]{gal2022image}
Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or Patashnik, Amit~H Bermano, Gal Chechik, and Daniel Cohen-Or.
\newblock An image is worth one word: Personalizing text-to-image generation using textual inversion.
\newblock \emph{arXiv preprint arXiv:2208.01618}, 2022.

\bibitem[Gao et~al.(2021)Gao, Yao, and Chen]{gao2021simcse}
Tianyu Gao, Xingcheng Yao, and Danqi Chen.
\newblock Simcse: Simple contrastive learning of sentence embeddings.
\newblock \emph{arXiv preprint arXiv:2104.08821}, 2021.

\bibitem[Gordo et~al.(2016)Gordo, Almaz{\'a}n, Revaud, and Larlus]{gordo2016deep}
Albert Gordo, Jon Almaz{\'a}n, Jerome Revaud, and Diane Larlus.
\newblock Deep image retrieval: Learning global representations for image search.
\newblock In \emph{European conference on computer vision}, pages 241--257. Springer, 2016.

\bibitem[Gu et~al.(2023{\natexlab{a}})Gu, Chun, Kim, Jun, Kang, and Yun]{Gu2023CompoDiffVC}
Geonmo Gu, Sanghyuk Chun, Wonjae Kim, HeeJae Jun, Yoohoon Kang, and Sangdoo Yun.
\newblock Compodiff: Versatile composed image retrieval with latent diffusion.
\newblock \emph{ArXiv}, abs/2303.11916, 2023{\natexlab{a}}.

\bibitem[Gu et~al.(2023{\natexlab{b}})Gu, Chun, Kim, Kang, and Yun]{Gu2023LanguageonlyET}
Geonmo Gu, Sanghyuk Chun, Wonjae Kim, Yoohoon Kang, and Sangdoo Yun.
\newblock Language-only efficient training of zero-shot composed image retrieval.
\newblock \emph{2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 13225--13234, 2023{\natexlab{b}}.

\bibitem[Han et~al.(2023{\natexlab{a}})Han, Zhu, Yu, Zhang, Song, and Xiang]{Han2023FAMEViLMV}
Xiaoping Han, Xiatian Zhu, Licheng Yu, Li Zhang, Yi-Zhe Song, and Tao Xiang.
\newblock Fame-vil: Multi-tasking vision-language model for heterogeneous fashion tasks.
\newblock \emph{2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 2669--2680, 2023{\natexlab{a}}.

\bibitem[Han et~al.(2023{\natexlab{b}})Han, Zhang, Chen, Chen, Li, Yang, and Cao]{Han2023FashionSAPSA}
Yunpeng Han, Lisai Zhang, Qingcai Chen, Zhijian Chen, Zhonghua Li, Jianxin Yang, and Zhao Cao.
\newblock Fashionsap: Symbols and attributes prompt for fine-grained fashion vision-language pre-training.
\newblock \emph{2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 15028--15038, 2023{\natexlab{b}}.

\bibitem[Jia et~al.(2021)Jia, Yang, Xia, Chen, Parekh, Pham, Le, Sung, Li, and Duerig]{jia2021scaling}
Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le, Yun-Hsuan Sung, Zhen Li, and Tom Duerig.
\newblock Scaling up visual and vision-language representation learning with noisy text supervision.
\newblock In \emph{International conference on machine learning}, pages 4904--4916. PMLR, 2021.

\bibitem[Jiang et~al.(2024{\natexlab{a}})Jiang, Song, Zhang, Huang, Deng, Sun, Zhang, Wang, and Zhuang]{jiang2024e5}
Ting Jiang, Minghui Song, Zihan Zhang, Haizhen Huang, Weiwei Deng, Feng Sun, Qi Zhang, Deqing Wang, and Fuzhen Zhuang.
\newblock E5-v: Universal embeddings with multimodal large language models.
\newblock \emph{arXiv preprint arXiv:2407.12580}, 2024{\natexlab{a}}.

\bibitem[Jiang et~al.(2024{\natexlab{b}})Jiang, Wang, Li, Wu, Hu, and Qian]{jiang2024cala}
Xintong Jiang, Yaxiong Wang, Mengjian Li, Yujiao Wu, Bingwen Hu, and Xueming Qian.
\newblock Cala: Complementary association learning for augmenting comoposed image retrieval.
\newblock In \emph{Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval}, pages 2177--2187, 2024{\natexlab{b}}.

\bibitem[Karthik et~al.(2023)Karthik, Roth, Mancini, and Akata]{Karthik2023VisionbyLanguageFT}
Shyamgopal Karthik, Karsten Roth, Massimiliano Mancini, and Zeynep Akata.
\newblock Vision-by-language for training-free compositional image retrieval.
\newblock \emph{ArXiv}, abs/2310.09291, 2023.

\bibitem[Kwak et~al.(2025)Kwak, Inhar, Yun, and Lee]{kwak2025qure}
Jaehyun Kwak, Ramahdani Muhammad~Izaaz Inhar, Se-Young Yun, and Sung-Ju Lee.
\newblock Qure: Query-relevant retrieval through hard negative sampling in composed image retrieval.
\newblock \emph{arXiv preprint arXiv:2507.12416}, 2025.

\bibitem[Lai et~al.(2023)Lai, Tian, Chen, Li, Yuan, Liu, and Jia]{Lai2023LISARS}
Xin Lai, Zhuotao Tian, Yukang Chen, Yanwei Li, Yuhui Yuan, Shu Liu, and Jiaya Jia.
\newblock Lisa: Reasoning segmentation via large language model.
\newblock \emph{2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 9579--9589, 2023.

\bibitem[Levy et~al.(2023)Levy, Ben-Ari, Darshan, and Lischinski]{Levy2023DataRA}
Matan Levy, Rami Ben-Ari, Nir Darshan, and Dani Lischinski.
\newblock Data roaming and quality assessment for composed image retrieval.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2023.

\bibitem[Levy et~al.(2024)Levy, Ben-Ari, Darshan, and Lischinski]{levy2024data}
Matan Levy, Rami Ben-Ari, Nir Darshan, and Dani Lischinski.
\newblock Data roaming and quality assessment for composed image retrieval.
\newblock In \emph{Proceedings of the AAAI conference on artificial intelligence}, pages 2991--2999, 2024.

\bibitem[Li et~al.(2023)Li, Li, Savarese, and Hoi]{Li2023BLIP2BL}
Junnan Li, Dongxu Li, Silvio Savarese, and Steven C.~H. Hoi.
\newblock Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models.
\newblock In \emph{International Conference on Machine Learning}, 2023.

\bibitem[Li et~al.(2025{\natexlab{a}})Li, He, Liu, Zhou, Peng, and Hu]{li2025learning}
Shuxian Li, Changhao He, Xiting Liu, Joey~Tianyi Zhou, Xi Peng, and Peng Hu.
\newblock Learning with noisy triplet correspondence for composed image retrieval.
\newblock In \emph{Proceedings of the Computer Vision and Pattern Recognition Conference}, pages 19628--19637, 2025{\natexlab{a}}.

\bibitem[Li et~al.(2024)Li, Zhang, Wang, Zhong, Chen, Chu, Liu, and Jia]{li2024mini}
Yanwei Li, Yuechen Zhang, Chengyao Wang, Zhisheng Zhong, Yixin Chen, Ruihang Chu, Shaoteng Liu, and Jiaya Jia.
\newblock Mini-gemini: Mining the potential of multi-modality vision language models.
\newblock \emph{arXiv preprint arXiv:2403.18814}, 2024.

\bibitem[Li et~al.(2025{\natexlab{b}})Li, Chen, Wen, Fu, Hu, and Guan]{li2025encoder}
Zixu Li, Zhiwei Chen, Haokun Wen, Zhiheng Fu, Yupeng Hu, and Weili Guan.
\newblock Encoder: Entity mining and modification relation binding for composed image retrieval.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, pages 5101--5109, 2025{\natexlab{b}}.

\bibitem[Lin et~al.(2025)Lin, Ma, Sun, He, Ji, Cao, and Ji]{Lin2025HRSegHV}
Weihuang Lin, Yiwei Ma, Xiaoshuai Sun, Shuting He, Jiayi Ji, Liujuan Cao, and Rongrong Ji.
\newblock Hrseg: High-resolution visual perception and enhancement for reasoning segmentation.
\newblock \emph{ArXiv}, abs/2507.12883, 2025.

\bibitem[Liu et~al.(2023{\natexlab{a}})Liu, Li, Wu, and Lee]{liu2023visual}
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong~Jae Lee.
\newblock Visual instruction tuning.
\newblock \emph{Advances in neural information processing systems}, 36:\penalty0 34892--34916, 2023{\natexlab{a}}.

\bibitem[Liu et~al.(2024{\natexlab{a}})Liu, Li, Li, Li, Zhang, Shen, and Lee]{liu2024llavanext}
Haotian Liu, Chunyuan Li, Yuheng Li, Bo Li, Yuanhan Zhang, Sheng Shen, and Yong~Jae Lee.
\newblock Llavanext: Improved reasoning, ocr, and world knowledge, 2024{\natexlab{a}}.

\bibitem[Liu et~al.(2018)Liu, Wang, Nie, He, Chen, and Chua]{liu2018attentive}
Meng Liu, Xiang Wang, Liqiang Nie, Xiangnan He, Baoquan Chen, and Tat-Seng Chua.
\newblock Attentive moment retrieval in videos.
\newblock In \emph{The 41st international ACM SIGIR conference on research \& development in information retrieval}, pages 15--24, 2018.

\bibitem[Liu et~al.(2025)Liu, Zhang, Cai, Jiang, Hu, Yao, Wang, and Xie]{liu2025lamra}
Yikun Liu, Yajie Zhang, Jiayin Cai, Xiaolong Jiang, Yao Hu, Jiangchao Yao, Yanfeng Wang, and Weidi Xie.
\newblock Lamra: Large multimodal model as your advanced retrieval assistant.
\newblock In \emph{Proceedings of the Computer Vision and Pattern Recognition Conference}, pages 4015--4025, 2025.

\bibitem[Liu et~al.(2016)Liu, Luo, Qiu, Wang, and Tang]{liu2016deepfashion}
Ziwei Liu, Ping Luo, Shi Qiu, Xiaogang Wang, and Xiaoou Tang.
\newblock Deepfashion: Powering robust clothes recognition and retrieval with rich annotations.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 1096--1104, 2016.

\bibitem[Liu et~al.(2021)Liu, Rodriguez-Opazo, Teney, and Gould]{liu2021image}
Zheyuan Liu, Cristian Rodriguez-Opazo, Damien Teney, and Stephen Gould.
\newblock Image retrieval on real-life images with pre-trained vision-and-language models.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pages 2125--2134, 2021.

\bibitem[Liu et~al.(2023{\natexlab{b}})Liu, Sun, Teney, and Gould]{Liu2023CandidateSR}
Zheyuan Liu, Weixuan Sun, Damien Teney, and Stephen Gould.
\newblock Candidate set re-ranking for composed image retrieval with dual multi-modal encoder.
\newblock \emph{Trans. Mach. Learn. Res.}, 2024, 2023{\natexlab{b}}.

\bibitem[Liu et~al.(2023{\natexlab{c}})Liu, Sun, Teney, and Gould]{liu2023candidate}
Zheyuan Liu, Weixuan Sun, Damien Teney, and Stephen Gould.
\newblock Candidate set re-ranking for composed image retrieval with dual multi-modal encoder.
\newblock \emph{arXiv preprint arXiv:2305.16304}, 2023{\natexlab{c}}.

\bibitem[Liu et~al.(2024{\natexlab{b}})Liu, Dong, Liu, Hu, Lu, and Rao]{liu2024oryx}
Zuyan Liu, Yuhao Dong, Ziwei Liu, Winston Hu, Jiwen Lu, and Yongming Rao.
\newblock Oryx mllm: On-demand spatial-temporal understanding at arbitrary resolution.
\newblock \emph{arXiv preprint arXiv:2409.12961}, 2024{\natexlab{b}}.

\bibitem[Lu et~al.(2024)Lu, Liu, Zhang, Wang, Dong, Liu, Sun, Ren, Li, Yang, et~al.]{lu2024deepseek}
Haoyu Lu, Wen Liu, Bo Zhang, Bingxuan Wang, Kai Dong, Bo Liu, Jingxiang Sun, Tongzheng Ren, Zhuoshu Li, Hao Yang, et~al.
\newblock Deepseek-vl: towards real-world vision-language understanding.
\newblock \emph{arXiv preprint arXiv:2403.05525}, 2024.

\bibitem[Meta(2024)]{meta2024introducing}
AI Meta.
\newblock Introducing meta llama 3: The most capable openly available llm to date.
\newblock \emph{Meta AI}, 2024.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[OpenAI(2023)]{openai2023gpt}
R OpenAI.
\newblock Gpt-4 technical report. arxiv 2303.08774.
\newblock \emph{View in Article}, 2\penalty0 (5), 2023.

\bibitem[Qiao et~al.(2024)Qiao, Duan, Fang, Yang, Chen, Zhang, Wang, Lin, and Chen]{Qiao2024PrismAF}
Yu Qiao, Haodong Duan, Xinyu Fang, Junming Yang, Lin Chen, Songyang Zhang, Jiaqi Wang, Dahua Lin, and Kai Chen.
\newblock Prism: A framework for decoupling and assessing the capabilities of vlms.
\newblock \emph{ArXiv}, abs/2406.14544, 2024.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{International conference on machine learning}, pages 8748--8763. PmLR, 2021.

\bibitem[Saito et~al.(2023)Saito, Sohn, Zhang, Li, Lee, Saenko, and Pfister]{saito2023pic2word}
Kuniaki Saito, Kihyuk Sohn, Xiang Zhang, Chun-Liang Li, Chen-Yu Lee, Kate Saenko, and Tomas Pfister.
\newblock Pic2word: Mapping pictures to words for zero-shot composed image retrieval.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 19305--19314, 2023.

\bibitem[Song et~al.(2024)Song, Hwang, Yoon, Choi, and Gu]{Song2024SyncMaskSA}
Chull~Hwan Song, Taebaek Hwang, Jooyoung Yoon, Shunghyun Choi, and Yeong~Hyeon Gu.
\newblock Syncmask: Synchronized attentional masking for fashion-centric vision-language pretraining.
\newblock \emph{2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 13948--13957, 2024.

\bibitem[Sun et~al.(2025)Sun, Jing, Yang, Fei, and Lu]{sun2025leveraging}
Zelong Sun, Dong Jing, Guoxing Yang, Nanyi Fei, and Zhiwu Lu.
\newblock Leveraging large vision-language model as user intent-aware encoder for composed image retrieval.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, pages 7149--7157, 2025.

\bibitem[Tang et~al.(2023)Tang, Yu, Gai, Zhuang, Xiong, Hu, and Wu]{Tang2023ContextI2WMI}
Yuanmin Tang, J. Yu, Keke Gai, Jiamin Zhuang, Gang Xiong, Yue Hu, and Qi Wu.
\newblock Context-i2w: Mapping images to context-dependent words for accurate zero-shot composed image retrieval.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2023.

\bibitem[Tang et~al.(2024)Tang, Qin, Zhang, Yu, Gou, Xiong, Ling, Rajmohan, Zhang, and Wu]{Tang2024OR}
Yuanmin Tang, Xiaoting Qin, Jue Zhang, Jing Yu, Gaopeng Gou, Gang Xiong, Qingwei Ling, S. Rajmohan, Dongmei Zhang, and Qi Wu.
\newblock Reason-before-retrieve: One-stage reflective chain-of-thoughts for training-free zero-shot composed image retrieval.
\newblock \emph{2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 14400--14410, 2024.

\bibitem[Tang et~al.(2025)Tang, Yu, Gai, Zhuang, Xiong, Gou, and Wu]{Tang2025MissingTI}
Yuanmin Tang, Jing Yu, Keke Gai, Jiamin Zhuang, Gang Xiong, Gaopeng Gou, and Qi Wu.
\newblock Missing target-relevant information prediction with world model for accurate zero-shot composed image retrieval.
\newblock \emph{2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 24785--24795, 2025.

\bibitem[Team(2023)]{team2023internlm}
InternLM Team.
\newblock Internlm: A multilingual language model with progressively enhanced capabilities, 2023.

\bibitem[Team et~al.(2025)Team, Yang, Wen, Liu, Chu, Song, Rao, Yi, Li, Zang, et~al.]{team2025kwai}
Kwai~Keye Team, Biao Yang, Bin Wen, Changyi Liu, Chenglong Chu, Chengru Song, Chongling Rao, Chuan Yi, Da Li, Dunju Zang, et~al.
\newblock Kwai keye-vl technical report.
\newblock \emph{arXiv preprint arXiv:2507.01949}, 2025.

\bibitem[Tian et~al.(2025)Tian, Zhao, Hu, Yang, Li, Jin, Wang, and Li]{tian2025ccin}
Likai Tian, Jian Zhao, Zechao Hu, Zhengwei Yang, Hao Li, Lei Jin, Zheng Wang, and Xuelong Li.
\newblock Ccin: Compositional conflict identification and neutralization for composed image retrieval.
\newblock In \emph{Proceedings of the Computer Vision and Pattern Recognition Conference}, pages 3974--3983, 2025.

\bibitem[Touvron et~al.(2023)Touvron, Lavril, Izacard, Martinet, Lachaux, Lacroix, Rozi{\`e}re, Goyal, Hambro, Azhar, et~al.]{touvron2023llama}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth{\'e}e Lacroix, Baptiste Rozi{\`e}re, Naman Goyal, Eric Hambro, Faisal Azhar, et~al.
\newblock Llama: open and efficient foundation language models. arxiv.
\newblock \emph{arXiv preprint arXiv:2302.13971}, 2023.

\bibitem[Ventura et~al.(2024)Ventura, Yang, Schmid, and Varol]{ventura2024covr}
Lucas Ventura, Antoine Yang, Cordelia Schmid, and G{\"u}l Varol.
\newblock Covr-2: Automatic data construction for composed video retrieval.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 2024.

\bibitem[Wang et~al.(2024{\natexlab{a}})Wang, Bai, Tan, Wang, Fan, Bai, Chen, Liu, Wang, Ge, et~al.]{wang2024qwen2}
Peng Wang, Shuai Bai, Sinan Tan, Shijie Wang, Zhihao Fan, Jinze Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, et~al.
\newblock Qwen2-vl: Enhancing vision-language model's perception of the world at any resolution.
\newblock \emph{arXiv preprint arXiv:2409.12191}, 2024{\natexlab{a}}.

\bibitem[Wang et~al.(2024{\natexlab{b}})Wang, Huang, Li, and Yuan]{wang2024semantic}
Yifan Wang, Wuliang Huang, Lei Li, and Chun Yuan.
\newblock Semantic distillation from neighborhood for composed image retrieval.
\newblock In \emph{Proceedings of the 32nd ACM International Conference on Multimedia}, pages 5575--5583, 2024{\natexlab{b}}.

\bibitem[Wen et~al.(2023{\natexlab{a}})Wen, Song, Yin, Wu, Guan, and Nie]{wen2023self}
Haokun Wen, Xuemeng Song, Jianhua Yin, Jianlong Wu, Weili Guan, and Liqiang Nie.
\newblock Self-training boosted multi-factor matching network for composed image retrieval.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 46\penalty0 (5):\penalty0 3665--3678, 2023{\natexlab{a}}.

\bibitem[Wen et~al.(2023{\natexlab{b}})Wen, Zhang, Song, Wei, and Nie]{wen2023target}
Haokun Wen, Xian Zhang, Xuemeng Song, Yinwei Wei, and Liqiang Nie.
\newblock Target-guided composed image retrieval.
\newblock In \emph{Proceedings of the 31st ACM international conference on multimedia}, pages 915--923, 2023{\natexlab{b}}.

\bibitem[Wen et~al.(2024)Wen, Song, Chen, Wei, Nie, and Chua]{wen2024simple}
Haokun Wen, Xuemeng Song, Xiaolin Chen, Yinwei Wei, Liqiang Nie, and Tat-Seng Chua.
\newblock Simple but effective raw-data level multimodal fusion for composed image retrieval.
\newblock In \emph{Proceedings of the 47th International ACM SIGIR conference on research and development in information retrieval}, pages 229--239, 2024.

\bibitem[Wu et~al.(2021)Wu, Gao, Guo, Al-Halah, Rennie, Grauman, and Feris]{wu2021fashion}
Hui Wu, Yupeng Gao, Xiaoxiao Guo, Ziad Al-Halah, Steven Rennie, Kristen Grauman, and Rogerio Feris.
\newblock Fashion iq: A new dataset towards retrieving images by natural language feedback.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on computer vision and pattern recognition}, pages 11307--11317, 2021.

\bibitem[Xu et~al.(2024{\natexlab{a}})Xu, Jin, Li, Song, Sun, and Yuan]{Xu2024LLaVACoTLV}
Guowei Xu, Peng Jin, Hao Li, Yibing Song, Lichao Sun, and Li Yuan.
\newblock Llava-cot: Let vision language models reason step-by-step.
\newblock \emph{ArXiv}, abs/2411.10440, 2024{\natexlab{a}}.

\bibitem[Xu et~al.(2024{\natexlab{b}})Xu, Jin, Wu, Li, Song, Sun, and Yuan]{xu2024llava}
Guowei Xu, Peng Jin, Ziang Wu, Hao Li, Yibing Song, Lichao Sun, and Li Yuan.
\newblock Llava-cot: Let vision language models reason step-by-step.
\newblock \emph{arXiv preprint arXiv:2411.10440}, 2024{\natexlab{b}}.

\bibitem[Yang et~al.(2024)Yang, Yang, Hui, Zheng, Yu, Zhou, Li, Li, Liu, Huang, et~al.]{yang2024qwen2}
An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, et~al.
\newblock Qwen2 technical report.
\newblock \emph{arXiv preprint arXiv:2407.10671}, 2024.

\bibitem[Yang et~al.(2022)Yang, Wang, Dong, Dong, Wang, and Chua]{yang2022video}
Xun Yang, Shanshan Wang, Jian Dong, Jianfeng Dong, Meng Wang, and Tat-Seng Chua.
\newblock Video moment retrieval with cross-modal neural architecture search.
\newblock \emph{IEEE Transactions on Image Processing}, 31:\penalty0 1204--1216, 2022.

\bibitem[Yue et~al.(2025)Yue, Lin, Song, Wang, Ren, Gu, Li, Li, Zhao, Li, et~al.]{Yue2025MiMoVLTR}
Xiaomi LLM-Core Team~Zihao Yue, Zhenrui Lin, Yi-Hao Song, Weikun Wang, Shu-Qin Ren, Shuhao Gu, Shi-Guang Li, Peidian Li, Liang Zhao, Lei Li, et~al.
\newblock Mimo-vl technical report.
\newblock \emph{ArXiv}, abs/2506.03569, 2025.

\bibitem[Zhang et~al.(2024)Zhang, Zhang, Xie, Li, Dai, Long, Xie, Zhang, Li, and Zhang]{zhang2024gme}
Xin Zhang, Yanzhao Zhang, Wen Xie, Mingxin Li, Ziqi Dai, Dingkun Long, Pengjun Xie, Meishan Zhang, Wenjie Li, and Min Zhang.
\newblock Gme: Improving universal multimodal retrieval by multimodal llms.
\newblock \emph{arXiv preprint arXiv:2412.16855}, 2024.

\bibitem[Zheng et~al.(2023)Zheng, Chiang, Sheng, Zhuang, Wu, Zhuang, Lin, Li, Li, Xing, et~al.]{zheng2023judging}
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et~al.
\newblock Judging llm-as-a-judge with mt-bench and chatbot arena.
\newblock \emph{Advances in Neural Information Processing Systems}, 36:\penalty0 46595--46623, 2023.

\bibitem[Zhu et~al.(2023)Zhu, Chen, Shen, Li, and Elhoseiny]{zhu2023minigpt}
Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny.
\newblock Minigpt-4: Enhancing vision-language understanding with advanced large language models.
\newblock \emph{arXiv preprint arXiv:2304.10592}, 2023.

\bibitem[Zhu et~al.(2025)Zhu, Wang, Chen, Liu, Ye, Gu, Tian, Duan, Su, Shao, et~al.]{zhu2025internvl3}
Jinguo Zhu, Weiyun Wang, Zhe Chen, Zhaoyang Liu, Shenglong Ye, Lixin Gu, Hao Tian, Yuchen Duan, Weijie Su, Jie Shao, et~al.
\newblock Internvl3: Exploring advanced training and test-time recipes for open-source multimodal models.
\newblock \emph{arXiv preprint arXiv:2504.10479}, 2025.

\end{thebibliography}
