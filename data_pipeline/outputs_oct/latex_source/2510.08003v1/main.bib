@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})


@inproceedings{gordo2016deep,
  title={Deep image retrieval: Learning global representations for image search},
  author={Gordo, Albert and Almaz{\'a}n, Jon and Revaud, Jerome and Larlus, Diane},
  booktitle={European conference on computer vision},
  pages={241--257},
  year={2016},
  organization={Springer}
}
@inproceedings{liu2016deepfashion,
  title={Deepfashion: Powering robust clothes recognition and retrieval with rich annotations},
  author={Liu, Ziwei and Luo, Ping and Qiu, Shi and Wang, Xiaogang and Tang, Xiaoou},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1096--1104},
  year={2016}
}
@inproceedings{liu2018attentive,
  title={Attentive moment retrieval in videos},
  author={Liu, Meng and Wang, Xiang and Nie, Liqiang and He, Xiangnan and Chen, Baoquan and Chua, Tat-Seng},
  booktitle={The 41st international ACM SIGIR conference on research \& development in information retrieval},
  pages={15--24},
  year={2018}
}
@article{yang2022video,
  title={Video moment retrieval with cross-modal neural architecture search},
  author={Yang, Xun and Wang, Shanshan and Dong, Jian and Dong, Jianfeng and Wang, Meng and Chua, Tat-Seng},
  journal={IEEE Transactions on Image Processing},
  volume={31},
  pages={1204--1216},
  year={2022},
  publisher={IEEE}
}

@inproceedings{anwaar2021compositional,
  title={Compositional learning of image-text query for image retrieval},
  author={Anwaar, Muhammad Umer and Labintcev, Egor and Kleinsteuber, Martin},
  booktitle={Proceedings of the IEEE/CVF Winter conference on Applications of Computer Vision},
  pages={1140--1149},
  year={2021}
}
@inproceedings{chen2020image,
  title={Image search with text feedback by visiolinguistic attention learning},
  author={Chen, Yanbei and Gong, Shaogang and Bazzani, Loris},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3001--3011},
  year={2020}
}
@inproceedings{liu2021image,
  title={Image retrieval on real-life images with pre-trained vision-and-language models},
  author={Liu, Zheyuan and Rodriguez-Opazo, Cristian and Teney, Damien and Gould, Stephen},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={2125--2134},
  year={2021}
}
@inproceedings{levy2024data,
  title={Data roaming and quality assessment for composed image retrieval},
  author={Levy, Matan and Ben-Ari, Rami and Darshan, Nir and Lischinski, Dani},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={38},
  number={4},
  pages={2991--2999},
  year={2024}
}
@article{liu2023candidate,
  title={Candidate set re-ranking for composed image retrieval with dual multi-modal encoder},
  author={Liu, Zheyuan and Sun, Weixuan and Teney, Damien and Gould, Stephen},
  journal={arXiv preprint arXiv:2305.16304},
  year={2023}
}
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PmLR}
}
@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International conference on machine learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}
@inproceedings{saito2023pic2word,
  title={Pic2word: Mapping pictures to words for zero-shot composed image retrieval},
  author={Saito, Kuniaki and Sohn, Kihyuk and Zhang, Xiang and Li, Chun-Liang and Lee, Chen-Yu and Saenko, Kate and Pfister, Tomas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19305--19314},
  year={2023}
}
@article{bai2023sentence,
  title={Sentence-level prompts benefit composed image retrieval},
  author={Bai, Yang and Xu, Xinxing and Liu, Yong and Khan, Salman and Khan, Fahad and Zuo, Wangmeng and Goh, Rick Siow Mong and Feng, Chun-Mei},
  journal={arXiv preprint arXiv:2310.05473},
  year={2023}
}
@article{gal2022image,
  title={An image is worth one word: Personalizing text-to-image generation using textual inversion},
  author={Gal, Rinon and Alaluf, Yuval and Atzmon, Yuval and Patashnik, Or and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2208.01618},
  year={2022}
}

@article{liu2023visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  pages={34892--34916},
  year={2023}
}
@article{wang2024qwen2,
  title={Qwen2-vl: Enhancing vision-language model's perception of the world at any resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and others},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}
@article{bai2025qwen2,
  title={Qwen2. 5-vl technical report},
  author={Bai, Shuai and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and Song, Sibo and Dang, Kai and Wang, Peng and Wang, Shijie and Tang, Jun and others},
  journal={arXiv preprint arXiv:2502.13923},
  year={2025}
}
@misc{liu2024llavanext,
  title={Llavanext: Improved reasoning, ocr, and world knowledge},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae},
  year={2024}
}
@article{jiang2024e5,
  title={E5-v: Universal embeddings with multimodal large language models},
  author={Jiang, Ting and Song, Minghui and Zhang, Zihan and Huang, Haizhen and Deng, Weiwei and Sun, Feng and Zhang, Qi and Wang, Deqing and Zhuang, Fuzhen},
  journal={arXiv preprint arXiv:2407.12580},
  year={2024}
}
@inproceedings{liu2025lamra,
  title={Lamra: Large multimodal model as your advanced retrieval assistant},
  author={Liu, Yikun and Zhang, Yajie and Cai, Jiayin and Jiang, Xiaolong and Hu, Yao and Yao, Jiangchao and Wang, Yanfeng and Xie, Weidi},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={4015--4025},
  year={2025}
}
@inproceedings{sun2025leveraging,
  title={Leveraging large vision-language model as user intent-aware encoder for composed image retrieval},
  author={Sun, Zelong and Jing, Dong and Yang, Guoxing and Fei, Nanyi and Lu, Zhiwu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={39},
  number={7},
  pages={7149--7157},
  year={2025}
}
@article{zhang2024gme,
  title={GME: Improving Universal Multimodal Retrieval by Multimodal LLMs},
  author={Zhang, Xin and Zhang, Yanzhao and Xie, Wen and Li, Mingxin and Dai, Ziqi and Long, Dingkun and Xie, Pengjun and Zhang, Meishan and Li, Wenjie and Zhang, Min},
  journal={arXiv preprint arXiv:2412.16855},
  year={2024}
}
@inproceedings{wu2021fashion,
  title={Fashion iq: A new dataset towards retrieving images by natural language feedback},
  author={Wu, Hui and Gao, Yupeng and Guo, Xiaoxiao and Al-Halah, Ziad and Rennie, Steven and Grauman, Kristen and Feris, Rogerio},
  booktitle={Proceedings of the IEEE/CVF Conference on computer vision and pattern recognition},
  pages={11307--11317},
  year={2021}
}
@article{xu2024llava,
  title={Llava-cot: Let vision language models reason step-by-step},
  author={Xu, Guowei and Jin, Peng and Wu, Ziang and Li, Hao and Song, Yibing and Sun, Lichao and Yuan, Li},
  journal={arXiv preprint arXiv:2411.10440},
  year={2024}
}
@article{gao2021simcse,
  title={Simcse: Simple contrastive learning of sentence embeddings},
  author={Gao, Tianyu and Yao, Xingcheng and Chen, Danqi},
  journal={arXiv preprint arXiv:2104.08821},
  year={2021}
}
@inproceedings{baldrati2023zero,
  title={Zero-shot composed image retrieval with textual inversion},
  author={Baldrati, Alberto and Agnolucci, Lorenzo and Bertini, Marco and Del Bimbo, Alberto},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={15338--15347},
  year={2023}
}
@inproceedings{Tang2023ContextI2WMI,
  title={Context-I2W: Mapping Images to Context-dependent Words for Accurate Zero-Shot Composed Image Retrieval},
  author={Yuanmin Tang and J. Yu and Keke Gai and Jiamin Zhuang and Gang Xiong and Yue Hu and Qi Wu},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2023},
}
@inproceedings{Levy2023DataRA,
  title={Data Roaming and Quality Assessment for Composed Image Retrieval},
  author={Matan Levy and Rami Ben-Ari and Nir Darshan and Dani Lischinski},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:257557363}
}
@article{Liu2023CandidateSR,
  title={Candidate Set Re-ranking for Composed Image Retrieval with Dual Multi-modal Encoder},
  author={Zheyuan Liu and Weixuan Sun and Damien Teney and Stephen Gould},
  journal={Trans. Mach. Learn. Res.},
  year={2023},
  volume={2024},
  url={https://api.semanticscholar.org/CorpusID:258888242}
}
@article{Anwaar2020CompositionalLO,
  title={Compositional Learning of Image-Text Query for Image Retrieval},
  author={Muhammad Umer Anwaar and Egor Labintcev and Martin Kleinsteuber},
  journal={2021 IEEE Winter Conference on Applications of Computer Vision (WACV)},
  year={2020},
  pages={1139-1148},
  url={https://api.semanticscholar.org/CorpusID:219955754}
}
@InProceedings{Chen_2020_CVPR,
author = {Chen, Yanbei and Gong, Shaogang and Bazzani, Loris},
title = {Image Search With Text Feedback by Visiolinguistic Attention Learning},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}
@inproceedings{Li2023BLIP2BL,
  title={BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models},
  author={Junnan Li and Dongxu Li and Silvio Savarese and Steven C. H. Hoi},
  booktitle={International Conference on Machine Learning},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:256390509}
}
@article{Lai2023LISARS,
  title={LISA: Reasoning Segmentation via Large Language Model},
  author={Xin Lai and Zhuotao Tian and Yukang Chen and Yanwei Li and Yuhui Yuan and Shu Liu and Jiaya Jia},
  journal={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023},
  pages={9579-9589},
  url={https://api.semanticscholar.org/CorpusID:260351258}
}
@article{Lin2025HRSegHV,
  title={HRSeg: High-Resolution Visual Perception and Enhancement for Reasoning Segmentation},
  author={Weihuang Lin and Yiwei Ma and Xiaoshuai Sun and Shuting He and Jiayi Ji and Liujuan Cao and Rongrong Ji},
  journal={ArXiv},
  year={2025},
  volume={abs/2507.12883},
  url={https://api.semanticscholar.org/CorpusID:280283455}
}
@article{Qiao2024PrismAF,
  title={Prism: A Framework for Decoupling and Assessing the Capabilities of VLMs},
  author={Yu Qiao and Haodong Duan and Xinyu Fang and Junming Yang and Lin Chen and Songyang Zhang and Jiaqi Wang and Dahua Lin and Kai Chen},
  journal={ArXiv},
  year={2024},
  volume={abs/2406.14544},
  url={https://api.semanticscholar.org/CorpusID:270620510}
}
@article{Cesista2024MultimodalSG,
  title={Multimodal Structured Generation: CVPR's 2nd MMFM Challenge Technical Report},
  author={Franz Louis Cesista},
  journal={ArXiv},
  year={2024},
  volume={abs/2406.11403},
  url={https://api.semanticscholar.org/CorpusID:270558908}
}
@inproceedings{Chu2023NavigateTE,
  title={Navigate through Enigmatic Labyrinth A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future},
  author={Zheng Chu and Jingchang Chen and Qianglong Chen and Weijiang Yu and Tao He and Haotian Wang and Weihua Peng and Ming Liu and Bing Qin and Ting Liu},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:263153015}
}
@article{Xu2024LLaVACoTLV,
  title={LLaVA-CoT: Let Vision Language Models Reason Step-by-Step},
  author={Guowei Xu and Peng Jin and Hao Li and Yibing Song and Lichao Sun and Li Yuan},
  journal={ArXiv},
  year={2024},
  volume={abs/2411.10440},
  url={https://api.semanticscholar.org/CorpusID:274116688}
}
@article{chiang2023vicuna,
  title={Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality},
  author={Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E and others},
  journal={See https://vicuna. lmsys. org (accessed 14 April 2023)},
  volume={2},
  number={3},
  pages={6},
  year={2023}
}
@article{touvron2023llama,
  title={LLaMA: open and efficient foundation language models. arXiv},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}
@article{jiang2024mixtral,
  title={Mixtral of experts},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Hanna, Emma Bou and Bressand, Florian and others},
  journal={arXiv preprint arXiv:2401.04088},
  year={2024}
}
@article{yang2024qwen2,
  title={Qwen2 technical report},
  author={Yang, An and Yang, Baosong and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Zhou, Chang and Li, Chengpeng and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and others},
  journal={arXiv preprint arXiv:2407.10671},
  year={2024}
}
@article{zheng2023judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46595--46623},
  year={2023}
}
@misc{team2023internlm,
  title={Internlm: A multilingual language model with progressively enhanced capabilities},
  author={Team, InternLM},
  journal={2023-01-06)[2023-09-27]. https://github. com/InternLM/InternLM},
  year={2023}
}
@article{openai2023gpt,
  title={Gpt-4 technical report. arxiv 2303.08774},
  author={OpenAI, R},
  journal={View in Article},
  volume={2},
  number={5},
  year={2023}
}
@article{meta2024introducing,
  title={Introducing meta llama 3: The most capable openly available llm to date},
  author={Meta, AI},
  journal={Meta AI},
  year={2024}
}
@article{bi2024deepseek,
  title={Deepseek llm: Scaling open-source language models with longtermism},
  author={Bi, Xiao and Chen, Deli and Chen, Guanting and Chen, Shanhuang and Dai, Damai and Deng, Chengqi and Ding, Honghui and Dong, Kai and Du, Qiushi and Fu, Zhe and others},
  journal={arXiv preprint arXiv:2401.02954},
  year={2024}
}
@article{zhu2023minigpt,
  title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2304.10592},
  year={2023}
}
@article{liu2024oryx,
  title={Oryx mllm: On-demand spatial-temporal understanding at arbitrary resolution},
  author={Liu, Zuyan and Dong, Yuhao and Liu, Ziwei and Hu, Winston and Lu, Jiwen and Rao, Yongming},
  journal={arXiv preprint arXiv:2409.12961},
  year={2024}
}
@article{li2024mini,
  title={Mini-gemini: Mining the potential of multi-modality vision language models},
  author={Li, Yanwei and Zhang, Yuechen and Wang, Chengyao and Zhong, Zhisheng and Chen, Yixin and Chu, Ruihang and Liu, Shaoteng and Jia, Jiaya},
  journal={arXiv preprint arXiv:2403.18814},
  year={2024}
}
@article{bai2023qwen,
  title={Qwen-vl: A frontier large vision-language model with versatile abilities},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  year={2023}
}
@article{lu2024deepseek,
  title={Deepseek-vl: towards real-world vision-language understanding},
  author={Lu, Haoyu and Liu, Wen and Zhang, Bo and Wang, Bingxuan and Dong, Kai and Liu, Bo and Sun, Jingxiang and Ren, Tongzheng and Li, Zhuoshu and Yang, Hao and others},
  journal={arXiv preprint arXiv:2403.05525},
  year={2024}
}
@inproceedings{chen2024mllm,
  title={Mllm-as-a-judge: Assessing multimodal llm-as-a-judge with vision-language benchmark},
  author={Chen, Dongping and Chen, Ruoxi and Zhang, Shilin and Wang, Yaochen and Liu, Yinuo and Zhou, Huichi and Zhang, Qihui and Wan, Yao and Zhou, Pan and Sun, Lichao},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}
@article{zhu2025internvl3,
  title={Internvl3: Exploring advanced training and test-time recipes for open-source multimodal models},
  author={Zhu, Jinguo and Wang, Weiyun and Chen, Zhe and Liu, Zhaoyang and Ye, Shenglong and Gu, Lixin and Tian, Hao and Duan, Yuchen and Su, Weijie and Shao, Jie and others},
  journal={arXiv preprint arXiv:2504.10479},
  year={2025}
}
@article{Yue2025MiMoVLTR,
  title={MiMo-VL Technical Report},
  author={Xiaomi LLM-Core Team Zihao Yue and Zhenrui Lin and Yi-Hao Song and Weikun Wang and Shu-Qin Ren and Shuhao Gu and Shi-Guang Li and Peidian Li and Liang Zhao and Lei Li and others},
  journal={ArXiv},
  year={2025},
  volume={abs/2506.03569},
  url={https://api.semanticscholar.org/CorpusID:279155294}
}
@article{team2025kwai,
  title={Kwai Keye-VL Technical Report},
  author={Team, Kwai Keye and Yang, Biao and Wen, Bin and Liu, Changyi and Chu, Chenglong and Song, Chengru and Rao, Chongling and Yi, Chuan and Li, Da and Zang, Dunju and others},
  journal={arXiv preprint arXiv:2507.01949},
  year={2025}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}
@article{suhr2018corpus,
  title={A corpus or reasoning about natural language grounded in photographs},
  author={Suhr, Alane and Zhou, Stephanie and Zhang, Ally and Zhang, Iris and Bai, Huajun and Artzi, Yoav},
  journal={arXiv preprint arXiv:1811.00491},
  year={2018}
}
@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European conference on computer vision},
  pages={740--755},
  year={2014},
  organization={Springer}
}
@inproceedings{vo2019composing,
  title={Composing text and image for image retrieval-an empirical odyssey},
  author={Vo, Nam and Jiang, Lu and Sun, Chen and Murphy, Kevin and Li, Li-Jia and Fei-Fei, Li and Hays, James},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6439--6448},
  year={2019}
}

@article{delmas2022artemis,
  title={Artemis: Attention-based retrieval with text-explicit matching and implicit similarity},
  author={Delmas, Ginger and de Rezende, Rafael Sampaio and Csurka, Gabriela and Larlus, Diane},
  journal={arXiv preprint arXiv:2203.08101},
  year={2022}
}
@article{xu2023multi,
  title={Multi-modal transformer with global-local alignment for composed query image retrieval},
  author={Xu, Yahui and Bin, Yi and Wei, Jiwei and Yang, Yang and Wang, Guoqing and Shen, Heng Tao},
  journal={IEEE Transactions on Multimedia},
  volume={25},
  pages={8346--8357},
  year={2023},
  publisher={IEEE}
}

@inproceedings{baldrati2022effective,
  title={Effective conditioned and composed image retrieval combining clip-based features},
  author={Baldrati, Alberto and Bertini, Marco and Uricchio, Tiberio and Del Bimbo, Alberto},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={21466--21474},
  year={2022}
}
@inproceedings{baldrati2022conditioned,
  title={Conditioned and composed image retrieval combining and partially fine-tuning clip-based features},
  author={Baldrati, Alberto and Bertini, Marco and Uricchio, Tiberio and Del Bimbo, Alberto},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4959--4968},
  year={2022}
}
@inproceedings{wen2023target,
  title={Target-guided composed image retrieval},
  author={Wen, Haokun and Zhang, Xian and Song, Xuemeng and Wei, Yinwei and Nie, Liqiang},
  booktitle={Proceedings of the 31st ACM international conference on multimedia},
  pages={915--923},
  year={2023}
}
@inproceedings{chen2024fashionern,
  title={FashionERN: enhance-and-refine network for composed fashion image retrieval},
  author={Chen, Yanzhe and Zhong, Huasong and He, Xiangteng and Peng, Yuxin and Zhou, Jiahuan and Cheng, Lele},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={2},
  pages={1228--1236},
  year={2024}
}
@article{wen2023self,
  title={Self-training boosted multi-factor matching network for composed image retrieval},
  author={Wen, Haokun and Song, Xuemeng and Yin, Jianhua and Wu, Jianlong and Guan, Weili and Nie, Liqiang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={46},
  number={5},
  pages={3665--3678},
  year={2023},
  publisher={IEEE}
}
@inproceedings{wang2024semantic,
  title={Semantic Distillation from Neighborhood for Composed Image Retrieval},
  author={Wang, Yifan and Huang, Wuliang and Li, Lei and Yuan, Chun},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={5575--5583},
  year={2024}
}
@inproceedings{wen2024simple,
  title={Simple but effective raw-data level multimodal fusion for composed image retrieval},
  author={Wen, Haokun and Song, Xuemeng and Chen, Xiaolin and Wei, Yinwei and Nie, Liqiang and Chua, Tat-Seng},
  booktitle={Proceedings of the 47th International ACM SIGIR conference on research and development in information retrieval},
  pages={229--239},
  year={2024}
}
@inproceedings{jiang2024cala,
  title={Cala: Complementary association learning for augmenting comoposed image retrieval},
  author={Jiang, Xintong and Wang, Yaxiong and Li, Mengjian and Wu, Yujiao and Hu, Bingwen and Qian, Xueming},
  booktitle={Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={2177--2187},
  year={2024}
}
@article{ventura2024covr,
  title={CoVR-2: Automatic data construction for composed video retrieval},
  author={Ventura, Lucas and Yang, Antoine and Schmid, Cordelia and Varol, G{\"u}l},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  publisher={IEEE}
}
@inproceedings{li2025encoder,
  title={Encoder: Entity mining and modification relation binding for composed image retrieval},
  author={Li, Zixu and Chen, Zhiwei and Wen, Haokun and Fu, Zhiheng and Hu, Yupeng and Guan, Weili},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={39},
  number={5},
  pages={5101--5109},
  year={2025}
}
@inproceedings{tian2025ccin,
  title={CCIN: Compositional Conflict Identification and Neutralization for Composed Image Retrieval},
  author={Tian, Likai and Zhao, Jian and Hu, Zechao and Yang, Zhengwei and Li, Hao and Jin, Lei and Wang, Zheng and Li, Xuelong},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={3974--3983},
  year={2025}
}
@article{kwak2025qure,
  title={QuRe: Query-Relevant Retrieval through Hard Negative Sampling in Composed Image Retrieval},
  author={Kwak, Jaehyun and Inhar, Ramahdani Muhammad Izaaz and Yun, Se-Young and Lee, Sung-Ju},
  journal={arXiv preprint arXiv:2507.12416},
  year={2025}
}
@inproceedings{li2025learning,
  title={Learning with Noisy Triplet Correspondence for Composed Image Retrieval},
  author={Li, Shuxian and He, Changhao and Liu, Xiting and Zhou, Joey Tianyi and Peng, Xi and Hu, Peng},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={19628--19637},
  year={2025}
}
@article{Chen2022ComposedIR,
  title={Composed Image Retrieval with Text Feedback via Multi-grained Uncertainty Regularization},
  author={Yiyang Chen and Zhedong Zheng and Wei Ji and Leigang Qu and Tat-Seng Chua},
  journal={ArXiv},
  year={2022},
  volume={abs/2211.07394},
  url={https://api.semanticscholar.org/CorpusID:253510860}
}
@article{Zhao2022ProgressiveLF,
  title={Progressive Learning for Image Retrieval with Hybrid-Modality Queries},
  author={Yida Zhao and Yuqing Song and Qin Jin},
  journal={Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year={2022},
  url={https://api.semanticscholar.org/CorpusID:248377098}
}
@article{Han2023FashionSAPSA,
  title={FashionSAP: Symbols and Attributes Prompt for Fine-Grained Fashion Vision-Language Pre-Training},
  author={Yunpeng Han and Lisai Zhang and Qingcai Chen and Zhijian Chen and Zhonghua Li and Jianxin Yang and Zhao Cao},
  journal={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023},
  pages={15028-15038},
  url={https://api.semanticscholar.org/CorpusID:258060056}
}
@article{Han2023FAMEViLMV,
  title={FAME-ViL: Multi-Tasking Vision-Language Model for Heterogeneous Fashion Tasks},
  author={Xiaoping Han and Xiatian Zhu and Licheng Yu and Li Zhang and Yi-Zhe Song and Tao Xiang},
  journal={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023},
  pages={2669-2680},
  url={https://api.semanticscholar.org/CorpusID:257364872}
}
@article{Song2024SyncMaskSA,
  title={SyncMask: Synchronized Attentional Masking for Fashion-centric Vision-Language Pretraining},
  author={Chull Hwan Song and Taebaek Hwang and Jooyoung Yoon and Shunghyun Choi and Yeong Hyeon Gu},
  journal={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024},
  pages={13948-13957},
  url={https://api.semanticscholar.org/CorpusID:268820144}
}
@article{Baldrati2023ZeroShotCI,
  title={Zero-Shot Composed Image Retrieval with Textual Inversion},
  author={Alberto Baldrati and Lorenzo Agnolucci and Marco Bertini and A. Bimbo},
  journal={2023 IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2023},
  pages={15292-15301},
  url={https://api.semanticscholar.org/CorpusID:257766776}
}
@article{Tang2024OR,
  title={Reason-before-Retrieve: One-Stage Reflective Chain-of-Thoughts for Training-Free Zero-Shot Composed Image Retrieval},
  author={Yuanmin Tang and Xiaoting Qin and Jue Zhang and Jing Yu and Gaopeng Gou and Gang Xiong and Qingwei Ling and S. Rajmohan and Dongmei Zhang and Qi Wu},
  journal={2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024},
  pages={14400-14410},
  url={https://api.semanticscholar.org/CorpusID:274776749}
}
@article{Karthik2023VisionbyLanguageFT,
  title={Vision-by-Language for Training-Free Compositional Image Retrieval},
  author={Shyamgopal Karthik and Karsten Roth and Massimiliano Mancini and Zeynep Akata},
  journal={ArXiv},
  year={2023},
  volume={abs/2310.09291},
  url={https://api.semanticscholar.org/CorpusID:264128238}
}
@article{Gu2023LanguageonlyET,
  title={Language-only Efficient Training of Zero-shot Composed Image Retrieval},
  author={Geonmo Gu and Sanghyuk Chun and Wonjae Kim and Yoohoon Kang and Sangdoo Yun},
  journal={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023},
  pages={13225-13234},
  url={https://api.semanticscholar.org/CorpusID:265609308}
}
@article{Gu2023CompoDiffVC,
  title={CompoDiff: Versatile Composed Image Retrieval With Latent Diffusion},
  author={Geonmo Gu and Sanghyuk Chun and Wonjae Kim and HeeJae Jun and Yoohoon Kang and Sangdoo Yun},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.11916},
  url={https://api.semanticscholar.org/CorpusID:257636726}
}
@article{Tang2025MissingTI,
  title={Missing Target-Relevant Information Prediction with World Model for Accurate Zero-Shot Composed Image Retrieval},
  author={Yuanmin Tang and Jing Yu and Keke Gai and Jiamin Zhuang and Gang Xiong and Gaopeng Gou and Qi Wu},
  journal={2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2025},
  pages={24785-24795},
  url={https://api.semanticscholar.org/CorpusID:277244189}
}