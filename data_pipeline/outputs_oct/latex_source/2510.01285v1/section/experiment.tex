\section{Experiments}

\subsection{Experimental Setup}
\label{sec:exp-setup}

\paragraph{Benchmarks:}


To the best of our knowledge, KramaBench is the only public benchmark for data science problems that explicitly incorporates a data discovery phase, which we adopt in our evaluation. In addition, we repurpose two existing datasets, DS-Bench \citep{jing2025dsbench} and DA-Code \citep{huang-etal-2024-da}, to include in this phase. Specifically, we manually filtered out all questions that do not require any data file for answering, as well as those that lack sufficient hints for data discovery.\footnote{For example, questions that request the computation of a data science metric on a column without specifying the structure or content of the relevant file.} After filtering, we aggregated all remaining files across questions into a unified data lake, such that the model must perform discovery to identify relevant files at inference time. In this setup, only the question and the data lake are provided to the model, requiring it to identify the relevant files to answer the question, following the same protocol as KramaBench.
% \footnote{The constructed datasets will be released publicly upon acceptance of the paper.} 
Further details on this filtering process, along with dataset statistics in Table~\ref{tab:stats}, are provided in Appendix~\ref{app:dataset}.


\paragraph{Evaluation:}

To evaluate the generated programs, we execute each and compare its output against the ground-truth reference for the corresponding question. For each dataset, we adopt its standard evaluation protocol. For KramaBench, we use the official evaluation script provided in its repository.\footnote{Available at: \url{https://github.com/mitdbg/KramaBench}} For DA-Code, we likewise rely on the official evaluation script released by its authors.\footnote{Available at: \url{https://github.com/yiyihum/da-code}} For DS-Bench, we use the original evaluation method, in which an LLM serves as the judge. The generated programs output is compared against the reference answer using Gemini-2.5-Pro as the judge LLM, with the evaluation prompt shown in Figure \ref{fig:eval-ds-bench} in Appendix \ref{app:dataset}, producing a binary score.

\paragraph{Inference Setup:} We set the maximum actions of the main agent to $T = 10$. We use nucleus sampling \citep{Holtzman2020The} with a temperature of $0.1$ for more deterministic inference and default value for other hyperparameters. Proprietary models are accessed via Vertex AI,\footnote{Available at: \url{https://cloud.google.com/vertex-ai?hl=en}} while open-source models are served by vLLM.\footnote{Available at: \url{https://docs.vllm.ai/en/latest/}} At each step, we cap the number of generated tokens at 8,192. We use Gemini-2.5-Pro and -Flash \citep{comanici2025gemini25pushingfrontier}, and Claude-4-Opus \citep{anthropic2025claude4} as the proprietary and Qwen3-Coder\footnote{Available at: \url{https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct}} with 30 billion parameters \citep{qwen3technicalreport} as the open-source LLMs. Experiments are conducted on 2 NVIDIA A100 (each with 80GB VRAM) GPUs.

% \begin{table}[]
%     \centering
%     \caption{Results of our method and the baselines on the KramaBench, DS-Bench, and DA-Code benchmarks. The best results are highlighted in \textbf{bold}.}
%     \label{tab:main-result}
%     \adjustbox{max width=\textwidth}{
%     \begin{tabular}{ll|l|cccccc|c|c|c}
%         \toprule
%         \multirow{2}{*}{\textbf{Method}} & & \multirow{2}{*}{\textbf{LLM}} & \multicolumn{6}{|c|}{\textbf{KramaBench}} & \multirow{2}{*}{\textbf{DS-Bench}} & \multirow{2}{*}{\textbf{DA-Code}} & {\textbf{Average}} \\
%         \cmidrule{4-9}
%         & & & Archaeology & Astronomy & Biomedical & Environment & Legal & Wildfire & & & (macro) \\
%         \midrule
        
%         \multirow{4}{*}{DS-GRU} & (1) & Qwen3-Coder & 0.00\% & 1.80\% & 2.11\% & 1.15\% & 3.27\% & 13.54\% & 0.00\% & 0.00\% & 2.73\% \\
        
%         & (2) & Gemini 2.5 Flash & 0.00\% & 7.83\% & 0.09\% & 10.93\% & 12.46\% & 13.34\% & 5.53\% & 0.00\% & 6.38\% \\
        
%         & (3) & Gemini 2.5 Pro & 25.00\% & 6.69\% & 10.64\% & 27.47\% & 5.94\% & 39.36\% & 3.95\% & 0.00\% & 14.88\% \\
%         & (4) & Claude 4 Opus & 8.33\% & 1.38\% & 1.90\% & 8.14\% & 9.80\% & 23.14\% & 3.55\% & 0.00\% & 7.03\% \\
%         \midrule
        
%         \multirow{4}{*}{RAG} & (5) & Qwen3-Coder & 0.00\% & 3.16\% & 4.99\% & 0.54\% & 6.19\% & 16.93\% & 6.32\% & 0.00\% & 4.76\% \\
        
%         & (6) & Gemini 2.5 Flash & 16.66\% & 3.57\% & 13.98\% & 28.57\% & 10.97\% & 33.67\% & 22.92\% & 2.75\% & 17.44\% \\
        
%         & (7) & Gemini 2.5 Pro & \textbf{33.33\%} & 8.47\% & 32.53\% & 31.36\% & 25.55\% & 38.32\% & 27.27\% & 0.00\% & 25.32\% \\
        
%         & (8) & Claude 4 Opus & \textbf{33.33\%} & 11.52\% & 23.42\% & 31.61\% & 31.80\% & 45.80\% & 35.57\% & 3.85\% & 27.11\% \\
%         \midrule
        
%         \multirow{4}{*}{Master-Slave} & (9) & Qwen3-Coder & 0.00\% & 3.55\% & 3.39\% & 7.77\% & 8.90\% & 21.79\% & 7.55\% & 0.00\% & 6.61\% \\
        
%         & (10) & Gemini 2.5 Flash & 16.66\% & 3.16\% & 13.98\% & 17.46\% & 21.75\% & 25.80\% & 26.48\% & 0.55\% & 14.87\% \\
        
        
%         & (11) & Gemini 2.5 Pro & \textbf{33.33\%} & 8.47\% & 24.74\% & 32.81\% & 34.64\% & 58.98\% & 34.38\% & 5.49\% & 29.10\% \\
        
%         & (12) & Claude 4 Opus & \textbf{33.33\%} & 8.69\% & 32.28\% & 39.16\% & \textbf{44.08\%} & 48.35\% & 45.84\% & 2.75\% & 31.81\% \\
%         \midrule
        
%         \multirow{4}{*}{Blackboard} & (13) & Qwen3-Coder & 0.00\% & 7.69\% & 7.85\% & 4.47\% & 6.36\% & 23.97\% & 14.22\% & 1.11\% & 8.47\% \\
        
%         & (14) & Gemini 2.5 Flash & 16.66\% & 3.57\% & 14.78\% & 22.92\% & 27.09\% & 41.04\% & 28.06\% & 0.55\% & 18.22\% \\
        
%         & (15) & Gemini 2.5 Pro & \textbf{33.33\%} & 17.95\% & 36.83\% & \textbf{39.31\%} & 34.92\% & \textbf{62.88\%} & 38.73\% & \textbf{9.34\%} & 34.16\% \\
        
%         & (16) & Claude 4 Opus & \textbf{\textbf{33.33\%}} & \textbf{18.69\%} & \textbf{45.31\%} & 34.35\% & 42.48\% & 50.06\% & \textbf{49.80\%} & 7.14\% & \textbf{35.14\%} \\
%         \bottomrule
%     \end{tabular}}
% \end{table}



\paragraph{Baselines:} To evaluate our method against alternative approaches for solving data science problems involving data discovery, we compare it with the following baselines:
\begin{itemize}[leftmargin=*]
    \item \textit{\textbf{DS-GRU:}} We adopt the only existing baseline (to the best of our knowledge) for data discovery in data science problems, which appends all available files directly into the LLM prompt and attempts to solve the problem \citep{lai2025kramabenchbenchmarkaisystems}. This baseline uses a self-correction loop that retries when errors occur in generated codes. For details, we refer the reader to \citet{lai2025kramabenchbenchmarkaisystems}.
    
    \item \textit{\textbf{Retrieval-Augmented Generation (RAG):}} This retrieves the top 5 files\footnote{This number is chosen based on the average number of files required to solve the problems (1.6) and the length of the context window of the backbone LLMs used in this paper.} based on the file names and contents (the method for presenting a file content to the LLM is explained in Appendix~\ref{app:implementation}) from the data lake using E5-large\footnote{Available at: \url{https://huggingface.co/intfloat/e5-large-v2}} \citep{wang2022text}, a 330M-parameter embedding model and use it to solve the problem. It then follows the same procedure as the main agent described in Section~\ref{sec:main-agent}, with two key modification: 1) the retrieved files contents and addresses are presented directly to the LLM in the prompt and 2) the general help-request action is replaced with a restricted action that only allows direct requests to the search agent. This design isolates the effect of substituting the file discovery mechanism with RAG, enabling a controlled study of its impact on performance. The prompt used for this baseline is shown in Figure~\ref{fig:main-agent-rag-prompt} in Appendix~\ref{app:prompts}.
    
    \item \textit{\textbf{Master-Slave:}} This baseline follows the same procedure as the main agent described in Section~\ref{sec:main-agent}. The key difference is that, instead of posting requests on the blackboard, the agent directly invokes sub-agents (consisting of the search agent and the file agents as explained in Section~\ref{sec:sub-agents}) based on their description by referencing their names and assign task to them. The prompt used for this baseline is shown in Figure~\ref{fig:main-agent-master-slave-prompt} in Appendix~\ref{app:prompts}.
\end{itemize} 


% \begin{table}[]
%     \centering
%     \caption{Results of our method and the baselines on the KramaBench, DS-Bench, and DA-Code benchmarks. The best results for each backbone LLMs are highlighted in \textbf{bold}.}
%     \label{tab:main-result}
%     \adjustbox{max width=\textwidth}{
%     \begin{tabular}{ll|c|cccccc|c|c|c|c}
%         \toprule
%         & \multirow{2}{*}{\textbf{Method}}& \multirow{2}{*}{\textbf{LLM}} & \multicolumn{7}{|c|}{\textbf{KramaBench}} & \multirow{2}{*}{\textbf{DS-Bench}} & \multirow{2}{*}{\textbf{DA-Code}} & {\textbf{Average}} \\
%         \cmidrule{4-10}
%         & & & Archaeology & Astronomy & Biomedical & Environment & Legal & Wildfire & Average & & & (macro) \\
%         \midrule
        
%         (1) & {DS-GRU} & \multirow{4}{*}{Qwen3-Coder} & \textbf{0.00\%} & 1.80\% & 2.11\% & 1.15\% & 3.27\% & 13.54\% & 3.64\% & 0.00\% & 0.00\% & 1.21\% \\
        
%         (2) & {RAG} &  & \textbf{0.00\%} & 3.16\% & 4.99\% & 0.54\% & 6.19\% & 16.93\% & 5.30\% & 6.32\% & 0.00\% & 3.87\% \\
        
%         (3) & {Master-Slave} &  & \textbf{0.00\%} & 3.55\% & 3.39\% & \textbf{7.77\%} & \textbf{8.90\%} & 21.79\% & 7.56\% & 7.55\% & 0.00\% & 5.03\% \\
        
%         \cmidrule{1-2} \cmidrule{4-13}
        
%         (4) & {Blackboard} & & \textbf{0.00\%} & \textbf{7.69\%} & \textbf{7.85\%} & 4.47\% & 6.36\% & \textbf{23.97\%} & \textbf{8.39\%} & \textbf{14.22\%} & \textbf{1.11\%} & \textbf{7.90\%} \\
        
%         \midrule
%         \midrule
        
%         (5) & {DS-GRU} & \multirow{4}{*}{Gemini 2.5 Flash} & 0.00\% & \textbf{7.83\%} & 0.09\% & 10.93\% & 12.46\% & 13.34\% & 7.44\% & 5.53\% & 0.00\% & 4.32\% \\
        
%         (6) & {RAG} & & \textbf{16.66\%} & 3.57\% & 13.98\% & \textbf{28.57\%} & 10.97\% & 33.67\% & 17.90\% & 22.92\% & \textbf{2.75\%} & 14.52\% \\
        
%         (7) & {Master-Slave} & & \textbf{16.66\%} & 3.16\% & 13.98\% & 17.46\% & 21.75\% & 25.80\% & 16.46\% & 26.48\% & 0.55\% & 14.49\% \\
        
%         \cmidrule{1-2} \cmidrule{4-13}
        
%         (8) & {Blackboard} & & \textbf{16.66\%} & 3.57\% & \textbf{14.78\%} & 22.92\% & \textbf{27.09\%} & \textbf{41.04\%} & \textbf{21.01\%} & \textbf{28.06\%} & 0.55\% & \textbf{16.54\%} \\
        
%         \midrule
%         \midrule
        
%         (9) & {DS-GRU} & \multirow{4}{*}{Gemini 2.5 Pro} & 25.00\% & 6.69\% & 10.64\% & 27.47\% & 5.94\% & 39.36\% & 19.18\% & 3.95\% & 0.00\% & 7.71\% \\
        
%         (10) & {RAG} & & \textbf{33.33\%} & 8.47\% & 32.53\% & 31.36\% & 25.55\% & 38.32\% & 28.26\% & 27.27\% & 0.00\% & 18.51\% \\
        
%         (11) & {Master-Slave} & & \textbf{33.33\%} & 8.47\% & 24.74\% & 32.81\% & 34.64\% & 58.98\% & 32.16\% & 34.38\% & 5.49\% & 24.01\% \\
        
%         \cmidrule{1-2} \cmidrule{4-13}
        
%         (12) & {Blackboard} & & \textbf{33.33\%} & \textbf{17.95\%} & \textbf{36.83\%} & \textbf{39.31\%} & \textbf{34.92\%} & \textbf{62.88\%} & \textbf{37.53\%} & \textbf{38.73\%} & \textbf{9.34\%} & \textbf{28.53\%} \\
        
%         \midrule
%         \midrule
        
%         (13) & {DS-GRU} & \multirow{4}{*}{Claude 4 Opus} & 8.33\% & 1.38\% & 1.90\% & 8.14\% & 9.80\% & 23.14\% & 8.78\% & 3.55\% & 0.00\% & 4.11\% \\
        
        
%         (14) & {RAG} &  & \textbf{33.33\%} & 11.52\% & 23.42\% & 31.61\% & 31.80\% & 45.80\% & 29.58\% & 35.57\% & 3.85\% & 23.00\% \\


%         (15) & {Master-Slave} & & \textbf{33.33\%} & 8.69\% & 32.28\% & \textbf{39.16\%} & \textbf{44.08\%} & 48.35\% & 34.31\% & 45.84\% & 2.75\% & 27.63\% \\

%         \cmidrule{1-2} \cmidrule{4-13}

%         (16) & {Blackboard} &  & \textbf{\textbf{33.33\%}} & \textbf{18.69\%} & \textbf{45.31\%} & 34.35\% & 42.48\% & \textbf{50.06\%} & \textbf{37.37\%} & \textbf{49.80\%} & \textbf{7.14\%} & \textbf{31.43\%} \\
%         \bottomrule
%     \end{tabular}}
% \end{table}

\begin{table*}
    \centering
    \caption{Results on the KramaBench, DS-Bench, and DA-Code benchmarks. The best results for each LLM are highlighted in \textbf{bold}. The KramaBench categories are abbreviated: Arc. (Archaeology), Ast. (Astronomy), Bio. (Biomedical), Env. (Environment), Leg. (Legal), and Wild. (Wildfire).}
    \label{tab:main-result}
    \adjustbox{max width=\textwidth}{
    \begin{tabular}{ll c cccccc c c c c}
        \toprule
        & \multirow{2}{*}{\textbf{Method}}& \multirow{2}{*}{\textbf{LLM}} & \multicolumn{7}{c}{\multirow{1}{*}{\textbf{KramaBench}}} & \multirow{2}{*}{\textbf{\makecell{DS-\\Bench}}} & \multirow{2}{*}{\textbf{\makecell{DA-\\Code}}} & \multirow{2}{*}{\textbf{\makecell{Average \\ (macro)}}} \\
        \cmidrule{4-10}
        & & & Arc. & Ast. & Bio. & Env. & Leg. & Wild. & Average & & & \\
        \midrule
        
        (1) & {DS-GRU} & \multirow{4}{*}{\makecell{Qwen3-\\Coder}} & \textbf{0.00\%} & 1.80\% & 2.11\% & 1.15\% & 3.27\% & 13.54\% & 3.64\% & 0.00\% & 0.00\% & 1.21\% \\
        
        (2) & {RAG} &  & \textbf{0.00\%} & 3.16\% & 4.99\% & 0.54\% & 6.19\% & 16.93\% & 5.30\% & 6.32\% & 0.00\% & 3.87\% \\
        
        (3) & {Master-Slave} &  & \textbf{0.00\%} & 3.55\% & 3.39\% & \textbf{7.77\%} & \textbf{8.90\%} & 21.79\% & 7.56\% & 7.55\% & 0.00\% & 5.03\% \\
        
        \cmidrule{1-2} \cmidrule{4-13}
        
        (4) & {Blackboard} & & \textbf{0.00\%} & \textbf{7.69\%} & \textbf{7.85\%} & 4.47\% & 6.36\% & \textbf{23.97\%} & \textbf{8.39\%} & \textbf{14.22\%} & \textbf{1.11\%} & \textbf{7.90\%} \\
        
        \midrule
        \midrule
        
        (5) & {DS-GRU} & \multirow{4}{*}{\makecell{Gemini 2.5\\Flash}} & 0.00\% & \textbf{7.83\%} & 0.09\% & 10.93\% & 12.46\% & 13.34\% & 7.44\% & 5.53\% & 0.00\% & 4.32\% \\
        
        (6) & {RAG} & & \textbf{16.66\%} & 3.57\% & 13.98\% & \textbf{28.57\%} & 10.97\% & 33.67\% & 17.90\% & 22.92\% & \textbf{2.75\%} & 14.52\% \\
        
        (7) & {Master-Slave} & & \textbf{16.66\%} & 3.16\% & 13.98\% & 17.46\% & 21.75\% & 25.80\% & 16.46\% & 26.48\% & 0.55\% & 14.49\% \\
        
        \cmidrule{1-2} \cmidrule{4-13}
        
        (8) & {Blackboard} & & \textbf{16.66\%} & 3.57\% & \textbf{14.78\%} & 22.92\% & \textbf{27.09\%} & \textbf{41.04\%} & \textbf{21.01\%} & \textbf{28.06\%} & 0.55\% & \textbf{16.54\%} \\
        
        \midrule
        \midrule
        
        (9) & {DS-GRU} & \multirow{4}{*}{\makecell{Gemini 2.5\\Pro}} & 25.00\% & 6.69\% & 10.64\% & 27.47\% & 5.94\% & 39.36\% & 19.18\% & 3.95\% & 0.00\% & 7.71\% \\
        
        (10) & {RAG} & & \textbf{33.33\%} & 8.47\% & 32.53\% & 31.36\% & 25.55\% & 38.32\% & 28.26\% & 27.27\% & 0.00\% & 18.51\% \\
        
        (11) & {Master-Slave} & & \textbf{33.33\%} & 8.47\% & 24.74\% & 32.81\% & 34.64\% & 58.98\% & 32.16\% & 34.38\% & 5.49\% & 24.01\% \\
        
        \cmidrule{1-2} \cmidrule{4-13}
        
        (12) & {Blackboard} & & \textbf{33.33\%} & \textbf{17.95\%} & \textbf{36.83\%} & \textbf{39.31\%} & \textbf{34.92\%} & \textbf{62.88\%} & \textbf{37.53\%} & \textbf{38.73\%} & \textbf{9.34\%} & \textbf{28.53\%} \\
        
        \midrule
        \midrule
        
        (13) & {DS-GRU} & \multirow{4}{*}{\makecell{Claude 4\\Opus}} & 8.33\% & 1.38\% & 1.90\% & 8.14\% & 9.80\% & 23.14\% & 8.78\% & 3.55\% & 0.00\% & 4.11\% \\
        
        
        (14) & {RAG} &  & \textbf{33.33\%} & 11.52\% & 23.42\% & 31.61\% & 31.80\% & 45.80\% & 29.58\% & 35.57\% & 3.85\% & 23.00\% \\


        (15) & {Master-Slave} & & \textbf{33.33\%} & 8.69\% & 32.28\% & \textbf{39.16\%} & \textbf{44.08\%} & 48.35\% & 34.31\% & 45.84\% & 2.75\% & 27.63\% \\

        \cmidrule{1-2} \cmidrule{4-13}

        (16) & {Blackboard} &  & \textbf{33.33\%} & \textbf{18.69\%} & \textbf{45.31\%} & 34.35\% & 42.48\% & \textbf{50.06\%} & \textbf{37.37\%} & \textbf{49.80\%} & \textbf{7.14\%} & \textbf{31.43\%} \\
        \bottomrule
    \end{tabular}}
    % \vspace{-0.4cm}
\end{table*}


\subsection{Empirical Findings}

\paragraph{Main Results:} 


We conduct our experiments on the datasets described in Section~\ref{sec:exp-setup} using our method and the baselines. The results are presented in Table~\ref{tab:main-result}. These results demonstrate that our method, the Blackboard System, outperforms all baselines on average across all the datasets. Specifically, the Blackboard System surpasses the DS-GRU, RAG and Master-Slave approaches on all three datasets and achieves similar or higher performance in 4 out of 6 categories on KramaBench. Furthermore, we observe that the Blackboard System consistently outperforms the baselines regardless of the backbone LLM, highlighting its robustness and generalizability. We attribute this improvement to the design of the Blackboard System, where tasks are not explicitly assigned to helper agents; instead, each agent autonomously decides whether to participate based on its capabilities. This self-selection enhances both problem-solving efficiency and data discovery performance.




\paragraph{File Discovery Performance:}

To analyze the effectiveness of different methods in data discovery, we report recall, precision, and F1-score for the file discovery task, i.e., identifying the correct files required to answer each question. The results of this experiment, using Gemini 2.5 Pro as the backbone LLM, are presented in Table~\ref{tab:result-file-discovery}. The results in this table indicate that the blackboard system achieves the highest recall, precision, and F1-score compared to all baselines, both on average and across the three datasets. In particular, for KramaBench, the blackboard system attains the highest F1-score in 4 out of 6 domains. We attribute this improvement to the design of the blackboard system, where the main agent does not directly assign requests to specific file agents, as in the master–slave setup. Instead, each file agent independently decides whether it can contribute based on its capabilities and data holdings, leading to more accurate and comprehensive file discovery.




\paragraph{Effect of Web Search (Search Agent) on the Performance:}

We observed that in some cases the backbone LLM lacks the necessary domain-specific knowledge or familiarity with specialized algorithms to fully understand and solve the problem. To address this limitation, the inclusion of a search agent that can retrieve relevant external information may be beneficial. To evaluate this, we compare the blackboard system with and without the search agent. The results on KramaBench, shown in Figure~\ref{fig:search-wo-search} using Gemini 2.5 Pro as the backbone LLM, demonstrate that incorporating the search agent improves the average performance of the blackboard system. Further analysis reveals that when the main agent encounters unfamiliar concepts, it issues requests to obtain such information from the web. In these cases, the search agent typically responds by retrieving the required knowledge, thereby enabling the main agent to continue solving the problem effectively. Illustrative examples of this behavior are provided in Figures~\ref{fig:search-example-1} and \ref{fig:search-example-2} in Appendix~\ref{app:case-study}, highlighting the importance of the search agent in scenarios where external domain knowledge is essential.

\begin{table}[]
    \centering
    \caption{File discovery performance reported using recall, precision, and f1-score. The results are obtained using Gemini 2.5 Pro as the backbone LLM. The best results are highlighted in \textbf{bold}.}
    \label{tab:result-file-discovery}
    \adjustbox{max width=\textwidth}{
    \begin{tabular}{ll l cccccc c c c c}
        \toprule
        &\multirow{2}{*}{\textbf{Method}} & \multirow{2}{*}{\textbf{Metric}} & \multicolumn{7}{c}{\textbf{KramaBench}} & \multirow{2}{*}{\textbf{DS-Bench}} & \multirow{2}{*}{\textbf{DA-Code}} & {\textbf{Average}} \\
        \cmidrule{4-10}
        & & & Archaeology & Astronomy & Biomedical & Environment & Legal & Wildfire & Average & & & (macro) \\
        \midrule
        \multirow{3}{*}{(1)} & \multirow{3}{*}{RAG } & recall & 0.875 & 0.125 & \textbf{0.666} & 0.3506 & 0.127 & 0.238 & 0.396 & 0.035 & 0.257 & 0.229 \\
        & & precision & \textbf{1.000} & 0.125 & 0.666 & 0.450 & 0.133 & 0.452 & 0.471 & 0.047 & 0.456 & 0.324  \\
        & & F1 & 0.916 & 0.125 & 0.629 & 0.332 & 0.105 & 0.301 & 0.401 & 0.034 & 0.307 & 0.247 \\
        \midrule
        \multirow{3}{*}{(2)} & \multirow{3}{*}{Master-Slave} & recall & \textbf{0.916} & 0.5138 & 0.648 & {0.382} & \textbf{0.444} & \textbf{0.567} & 0.578 & 0.323 & 0.546 & 0.482 \\
        & & precision & 0.930 & \textbf{0.750} & \textbf{0.722} & {0.500} & \textbf{0.494} & \textbf{0.642} & 0.673 & 0.503 & 0.767 & 0.647 \\
        & & F1 & 0.913 & 0.577 & \textbf{0.674} & 0.389 & \textbf{0.450} & \textbf{0.576} & 0.596 & 0.358 & 0.584 & 0.513 \\
        \midrule
        \multirow{3}{*}{(3)} & \multirow{3}{*}{Blackboard} & recall & \textbf{0.916} & \textbf{0.576} & 0.648 & \textbf{0.604} & 0.383 & 0.464 & \textbf{0.598} & \textbf{0.402} & \textbf{0.600} & \textbf{0.533} \\
        & & precision & \textbf{1.000} & 0.733 & \textbf{0.722} & \textbf{0.703} & 0.302 & 0.603 & \textbf{0.677} & \textbf{0.584} & \textbf{0.837} & \textbf{0.699} \\
        & & F1 & \textbf{0.944} & \textbf{0.618} & \textbf{0.674} & \textbf{0.588} & 0.304 & 0.495 & \textbf{0.603} & \textbf{0.438} & \textbf{0.643} & \textbf{0.561} \\
        \bottomrule
    \end{tabular}}
\end{table}


\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figs/search_without_search_compare.png}
    % \vspace{-0.4cm}
    % \centering
    \caption{Performance of Blackboard System w/ and w/o search agent (Gemini 2.5 Pro).}
    % \vspace{-0.4cm}
    \label{fig:search-wo-search}
\end{figure}


\paragraph{Effect of Number of Main Agent's Actions on the Performance:}

To examine the impact of the maximum number of actions available to the main agent, we vary this parameter across ${2, 4, 6, 8, 10}$ and evaluate the blackboard system on KramaBench using Gemini 2.5 Pro as the backbone LLM. The results, presented in Figure~\ref{fig:num-actions}, indicate that increasing the action budget consistently improves the average performance of the system. This trend aligns with intuition: a larger exploration budget allows the agent to more thoroughly analyze the problem, consider alternative strategies, better investigate the solution space, and generate a better program that answers the question.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figs/num_actions_performance.png}
    % \vspace{-0.4cm}
    \caption{Performance of Blackboard System with various maximum actions by the main agent.}
    \label{fig:num-actions}
    % \vspace{-0.5cm}
\end{figure}

\paragraph{Case Studies:}

To qualitatively analyze the blackboard system---specifically how it formulates requests and how this process improves the generated program---we present several case studies:
\begin{itemize}[leftmargin=*]

\item \textbf{Writing Request on the blackboard:} An example of a request posted by on the blackboard is shown in Figure~\ref{fig:request-example} in Appendix~\ref{app:case-study}. In this case, the main agent, given the data science question, formulates a request that specifies the likely column names and data formats needed to solve the problem, along with some guidance for interpretation. In response, several helper agents (3 out of 8 in this example) chose to contribute. Although the relevant files were distributed across different clusters managed by different file agents, each responding agent independently provided the file addresses, code snippets for loading the data, and explanations of the data structure along with suggested preprocessing steps. Collectively, these responses covered all the ground-truth files required to answer the question. This case study demonstrates how the main agent can effectively leverage the blackboard mechanism to discover and integrate necessary information.

\item \textbf{Comparing Generated Program by Blackboard System with Master-Slave System:} To study this further, we present an example of programs generated by the Blackboard system and the Master–Slave system in Figure~\ref{fig:program-example} in Appendix~\ref{app:case-study}. In this case, the Blackboard agent achieved a better solution because it accurately interpreted the prompt and selected the correct data files. Specifically, it identified that the patients \texttt{Age} was located in the \texttt{mmc1.xlsx} file and, more importantly, that the requested \texttt{APP-Z score} was in the \texttt{mmc7.xlsx} file. In contrast, the Master–Slave agent misinterpreted the request and instead used a general protein abundance score (\texttt{APP\_log2\_abundance}) from the wrong file, \texttt{mmc2.xlsx}. This critical error in data selection led the Master–Slave agent to produce an incorrect result of \texttt{74}, while the Blackboard agents precise data discovery and reasoning yielded the correct answer of \texttt{60}.

\end{itemize}