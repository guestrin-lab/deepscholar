\section{LLM-based Multi-Agent Blackboard System}

This section introduces an alternative communication paradigm for LLM-based multi-agent systems inspired by blackboard systems \citep{10.1145/356810.356816}, distinct from the widely used masterâ€“slave architecture. As outlined in \textsection \ref{sec:introduction}, blackboard-based multi-agent systems provide several advantages over the master-slave approach. Here, rather than directly assigning tasks to sub-agents, the main agent posts its requests (i.e., sub-tasks for which it requires assistance) on a shared blackboard, which functions as a broadcast channel accessible to all other agents. Each helper agent independently evaluates whether it can respond to a request, considering its own capabilities, availability, cost, and other factors. If an agent decides to contribute, it writes its response to the corresponding request, and the main agent then decides whether to use or ignore the provided information. \textit{This way, all agents in the system retain full autonomy over their actions, and no centralized controller forces them to execute a specific task.} While the blackboard paradigm is applicable to a wide range of multi-agent systems, we focus on data science tasks that require data discovery, where its characteristics are particularly advantageous, as discussed in \textsection \ref{sec:introduction}. The remainder of this section details our method and its design for data science problems that require information discovery.



\paragraph{Overview:} 

An overview of our proposed method is presented in Figure~\ref{fig:overview}. The system $\pi_{s}$ operates over the data lake $\sD$ by first partitioning $\sD$ into $C$ clusters of related files. Each cluster $\sD_i$ is assigned to a file agent $\pi_{f_i}$, which is responsible for handling, loading, processing, and retrieving information from the files within its cluster. In addition, a search agent $\pi_{s}$ is included to retrieve external information from the web that may be required to solve the problem. The overall system $\pi_{s}$ is composed of a main agent $\pi_{m}$, which is responsible for solving the query $q$, and a set of $C+1$ helper agents $\Pi_{\text{helper}} = \{\pi_{f_i}\}_{i=1}^{M} \cup \{\pi_{s}\}$ that provide specialized assistance. The query $q$ is presented to $\pi_{m}$, which iteratively selects an action $a \in \sA$ from the action space $\sA$, executes the chosen action, and observes the resulting outcome from the environment. Among its actions, the main agent may interact with a blackboard $\beta$, a shared communication medium where it can post a request $r$ without addressing a specific sub-agent. The helper agents $\Pi_{\text{helper}}$ continuously monitor the blackboard, determine whether they can address a posted request, and, if so, provide their outputs on the corresponding response board $\beta_{r}$. These responses are then collected and made available to $\pi_{m}$, which incorporates them into its decision-making process.\footnote{Responses are not written back to the blackboard $\beta$ to avoid dependencies where one sub-agent's output could influence the behavior of others negatively. Instead, all responses are directed exclusively to the response board $\beta_{r}$, ensuring independent operation of sub-agents and exclusive access by the main agent $\pi_{m}$.} The main agent is limited to at most $T$ sequential actions (including actions that interact with the blackboard) to solve the query $q$, ultimately producing a program $p$ in python programming language that computes the final answer to $q$.

\paragraph{Clustering Data Lake:} 

There are multiple approaches for partitioning the data lake into clusters; applying clustering algorithms over file representations, random partitioning, or other heuristic methods. For simplicity, we do not utilize file content and instead rely solely on file names during clustering. Specifically, the file names are provided to an LLM---Gemini-2.5-Pro\footnote{Available at: \url{https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-pro}}---which using the prompt shown in Figure~\ref{fig:clustering-prompt}, clusters the files into categories based only on their names.\footnote{This method represents just one simple possible approach to clustering, chosen for simplicity; more scalable and accurate alternatives could equally be employed in real world scenarios.} An example of this clustering is provided in Figure~\ref{fig:clustering-example} in Appendix~\ref{app:case-study}, where the model successfully groups related files together. For instance, it clusters all files originating from the National Interagency Fire Center into a category labeled ``NIFC Wildfire Statistics.'' The number of automatically derived clusters for each dataset is reported in Table~\ref{tab:stats} in Appendix~\ref{app:dataset}.



% The remainder of this section details the design of the main agent and the helper agents, emphasizing how their coordination supports effective information discovery in data science tasks.

\subsection{Main Agent}
\label{sec:main-agent}

The primary role of the main agent is to solve the problem in collaboration with the helper agents. The main agent follows the ReAct framework \citep{yao2023react}, where at each step $t$, given the query $q$ and the history of actions and observations $\sH_{t-1}$, it first reasons about what is the best next action and selects an action from a predefined action space, executes the action, observes the outcome, and appends the resulting observation to update the history $\sH_{t}$.\footnote{In this work, the inputs, outputs of the model, and observations are appended directly to the prompt of the LLM, formatted according to its chat-based input template.} The prompt used by the main agent is shown in Figure~\ref{fig:main-agent-blackboard-prompt} in Appendix~\ref{app:prompts}. The agent selects one of the following predefined actions in each step, executes them, and observe their outcomes:

\begin{itemize}[leftmargin=*]
    \item \textit{\textbf{Planning:}} In this action, the LLM decomposes the problem into smaller sub-problems and outlines a plan for addressing each of them. This action has no external effect on the environment but serves as an internal reasoning step to guide the LLM's problem-solving process. In response, the system simply acknowledges the proposed plan and instructs the LLM to proceed.
    
    \item \textit{\textbf{Reasoning:}} In this action, the LLM focuses on a specific aspect of the problem and explains its reasoning, analysis, or interpretation of the available observations and steps taken so far in this process. Similar to the planning step, this action has no external effect on the environment but functions as an internal reasoning mechanism to guide the LLM's problem-solving process. In response, the system simply acknowledges the reasoning and prompts the LLM to continue.
    
    \item \textit{\textbf{Executing Code:}} In this action, the agent generates python code, which is executed using a python interpreter. If the code runs successfully, the resulting outputs are returned to the agent for observation; otherwise, the agent receives the corresponding error messages. This action enables the agent to explore the problem interactively, inspect data files, and experiment with them to gain a deeper understanding of their content and structure and how to process them.
    
    \item \textit{\textbf{Requesting Help:}} In this action, the agent formulates a request for assistance from the sub-agents, specifying, for example, the types of data files or information needed, or the resources required to apply a tool or solve a sub-problem. This request is posted on the blackboard $\beta$ for visibility by the helper agents. Once the sub-agents respond, if they respond, their responses on the response board $\beta_r$ are collected and provided back to the main agent as the outcome of this action for observation and further use in its decision-making process.
    
    \item \textit{\textbf{Answering:}} In this action, the agent concludes the problem-solving process by generating a final program that produces the answer to the query. This action terminates the process, and the output of this step constitutes the final program $p$ generated by the system to address the problem.
\end{itemize}

\subsection{Helper Agents}
\label{sec:sub-agents}

In a data science, information discovery can typically be categorized into two tasks: (1) identifying the specific files that contain the data necessary to the problem, and (2) retrieving general knowledge about concepts relevant to the problem, such as domain-specific terms or details of particular algorithms and methods. To support these, our framework employs two types of helper agents:

\paragraph{File Agent:} 

Handling all the files in a data lake with a single agent is not feasible for several reasons: it typically involve a large number of files, many of which are lengthy and may exceed the agents context window; the files span diverse topics, which can confuse the agent and hinder effective reasoning; and accessing and processing all files simultaneously can be computationally expensive and inefficient, leading to unnecessary overhead and slower problem-solving. For these reasons, in our framework each file agent is assigned responsibility for a subset of data files determined to be relevant, as described earlier in the clustering procedure. In an offline phase, the file agent $\pi_{f_i}$ takes as input a subset of the data lake $\sD_{i}$ and operates through a two-step procedure. In the first step, the agent selects a subset\footnote{When filenames indicate multiple files containing the same type of data over different time periods, the agent does not need to inspect all of them to infer the structure; a small representative sample is sufficient.} (or all) of the files to examine their content. The contents of them are presented to the agent for inspection (details of presentation are in Appendix~\ref{app:implementation}). In the second step, after observing the selected files, the agent reasons about and analyzes them, learning how they are structured, what pre-processing or transformations may be required, and how they should be processed in general. An example of such an analysis is provided in Figure~\ref{fig:file-agent-analyze-example} in Appendix~\ref{app:case-study}. Then, in the online phase, the agent listens for requests from the main agent. Upon receiving a request, based on the analysis it did earlier, it determines whether it can contribute to answering it. If so, the agent generates a detailed plan specifying which files in $\sD_i$ are relevant, how they should be loaded in Python code, what libraries to use, the steps required for data processing, and samples from the data. The prompt used to guide the file agent is shown in Figure~\ref{fig:file-agent-prompt} in Appendix~\ref{app:prompts}. 

\paragraph{Search Agent:}

Certain data science problems require task-specific knowledge about algorithms or domain expertise that the LLM may not possess. To address this, we design a web-search agent that retrieves relevant information from a search engine. This agent operates according to the prompt shown in Figure~\ref{fig:search-agent-prompt} in Appendix~\ref{app:prompts}. Given a request $r$ posted on the blackboard $\beta$, the agent first determines whether it is capable of addressing the request. It is specifically restricted to general web-based information retrieval and does not respond to requests involving access to local files or datasets. If the agent determines that the request can be answered, it enters an iterative search process with a maximum of $T_{\text{search}} = 3$ steps. At each step $t$, the agent generates a set of queries $\sQ_{t}$, which are submitted to a search engine---in this work, Google Custom Search Engine\footnote{We use Google Custom Search Engine, configured to exclude all websites associated with the datasets used in this paper to prevent data leakage: \url{https://developers.google.com/custom-search}}---to retrieve $k=3$ webpage per query. The content of the webpages are then extracted using \textit{beautifulsoup} library\footnote{Available at: \url{https://pypi.org/project/beautifulsoup4/}} to be presented to the search agent. The extracted documents are then evaluated by the agent to determine whether they provide sufficient information to answer the request. If so, the agent generates a response to the request, which is posted to the response board $\beta_r$. If the information is insufficient, a new set of queries is generated to continue gathering relevant data from the web.
