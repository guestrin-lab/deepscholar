\section{Introduction}
\label{sec:intro}
%
Object recognition and retrieval span multiple levels of granularity, from semantic-level labels~\citep{rds+15} to fine-grained categories~\citep{gmj+14,kjh+15}, and the most detailed form, \ie instance-level recognition (ILR)~\citep{ypsilantis2021met}. Unlike semantic recognition, which groups objects into broad classes, ILR identifies unique object instances, treating each real-world entity as its own category. This extreme granularity makes ILR particularly challenging.

ILR has applications in domains such as landmarks~\citep{wac+20,pci+07,pci+08}, artwork~\citep{ypsilantis2021met}, products~\citep{sxj+15,rp2k}, fashion~\citep{liu2016deepfashion}, and everyday objects~\citep{wj15,ilias}. However, large-scale training data remains a major bottleneck. Unlike semantic or fine-grained recognition, where class names help structure data and reduce false negatives, ILR requires exhaustive, instance-specific annotations, an expensive and labor-intensive process. Single-domain datasets rely on manually curated ground truth, while multi-domain datasets often lack dedicated training sets~\citep{wj15,ilias}. Collecting images of the same instance under different conditions further compounds the challenge, slowing progress.

To address this, we propose a novel pipeline that automatically generates images of unique objects under diverse conditions, enabling instance-level representation learning without manual data collection. The pipeline requires only the name of one or more domains, \eg ``everyday objects'' or ``artworks'', as input and outputs a representation model fine-tuned for those domains. A large language model (LLM)~\citep{hurst2024gpt} generates a list of relevant object categories, and a generative diffusion model (GDM)~\citep{sauer2025adversarial,rombach2022high} synthesizes images for those categories. We assume that generations from a given seed define an instance-level class, while different seeds correspond to distinct classes. To ensure diversity, we introduce background and lighting variations using ICLight~\citep{iclight}.

The generated instances (see \cref{fig:fig1}) are used to fine-tune a foundational vision encoder such as SigLIP~\citep{zhai2023sigmoid}. We adopt a metric learning approach~\citep{ptm22}, treating images of the same instance as positives and others as negatives, and optimize an information retrieval metric across large batches. The resulting representation improves over the base model across multiple ILR benchmarks, including artwork, landmark, and product datasets.

This is the first work to learn a single representation model that generalizes across diverse ILR domains while %eliminating the need for
providing an effective alternative to large-scale real data . While prior research explored synthetic training data~\citep{peng2015learning,fan2024scaling,tian2024stablerep}, our method is the first tailored specifically for ILR. The pipeline synergistically integrates LLMs and GDMs, leveraging rapid advances in both fields and remaining adaptable to future improvements.
