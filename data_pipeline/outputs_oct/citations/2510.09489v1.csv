parent_paper_title,parent_arxiv_link,citation_shorthand,raw_citation_text,cited_paper_title,cited_paper_arxiv_link,cited_paper_abstract,bib_paper_authors,bib_paper_year,bib_paper_month,bib_paper_url,bib_paper_doi,bib_paper_journal
Two-Stage Gaussian Splatting Optimization for Outdoor Scene Reconstruction,http://arxiv.org/abs/2510.09489v1,kerbl2023gsplatting,\cite{kerbl2023gsplatting},3D Gaussian Splatting for Real-Time Radiance Field Rendering,http://arxiv.org/abs/2308.04079v1,"Radiance Field methods have recently revolutionized novel-view synthesis of
scenes captured with multiple photos or videos. However, achieving high visual
quality still requires neural networks that are costly to train and render,
while recent faster methods inevitably trade off speed for quality. For
unbounded and complete scenes (rather than isolated objects) and 1080p
resolution rendering, no current method can achieve real-time display rates. We
introduce three key elements that allow us to achieve state-of-the-art visual
quality while maintaining competitive training times and importantly allow
high-quality real-time (>= 30 fps) novel-view synthesis at 1080p resolution.
First, starting from sparse points produced during camera calibration, we
represent the scene with 3D Gaussians that preserve desirable properties of
continuous volumetric radiance fields for scene optimization while avoiding
unnecessary computation in empty space; Second, we perform interleaved
optimization/density control of the 3D Gaussians, notably optimizing
anisotropic covariance to achieve an accurate representation of the scene;
Third, we develop a fast visibility-aware rendering algorithm that supports
anisotropic splatting and both accelerates training and allows realtime
rendering. We demonstrate state-of-the-art visual quality and real-time
rendering on several established datasets.","Kerbl, Bernhard and Kopanas, Georgios and Leimk{\""u}hler, Thomas and Drettakis, George",2023,,,10.1145/3597525.3630931,
Two-Stage Gaussian Splatting Optimization for Outdoor Scene Reconstruction,http://arxiv.org/abs/2510.09489v1,Kulhanek2025,\cite{Kulhanek2025},WildGaussians: 3D Gaussian Splatting in the Wild,http://arxiv.org/abs/2407.08447v2,"While the field of 3D scene reconstruction is dominated by NeRFs due to their
photorealistic quality, 3D Gaussian Splatting (3DGS) has recently emerged,
offering similar quality with real-time rendering speeds. However, both methods
primarily excel with well-controlled 3D scenes, while in-the-wild data -
characterized by occlusions, dynamic objects, and varying illumination -
remains challenging. NeRFs can adapt to such conditions easily through
per-image embedding vectors, but 3DGS struggles due to its explicit
representation and lack of shared parameters. To address this, we introduce
WildGaussians, a novel approach to handle occlusions and appearance changes
with 3DGS. By leveraging robust DINO features and integrating an appearance
modeling module within 3DGS, our method achieves state-of-the-art results. We
demonstrate that WildGaussians matches the real-time rendering speed of 3DGS
while surpassing both 3DGS and NeRF baselines in handling in-the-wild data, all
within a simple architectural framework.","Kulhanek, Jonas and Peng, Songyou and Kukelova, Zuzana and Pollefeys, Marc and Sattler, Torsten",2025,,,,
Two-Stage Gaussian Splatting Optimization for Outdoor Scene Reconstruction,http://arxiv.org/abs/2510.09489v1,wang2025,\cite{wang2025},Look at the Sky: Sky-Aware Efficient 3D Gaussian Splatting in the Wild,,,"Wang, Yuze and Wang, Junyi and Gao, Ruicheng and Qu, Yansong and Duan, Wantong and Yang, Shuo and Qi, Yue",2025,,,10.1109/TVCG.2025.3549187,IEEE Transactions on Visualization and Computer Graphics
Two-Stage Gaussian Splatting Optimization for Outdoor Scene Reconstruction,http://arxiv.org/abs/2510.09489v1,cheng2024gaussianpro,\cite{cheng2024gaussianpro},GaussianPro: 3D Gaussian Splatting with Progressive Propagation,http://arxiv.org/abs/2402.14650v1,"The advent of 3D Gaussian Splatting (3DGS) has recently brought about a
revolution in the field of neural rendering, facilitating high-quality
renderings at real-time speed. However, 3DGS heavily depends on the initialized
point cloud produced by Structure-from-Motion (SfM) techniques. When tackling
with large-scale scenes that unavoidably contain texture-less surfaces, the SfM
techniques always fail to produce enough points in these surfaces and cannot
provide good initialization for 3DGS. As a result, 3DGS suffers from difficult
optimization and low-quality renderings. In this paper, inspired by classical
multi-view stereo (MVS) techniques, we propose GaussianPro, a novel method that
applies a progressive propagation strategy to guide the densification of the 3D
Gaussians. Compared to the simple split and clone strategies used in 3DGS, our
method leverages the priors of the existing reconstructed geometries of the
scene and patch matching techniques to produce new Gaussians with accurate
positions and orientations. Experiments on both large-scale and small-scale
scenes validate the effectiveness of our method, where our method significantly
surpasses 3DGS on the Waymo dataset, exhibiting an improvement of 1.15dB in
terms of PSNR.","Cheng, Kai and Long, Xiaoxiao and Yang, Kaizhi and Yao, Yao and Yin, Wei and Ma, Yuexin and Wang, Wenping and Chen, Xuejin",2024,,https://proceedings.mlr.press/v235/cheng24f.html,,
Two-Stage Gaussian Splatting Optimization for Outdoor Scene Reconstruction,http://arxiv.org/abs/2510.09489v1,lin2024vastgaussian,\cite{lin2024vastgaussian},VastGaussian: Vast 3D Gaussians for Large Scene Reconstruction,http://arxiv.org/abs/2402.17427v1,"Existing NeRF-based methods for large scene reconstruction often have
limitations in visual quality and rendering speed. While the recent 3D Gaussian
Splatting works well on small-scale and object-centric scenes, scaling it up to
large scenes poses challenges due to limited video memory, long optimization
time, and noticeable appearance variations. To address these challenges, we
present VastGaussian, the first method for high-quality reconstruction and
real-time rendering on large scenes based on 3D Gaussian Splatting. We propose
a progressive partitioning strategy to divide a large scene into multiple
cells, where the training cameras and point cloud are properly distributed with
an airspace-aware visibility criterion. These cells are merged into a complete
scene after parallel optimization. We also introduce decoupled appearance
modeling into the optimization process to reduce appearance variations in the
rendered images. Our approach outperforms existing NeRF-based methods and
achieves state-of-the-art results on multiple large scene datasets, enabling
fast optimization and high-fidelity real-time rendering.","Lin, Jiaqi and Li, Zhihao and Tang, Xiao and Liu, Jianzhuang and Liu, Shiyong and Liu, Jiayue and Lu, Yangdi and Wu, Xiaofei and Xu, Songcen and Yan, Youliang and Yang, Wenming",2024,,,10.1109/CVPR52733.2024.00494,
Two-Stage Gaussian Splatting Optimization for Outdoor Scene Reconstruction,http://arxiv.org/abs/2510.09489v1,ren2024octreegs,\cite{ren2024octreegs},Octree-GS: Towards Consistent Real-time Rendering with LOD-Structured 3D Gaussians,,,"Ren, Kerui and Jiang, Lihan and Lu, Tao and Yu, Mulin and Xu, Linning and Ni, Zhangkai and Dai, Bo",2025,,,10.1109/TPAMI.2025.3568201,IEEE Transactions on Pattern Analysis and Machine Intelligence
Two-Stage Gaussian Splatting Optimization for Outdoor Scene Reconstruction,http://arxiv.org/abs/2510.09489v1,zhang2024gaussianspa,\cite{zhang2024gaussianspa},"GaussianSpa: An ""Optimizing-Sparsifying"" Simplification Framework for
  Compact and High-Quality 3D Gaussian Splatting",http://arxiv.org/abs/2411.06019v3,"3D Gaussian Splatting (3DGS) has emerged as a mainstream for novel view
synthesis, leveraging continuous aggregations of Gaussian functions to model
scene geometry. However, 3DGS suffers from substantial memory requirements to
store the multitude of Gaussians, hindering its practicality. To address this
challenge, we introduce GaussianSpa, an optimization-based simplification
framework for compact and high-quality 3DGS. Specifically, we formulate the
simplification as an optimization problem associated with the 3DGS training.
Correspondingly, we propose an efficient ""optimizing-sparsifying"" solution that
alternately solves two independent sub-problems, gradually imposing strong
sparsity onto the Gaussians in the training process. Our comprehensive
evaluations on various datasets show the superiority of GaussianSpa over
existing state-of-the-art approaches. Notably, GaussianSpa achieves an average
PSNR improvement of 0.9 dB on the real-world Deep Blending dataset with
10$\times$ fewer Gaussians compared to the vanilla 3DGS. Our project page is
available at https://noodle-lab.github.io/gaussianspa/.","Zhang, Yangming and Jia, Wenqi and Niu, Wei and Yin, Miao",2025,June,,,
Two-Stage Gaussian Splatting Optimization for Outdoor Scene Reconstruction,http://arxiv.org/abs/2510.09489v1,pateux2024bogauss,\cite{pateux2024bogauss},BOGausS: Better Optimized Gaussian Splatting,http://arxiv.org/abs/2504.01844v1,"3D Gaussian Splatting (3DGS) proposes an efficient solution for novel view
synthesis. Its framework provides fast and high-fidelity rendering. Although
less complex than other solutions such as Neural Radiance Fields (NeRF), there
are still some challenges building smaller models without sacrificing quality.
In this study, we perform a careful analysis of 3DGS training process and
propose a new optimization methodology. Our Better Optimized Gaussian Splatting
(BOGausS) solution is able to generate models up to ten times lighter than the
original 3DGS with no quality degradation, thus significantly boosting the
performance of Gaussian Splatting compared to the state of the art.",Stéphane Pateux and Matthieu Gendrin and Luce Morin and Théo Ladune and Xiaoran Jiang,2025,,https://arxiv.org/abs/2504.01844,,
Two-Stage Gaussian Splatting Optimization for Outdoor Scene Reconstruction,http://arxiv.org/abs/2510.09489v1,franke2024trips,\cite{franke2024trips},TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering,http://arxiv.org/abs/2401.06003v2,"Point-based radiance field rendering has demonstrated impressive results for
novel view synthesis, offering a compelling blend of rendering quality and
computational efficiency. However, also latest approaches in this domain are
not without their shortcomings. 3D Gaussian Splatting [Kerbl and Kopanas et al.
2023] struggles when tasked with rendering highly detailed scenes, due to
blurring and cloudy artifacts. On the other hand, ADOP [R\""uckert et al. 2022]
can accommodate crisper images, but the neural reconstruction network decreases
performance, it grapples with temporal instability and it is unable to
effectively address large gaps in the point cloud.
  In this paper, we present TRIPS (Trilinear Point Splatting), an approach that
combines ideas from both Gaussian Splatting and ADOP. The fundamental concept
behind our novel technique involves rasterizing points into a screen-space
image pyramid, with the selection of the pyramid layer determined by the
projected point size. This approach allows rendering arbitrarily large points
using a single trilinear write. A lightweight neural network is then used to
reconstruct a hole-free image including detail beyond splat resolution.
Importantly, our render pipeline is entirely differentiable, allowing for
automatic optimization of both point sizes and positions.
  Our evaluation demonstrate that TRIPS surpasses existing state-of-the-art
methods in terms of rendering quality while maintaining a real-time frame rate
of 60 frames per second on readily available hardware. This performance extends
to challenging scenarios, such as scenes featuring intricate geometry,
expansive landscapes, and auto-exposed footage.
  The project page is located at: https://lfranke.github.io/trips/",Linus Franke and Darius Rückert and Laura Fink and Marc Stamminger,2024,,https://arxiv.org/abs/2401.06003,,
Two-Stage Gaussian Splatting Optimization for Outdoor Scene Reconstruction,http://arxiv.org/abs/2510.09489v1,Kerbletal2024,\cite{Kerbletal2024},"A Hierarchical 3D Gaussian Representation for Real-Time Rendering of
  Very Large Datasets",http://arxiv.org/abs/2406.12080v1,"Novel view synthesis has seen major advances in recent years, with 3D
Gaussian splatting offering an excellent level of visual quality, fast training
and real-time rendering. However, the resources needed for training and
rendering inevitably limit the size of the captured scenes that can be
represented with good visual quality. We introduce a hierarchy of 3D Gaussians
that preserves visual quality for very large scenes, while offering an
efficient Level-of-Detail (LOD) solution for efficient rendering of distant
content with effective level selection and smooth transitions between levels.We
introduce a divide-and-conquer approach that allows us to train very large
scenes in independent chunks. We consolidate the chunks into a hierarchy that
can be optimized to further improve visual quality of Gaussians merged into
intermediate nodes. Very large captures typically have sparse coverage of the
scene, presenting many challenges to the original 3D Gaussian splatting
training method; we adapt and regularize training to account for these issues.
We present a complete solution, that enables real-time rendering of very large
scenes and can adapt to available resources thanks to our LOD method. We show
results for captured scenes with up to tens of thousands of images with a
simple and affordable rig, covering trajectories of up to several kilometers
and lasting up to one hour. Project Page:
https://repo-sam.inria.fr/fungraph/hierarchical-3d-gaussians/","Kerbl, Bernhard and Meuleman, Andreas and Kopanas, Georgios and Wimmer, Michael and Lanvin, Alexandre and Drettakis, George",2024,,https://doi.org/10.1145/3658160,10.1145/3658160,ACM Trans. Graph.
