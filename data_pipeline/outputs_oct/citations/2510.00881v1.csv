parent_paper_title,parent_arxiv_link,citation_shorthand,raw_citation_text,cited_paper_title,cited_paper_arxiv_link,cited_paper_abstract,bib_paper_authors,bib_paper_year,bib_paper_month,bib_paper_url,bib_paper_doi,bib_paper_journal
Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning,http://arxiv.org/abs/2510.00881v1,suri2023software,\cite{suri2023software},Software Engineering Using Autonomous Agents: Are We There Yet?,,,"Suri, Samdyuti and Das, Sankar Narayan and Singi, Kapil and Dey, Kuntal and Sharma, Vibhu Saujanya and Kaulgud, Vikrant",2023,,,,
Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning,http://arxiv.org/abs/2510.00881v1,alidoosti2021ethics,\cite{alidoosti2021ethics},Ethics-driven software architecture decision making,,,"Alidoosti, Razieh",2021,,,,
Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning,http://arxiv.org/abs/2510.00881v1,alidoosti2022incorporating,\cite{alidoosti2022incorporating},Incorporating ethical values into software architecture design practices,,,"Alidoosti, Razieh and Lago, Patricia and Poort, Eltjo and Razavian, Maryam and Tang, Antony",,,,,
Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning,http://arxiv.org/abs/2510.00881v1,DBLP:journals/access/ShahinHNPSGW22,\cite{DBLP:journals/access/ShahinHNPSGW22},Operationalizing Human Values in Software Engineering: A Survey,http://arxiv.org/abs/2108.05624v3,"Human values (e.g., pleasure, privacy, and social justice) are what a person
or a society considers important. The inability to address them in
software-intensive systems can result in numerous undesired consequences (e.g.,
financial losses) for individuals and communities. Various solutions (e.g.,
methodologies, techniques) are developed to help ""operationalize values in
software"". The ultimate goal is to ensure building software (better) reflects
and respects human values. In this survey, ""operationalizing values"" is
referred to as the process of identifying human values and translating them to
accessible and concrete concepts so that they can be implemented, validated,
verified, and measured in software. This paper provides a deep understanding of
the research landscape on operationalizing values in software engineering,
covering 51 primary studies. It also presents an analysis and taxonomy of 51
solutions for operationalizing values in software engineering. Our survey
reveals that most solutions attempt to help operationalize values in the early
phases (requirements and design) of the software development life cycle.
However, the later phases (implementation and testing) and other aspects of
software development (e.g., ""team organization"") still need adequate
consideration. We outline implications for research and practice and identify
open issues and future research directions to advance this area.","Shahin, Mojtaba and Hussain, Waqar and Nurwidyantoro, Arif and Perera, Harsha and Shams, Rifat and Grundy, John and Whittle, Jon",2022,,,,{IEEE} Access
Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning,http://arxiv.org/abs/2510.00881v1,trailer2024ciniselli,\cite{trailer2024ciniselli},The Trailer of the {ACM} 2030 Roadmap for Software Engineering,,,"Pezz\`{e}, Mauro and Ciniselli, Matteo and Di Grazia, Luca and Puccinelli, Niccol\`{o} and Qiu, Ketai",2024,,https://doi.org/10.1145/3696117.3696126,10.1145/3696117.3696126,SIGSOFT Softw. Eng. Notes
Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning,http://arxiv.org/abs/2510.00881v1,jedlickova2024ensuring,\cite{jedlickova2024ensuring},Ensuring Ethical Standards in the Development of Autonomous and Intelligent Systems,,,"Jedlickova, Anetta",2024,,,,IEEE Transactions on Artificial Intelligence
Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning,http://arxiv.org/abs/2510.00881v1,dennis2016formal,\cite{dennis2016formal},Formal verification of ethical choices in autonomous systems,,,"Dennis, Louise and Fisher, Michael and Slavkovik, Marija and Webster, Matt",2016,,,,Robotics and Autonomous Systems
Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning,http://arxiv.org/abs/2510.00881v1,cardoso2021implementing,\cite{cardoso2021implementing},Implementing ethical governors in BDI,,,"Cardoso, Rafael C and Ferrando, Angelo and Dennis, Louise A and Fisher, Michael",2021,,,,
Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning,http://arxiv.org/abs/2510.00881v1,inverardi2019ethics,\cite{inverardi2019ethics},Ethics and privacy in autonomous systems: A software exoskeleton to empower the user,,,"Inverardi, Paola",,,,,
Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning,http://arxiv.org/abs/2510.00881v1,de2024engineering,\cite{de2024engineering},Engineering ethical-aware collective adaptive systems,,,"De Sanctis, Martina and Inverardi, Paola",2024,,,,
Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning,http://arxiv.org/abs/2510.00881v1,inverardi2022ethical,\cite{inverardi2022ethical},Ethical-aware autonomous systems from a social psychological lens.,,,"Paola Inverardi and
                  Massimiliano Palmiero and
                  Patrizio Pelliccione and
                  Massimo Tivoli",2022,,,,
Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning,http://arxiv.org/abs/2510.00881v1,Machine_Ethics_in_Changing_Contexts:2021,\cite{Machine_Ethics_in_Changing_Contexts:2021},Verifiable machine ethics in changing contexts,,,"Dennis, Louise A and Bentzen, Martin Mose and Lindner, Felix and Fisher, Michael",2021,,,,
Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning,http://arxiv.org/abs/2510.00881v1,karim2017ethical,\cite{karim2017ethical},Ethical software: Integrating code of ethics into software development life cycle,,,"Karim, Nor Shahriza Abdul and Al Ammar, Fahda and Aziz, Romana",2017,,,,
Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning,http://arxiv.org/abs/2510.00881v1,hou2024large,\cite{hou2024large},Large language models for software engineering: A systematic literature review,,,"Hou, Xinyi and Zhao, Yanjie and Liu, Yue and Yang, Zhou and Wang, Kailong and Li, Li and Luo, Xiapu and Lo, David and Grundy, John and Wang, Haoyu",2024,,,,ACM Transactions on Software Engineering and Methodology
Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning,http://arxiv.org/abs/2510.00881v1,DBLP:conf/emnlp/RaoKTAC23,\cite{DBLP:conf/emnlp/RaoKTAC23},"Ethical Reasoning over Moral Alignment: A Case and Framework for
  In-Context Ethical Policies in LLMs",http://arxiv.org/abs/2310.07251v1,"In this position paper, we argue that instead of morally aligning LLMs to
specific set of ethical principles, we should infuse generic ethical reasoning
capabilities into them so that they can handle value pluralism at a global
scale. When provided with an ethical policy, an LLM should be capable of making
decisions that are ethically consistent to the policy. We develop a framework
that integrates moral dilemmas with moral principles pertaining to different
foramlisms of normative ethics, and at different levels of abstractions.
Initial experiments with GPT-x models shows that while GPT-4 is a nearly
perfect ethical reasoner, the models still have bias towards the moral values
of Western and English speaking societies.","Abhinav Rao and
                  Aditi Khandelwal and
                  Kumar Tanmay and
                  Utkarsh Agarwal and
                  Monojit Choudhury",2023,,,,
Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning,http://arxiv.org/abs/2510.00881v1,han2022aligning,\cite{han2022aligning},Aligning artificial intelligence with human values: reflections from a phenomenological perspective,,,"Han, Shengnan and Kelly, Eugene and Nikou, Shahrokh and Svee, Eric-Oluf",,,,,AI \& SOCIETY
Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning,http://arxiv.org/abs/2510.00881v1,ICSE2025PAPER,\cite{ICSE2025PAPER},A First Look at AI Trends in Value-Aligned Software Engineering Publications: Human-LLM Insights,,,"Davoud Mougouei and
                  Ahmad Azarnik and
                  Mahdi Fahmideh  and 
Elahe Mougouei and Hoa Khanh Dam and Arif Ali Khan and Saima Rafi and Javed Ali Khan and Aakash Ahmad",2025,,,,
Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning,http://arxiv.org/abs/2510.00881v1,schwartz2012overview,\cite{schwartz2012overview},An overview of the Schwartz theory of basic values,,,"Schwartz, Shalom H",2012,,,,Online readings in Psychology and Culture
Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning,http://arxiv.org/abs/2510.00881v1,alshami2023harnessing,\cite{alshami2023harnessing},"Harnessing the power of ChatGPT for automating systematic review process: methodology, case study, limitations, and future directions",,,"Alshami, Ahmad and Elsayed, Moustafa and Ali, Eslam and Eltoukhy, Abdelrahman EE and Zayed, Tarek",2023,,,,Systems
Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning,http://arxiv.org/abs/2510.00881v1,DBLP:conf/iclr/TennantHM25,\cite{DBLP:conf/iclr/TennantHM25},Moral Alignment for LLM Agents,http://arxiv.org/abs/2410.01639v4,"Decision-making agents based on pre-trained Large Language Models (LLMs) are
increasingly being deployed across various domains of human activity. While
their applications are currently rather specialized, several research efforts
are underway to develop more generalist agents. As LLM-based systems become
more agentic, their influence on human activity will grow and their
transparency will decrease. Consequently, developing effective methods for
aligning them to human values is vital.
  The prevailing practice in alignment often relies on human preference data
(e.g., in RLHF or DPO), in which values are implicit, opaque and are
essentially deduced from relative preferences over different model outputs. In
this work, instead of relying on human feedback, we introduce the design of
reward functions that explicitly and transparently encode core human values for
Reinforcement Learning-based fine-tuning of foundation agent models.
Specifically, we use intrinsic rewards for the moral alignment of LLM agents.
  We evaluate our approach using the traditional philosophical frameworks of
Deontological Ethics and Utilitarianism, quantifying moral rewards for agents
in terms of actions and consequences on the Iterated Prisoner's Dilemma (IPD)
environment. We also show how moral fine-tuning can be deployed to enable an
agent to unlearn a previously developed selfish strategy. Finally, we find that
certain moral strategies learned on the IPD game generalize to several other
matrix game environments. In summary, we demonstrate that fine-tuning with
intrinsic rewards is a promising general solution for aligning LLM agents to
human values, and it might represent a more transparent and cost-effective
alternative to currently predominant alignment techniques.","Elizaveta Tennant and
                  Stephen Hailes and
                  Mirco Musolesi",2025,,,,
