parent_paper_title,parent_arxiv_link,citation_shorthand,raw_citation_text,cited_paper_title,cited_paper_arxiv_link,cited_paper_abstract,bib_paper_authors,bib_paper_year,bib_paper_month,bib_paper_url,bib_paper_doi,bib_paper_journal
CRPS-LAM: Regional ensemble weather forecasting from matching marginals,http://arxiv.org/abs/2510.09484v1,prob_fc_scoring_rules,\cite{prob_fc_scoring_rules},"Probabilistic Forecasting with Generative Networks via Scoring Rule
  Minimization",http://arxiv.org/abs/2112.08217v3,"Probabilistic forecasting relies on past observations to provide a
probability distribution for a future outcome, which is often evaluated against
the realization using a scoring rule. Here, we perform probabilistic
forecasting with generative neural networks, which parametrize distributions on
high-dimensional spaces by transforming draws from a latent variable.
Generative networks are typically trained in an adversarial framework. In
contrast, we propose to train generative networks to minimize a
predictive-sequential (or prequential) scoring rule on a recorded temporal
sequence of the phenomenon of interest, which is appealing as it corresponds to
the way forecasting systems are routinely evaluated. Adversarial-free
minimization is possible for some scoring rules; hence, our framework avoids
the cumbersome hyperparameter tuning and uncertainty underestimation due to
unstable adversarial training, thus unlocking reliable use of generative
networks in probabilistic forecasting. Further, we prove consistency of the
minimizer of our objective with dependent data, while adversarial training
assumes independence. We perform simulation studies on two chaotic dynamical
models and a benchmark data set of global weather observations; for this last
example, we define scoring rules for spatial data by drawing from the relevant
literature. Our method outperforms state-of-the-art adversarial approaches,
especially in probabilistic calibration, while requiring less hyperparameter
tuning.","Pacchiardi, Lorenzo and Adewoyin, Rilwan A. and Dueben, Peter and Dutta, Ritabrata",2024,,http://jmlr.org/papers/v25/23-0038.html,,
CRPS-LAM: Regional ensemble weather forecasting from matching marginals,http://arxiv.org/abs/2510.09484v1,lang2024aifscrpsensembleforecastingusing,\cite{lang2024aifscrpsensembleforecastingusing},{AIFS-CRPS}: Ensemble forecasting using a model trained with a loss function based on the Continuous Ranked Probability Score,,,Simon Lang and Mihai Alexe and Mariana C. A. Clare and Christopher Roberts and Rilwan Adewoyin and Zied Ben Bouall√®gue and Matthew Chantry and Jesper Dramsch and Peter D. Dueben and Sara Hahner and Pedro Maciel and Ana Prieto-Nemesio and Cathal O'Brien and Florian Pinault and Jan Polster and Baudouin Raoult and Steffen Tietsche and Martin Leutbecher,2024,,https://arxiv.org/abs/2412.15832,,
CRPS-LAM: Regional ensemble weather forecasting from matching marginals,http://arxiv.org/abs/2510.09484v1,lang_multi-scale,\cite{lang_multi-scale},"A multi-scale loss formulation for learning a probabilistic model with
  proper score optimisation",http://arxiv.org/abs/2506.10868v1,"We assess the impact of a multi-scale loss formulation for training
probabilistic machine-learned weather forecasting models. The multi-scale loss
is tested in AIFS-CRPS, a machine-learned weather forecasting model developed
at the European Centre for Medium-Range Weather Forecasts (ECMWF). AIFS-CRPS is
trained by directly optimising the almost fair continuous ranked probability
score (afCRPS). The multi-scale loss better constrains small scale variability
without negatively impacting forecast skill. This opens up promising directions
for future work in scale-aware model training.","Lang, Simon and Leutbecher, Martin and Maciel, Pedro",2025,,http://arxiv.org/abs/2506.10868,10.48550/arXiv.2506.10868,
CRPS-LAM: Regional ensemble weather forecasting from matching marginals,http://arxiv.org/abs/2510.09484v1,fourcastnet3,\cite{fourcastnet3},"FourCastNet 3: A geometric approach to probabilistic machine-learning
  weather forecasting at scale",http://arxiv.org/abs/2507.12144v2,"FourCastNet 3 advances global weather modeling by implementing a scalable,
geometric machine learning (ML) approach to probabilistic ensemble forecasting.
The approach is designed to respect spherical geometry and to accurately model
the spatially correlated probabilistic nature of the problem, resulting in
stable spectra and realistic dynamics across multiple scales. FourCastNet 3
delivers forecasting accuracy that surpasses leading conventional ensemble
models and rivals the best diffusion-based methods, while producing forecasts 8
to 60 times faster than these approaches. In contrast to other ML approaches,
FourCastNet 3 demonstrates excellent probabilistic calibration and retains
realistic spectra, even at extended lead times of up to 60 days. All of these
advances are realized using a purely convolutional neural network architecture
tailored for spherical geometry. Scalable and efficient large-scale training on
1024 GPUs and more is enabled by a novel training paradigm for combined model-
and data-parallelism, inspired by domain decomposition methods in classical
numerical models. Additionally, FourCastNet 3 enables rapid inference on a
single GPU, producing a 60-day global forecast at 0.25{\deg}, 6-hourly
resolution in under 4 minutes. Its computational efficiency, medium-range
probabilistic skill, spectral fidelity, and rollout stability at subseasonal
timescales make it a strong candidate for improving meteorological forecasting
and early warning systems through large ensemble predictions.","Bonev, Boris and Kurth, Thorsten and Mahesh, Ankur and Bisson, Mauro and Kossaifi, Jean and Kashinath, Karthik and Anandkumar, Anima and Collins, William D. and Pritchard, Michael S. and Keller, Alexander",2025,,http://arxiv.org/abs/2507.12144,10.48550/arXiv.2507.12144,
CRPS-LAM: Regional ensemble weather forecasting from matching marginals,http://arxiv.org/abs/2510.09484v1,FGNalet2025skillfuljointprobabilisticweather,\cite{FGNalet2025skillfuljointprobabilisticweather},Skillful joint probabilistic weather forecasting from marginals,http://arxiv.org/abs/2506.10772v1,"Machine learning (ML)-based weather models have rapidly risen to prominence
due to their greater accuracy and speed than traditional forecasts based on
numerical weather prediction (NWP), recently outperforming traditional
ensembles in global probabilistic weather forecasting. This paper presents FGN,
a simple, scalable and flexible modeling approach which significantly
outperforms the current state-of-the-art models. FGN generates ensembles via
learned model-perturbations with an ensemble of appropriately constrained
models. It is trained directly to minimize the continuous rank probability
score (CRPS) of per-location forecasts. It produces state-of-the-art ensemble
forecasts as measured by a range of deterministic and probabilistic metrics,
makes skillful ensemble tropical cyclone track predictions, and captures joint
spatial structure despite being trained only on marginals.",Ferran Alet and Ilan Price and Andrew El-Kadi and Dominic Masters and Stratis Markou and Tom R. Andersson and Jacklynn Stott and Remi Lam and Matthew Willson and Alvaro Sanchez-Gonzalez and Peter Battaglia,2025,,https://arxiv.org/abs/2506.10772,,
CRPS-LAM: Regional ensemble weather forecasting from matching marginals,http://arxiv.org/abs/2510.09484v1,oskarsson2024probabilistic,\cite{oskarsson2024probabilistic},"Probabilistic Weather Forecasting with Hierarchical Graph Neural
  Networks",http://arxiv.org/abs/2406.04759v2,"In recent years, machine learning has established itself as a powerful tool
for high-resolution weather forecasting. While most current machine learning
models focus on deterministic forecasts, accurately capturing the uncertainty
in the chaotic weather system calls for probabilistic modeling. We propose a
probabilistic weather forecasting model called Graph-EFM, combining a flexible
latent-variable formulation with the successful graph-based forecasting
framework. The use of a hierarchical graph construction allows for efficient
sampling of spatially coherent forecasts. Requiring only a single forward pass
per time step, Graph-EFM allows for fast generation of arbitrarily large
ensembles. We experiment with the model on both global and limited area
forecasting. Ensemble forecasts from Graph-EFM achieve equivalent or lower
errors than comparable deterministic models, with the added benefit of
accurately capturing forecast uncertainty.","Oskarsson, Joel and Landelius, Tomas and Deisenroth, Marc Peter and Lindsten, Fredrik",2024,,,,
CRPS-LAM: Regional ensemble weather forecasting from matching marginals,http://arxiv.org/abs/2510.09484v1,stormCast,\cite{stormCast},"Kilometer-Scale Convection Allowing Model Emulation using Generative
  Diffusion Modeling",http://arxiv.org/abs/2408.10958v1,"Storm-scale convection-allowing models (CAMs) are an important tool for
predicting the evolution of thunderstorms and mesoscale convective systems that
result in damaging extreme weather. By explicitly resolving convective dynamics
within the atmosphere they afford meteorologists the nuance needed to provide
outlook on hazard. Deep learning models have thus far not proven skilful at
km-scale atmospheric simulation, despite being competitive at coarser
resolution with state-of-the-art global, medium-range weather forecasting. We
present a generative diffusion model called StormCast, which emulates the
high-resolution rapid refresh (HRRR) model-NOAA's state-of-the-art 3km
operational CAM. StormCast autoregressively predicts 99 state variables at km
scale using a 1-hour time step, with dense vertical resolution in the
atmospheric boundary layer, conditioned on 26 synoptic variables. We present
evidence of successfully learnt km-scale dynamics including competitive 1-6
hour forecast skill for composite radar reflectivity alongside physically
realistic convective cluster evolution, moist updrafts, and cold pool
morphology. StormCast predictions maintain realistic power spectra for multiple
predicted variables across multi-hour forecasts. Together, these results
establish the potential for autoregressive ML to emulate CAMs -- opening up new
km-scale frontiers for regional ML weather prediction and future climate hazard
dynamical downscaling.",Jaideep Pathak and Yair Cohen and Piyush Garg and Peter Harrington and Noah Brenowitz and Dale Durran and Morteza Mardani and Arash Vahdat and Shaoming Xu and Karthik Kashinath and Michael Pritchard,2024,,https://arxiv.org/abs/2408.10958,,
CRPS-LAM: Regional ensemble weather forecasting from matching marginals,http://arxiv.org/abs/2510.09484v1,larsson2025diffusionlam,\cite{larsson2025diffusionlam},Diffusion-LAM: Probabilistic Limited Area Weather Forecasting with Diffusion,,,"Larsson, Erik and Oskarsson, Joel and Landelius, Tomas and Lindsten, Fredrik",2025,,https://www.climatechange.ai/papers/iclr2025/36,,
CRPS-LAM: Regional ensemble weather forecasting from matching marginals,http://arxiv.org/abs/2510.09484v1,hrrrcast,\cite{hrrrcast},"HRRRCast: a data-driven emulator for regional weather forecasting at
  convection allowing scales",http://arxiv.org/abs/2507.05658v1,"The High-Resolution Rapid Refresh (HRRR) model is a convection-allowing model
used in operational weather forecasting across the contiguous United States
(CONUS). To provide a computationally efficient alternative, we introduce
HRRRCast, a data-driven emulator built with advanced machine learning
techniques. HRRRCast includes two architectures: a ResNet-based model (ResHRRR)
and a Graph Neural Network-based model (GraphHRRR). ResHRRR uses convolutional
neural networks enhanced with squeeze-and-excitation blocks and Feature-wise
Linear Modulation, and supports probabilistic forecasting via the Denoising
Diffusion Implicit Model (DDIM). To better handle longer lead times, we train a
single model to predict multiple lead times (1h, 3h, and 6h), then use a greedy
rollout strategy during inference. When evaluated on composite reflectivity
over the full CONUS domain using ensembles of 3 to 10 members, ResHRRR
outperforms HRRR forecast at light rainfall threshold (20 dBZ) and achieves
competitive performance at moderate thresholds (30 dBZ). Our work advances the
StormCast model of Pathak et al. [21] by: a) training on the full CONUS domain,
b) using multiple lead times to improve long-range skill, c) training on
analysis data instead of the +1h post-analysis data inadvertently used in
StormCast, and d) incorporating future GFS states as inputs, enabling
downscaling that improves long-lead accuracy. Grid-, neighborhood-, and
object-based metrics confirm better storm placement, lower frequency bias, and
higher success ratios than HRRR. HRRRCast ensemble forecasts also maintain
sharper spatial detail, with power spectra more closely matching HRRR analysis.
While GraphHRRR underperforms in its current form, it lays groundwork for
future graph-based forecasting. HRRRCast represents a step toward efficient,
data-driven regional weather prediction with competitive accuracy and ensemble
capability.","Abdi, Daniel and Jankov, Isidora and Madden, Paul and Vargas, Vanderlei and Smith, Timothy A and Frolov, Sergey and Flora, Montgomery and Potvin, Corey",2025,,,,arXiv preprint arXiv:2507.05658
CRPS-LAM: Regional ensemble weather forecasting from matching marginals,http://arxiv.org/abs/2510.09484v1,oskarsson2023graph-lam,\cite{oskarsson2023graph-lam},Graph-based Neural Weather Prediction for Limited Area Modeling,http://arxiv.org/abs/2309.17370v2,"The rise of accurate machine learning methods for weather forecasting is
creating radical new possibilities for modeling the atmosphere. In the time of
climate change, having access to high-resolution forecasts from models like
these is also becoming increasingly vital. While most existing Neural Weather
Prediction (NeurWP) methods focus on global forecasting, an important question
is how these techniques can be applied to limited area modeling. In this work
we adapt the graph-based NeurWP approach to the limited area setting and
propose a multi-scale hierarchical model extension. Our approach is validated
by experiments with a local model for the Nordic region.","Oskarsson, Joel and Landelius, Tomas and Lindsten, Fredrik",2023,,,,
