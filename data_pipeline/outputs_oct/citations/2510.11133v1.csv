parent_paper_title,parent_arxiv_link,citation_shorthand,raw_citation_text,cited_paper_title,cited_paper_arxiv_link,cited_paper_abstract,bib_paper_authors,bib_paper_year,bib_paper_month,bib_paper_url,bib_paper_doi,bib_paper_journal
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,foa,\cite{foa},Test-Time Model Adaptation with Only Forward Passes,,,Shuaicheng Niu and Chunyan Miao and Guohao Chen and Pengcheng Wu and Peilin Zhao,2024,,https://openreview.net/forum?id=qz1Vx1v9iK,,
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,bn_adapt,\cite{bn_adapt},"Improving robustness against common corruptions by covariate shift
  adaptation",http://arxiv.org/abs/2006.16971v2,"Today's state-of-the-art machine vision models are vulnerable to image
corruptions like blurring or compression artefacts, limiting their performance
in many real-world applications. We here argue that popular benchmarks to
measure model robustness against common corruptions (like ImageNet-C)
underestimate model robustness in many (but not all) application scenarios. The
key insight is that in many scenarios, multiple unlabeled examples of the
corruptions are available and can be used for unsupervised online adaptation.
Replacing the activation statistics estimated by batch normalization on the
training set with the statistics of the corrupted images consistently improves
the robustness across 25 different popular computer vision models. Using the
corrected statistics, ResNet-50 reaches 62.2% mCE on ImageNet-C compared to
76.7% without adaptation. With the more robust DeepAugment+AugMix model, we
improve the state of the art achieved by a ResNet50 model up to date from 53.6%
mCE to 45.4% mCE. Even adapting to a single sample improves robustness for the
ResNet-50 and AugMix models, and 32 samples are sufficient to improve the
current state of the art for a ResNet-50 architecture. We argue that results
with adapted statistics should be included whenever reporting scores in
corruption benchmarks and other out-of-distribution generalization settings.","Schneider, Steffen and Rusak, Evgenia and Eck, Luisa and Bringmann, Oliver and Brendel, Wieland and Bethge, Matthias",2020,,,,
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,t3a,\cite{t3a},Test-Time Classifier Adjustment Module for Model-Agnostic Domain Generalization,,,"Iwasawa, Yusuke and Matsuo, Yutaka",2021,,https://proceedings.neurips.cc/paper_files/paper/2021/file/1415fe9fea0fa1e45dddcff5682239a0-Paper.pdf,,
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,adanpc,\cite{adanpc},AdaNPC: Exploring Non-Parametric Classifier for Test-Time Adaptation,http://arxiv.org/abs/2304.12566v2,"Many recent machine learning tasks focus to develop models that can
generalize to unseen distributions. Domain generalization (DG) has become one
of the key topics in various fields. Several literatures show that DG can be
arbitrarily hard without exploiting target domain information. To address this
issue, test-time adaptive (TTA) methods are proposed. Existing TTA methods
require offline target data or extra sophisticated optimization procedures
during the inference stage. In this work, we adopt Non-Parametric Classifier to
perform the test-time Adaptation (AdaNPC). In particular, we construct a memory
that contains the feature and label pairs from training domains. During
inference, given a test instance, AdaNPC first recalls K closed samples from
the memory to vote for the prediction, and then the test feature and predicted
label are added to the memory. In this way, the sample distribution in the
memory can be gradually changed from the training distribution towards the test
distribution with very little extra computation cost. We theoretically justify
the rationality behind the proposed method. Besides, we test our model on
extensive numerical experiments. AdaNPC significantly outperforms competitive
baselines on various DG benchmarks. In particular, when the adaptation target
is a series of domains, the adaptation accuracy of AdaNPC is 50% higher than
advanced TTA methods. The code is available at
https://github.com/yfzhang114/AdaNPC.","Zhang, Yifan and Wang, Xue and Jin, Kexin and Yuan, Kun and Zhang, Zhang and Wang, Liang and Jin, Rong and Tan, Tieniu",2023,,,,
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,lame,\cite{lame},Parameter-free Online Test-time Adaptation,http://arxiv.org/abs/2201.05718v2,"Training state-of-the-art vision models has become prohibitively expensive
for researchers and practitioners. For the sake of accessibility and resource
reuse, it is important to focus on adapting these models to a variety of
downstream scenarios. An interesting and practical paradigm is online test-time
adaptation, according to which training data is inaccessible, no labelled data
from the test distribution is available, and adaptation can only happen at test
time and on a handful of samples. In this paper, we investigate how test-time
adaptation methods fare for a number of pre-trained models on a variety of
real-world scenarios, significantly extending the way they have been originally
evaluated. We show that they perform well only in narrowly-defined experimental
setups and sometimes fail catastrophically when their hyperparameters are not
selected for the same scenario in which they are being tested. Motivated by the
inherent uncertainty around the conditions that will ultimately be encountered
at test time, we propose a particularly ""conservative"" approach, which
addresses the problem with a Laplacian Adjusted Maximum-likelihood Estimation
(LAME) objective. By adapting the model's output (not its parameters), and
solving our objective with an efficient concave-convex procedure, our approach
exhibits a much higher average accuracy across scenarios than existing methods,
while being notably faster and have a much lower memory footprint. The code is
available at https://github.com/fiveai/LAME.","Boudiaf, Malik and Mueller, Romain and Ben Ayed, Ismail and Bertinetto, Luca",2022,,,,
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,sotta,\cite{sotta},So{TTA}: Robust Test-Time Adaptation on Noisy Data Streams,,,Taesik Gong and Yewon Kim and Taeckyung Lee and Sorn Chottananurak and Sung-Ju Lee,2023,,https://openreview.net/forum?id=3bdXag2rUd,,
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,eata,\cite{eata},Efficient Test-Time Model Adaptation without Forgetting,http://arxiv.org/abs/2204.02610v2,"Test-time adaptation (TTA) seeks to tackle potential distribution shifts
between training and testing data by adapting a given model w.r.t. any testing
sample. This task is particularly important for deep models when the test
environment changes frequently. Although some recent attempts have been made to
handle this task, we still face two practical challenges: 1) existing methods
have to perform backward computation for each test sample, resulting in
unbearable prediction cost to many applications; 2) while existing TTA
solutions can significantly improve the test performance on out-of-distribution
data, they often suffer from severe performance degradation on in-distribution
data after TTA (known as catastrophic forgetting). In this paper, we point out
that not all the test samples contribute equally to model adaptation, and
high-entropy ones may lead to noisy gradients that could disrupt the model.
Motivated by this, we propose an active sample selection criterion to identify
reliable and non-redundant samples, on which the model is updated to minimize
the entropy loss for test-time adaptation. Furthermore, to alleviate the
forgetting issue, we introduce a Fisher regularizer to constrain important
model parameters from drastic changes, where the Fisher importance is estimated
from test samples with generated pseudo labels. Extensive experiments on
CIFAR-10-C, ImageNet-C, and ImageNet-R verify the effectiveness of our proposed
method.","Niu, Shuaicheng and Wu, Jiaxiang and Zhang, Yifan and Chen, Yaofo and Zheng, Shijian and Zhao, Peilin and Tan, Mingkui",2022,,https://proceedings.mlr.press/v162/niu22a.html,,
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,sar,\cite{sar},Towards Stable Test-Time Adaptation in Dynamic Wild World,http://arxiv.org/abs/2302.12400v1,"Test-time adaptation (TTA) has shown to be effective at tackling distribution
shifts between training and testing data by adapting a given model on test
samples. However, the online model updating of TTA may be unstable and this is
often a key obstacle preventing existing TTA methods from being deployed in the
real world. Specifically, TTA may fail to improve or even harm the model
performance when test data have: 1) mixed distribution shifts, 2) small batch
sizes, and 3) online imbalanced label distribution shifts, which are quite
common in practice. In this paper, we investigate the unstable reasons and find
that the batch norm layer is a crucial factor hindering TTA stability.
Conversely, TTA can perform more stably with batch-agnostic norm layers, \ie,
group or layer norm. However, we observe that TTA with group and layer norms
does not always succeed and still suffers many failure cases. By digging into
the failure cases, we find that certain noisy test samples with large gradients
may disturb the model adaption and result in collapsed trivial solutions, \ie,
assigning the same class label for all samples. To address the above collapse
issue, we propose a sharpness-aware and reliable entropy minimization method,
called SAR, for further stabilizing TTA from two aspects: 1) remove partial
noisy samples with large gradients, 2) encourage model weights to go to a flat
minimum so that the model is robust to the remaining noisy samples. Promising
results demonstrate that SAR performs more stably over prior methods and is
computationally efficient under the above wild test scenarios.",Shuaicheng Niu and Jiaxiang Wu and Yifan Zhang and Zhiquan Wen and Yaofo Chen and Peilin Zhao and Mingkui Tan,2023,,https://openreview.net/forum?id=g2YraF75Tj,,
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,tent,\cite{tent},Tent: Fully Test-time Adaptation by Entropy Minimization,http://arxiv.org/abs/2006.10726v3,"A model must adapt itself to generalize to new and different data during
testing. In this setting of fully test-time adaptation the model has only the
test data and its own parameters. We propose to adapt by test entropy
minimization (tent): we optimize the model for confidence as measured by the
entropy of its predictions. Our method estimates normalization statistics and
optimizes channel-wise affine transformations to update online on each batch.
Tent reduces generalization error for image classification on corrupted
ImageNet and CIFAR-10/100 and reaches a new state-of-the-art error on
ImageNet-C. Tent handles source-free domain adaptation on digit recognition
from SVHN to MNIST/MNIST-M/USPS, on semantic segmentation from GTA to
Cityscapes, and on the VisDA-C benchmark. These results are achieved in one
epoch of test-time optimization without altering training.",Dequan Wang and Evan Shelhamer and Shaoteng Liu and Bruno Olshausen and Trevor Darrell,2021,,https://openreview.net/forum?id=uXl3bZLkr3c,,
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,pasle,\cite{pasle},Selective Label Enhancement Learning for Test-Time Adaptation,,,Yihao Hu and Congyu Qiao and Xin Geng and Ning Xu,2025,,https://openreview.net/forum?id=3Z2flzXzBY,,
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,crkd,\cite{crkd},Leveraging Proxy of Training Data for Test-Time Adaptation,,,"Kang, Juwon and Kim, Nayeong and Kwon, Donghyeon and Ok, Jungseul and Kwak, Suha",2023,,https://proceedings.mlr.press/v202/kang23a.html,,
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,program,\cite{program},{PROGRAM}: {PRO}totype {GRA}ph Model based Pseudo-Label Learning for Test-Time Adaptation,,,Haopeng Sun and Lumin Xu and Sheng Jin and Ping Luo and Chen Qian and Wentao Liu,2024,,https://openreview.net/forum?id=x5LvBK43wg,,
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,cotta,\cite{cotta},Continual Test-Time Domain Adaptation,http://arxiv.org/abs/2203.13591v1,"Test-time domain adaptation aims to adapt a source pre-trained model to a
target domain without using any source data. Existing works mainly consider the
case where the target domain is static. However, real-world machine perception
systems are running in non-stationary and continually changing environments
where the target domain distribution can change over time. Existing methods,
which are mostly based on self-training and entropy regularization, can suffer
from these non-stationary environments. Due to the distribution shift over time
in the target domain, pseudo-labels become unreliable. The noisy pseudo-labels
can further lead to error accumulation and catastrophic forgetting. To tackle
these issues, we propose a continual test-time adaptation approach~(CoTTA)
which comprises two parts. Firstly, we propose to reduce the error accumulation
by using weight-averaged and augmentation-averaged predictions which are often
more accurate. On the other hand, to avoid catastrophic forgetting, we propose
to stochastically restore a small part of the neurons to the source pre-trained
weights during each iteration to help preserve source knowledge in the
long-term. The proposed method enables the long-term adaptation for all
parameters in the network. CoTTA is easy to implement and can be readily
incorporated in off-the-shelf pre-trained models. We demonstrate the
effectiveness of our approach on four classification tasks and a segmentation
task for continual test-time adaptation, on which we outperform existing
methods. Our code is available at \url{https://qin.ee/cotta}.","Wang, Qin and Fink, Olga and Van Gool, Luc and Dai, Dengxin",2022,,,,
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,adacontrast,\cite{adacontrast},Contrastive Test-Time Adaptation,http://arxiv.org/abs/2204.10377v1,"Test-time adaptation is a special setting of unsupervised domain adaptation
where a trained model on the source domain has to adapt to the target domain
without accessing source data. We propose a novel way to leverage
self-supervised contrastive learning to facilitate target feature learning,
along with an online pseudo labeling scheme with refinement that significantly
denoises pseudo labels. The contrastive learning task is applied jointly with
pseudo labeling, contrasting positive and negative pairs constructed similarly
as MoCo but with source-initialized encoder, and excluding same-class negative
pairs indicated by pseudo labels. Meanwhile, we produce pseudo labels online
and refine them via soft voting among their nearest neighbors in the target
feature space, enabled by maintaining a memory queue. Our method, AdaContrast,
achieves state-of-the-art performance on major benchmarks while having several
desirable properties compared to existing works, including memory efficiency,
insensitivity to hyper-parameters, and better model calibration. Project page:
sites.google.com/view/adacontrast.","Chen, Dian and Wang, Dequan and Darrell, Trevor and Ebrahimi, Sayna",2022,,,,
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,shot,\cite{shot},"Do We Really Need to Access the Source Data? Source Hypothesis Transfer
  for Unsupervised Domain Adaptation",http://arxiv.org/abs/2002.08546v6,"Unsupervised domain adaptation (UDA) aims to leverage the knowledge learned
from a labeled source dataset to solve similar tasks in a new unlabeled domain.
Prior UDA methods typically require to access the source data when learning to
adapt the model, making them risky and inefficient for decentralized private
data. This work tackles a practical setting where only a trained source model
is available and investigates how we can effectively utilize such a model
without source data to solve UDA problems. We propose a simple yet generic
representation learning framework, named \emph{Source HypOthesis Transfer}
(SHOT). SHOT freezes the classifier module (hypothesis) of the source model and
learns the target-specific feature extraction module by exploiting both
information maximization and self-supervised pseudo-labeling to implicitly
align representations from the target domains to the source hypothesis. To
verify its versatility, we evaluate SHOT in a variety of adaptation cases
including closed-set, partial-set, and open-set domain adaptation. Experiments
indicate that SHOT yields state-of-the-art results among multiple domain
adaptation benchmarks.","Liang, Jian and Hu, Dapeng and Feng, Jiashi",2020,,https://proceedings.mlr.press/v119/liang20a.html,,
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,tsd,\cite{tsd},Feature Alignment and Uniformity for Test Time Adaptation,http://arxiv.org/abs/2303.10902v3,"Test time adaptation (TTA) aims to adapt deep neural networks when receiving
out of distribution test domain samples. In this setting, the model can only
access online unlabeled test samples and pre-trained models on the training
domains. We first address TTA as a feature revision problem due to the domain
gap between source domains and target domains. After that, we follow the two
measurements alignment and uniformity to discuss the test time feature
revision. For test time feature uniformity, we propose a test time
self-distillation strategy to guarantee the consistency of uniformity between
representations of the current batch and all the previous batches. For test
time feature alignment, we propose a memorized spatial local clustering
strategy to align the representations among the neighborhood samples for the
upcoming batch. To deal with the common noisy label problem, we propound the
entropy and consistency filters to select and drop the possible noisy labels.
To prove the scalability and efficacy of our method, we conduct experiments on
four domain generalization benchmarks and four medical image segmentation tasks
with various backbones. Experiment results show that our method not only
improves baseline stably but also outperforms existing state-of-the-art test
time adaptation methods. Code is available at
\href{https://github.com/SakurajimaMaiii/TSD}{https://github.com/SakurajimaMaiii/TSD}.","Wang, Shuai and Zhang, Daoan and Yan, Zipei and Zhang, Jianguo and Li, Rui",2023,,,,
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,cafa,\cite{cafa},CAFA: Class-Aware Feature Alignment for Test-Time Adaptation,http://arxiv.org/abs/2206.00205v3,"Despite recent advancements in deep learning, deep neural networks continue
to suffer from performance degradation when applied to new data that differs
from training data. Test-time adaptation (TTA) aims to address this challenge
by adapting a model to unlabeled data at test time. TTA can be applied to
pretrained networks without modifying their training procedures, enabling them
to utilize a well-formed source distribution for adaptation. One possible
approach is to align the representation space of test samples to the source
distribution (\textit{i.e.,} feature alignment). However, performing feature
alignment in TTA is especially challenging in that access to labeled source
data is restricted during adaptation. That is, a model does not have a chance
to learn test data in a class-discriminative manner, which was feasible in
other adaptation tasks (\textit{e.g.,} unsupervised domain adaptation) via
supervised losses on the source data. Based on this observation, we propose a
simple yet effective feature alignment loss, termed as Class-Aware Feature
Alignment (CAFA), which simultaneously 1) encourages a model to learn target
representations in a class-discriminative manner and 2) effectively mitigates
the distribution shifts at test time. Our method does not require any
hyper-parameters or additional losses, which are required in previous
approaches. We conduct extensive experiments on 6 different datasets and show
our proposed method consistently outperforms existing baselines.","Jung, Sanghun and Lee, Jungsoo and Kim, Nanhee and Shaban, Amirreza and Boots, Byron and Choo, Jaegul",2023,,,,
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,AdaRealign,\cite{AdaRealign},Test-time Adaptation in Non-stationary Environments via Adaptive Representation Alignment,,,"Zhang, Zhen-Yu and Xie, Zhiyu and Yao, Huaxiu and Sugiyama, Masashi",2024,,https://proceedings.neurips.cc/paper_files/paper/2024/file/abe31a12e83111fdf2cfd54deed5a2ce-Paper-Conference.pdf,,
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,tipi,\cite{tipi},TIPI: Test Time Adaptation With Transformation Invariance,,,"Nguyen, A. Tuan and Nguyen-Tang, Thanh and Lim, Ser-Nam and Torr, Philip H.S.",2023,June,,,
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,memo,\cite{memo},MEMO: Test Time Robustness via Adaptation and Augmentation,http://arxiv.org/abs/2110.09506v3,"While deep neural networks can attain good accuracy on in-distribution test
points, many applications require robustness even in the face of unexpected
perturbations in the input, changes in the domain, or other sources of
distribution shift. We study the problem of test time robustification, i.e.,
using the test input to improve model robustness. Recent prior works have
proposed methods for test time adaptation, however, they each introduce
additional assumptions, such as access to multiple test points, that prevent
widespread adoption. In this work, we aim to study and devise methods that make
no assumptions about the model training process and are broadly applicable at
test time. We propose a simple approach that can be used in any test setting
where the model is probabilistic and adaptable: when presented with a test
example, perform different data augmentations on the data point, and then adapt
(all of) the model parameters by minimizing the entropy of the model's average,
or marginal, output distribution across the augmentations. Intuitively, this
objective encourages the model to make the same prediction across different
augmentations, thus enforcing the invariances encoded in these augmentations,
while also maintaining confidence in its predictions. In our experiments, we
evaluate two baseline ResNet models, two robust ResNet-50 models, and a robust
vision transformer model, and we demonstrate that this approach achieves
accuracy gains of 1-8\% over standard model evaluation and also generally
outperforms prior augmentation and adaptation strategies. For the setting in
which only one test point is available, we achieve state-of-the-art results on
the ImageNet-C, ImageNet-R, and, among ResNet-50 models, ImageNet-A
distribution shift benchmarks.","Zhang, Marvin and Levine, Sergey and Finn, Chelsea",2022,,,,
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,deyo,\cite{deyo},"Entropy is not Enough for Test-Time Adaptation: From the Perspective of
  Disentangled Factors",http://arxiv.org/abs/2403.07366v1,"Test-time adaptation (TTA) fine-tunes pre-trained deep neural networks for
unseen test data. The primary challenge of TTA is limited access to the entire
test dataset during online updates, causing error accumulation. To mitigate it,
TTA methods have utilized the model output's entropy as a confidence metric
that aims to determine which samples have a lower likelihood of causing error.
Through experimental studies, however, we observed the unreliability of entropy
as a confidence metric for TTA under biased scenarios and theoretically
revealed that it stems from the neglect of the influence of latent disentangled
factors of data on predictions. Building upon these findings, we introduce a
novel TTA method named Destroy Your Object (DeYO), which leverages a newly
proposed confidence metric named Pseudo-Label Probability Difference (PLPD).
PLPD quantifies the influence of the shape of an object on prediction by
measuring the difference between predictions before and after applying an
object-destructive transformation. DeYO consists of sample selection and sample
weighting, which employ entropy and PLPD concurrently. For robust adaptation,
DeYO prioritizes samples that dominantly incorporate shape information when
making predictions. Our extensive experiments demonstrate the consistent
superiority of DeYO over baseline methods across various scenarios, including
biased and wild. Project page is publicly available at
https://whitesnowdrop.github.io/DeYO/.",Jonghyun Lee and Dahuin Jung and Saehyung Lee and Junsung Park and Juhyeon Shin and Uiwon Hwang and Sungroh Yoon,2024,,https://openreview.net/forum?id=9w3iw8wDuE,,
Test-Time Adaptation by Causal Trimming,http://arxiv.org/abs/2510.11133v1,tast,\cite{tast},Test-Time Adaptation via Self-Training with Nearest Neighbor Information,http://arxiv.org/abs/2207.10792v2,"Test-time adaptation (TTA) aims to adapt a trained classifier using online
unlabeled test data only, without any information related to the training
procedure. Most existing TTA methods adapt the trained classifier using the
classifier's prediction on the test data as pseudo-label. However, under
test-time domain shift, accuracy of the pseudo labels cannot be guaranteed, and
thus the TTA methods often encounter performance degradation at the adapted
classifier. To overcome this limitation, we propose a novel test-time
adaptation method, called Test-time Adaptation via Self-Training with nearest
neighbor information (TAST), which is composed of the following procedures: (1)
adds trainable adaptation modules on top of the trained feature extractor; (2)
newly defines a pseudo-label distribution for the test data by using the
nearest neighbor information; (3) trains these modules only a few times during
test time to match the nearest neighbor-based pseudo label distribution and a
prototype-based class distribution for the test data; and (4) predicts the
label of test data using the average predicted class distribution from these
modules. The pseudo-label generation is based on the basic intuition that a
test data and its nearest neighbor in the embedding space are likely to share
the same label under the domain shift. By utilizing multiple randomly
initialized adaptation modules, TAST extracts useful information for the
classification of the test data under the domain shift, using the nearest
neighbor information. TAST showed better performance than the state-of-the-art
TTA methods on two standard benchmark tasks, domain generalization, namely
VLCS, PACS, OfficeHome, and TerraIncognita, and image corruption, particularly
CIFAR-10/100C.",Minguk Jang and Sae-Young Chung and Hye Won Chung,2023,,https://openreview.net/forum?id=EzLtB4M1SbM,,
