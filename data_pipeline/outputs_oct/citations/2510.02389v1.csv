parent_paper_title,parent_arxiv_link,citation_shorthand,raw_citation_text,cited_paper_title,cited_paper_arxiv_link,cited_paper_abstract,bib_paper_authors,bib_paper_year,bib_paper_month,bib_paper_url,bib_paper_doi,bib_paper_journal
From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization,http://arxiv.org/abs/2510.02389v1,yang2024large,\cite{yang2024large},Large language models for test-free fault localization,,,"Yang, Aidan ZH and Le Goues, Claire and Martins, Ruben and Hellendoorn, Vincent",2024,,,,
From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization,http://arxiv.org/abs/2510.02389v1,stein2025s,\cite{stein2025s},Where's the Bug? Attention Probing for Scalable Fault Localization,http://arxiv.org/abs/2502.13966v2,"Ensuring code correctness remains a challenging problem even as large
language models (LLMs) become increasingly capable at code-related tasks. While
LLM-based program repair systems can propose bug fixes using only a user's bug
report, their effectiveness is fundamentally limited by their ability to
perform fault localization (FL), a challenging problem for both humans and
LLMs. Existing FL approaches rely on executable test cases, require training on
costly and often noisy line-level annotations, or demand resource-intensive
LLMs. In this paper, we present Bug Attention Probe (BAP), a method which
learns state-of-the-art fault localization without any direct localization
labels, outperforming traditional FL baselines and prompting of large-scale
LLMs. We evaluate our approach across a variety of code settings, including
real-world Java bugs from the standard Defects4J dataset as well as seven other
datasets which span a diverse set of bug types and languages. Averaged across
all eight datasets, BAP improves by 34.6% top-1 accuracy compared to the
strongest baseline and 93.4% over zero-shot prompting GPT-4o. BAP is also
significantly more efficient than prompting, outperforming large open-weight
models at a small fraction of the computational cost.","Stein, Adam and Wayne, Arthur and Naik, Aaditya and Naik, Mayur and Wong, Eric",2025,,,,arXiv preprint arXiv:2502.13966
From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization,http://arxiv.org/abs/2510.02389v1,zhou2019devign,\cite{zhou2019devign},"Devign: Effective Vulnerability Identification by Learning Comprehensive
  Program Semantics via Graph Neural Networks",http://arxiv.org/abs/1909.03496v1,"Vulnerability identification is crucial to protect the software systems from
attacks for cyber security. It is especially important to localize the
vulnerable functions among the source code to facilitate the fix. However, it
is a challenging and tedious process, and also requires specialized security
expertise. Inspired by the work on manually-defined patterns of vulnerabilities
from various code representation graphs and the recent advance on graph neural
networks, we propose Devign, a general graph neural network based model for
graph-level classification through learning on a rich set of code semantic
representations. It includes a novel Conv module to efficiently extract useful
features in the learned rich node representations for graph-level
classification. The model is trained over manually labeled datasets built on 4
diversified large-scale open-source C projects that incorporate high complexity
and variety of real source code instead of synthesis code used in previous
works. The results of the extensive evaluation on the datasets demonstrate that
Devign outperforms the state of the arts significantly with an average of
10.51% higher accuracy and 8.68\% F1 score, increases averagely 4.66% accuracy
and 6.37% F1 by the Conv module.","Zhou, Yaqin and Liu, Shangqing and Siow, Jingkai and Du, Xiaoning and Liu, Yang",2019,,,,Advances in neural information processing systems
From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization,http://arxiv.org/abs/2510.02389v1,croft2023data,\cite{croft2023data},Data Quality for Software Vulnerability Datasets,http://arxiv.org/abs/2301.05456v1,"The use of learning-based techniques to achieve automated software
vulnerability detection has been of longstanding interest within the software
security domain. These data-driven solutions are enabled by large software
vulnerability datasets used for training and benchmarking. However, we observe
that the quality of the data powering these solutions is currently
ill-considered, hindering the reliability and value of produced outcomes.
Whilst awareness of software vulnerability data preparation challenges is
growing, there has been little investigation into the potential negative
impacts of software vulnerability data quality. For instance, we lack
confirmation that vulnerability labels are correct or consistent. Our study
seeks to address such shortcomings by inspecting five inherent data quality
attributes for four state-of-the-art software vulnerability datasets and the
subsequent impacts that issues can have on software vulnerability prediction
models. Surprisingly, we found that all the analyzed datasets exhibit some data
quality problems. In particular, we found 20-71% of vulnerability labels to be
inaccurate in real-world datasets, and 17-99% of data points were duplicated.
We observed that these issues could cause significant impacts on downstream
models, either preventing effective model training or inflating benchmark
performance. We advocate for the need to overcome such challenges. Our findings
will enable better consideration and assessment of software vulnerability data
quality in the future.","Croft, Roland and Babar, M Ali and Kholoosi, M Mehdi",2023,,,,
From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization,http://arxiv.org/abs/2510.02389v1,asad2025leveraging,\cite{asad2025leveraging},Leveraging Large Language Model for Information Retrieval-based Bug Localization,,,"Asad, Moumita and Yasir, Rafed Muhammad and Geramirad, Armin and Malek, Sam",2025,,,,arXiv preprint arXiv:2508.00253
From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization,http://arxiv.org/abs/2510.02389v1,qin2024agentfl,\cite{qin2024agentfl},AgentFL: Scaling LLM-based Fault Localization to Project-Level Context,http://arxiv.org/abs/2403.16362v2,"Fault Localization (FL) is an essential step during the debugging process.
With the strong capabilities of code comprehension, the recent Large Language
Models (LLMs) have demonstrated promising performance in diagnosing bugs in the
code. Nevertheless, due to LLMs' limited performance in handling long contexts,
existing LLM-based fault localization remains on localizing bugs within a small
code scope (i.e., a method or a class), which struggles to diagnose bugs for a
large code scope (i.e., an entire software system). To address the limitation,
this paper presents AgentFL, a multi-agent system based on ChatGPT for
automated fault localization. By simulating the behavior of a human developer,
AgentFL models the FL task as a three-step process, which involves
comprehension, navigation, and confirmation. Within each step, AgentFL hires
agents with diversified expertise, each of which utilizes different tools to
handle specific tasks. Particularly, we adopt a series of auxiliary strategies
such as Test Behavior Tracking, Document-Guided Search, and Multi-Round
Dialogue to overcome the challenges in each step. The evaluation on the widely
used Defects4J-V1.2.0 benchmark shows that AgentFL can localize 157 out of 395
bugs within Top-1, which outperforms the other LLM-based approaches and
exhibits complementarity to the state-of-the-art learning-based techniques.
Additionally, we confirm the indispensability of the components in AgentFL with
the ablation study and demonstrate the usability of AgentFL through a user
study. Finally, the cost analysis shows that AgentFL spends an average of only
0.074 dollars and 97 seconds for a single bug.","Qin, Yihao and Wang, Shangwen and Lou, Yiling and Dong, Jinhao and Wang, Kaixin and Li, Xiaoling and Mao, Xiaoguang",2024,,,,arXiv preprint arXiv:2403.16362
From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization,http://arxiv.org/abs/2510.02389v1,jiang2025cosil,\cite{jiang2025cosil},CoSIL: Software Issue Localization via LLM-Driven Code Repository Graph Searching,,,"Jiang, Zhonghao and Ren, Xiaoxue and Yan, Meng and Jiang, Wei and Li, Yong and Liu, Zhongxin",2025,,,,arXiv preprint arXiv:2503.22424
From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization,http://arxiv.org/abs/2510.02389v1,kang2024quantitative,\cite{kang2024quantitative},"A Quantitative and Qualitative Evaluation of LLM-Based Explainable Fault
  Localization",http://arxiv.org/abs/2308.05487v3,"Fault Localization (FL), in which a developer seeks to identify which part of
the code is malfunctioning and needs to be fixed, is a recurring challenge in
debugging. To reduce developer burden, many automated FL techniques have been
proposed. However, prior work has noted that existing techniques fail to
provide rationales for the suggested locations, hindering developer adoption of
these techniques. With this in mind, we propose AutoFL, a Large Language Model
(LLM)-based FL technique that generates an explanation of the bug along with a
suggested fault location. AutoFL prompts an LLM to use function calls to
navigate a repository, so that it can effectively localize faults over a large
software repository and overcome the limit of the LLM context length. Extensive
experiments on 798 real-world bugs in Java and Python reveal AutoFL improves
method-level acc@1 by up to 233.3% over baselines. Furthermore, developers were
interviewed on their impression of AutoFL-generated explanations, showing that
developers generally liked the natural language explanations of AutoFL, and
that they preferred reading a few, high-quality explanations instead of many.","Kang, Sungmin and An, Gabin and Yoo, Shin",2024,,,,Proceedings of the ACM on Software Engineering
From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization,http://arxiv.org/abs/2510.02389v1,9796256,\cite{9796256},LineVul: A Transformer-based Line-Level Vulnerability Prediction,,,"Fu, Michael and Tantithamthavorn, Chakkrit",2022,,,10.1145/3524842.3528452,
From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization,http://arxiv.org/abs/2510.02389v1,li2024attention,\cite{li2024attention},Attention is all you need for llm-based code vulnerability localization,,,"Li, Yue and Li, Xiao and Wu, Hao and Zhang, Yue and Cheng, Xiuzhen and Zhong, Sheng and Xu, Fengyuan",2024,,,,arXiv e-prints
From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization,http://arxiv.org/abs/2510.02389v1,10.1145/3671016.3674807,\cite{10.1145/3671016.3674807},MatsVD: Boosting Statement-Level Vulnerability Detection via Dependency-Based Attention,,,"Weng, Cheng and Qin, Yihao and Lin, Bo and Liu, Pei and Chen, Liqian",2024,,https://doi.org/10.1145/3671016.3674807,10.1145/3671016.3674807,
From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization,http://arxiv.org/abs/2510.02389v1,10.1145/3660804,\cite{10.1145/3660804},Learning to Detect and Localize Multilingual Bugs,,,"Yang, Haoran and Nong, Yu and Zhang, Tao and Luo, Xiapu and Cai, Haipeng",2024,,https://doi.org/10.1145/3660804,10.1145/3660804,Proc. ACM Softw. Eng.
From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization,http://arxiv.org/abs/2510.02389v1,rafi2024multi,\cite{rafi2024multi},"A Multi-Agent Approach to Fault Localization via Graph-Based Retrieval
  and Reflexion",http://arxiv.org/abs/2409.13642v2,"Identifying and resolving software faults remains a challenging and
resource-intensive process. Traditional fault localization techniques, such as
Spectrum-Based Fault Localization (SBFL), leverage statistical analysis of test
coverage but often suffer from limited accuracy. While learning-based
approaches improve fault localization, they demand extensive training datasets
and high computational resources. Recent advances in Large Language Models
(LLMs) offer new opportunities by enhancing code understanding and reasoning.
However, existing LLM-based fault localization techniques face significant
challenges, including token limitations, performance degradation with long
inputs, and scalability issues in complex software systems. To overcome these
obstacles, we propose LLM4FL, a multi-agent fault localization framework that
utilizes three specialized LLM agents. First, the Context Extraction Agent
applies an order-sensitive segmentation strategy to partition large coverage
data within the LLM's token limit, analyze failure context, and prioritize
failure-related methods. The Debugger Agent then processes the extracted data,
which employs graph-based retrieval-augmented code navigation to reason about
failure causes and rank suspicious methods. Finally, the Reviewer Agent
re-evaluates the identified faulty methods using verbal reinforcement learning,
engaging in self-criticism and iterative refinement. Evaluated on the Defects4J
(V2.0.0) benchmark, which includes 675 faults from 14 Java projects, LLM4FL
achieves an 18.55\% improvement in Top-1 accuracy over AutoFL and 4.82\% over
SoapFL. It outperforms supervised techniques such as DeepFL and Grace, all
without requiring task-specific training. Furthermore, its coverage
segmentation and prompt chaining strategies enhance performance, increasing
Top-1 accuracy by up to 22\%.","Rafi, Md Nakhla and Kim, Dong Jae and Chen, Tse-Hsun and Wang, Shaowei",2024,,,,arXiv preprint arXiv:2409.13642
From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization,http://arxiv.org/abs/2510.02389v1,yeo2025improving,\cite{yeo2025improving},"Improving LLM-Based Fault Localization with External Memory and Project
  Context",http://arxiv.org/abs/2506.03585v1,"Fault localization, the process of identifying the software components
responsible for failures, is essential but often time-consuming. Recent
advances in Large Language Models (LLMs) have enabled fault localization
without extensive defect datasets or model fine-tuning. However, existing
LLM-based methods rely only on general LLM capabilities and lack integration of
project-specific knowledge, resulting in limited effectiveness, especially for
complex software.
  We introduce MemFL, a novel approach that enhances LLM-based fault
localization by integrating project-specific knowledge via external memory.
This memory includes static summaries of the project and dynamic, iterative
debugging insights gathered from previous attempts. By leveraging external
memory, MemFL simplifies debugging into three streamlined steps, significantly
improving efficiency and accuracy. Iterative refinement through dynamic memory
further enhances reasoning quality over time.
  Evaluated on the Defects4J benchmark, MemFL using GPT-4o-mini localized 12.7%
more bugs than current LLM-based methods, achieving this improvement with just
21% of the execution time (17.4 seconds per bug) and 33% of the API cost
(0.0033 dollars per bug). On complex projects, MemFL's advantage increased to
27.6%. Additionally, MemFL with GPT-4.1-mini outperformed existing methods by
24.4%, requiring only 24.7 seconds and 0.0094 dollars per bug. MemFL thus
demonstrates significant improvements by effectively incorporating
project-specific knowledge into LLM-based fault localization, delivering high
accuracy with reduced time and cost.","Yeo, Inseok and Ryu, Duksan and Baik, Jongmoon",2025,,,,arXiv preprint arXiv:2506.03585
