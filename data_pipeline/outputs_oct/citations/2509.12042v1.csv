parent_paper_title,parent_arxiv_link,citation_shorthand,raw_citation_text,cited_paper_title,cited_paper_arxiv_link,cited_paper_abstract,bib_paper_authors,bib_paper_year,bib_paper_month,bib_paper_url,bib_paper_doi,bib_paper_journal
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,lewis2021retrievalaugmentedgenerationknowledgeintensivenlp,\cite{lewis2021retrievalaugmentedgenerationknowledgeintensivenlp},Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks,,,Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela,2021,,https://arxiv.org/abs/2005.11401,,
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,guu2020retrievalaugmented,\cite{guu2020retrievalaugmented},REALM: Retrieval-Augmented Language Model Pre-Training,http://arxiv.org/abs/2002.08909v1,"Language model pre-training has been shown to capture a surprising amount of
world knowledge, crucial for NLP tasks such as question answering. However,
this knowledge is stored implicitly in the parameters of a neural network,
requiring ever-larger networks to cover more facts.
  To capture knowledge in a more modular and interpretable way, we augment
language model pre-training with a latent knowledge retriever, which allows the
model to retrieve and attend over documents from a large corpus such as
Wikipedia, used during pre-training, fine-tuning and inference. For the first
time, we show how to pre-train such a knowledge retriever in an unsupervised
manner, using masked language modeling as the learning signal and
backpropagating through a retrieval step that considers millions of documents.
  We demonstrate the effectiveness of Retrieval-Augmented Language Model
pre-training (REALM) by fine-tuning on the challenging task of Open-domain
Question Answering (Open-QA). We compare against state-of-the-art models for
both explicit and implicit knowledge storage on three popular Open-QA
benchmarks, and find that we outperform all previous methods by a significant
margin (4-16% absolute accuracy), while also providing qualitative benefits
such as interpretability and modularity.","Guu, Kelvin and Lee, Kenton and Tung, Zora and Pasupat, Panupong and Chang, Ming-Wei",2020,,,,
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,ram2023,\cite{ram2023},In-Context Retrieval-Augmented Language Models,http://arxiv.org/abs/2302.00083v3,"Retrieval-Augmented Language Modeling (RALM) methods, which condition a
language model (LM) on relevant documents from a grounding corpus during
generation, were shown to significantly improve language modeling performance.
In addition, they can mitigate the problem of factually inaccurate text
generation and provide natural source attribution mechanism. Existing RALM
approaches focus on modifying the LM architecture in order to facilitate the
incorporation of external information, significantly complicating deployment.
This paper considers a simple alternative, which we dub In-Context RALM:
leaving the LM architecture unchanged and prepending grounding documents to the
input, without any further training of the LM. We show that In-Context RALM
that builds on off-the-shelf general purpose retrievers provides surprisingly
large LM gains across model sizes and diverse corpora. We also demonstrate that
the document retrieval and ranking mechanism can be specialized to the RALM
setting to further boost performance. We conclude that In-Context RALM has
considerable potential to increase the prevalence of LM grounding, particularly
in settings where a pretrained LM must be used without modification or even via
API access.",Ori Ram and Yoav Levine and Itay Dalmedigos and Dor Muhlgay and Amnon Shashua and Kevin Leyton-Brown and Yoav Shoham,2023,,https://arxiv.org/abs/2302.00083,,
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,selfrag2023,\cite{selfrag2023},"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection",,,Akari Asai and Zeqiu Wu and Yizhong Wang and Avirup Sil and Hannaneh Hajishirzi,2023,,https://arxiv.org/abs/2310.11511,,
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,adaptive2023,\cite{adaptive2023},Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity,,,Soyeong Jeong and Jinheon Baek and Sukmin Cho and Sung Ju Hwang and Jong C. Park,2024,,https://arxiv.org/abs/2403.14403,,
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,fan-etal-2019-eli5,\cite{fan-etal-2019-eli5},ELI5: Long Form Question Answering,http://arxiv.org/abs/1907.09190v1,"We introduce the first large-scale corpus for long-form question answering, a
task requiring elaborate and in-depth answers to open-ended questions. The
dataset comprises 270K threads from the Reddit forum ``Explain Like I'm Five''
(ELI5) where an online community provides answers to questions which are
comprehensible by five year olds. Compared to existing datasets, ELI5 comprises
diverse questions requiring multi-sentence answers. We provide a large set of
web documents to help answer the question. Automatic and human evaluations show
that an abstractive model trained with a multi-task objective outperforms
conventional Seq2Seq, language modeling, as well as a strong extractive
baseline. However, our best model is still far from human performance since
raters prefer gold responses in over 86% of cases, leaving ample opportunity
for future improvement.","Fan, Angela and Jernite, Yacine and Perez, Ethan and Grangier, David and Weston, Jason and Auli, Michael",2019,,https://aclanthology.org/P19-1346/,10.18653/v1/P19-1346,
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,dai2019transformerxlattentivelanguagemodels,\cite{dai2019transformerxlattentivelanguagemodels},Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context,,,"Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime and Le, Quoc V. and Salakhutdinov, Ruslan",2019,,https://arxiv.org/abs/1901.02860,,arXiv preprint arXiv:1901.02860
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,zhong2025mixofgranularityoptimizechunkinggranularity,\cite{zhong2025mixofgranularityoptimizechunkinggranularity},"Mix-of-Granularity: Optimize the Chunking Granularity for
  Retrieval-Augmented Generation",http://arxiv.org/abs/2406.00456v2,"Integrating information from various reference databases is a major challenge
for Retrieval-Augmented Generation (RAG) systems because each knowledge source
adopts a unique data structure and follows different conventions. Retrieving
from multiple knowledge sources with one fixed strategy usually leads to
under-exploitation of information. To mitigate this drawback, inspired by
Mix-of-Expert, we introduce Mix-of-Granularity (MoG), a method that dynamically
determines the optimal granularity of a knowledge source based on input queries
using a router. The router is efficiently trained with a newly proposed loss
function employing soft labels. We further extend MoG to MoG-Graph (MoGG),
where reference documents are pre-processed as graphs, enabling the retrieval
of distantly situated snippets. Experiments demonstrate that MoG and MoGG
effectively predict optimal granularity levels, significantly enhancing the
performance of the RAG system in downstream tasks. The code of both MoG and
MoGG are released in https://github.com/ZGChung/Mix-of-Granularity.","Zhong, Zijie and Liu, Hanwen and Cui, Xiaoya and Zhang, Xiaofan and Qin, Zengchang",2025,,https://arxiv.org/abs/2406.00456,,arXiv preprint arXiv:2406.00456
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,liu2023lostmiddlelanguagemodels,\cite{liu2023lostmiddlelanguagemodels},Lost in the Middle: How Language Models Use Long Contexts,http://arxiv.org/abs/2307.03172v3,"While recent language models have the ability to take long contexts as input,
relatively little is known about how well they use longer context. We analyze
the performance of language models on two tasks that require identifying
relevant information in their input contexts: multi-document question answering
and key-value retrieval. We find that performance can degrade significantly
when changing the position of relevant information, indicating that current
language models do not robustly make use of information in long input contexts.
In particular, we observe that performance is often highest when relevant
information occurs at the beginning or end of the input context, and
significantly degrades when models must access relevant information in the
middle of long contexts, even for explicitly long-context models. Our analysis
provides a better understanding of how language models use their input context
and provides new evaluation protocols for future long-context language models.","Liu, Nelson F. and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy",2023,,https://arxiv.org/abs/2307.03172,,arXiv preprint arXiv:2307.03172
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,raptor,\cite{raptor},RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval,http://arxiv.org/abs/2401.18059v1,"Retrieval-augmented language models can better adapt to changes in world
state and incorporate long-tail knowledge. However, most existing methods
retrieve only short contiguous chunks from a retrieval corpus, limiting
holistic understanding of the overall document context. We introduce the novel
approach of recursively embedding, clustering, and summarizing chunks of text,
constructing a tree with differing levels of summarization from the bottom up.
At inference time, our RAPTOR model retrieves from this tree, integrating
information across lengthy documents at different levels of abstraction.
Controlled experiments show that retrieval with recursive summaries offers
significant improvements over traditional retrieval-augmented LMs on several
tasks. On question-answering tasks that involve complex, multi-step reasoning,
we show state-of-the-art results; for example, by coupling RAPTOR retrieval
with the use of GPT-4, we can improve the best performance on the QuALITY
benchmark by 20% in absolute accuracy.","Sarthi, Parth and Abdullah, Salman and Tuli, Aditi and Khanna, Shubh and Goldie, Anna and Manning, Christopher D.",2024,,,,
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,chen2024hiqa,\cite{chen2024hiqa},HiQA: A Hierarchical Contextual Augmentation RAG for Multi-Documents QA,http://arxiv.org/abs/2402.01767v2,"Retrieval-augmented generation (RAG) has rapidly advanced the language model
field, particularly in question-answering (QA) systems. By integrating external
documents during the response generation phase, RAG significantly enhances the
accuracy and reliability of language models. This method elevates the quality
of responses and reduces the frequency of hallucinations, where the model
generates incorrect or misleading information. However, these methods exhibit
limited retrieval accuracy when faced with numerous indistinguishable
documents, presenting notable challenges in their practical application. In
response to these emerging challenges, we present HiQA, an advanced
multi-document question-answering (MDQA) framework that integrates cascading
metadata into content and a multi-route retrieval mechanism. We also release a
benchmark called MasQA to evaluate and research in MDQA. Finally, HiQA
demonstrates the state-of-the-art performance in multi-document environments.","Chen, Xinyue and Gao, Pengyu and Song, Jiangjiang and Tan, Xiaoyang",2024,,,,arXiv preprint arXiv:2402.01767
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,edge2024localglobalgraphrag,\cite{edge2024localglobalgraphrag},"From Local to Global: A Graph RAG Approach to Query-Focused
  Summarization",http://arxiv.org/abs/2404.16130v2,"The use of retrieval-augmented generation (RAG) to retrieve relevant
information from an external knowledge source enables large language models
(LLMs) to answer questions over private and/or previously unseen document
collections. However, RAG fails on global questions directed at an entire text
corpus, such as ""What are the main themes in the dataset?"", since this is
inherently a query-focused summarization (QFS) task, rather than an explicit
retrieval task. Prior QFS methods, meanwhile, do not scale to the quantities of
text indexed by typical RAG systems. To combine the strengths of these
contrasting methods, we propose GraphRAG, a graph-based approach to question
answering over private text corpora that scales with both the generality of
user questions and the quantity of source text. Our approach uses an LLM to
build a graph index in two stages: first, to derive an entity knowledge graph
from the source documents, then to pregenerate community summaries for all
groups of closely related entities. Given a question, each community summary is
used to generate a partial response, before all partial responses are again
summarized in a final response to the user. For a class of global sensemaking
questions over datasets in the 1 million token range, we show that GraphRAG
leads to substantial improvements over a conventional RAG baseline for both the
comprehensiveness and diversity of generated answers.",Darren Edge and Ha Trinh and Newman Cheng and Joshua Bradley and Alex Chao and Apurva Mody and Steven Truitt and Jonathan Larson,2024,,https://arxiv.org/abs/2404.16130,,
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,guo2024lightragsimplefastretrievalaugmented,\cite{guo2024lightragsimplefastretrievalaugmented},LightRAG: Simple and Fast Retrieval-Augmented Generation,http://arxiv.org/abs/2410.05779v3,"Retrieval-Augmented Generation (RAG) systems enhance large language models
(LLMs) by integrating external knowledge sources, enabling more accurate and
contextually relevant responses tailored to user needs. However, existing RAG
systems have significant limitations, including reliance on flat data
representations and inadequate contextual awareness, which can lead to
fragmented answers that fail to capture complex inter-dependencies. To address
these challenges, we propose LightRAG, which incorporates graph structures into
text indexing and retrieval processes. This innovative framework employs a
dual-level retrieval system that enhances comprehensive information retrieval
from both low-level and high-level knowledge discovery. Additionally, the
integration of graph structures with vector representations facilitates
efficient retrieval of related entities and their relationships, significantly
improving response times while maintaining contextual relevance. This
capability is further enhanced by an incremental update algorithm that ensures
the timely integration of new data, allowing the system to remain effective and
responsive in rapidly changing data environments. Extensive experimental
validation demonstrates considerable improvements in retrieval accuracy and
efficiency compared to existing approaches. We have made our LightRAG
open-source and available at the link: https://github.com/HKUDS/LightRAG",Zirui Guo and Lianghao Xia and Yanhua Yu and Tu Ao and Chao Huang,2024,,https://arxiv.org/abs/2410.05779,,
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,yang-etal-2023-longtriever,\cite{yang-etal-2023-longtriever},Longtriever: a Pre-trained Long Text Encoder for Dense Document Retrieval,,,"Yang, Junhan and Liu, Zheng and Li, Chaozhuo and Sun, Guangzhong and Xie, Xing",2023,,https://aclanthology.org/2023.emnlp-main.223/,10.18653/v1/2023.emnlp-main.223,
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,maynez2020faithfulnessfactualityabstractivesummarization,\cite{maynez2020faithfulnessfactualityabstractivesummarization},On Faithfulness and Factuality in Abstractive Summarization,http://arxiv.org/abs/2005.00661v1,"It is well known that the standard likelihood training and approximate
decoding objectives in neural text generation models lead to less human-like
responses for open-ended tasks such as language modeling and story generation.
In this paper we have analyzed limitations of these models for abstractive
document summarization and found that these models are highly prone to
hallucinate content that is unfaithful to the input document. We conducted a
large scale human evaluation of several neural abstractive summarization
systems to better understand the types of hallucinations they produce. Our
human annotators found substantial amounts of hallucinated content in all model
generated summaries. However, our analysis does show that pretrained models are
better summarizers not only in terms of raw metrics, i.e., ROUGE, but also in
generating faithful and factual summaries as evaluated by humans. Furthermore,
we show that textual entailment measures better correlate with faithfulness
than standard metrics, potentially leading the way to automatic evaluation
metrics as well as training and decoding criteria.","Maynez, Joshua and Narayan, Shashi and Bohnet, Bernd and McDonald, Ryan",2020,,https://arxiv.org/abs/2005.00661,,arXiv preprint arXiv:2005.00661
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,li2023extracting,\cite{li2023extracting},Extracting Financial Data from Unstructured Sources: Leveraging Large Language Models,,,"Li, Huaxia and Gao, Haoyun and Wu, Chengzhang and Vasarhelyi, Miklos A.",2023,September 6,,,Forthcoming in the Journal of Information Systems
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,zhang2023financialsentiment,\cite{zhang2023financialsentiment},"Enhancing Financial Sentiment Analysis via Retrieval Augmented Large
  Language Models",http://arxiv.org/abs/2310.04027v2,"Financial sentiment analysis is critical for valuation and investment
decision-making. Traditional NLP models, however, are limited by their
parameter size and the scope of their training datasets, which hampers their
generalization capabilities and effectiveness in this field. Recently, Large
Language Models (LLMs) pre-trained on extensive corpora have demonstrated
superior performance across various NLP tasks due to their commendable
zero-shot abilities. Yet, directly applying LLMs to financial sentiment
analysis presents challenges: The discrepancy between the pre-training
objective of LLMs and predicting the sentiment label can compromise their
predictive performance. Furthermore, the succinct nature of financial news,
often devoid of sufficient context, can significantly diminish the reliability
of LLMs' sentiment analysis. To address these challenges, we introduce a
retrieval-augmented LLMs framework for financial sentiment analysis. This
framework includes an instruction-tuned LLMs module, which ensures LLMs behave
as predictors of sentiment labels, and a retrieval-augmentation module which
retrieves additional context from reliable external sources. Benchmarked
against traditional models and LLMs like ChatGPT and LLaMA, our approach
achieves 15\% to 48\% performance gain in accuracy and F1 score.",Boyu Zhang and Hongyang Yang and Tianyu Zhou and Ali Babar and Xiao-Yang Liu,2023,,https://arxiv.org/abs/2310.04027,,
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,wang2024mana,\cite{wang2024mana},Mana-net: Mitigating aggregated sentiment homogenization with news weighting for enhanced market prediction,,,"Wang, Mengyu and Ma, Tiejun",2024,,,,
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,li2024investorbench,\cite{li2024investorbench},"INVESTORBENCH: A Benchmark for Financial Decision-Making Tasks with
  LLM-based Agent",http://arxiv.org/abs/2412.18174v1,"Recent advancements have underscored the potential of large language model
(LLM)-based agents in financial decision-making. Despite this progress, the
field currently encounters two main challenges: (1) the lack of a comprehensive
LLM agent framework adaptable to a variety of financial tasks, and (2) the
absence of standardized benchmarks and consistent datasets for assessing agent
performance. To tackle these issues, we introduce \textsc{InvestorBench}, the
first benchmark specifically designed for evaluating LLM-based agents in
diverse financial decision-making contexts. InvestorBench enhances the
versatility of LLM-enabled agents by providing a comprehensive suite of tasks
applicable to different financial products, including single equities like
stocks, cryptocurrencies and exchange-traded funds (ETFs). Additionally, we
assess the reasoning and decision-making capabilities of our agent framework
using thirteen different LLMs as backbone models, across various market
environments and tasks. Furthermore, we have curated a diverse collection of
open-source, multi-modal datasets and developed a comprehensive suite of
environments for financial decision-making. This establishes a highly
accessible platform for evaluating financial agents' performance across various
scenarios.","Li, Haohang and Cao, Yupeng and Yu, Yangyang and Javaji, Shashidhar Reddy and Deng, Zhiyang and He, Yueru and Jiang, Yuechen and Zhu, Zining and Subbalakshmi, Koduvayur and Xiong, Guojun and others",2024,,,,arXiv preprint arXiv:2412.18174
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,wang2024modeling,\cite{wang2024modeling},Modeling News Interactions and Influence for Financial Market Prediction,http://arxiv.org/abs/2410.10614v1,"The diffusion of financial news into market prices is a complex process,
making it challenging to evaluate the connections between news events and
market movements. This paper introduces FININ (Financial Interconnected News
Influence Network), a novel market prediction model that captures not only the
links between news and prices but also the interactions among news items
themselves. FININ effectively integrates multi-modal information from both
market data and news articles. We conduct extensive experiments on two
datasets, encompassing the S&P 500 and NASDAQ 100 indices over a 15-year period
and over 2.7 million news articles. The results demonstrate FININ's
effectiveness, outperforming advanced market prediction models with an
improvement of 0.429 and 0.341 in the daily Sharpe ratio for the two markets
respectively. Moreover, our results reveal insights into the financial news,
including the delayed market pricing of news, the long memory effect of news,
and the limitations of financial sentiment analysis in fully extracting
predictive power from news data.","Wang, Mengyu and Cohen, Shay B and Ma, Tiejun",2024,,,,arXiv preprint arXiv:2410.10614
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,chen2021finqa,\cite{chen2021finqa},FinQA: A Dataset of Numerical Reasoning over Financial Data,http://arxiv.org/abs/2109.00122v3,"The sheer volume of financial statements makes it difficult for humans to
access and analyze a business's financials. Robust numerical reasoning likewise
faces unique challenges in this domain. In this work, we focus on answering
deep questions over financial data, aiming to automate the analysis of a large
corpus of financial documents. In contrast to existing tasks on general domain,
the finance domain includes complex numerical reasoning and understanding of
heterogeneous representations. To facilitate analytical progress, we propose a
new large-scale dataset, FinQA, with Question-Answering pairs over Financial
reports, written by financial experts. We also annotate the gold reasoning
programs to ensure full explainability. We further introduce baselines and
conduct comprehensive experiments in our dataset. The results demonstrate that
popular, large, pre-trained models fall far short of expert humans in acquiring
finance knowledge and in complex multi-step numerical reasoning on that
knowledge. Our dataset -- the first of its kind -- should therefore enable
significant, new community research into complex application domains. The
dataset and code are publicly available\url{https://github.com/czyssrs/FinQA}.","Chen, Zhiyu and Chen, Wenhu and Smiley, Charese and Shah, Sameena and Borova, Iana and Langdon, Dylan and Moussa, Reema and Beane, Matt and Huang, Ting-Hao and Routledge, Bryan and others",2021,,,,arXiv preprint arXiv:2109.00122
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,zhu2021tatqaquestionansweringbenchmark,\cite{zhu2021tatqaquestionansweringbenchmark},TAT-QA: A Question Answering Benchmark on a Hybrid of Tabular and Textual Content in Finance,,,"Zhu, Fengbin and Lei, Wenqiang and Huang, Youcheng and Wang, Chao and Zhang, Shuo and Lv, Jiancheng and Feng, Fuli and Chua, Tat-Seng",2021,,https://arxiv.org/abs/2105.07624,,arXiv preprint arXiv:2105.07624
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,finbertqa,\cite{finbertqa},FinBERT-QA: Financial Question Answering with Pre-trained BERT Language Models,,,"Yuan, Bit and others",2021,,,,
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,yang2023fingpt,\cite{yang2023fingpt},FinGPT: Open-Source Financial Large Language Models,http://arxiv.org/abs/2306.06031v1,"Large language models (LLMs) have shown the potential of revolutionizing
natural language processing tasks in diverse domains, sparking great interest
in finance. Accessing high-quality financial data is the first challenge for
financial LLMs (FinLLMs). While proprietary models like BloombergGPT have taken
advantage of their unique data accumulation, such privileged access calls for
an open-source alternative to democratize Internet-scale financial data.
  In this paper, we present an open-source large language model, FinGPT, for
the finance sector. Unlike proprietary models, FinGPT takes a data-centric
approach, providing researchers and practitioners with accessible and
transparent resources to develop their FinLLMs. We highlight the importance of
an automatic data curation pipeline and the lightweight low-rank adaptation
technique in building FinGPT. Furthermore, we showcase several potential
applications as stepping stones for users, such as robo-advising, algorithmic
trading, and low-code development. Through collaborative efforts within the
open-source AI4Finance community, FinGPT aims to stimulate innovation,
democratize FinLLMs, and unlock new opportunities in open finance. Two
associated code repos are \url{https://github.com/AI4Finance-Foundation/FinGPT}
and \url{https://github.com/AI4Finance-Foundation/FinNLP}","Yang, Hongyang and Liu, Xiao-Yang and Wang, Christina Dan",2023,,,,arXiv preprint arXiv:2306.06031
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,docfinQA,\cite{docfinQA},DocFinQA: A Long-Context Financial Reasoning Dataset,http://arxiv.org/abs/2401.06915v2,"For large language models (LLMs) to be effective in the financial domain --
where each decision can have a significant impact -- it is necessary to
investigate realistic tasks and data. Financial professionals often interact
with documents that are hundreds of pages long, but most financial research
datasets only deal with short excerpts from these documents. To address this,
we introduce a long-document financial QA task. We augment 7,437 questions from
the existing FinQA dataset with the full-document context, extending the
average context length from under 700 words in FinQA to 123k words in DocFinQA.
We conduct extensive experiments over retrieval-based QA pipelines and
long-context language models. DocFinQA proves a significant challenge for even
state-of-the-art systems. We also provide a case-study on the longest documents
in DocFinQA and find that models particularly struggle on these documents.
Addressing these challenges may have a wide reaching impact across applications
where specificity and long-range contexts are critical, like gene sequences and
legal document contract analysis.",Varshini Reddy and Rik Koncel-Kedziorski and Viet Dac Lai and Michael Krumdick and Charles Lovering and Chris Tanner,2024,,https://arxiv.org/abs/2401.06915,,
FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval,http://arxiv.org/abs/2509.12042v1,yu2024defense,\cite{yu2024defense},In Defense of RAG in the Era of Long-Context Language Models,http://arxiv.org/abs/2409.01666v1,"Overcoming the limited context limitations in early-generation LLMs,
retrieval-augmented generation (RAG) has been a reliable solution for
context-based answer generation in the past. Recently, the emergence of
long-context LLMs allows the models to incorporate much longer text sequences,
making RAG less attractive. Recent studies show that long-context LLMs
significantly outperform RAG in long-context applications. Unlike the existing
works favoring the long-context LLM over RAG, we argue that the extremely long
context in LLMs suffers from a diminished focus on relevant information and
leads to potential degradation in answer quality. This paper revisits the RAG
in long-context answer generation. We propose an order-preserve
retrieval-augmented generation (OP-RAG) mechanism, which significantly improves
the performance of RAG for long-context question-answer applications. With
OP-RAG, as the number of retrieved chunks increases, the answer quality
initially rises, and then declines, forming an inverted U-shaped curve. There
exist sweet points where OP-RAG could achieve higher answer quality with much
less tokens than long-context LLM taking the whole context as input. Extensive
experiments on public benchmark demonstrate the superiority of our OP-RAG.",Tan Yu and Anbang Xu and Rama Akkiraju,2024,,https://arxiv.org/abs/2409.01666,,
