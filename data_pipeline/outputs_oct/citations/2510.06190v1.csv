parent_paper_title,parent_arxiv_link,citation_shorthand,raw_citation_text,cited_paper_title,cited_paper_arxiv_link,cited_paper_abstract,bib_paper_authors,bib_paper_year,bib_paper_month,bib_paper_url,bib_paper_doi,bib_paper_journal
"On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",http://arxiv.org/abs/2510.06190v1,hoogeboom2021argmax,\cite{hoogeboom2021argmax},"Argmax Flows and Multinomial Diffusion: Learning Categorical
  Distributions",http://arxiv.org/abs/2102.05379v3,"Generative flows and diffusion models have been predominantly trained on
ordinal data, for example natural images. This paper introduces two extensions
of flows and diffusion for categorical data such as language or image
segmentation: Argmax Flows and Multinomial Diffusion. Argmax Flows are defined
by a composition of a continuous distribution (such as a normalizing flow), and
an argmax function. To optimize this model, we learn a probabilistic inverse
for the argmax that lifts the categorical data to a continuous space.
Multinomial Diffusion gradually adds categorical noise in a diffusion process,
for which the generative denoising process is learned. We demonstrate that our
method outperforms existing dequantization approaches on text modelling and
modelling on image segmentation maps in log-likelihood.","Hoogeboom, Emiel and Nielsen, Didrik and Jaini, Priyank and Forr{\'e}, Patrick and Welling, Max",2021,,,,Advances in neural information processing systems
"On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",http://arxiv.org/abs/2510.06190v1,austin2021structured,\cite{austin2021structured},Structured Denoising Diffusion Models in Discrete State-Spaces,http://arxiv.org/abs/2107.03006v3,"Denoising diffusion probabilistic models (DDPMs) (Ho et al. 2020) have shown
impressive results on image and waveform generation in continuous state spaces.
Here, we introduce Discrete Denoising Diffusion Probabilistic Models (D3PMs),
diffusion-like generative models for discrete data that generalize the
multinomial diffusion model of Hoogeboom et al. 2021, by going beyond
corruption processes with uniform transition probabilities. This includes
corruption with transition matrices that mimic Gaussian kernels in continuous
space, matrices based on nearest neighbors in embedding space, and matrices
that introduce absorbing states. The third allows us to draw a connection
between diffusion models and autoregressive and mask-based generative models.
We show that the choice of transition matrix is an important design decision
that leads to improved results in image and text domains. We also introduce a
new loss function that combines the variational lower bound with an auxiliary
cross entropy loss. For text, this model class achieves strong results on
character-level text generation while scaling to large vocabularies on LM1B. On
the image dataset CIFAR-10, our models approach the sample quality and exceed
the log-likelihood of the continuous-space DDPM model.","Austin, Jacob and Johnson, Daniel D and Ho, Jonathan and Tarlow, Daniel and van den Berg, Rianne",2021,,,,
"On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",http://arxiv.org/abs/2510.06190v1,lou2024discrete,\cite{lou2024discrete},"Discrete Diffusion Modeling by Estimating the Ratios of the Data
  Distribution",http://arxiv.org/abs/2310.16834v3,"Despite their groundbreaking performance for many generative modeling tasks,
diffusion models have fallen short on discrete data domains such as natural
language. Crucially, standard diffusion models rely on the well-established
theory of score matching, but efforts to generalize this to discrete structures
have not yielded the same empirical gains. In this work, we bridge this gap by
proposing score entropy, a novel loss that naturally extends score matching to
discrete spaces, integrates seamlessly to build discrete diffusion models, and
significantly boosts performance. Experimentally, we test our Score Entropy
Discrete Diffusion models (SEDD) on standard language modeling tasks. For
comparable model sizes, SEDD beats existing language diffusion paradigms
(reducing perplexity by $25$-$75$\%) and is competitive with autoregressive
models, in particular outperforming GPT-2. Furthermore, compared to
autoregressive mdoels, SEDD generates faithful text without requiring
distribution annealing techniques like temperature scaling (around
$6$-$8\times$ better generative perplexity than un-annealed GPT-2), can trade
compute and quality (similar quality with $32\times$ fewer network
evaluations), and enables controllable infilling (matching nucleus sampling
quality while enabling other strategies besides left to right prompting).","Lou, Aaron and Meng, Chenlin and Ermon, Stefano",2024,,https://arxiv.org/abs/2310.16834,,
"On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",http://arxiv.org/abs/2510.06190v1,sahoo2024simple,\cite{sahoo2024simple},Simple and Effective Masked Diffusion Language Models,http://arxiv.org/abs/2406.07524v2,"While diffusion models excel at generating high-quality images, prior work
reports a significant performance gap between diffusion and autoregressive (AR)
methods in language modeling. In this work, we show that simple masked discrete
diffusion is more performant than previously thought. We apply an effective
training recipe that improves the performance of masked diffusion models and
derive a simplified, Rao-Blackwellized objective that results in additional
improvements. Our objective has a simple form -- it is a mixture of classical
masked language modeling losses -- and can be used to train encoder-only
language models that admit efficient samplers, including ones that can generate
arbitrary lengths of text semi-autoregressively like a traditional language
model. On language modeling benchmarks, a range of masked diffusion models
trained with modern engineering practices achieves a new state-of-the-art among
diffusion models, and approaches AR perplexity. We provide the code, along with
a blog post and video tutorial on the project page: https://s-sahoo.com/mdlm",Subham Sekhar Sahoo and Marianne Arriola and Yair Schiff and Aaron Gokaslan and Edgar Mariano Marroquin and Justin T Chiu and Alexander M Rush and Volodymyr Kuleshov,2024,,https://openreview.net/forum?id=L4uaAR4ArM,,
"On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",http://arxiv.org/abs/2510.06190v1,shi2024simplified,\cite{shi2024simplified},Simplified and Generalized Masked Diffusion for Discrete Data,http://arxiv.org/abs/2406.04329v4,"Masked (or absorbing) diffusion is actively explored as an alternative to
autoregressive models for generative modeling of discrete data. However,
existing work in this area has been hindered by unnecessarily complex model
formulations and unclear relationships between different perspectives, leading
to suboptimal parameterization, training objectives, and ad hoc adjustments to
counteract these issues. In this work, we aim to provide a simple and general
framework that unlocks the full potential of masked diffusion models. We show
that the continuous-time variational objective of masked diffusion models is a
simple weighted integral of cross-entropy losses. Our framework also enables
training generalized masked diffusion models with state-dependent masking
schedules. When evaluated by perplexity, our models trained on OpenWebText
surpass prior diffusion language models at GPT-2 scale and demonstrate superior
performance on 4 out of 5 zero-shot language modeling tasks. Furthermore, our
models vastly outperform previous discrete diffusion models on pixel-level
image modeling, achieving 2.75 (CIFAR-10) and 3.40 (ImageNet 64x64) bits per
dimension that are better than autoregressive models of similar sizes. Our code
is available at https://github.com/google-deepmind/md4.","Shi, Jiaxin and Han, Kehang and Wang, Zhe and Doucet, Arnaud and Titsias, Michalis K.",2024,,,,
"On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",http://arxiv.org/abs/2510.06190v1,sohl2015deep,\cite{sohl2015deep},Deep Unsupervised Learning using Nonequilibrium Thermodynamics,http://arxiv.org/abs/1503.03585v8,"A central problem in machine learning involves modeling complex data-sets
using highly flexible families of probability distributions in which learning,
sampling, inference, and evaluation are still analytically or computationally
tractable. Here, we develop an approach that simultaneously achieves both
flexibility and tractability. The essential idea, inspired by non-equilibrium
statistical physics, is to systematically and slowly destroy structure in a
data distribution through an iterative forward diffusion process. We then learn
a reverse diffusion process that restores structure in data, yielding a highly
flexible and tractable generative model of the data. This approach allows us to
rapidly learn, sample from, and evaluate probabilities in deep generative
models with thousands of layers or time steps, as well as to compute
conditional and posterior probabilities under the learned model. We
additionally release an open source reference implementation of the algorithm.","Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya",2015,,,,
"On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",http://arxiv.org/abs/2510.06190v1,ho2020denoising,\cite{ho2020denoising},Denoising Diffusion Probabilistic Models,http://arxiv.org/abs/2006.11239v2,"We present high quality image synthesis results using diffusion probabilistic
models, a class of latent variable models inspired by considerations from
nonequilibrium thermodynamics. Our best results are obtained by training on a
weighted variational bound designed according to a novel connection between
diffusion probabilistic models and denoising score matching with Langevin
dynamics, and our models naturally admit a progressive lossy decompression
scheme that can be interpreted as a generalization of autoregressive decoding.
On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and
a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality
similar to ProgressiveGAN. Our implementation is available at
https://github.com/hojonathanho/diffusion","Ho, Jonathan and Jain, Ajay and Abbeel, Pieter",2020,,,,Advances in neural information processing systems
"On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",http://arxiv.org/abs/2510.06190v1,song2020score,\cite{song2020score},"Score-Based Generative Modeling through Stochastic Differential
  Equations",http://arxiv.org/abs/2011.13456v2,"Creating noise from data is easy; creating data from noise is generative
modeling. We present a stochastic differential equation (SDE) that smoothly
transforms a complex data distribution to a known prior distribution by slowly
injecting noise, and a corresponding reverse-time SDE that transforms the prior
distribution back into the data distribution by slowly removing the noise.
Crucially, the reverse-time SDE depends only on the time-dependent gradient
field (\aka, score) of the perturbed data distribution. By leveraging advances
in score-based generative modeling, we can accurately estimate these scores
with neural networks, and use numerical SDE solvers to generate samples. We
show that this framework encapsulates previous approaches in score-based
generative modeling and diffusion probabilistic modeling, allowing for new
sampling procedures and new modeling capabilities. In particular, we introduce
a predictor-corrector framework to correct errors in the evolution of the
discretized reverse-time SDE. We also derive an equivalent neural ODE that
samples from the same distribution as the SDE, but additionally enables exact
likelihood computation, and improved sampling efficiency. In addition, we
provide a new way to solve inverse problems with score-based models, as
demonstrated with experiments on class-conditional generation, image
inpainting, and colorization. Combined with multiple architectural
improvements, we achieve record-breaking performance for unconditional image
generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a
competitive likelihood of 2.99 bits/dim, and demonstrate high fidelity
generation of 1024 x 1024 images for the first time from a score-based
generative model.","Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben",2020,,,,arXiv preprint arXiv:2011.13456
"On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",http://arxiv.org/abs/2510.06190v1,vignac2022digress,\cite{vignac2022digress},DiGress: Discrete Denoising diffusion for graph generation,http://arxiv.org/abs/2209.14734v4,"This work introduces DiGress, a discrete denoising diffusion model for
generating graphs with categorical node and edge attributes. Our model utilizes
a discrete diffusion process that progressively edits graphs with noise,
through the process of adding or removing edges and changing the categories. A
graph transformer network is trained to revert this process, simplifying the
problem of distribution learning over graphs into a sequence of node and edge
classification tasks. We further improve sample quality by introducing a
Markovian noise model that preserves the marginal distribution of node and edge
types during diffusion, and by incorporating auxiliary graph-theoretic
features. A procedure for conditioning the generation on graph-level features
is also proposed. DiGress achieves state-of-the-art performance on molecular
and non-molecular datasets, with up to 3x validity improvement on a planar
graph dataset. It is also the first model to scale to the large GuacaMol
dataset containing 1.3M drug-like molecules without the use of
molecule-specific representations.","Vignac, Clement and Krawczuk, Igor and Siraudin, Antoine and Wang, Bohan and Cevher, Volkan and Frossard, Pascal",2022,,,,arXiv preprint arXiv:2209.14734
"On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",http://arxiv.org/abs/2510.06190v1,sun2023difusco,\cite{sun2023difusco},DIFUSCO: Graph-based Diffusion Solvers for Combinatorial Optimization,http://arxiv.org/abs/2302.08224v2,"Neural network-based Combinatorial Optimization (CO) methods have shown
promising results in solving various NP-complete (NPC) problems without relying
on hand-crafted domain knowledge. This paper broadens the current scope of
neural solvers for NPC problems by introducing a new graph-based diffusion
framework, namely DIFUSCO. Our framework casts NPC problems as discrete {0,
1}-vector optimization problems and leverages graph-based denoising diffusion
models to generate high-quality solutions. We investigate two types of
diffusion models with Gaussian and Bernoulli noise, respectively, and devise an
effective inference schedule to enhance the solution quality. We evaluate our
methods on two well-studied NPC combinatorial optimization problems: Traveling
Salesman Problem (TSP) and Maximal Independent Set (MIS). Experimental results
show that DIFUSCO strongly outperforms the previous state-of-the-art neural
solvers, improving the performance gap between ground-truth and neural solvers
from 1.76% to 0.46% on TSP-500, from 2.46% to 1.17% on TSP-1000, and from 3.19%
to 2.58% on TSP10000. For the MIS problem, DIFUSCO outperforms the previous
state-of-the-art neural solver on the challenging SATLIB benchmark.","Sun, Zhiqing and Yang, Yiming",2023,,,,Advances in neural information processing systems
"On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",http://arxiv.org/abs/2510.06190v1,gruver2023protein,\cite{gruver2023protein},Protein Design with Guided Discrete Diffusion,http://arxiv.org/abs/2305.20009v2,"A popular approach to protein design is to combine a generative model with a
discriminative model for conditional sampling. The generative model samples
plausible sequences while the discriminative model guides a search for
sequences with high fitness. Given its broad success in conditional sampling,
classifier-guided diffusion modeling is a promising foundation for protein
design, leading many to develop guided diffusion models for structure with
inverse folding to recover sequences. In this work, we propose diffusioN
Optimized Sampling (NOS), a guidance method for discrete diffusion models that
follows gradients in the hidden states of the denoising network. NOS makes it
possible to perform design directly in sequence space, circumventing
significant limitations of structure-based methods, including scarce data and
challenging inverse design. Moreover, we use NOS to generalize LaMBO, a
Bayesian optimization procedure for sequence design that facilitates multiple
objectives and edit-based constraints. The resulting method, LaMBO-2, enables
discrete diffusions and stronger performance with limited edits through a novel
application of saliency maps. We apply LaMBO-2 to a real-world protein design
task, optimizing antibodies for higher expression yield and binding affinity to
several therapeutic targets under locality and developability constraints,
attaining a 99% expression rate and 40% binding rate in exploratory in vitro
experiments.","Gruver, Nate and Stanton, Samuel and Frey, Nathan and Rudner, Tim GJ and Hotzel, Isidro and Lafrance-Vanasse, Julien and Rajpal, Arvind and Cho, Kyunghyun and Wilson, Andrew G",2023,,,,Advances in neural information processing systems
"On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",http://arxiv.org/abs/2510.06190v1,lee2025genmol,\cite{lee2025genmol},GenMol: A Drug Discovery Generalist with Discrete Diffusion,http://arxiv.org/abs/2501.06158v3,"Drug discovery is a complex process that involves multiple stages and tasks.
However, existing molecular generative models can only tackle some of these
tasks. We present Generalist Molecular generative model (GenMol), a versatile
framework that uses only a single discrete diffusion model to handle diverse
drug discovery scenarios. GenMol generates Sequential Attachment-based Fragment
Embedding (SAFE) sequences through non-autoregressive bidirectional parallel
decoding, thereby allowing the utilization of a molecular context that does not
rely on the specific token ordering while having better sampling efficiency.
GenMol uses fragments as basic building blocks for molecules and introduces
fragment remasking, a strategy that optimizes molecules by regenerating masked
fragments, enabling effective exploration of chemical space. We further propose
molecular context guidance (MCG), a guidance method tailored for masked
discrete diffusion of GenMol. GenMol significantly outperforms the previous
GPT-based model in de novo generation and fragment-constrained generation, and
achieves state-of-the-art performance in goal-directed hit generation and lead
optimization. These results demonstrate that GenMol can tackle a wide range of
drug discovery tasks, providing a unified and versatile approach for molecular
design. Our code is available at https://github.com/NVIDIA-Digital-Bio/genmol.","Lee, Seul and Kreis, Karsten and Veccham, Srimukh Prasad and Liu, Meng and Reidenbach, Danny and Peng, Yuxing and Paliwal, Saee and Nie, Weili and Vahdat, Arash",2025,,,,arXiv preprint arXiv:2501.06158
"On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",http://arxiv.org/abs/2510.06190v1,deepmind2025gemini,\cite{deepmind2025gemini},Gemini diffusion,,,DeepMind,2025,,https://deepmind.google/models/gemini-diffusion/,,
"On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",http://arxiv.org/abs/2510.06190v1,inceptionlabs2025mercury,\cite{inceptionlabs2025mercury},Mercury: Ultra-Fast Language Models Based on Diffusion,http://arxiv.org/abs/2506.17298v1,"We present Mercury, a new generation of commercial-scale large language
models (LLMs) based on diffusion. These models are parameterized via the
Transformer architecture and trained to predict multiple tokens in parallel. In
this report, we detail Mercury Coder, our first set of diffusion LLMs designed
for coding applications. Currently, Mercury Coder comes in two sizes: Mini and
Small. These models set a new state-of-the-art on the speed-quality frontier.
Based on independent evaluations conducted by Artificial Analysis, Mercury
Coder Mini and Mercury Coder Small achieve state-of-the-art throughputs of 1109
tokens/sec and 737 tokens/sec, respectively, on NVIDIA H100 GPUs and outperform
speed-optimized frontier models by up to 10x on average while maintaining
comparable quality. We discuss additional results on a variety of code
benchmarks spanning multiple languages and use-cases as well as real-world
validation by developers on Copilot Arena, where the model currently ranks
second on quality and is the fastest model overall. We also release a public
API at https://platform.inceptionlabs.ai/ and free playground at
https://chat.inceptionlabs.ai","Labs, Inception and Khanna, Samar and Kharbanda, Siddhant and Li, Shufan and Varma, Harshit and Wang, Eric and Birnbaum, Sawyer and Luo, Ziyang and Miraoui, Yanis and Palrecha, Akash and others",2025,,,,arXiv preprint arXiv:2506.17298
"On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",http://arxiv.org/abs/2510.06190v1,vonrutte2025generalized,\cite{vonrutte2025generalized},Generalized Interpolating Discrete Diffusion,http://arxiv.org/abs/2503.04482v2,"While state-of-the-art language models achieve impressive results through
next-token prediction, they have inherent limitations such as the inability to
revise already generated tokens. This has prompted exploration of alternative
approaches such as discrete diffusion. However, masked diffusion, which has
emerged as a popular choice due to its simplicity and effectiveness,
reintroduces this inability to revise words. To overcome this, we generalize
masked diffusion, deriving a new family of general interpolating discrete
diffusion (GIDD) which offers greater flexibility in the design of the noising
processes. Leveraging a novel diffusion ELBO, we achieve compute-matched
state-of-the-art performance in diffusion language modeling. Exploiting GIDD's
flexibility, we explore a hybrid approach combining masking and uniform noise,
leading to improved sample quality and unlocking the ability for the model to
correct its own mistakes, an area where autoregressive models notoriously have
struggled. Code: https://github.com/dvruette/gidd/",Dimitri von Rütte and Janis Fluri and Yuhui Ding and Antonio Orvieto and Bernhard Schölkopf and Thomas Hofmann,2025,,,,
"On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",http://arxiv.org/abs/2510.06190v1,wang2025remasking,\cite{wang2025remasking},Remasking Discrete Diffusion Models with Inference-Time Scaling,http://arxiv.org/abs/2503.00307v2,"Part of the success of diffusion models stems from their ability to perform
iterative refinement, i.e., repeatedly correcting outputs during generation.
However, modern masked discrete diffusion lacks this capability: when a token
is generated, it cannot be updated again, even when it introduces an error.
Here, we address this limitation by introducing the remasking diffusion model
(ReMDM) sampler, a method that can be applied to pretrained masked diffusion
models in a principled way and that is derived from a discrete diffusion model
with a custom remasking backward process. Most interestingly, ReMDM endows
discrete diffusion with a form of inference-time compute scaling. By increasing
the number of sampling steps, ReMDM generates natural language outputs that
approach the quality of autoregressive models, whereas when the computation
budget is limited, ReMDM better maintains quality. ReMDM also improves sample
quality of masked diffusion models for discretized images, and in scientific
domains such as molecule design, ReMDM facilitates diffusion guidance and
pushes the Pareto frontier of controllability relative to classical masking and
uniform noise diffusion. We provide the code along with a blog post on the
project page: https://remdm.github.io","Wang, Guanghan and Schiff, Yair and Sahoo, Subham Sekhar and Kuleshov, Volodymyr",2025,,,,arXiv preprint arXiv:2503.00307
"On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",http://arxiv.org/abs/2510.06190v1,peng2025path,\cite{peng2025path},Path Planning for Masked Diffusion Model Sampling,http://arxiv.org/abs/2502.03540v4,"Any order generation of discrete data using masked diffusion models (MDMs)
offers a compelling alternative to traditional autoregressive models,
especially in domains that lack a natural causal ordering of data. However,
current popular MDMs depart from their successful continuous diffusion model
counterparts with simplified masked inference wherein unmasked tokens cannot be
iteratively refined -- even if there is a mistake. In this paper, we extract
the full power of MDMs by introducing a novel inference sampling strategy
termed Path Planning (P2) that decomposes each generation step into two
sub-stages: planning and denoising. Under P2, the planner at every step selects
appropriate tokens that are marked to be updated, which can then be sampled
using the denoiser. We demonstrate that P2 generalizes all existing sampling
strategies for MDMs and critically enhances generative quality through the new
capability of refining and updating existing unmasked tokens. We theoretically
prove that P2 establishes a (new) expanded evidence lower bound (ELBO) on the
log marginal likelihood of data. We instantiate P2 with a family of planners
including: 1.) Self-Planning, 2.) BERT-Planning, and 3.) Trained-Planning with
a learned planner leading to SOTA generative performance for MDMs on a suite of
domains. Specifically, solely using P2 inference, we observe relative
improvements of 22% in protein sequence foldability, 8% in RNA sequence pLDDT,
4% in math reasoning, 68% in story generation (ROUGE score), and 33% in code
generation for the challenging pass@1 metric.",Fred Zhangzhi Peng and Zachary Bezemek and Sawan Patel and Jarrid Rector-Brooks and Sherwood Yao and Avishek Joey Bose and Alexander Tong and Pranam Chatterjee,2025,,,,
"On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",http://arxiv.org/abs/2510.06190v1,havasi2025edit,\cite{havasi2025edit},Edit Flows: Flow Matching with Edit Operations,http://arxiv.org/abs/2506.09018v1,"Autoregressive generative models naturally generate variable-length
sequences, while non-autoregressive models struggle, often imposing rigid,
token-wise structures. We propose Edit Flows, a non-autoregressive model that
overcomes these limitations by defining a discrete flow over sequences through
edit operations-insertions, deletions, and substitutions. By modeling these
operations within a Continuous-time Markov Chain over the sequence space, Edit
Flows enable flexible, position-relative generation that aligns more closely
with the structure of sequence data. Our training method leverages an expanded
state space with auxiliary variables, making the learning process efficient and
tractable. Empirical results show that Edit Flows outperforms both
autoregressive and mask models on image captioning and significantly
outperforms the mask construction in text and code generation.","Havasi, Marton and Karrer, Brian and Gat, Itai and Chen, Ricky TQ",2025,,,,arXiv preprint arXiv:2506.09018
"On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",http://arxiv.org/abs/2510.06190v1,wu2025dreamon,\cite{wu2025dreamon},DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-Size Canvas,,,"Wu, Zirui and Zheng, Lin and Xie, Zhihui and Ye, Jiacheng and Gao, Jiahui and Feng, Yansong and Li, Zhenguo and W., Victoria and Zhou, Guorui and Kong, Lingpeng",2025,,https://hkunlp.github.io/blog/2025/dreamon/,,
"On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",http://arxiv.org/abs/2510.06190v1,kim2025any,\cite{kim2025any},Any-Order Flexible Length Masked Diffusion,http://arxiv.org/abs/2509.01025v2,"Masked diffusion models (MDMs) have recently emerged as a promising
alternative to autoregressive models over discrete domains. MDMs generate
sequences in an any-order, parallel fashion, enabling fast inference and strong
performance on non-causal tasks. However, a crucial limitation is that they do
not support token insertions and are thus limited to fixed-length generations.
To this end, we introduce Flexible Masked Diffusion Models (FlexMDMs), a
discrete diffusion paradigm that simultaneously can model sequences of flexible
length while provably retaining MDMs' flexibility of any-order inference.
Grounded in an extension of the stochastic interpolant framework, FlexMDMs
generate sequences by inserting mask tokens and unmasking them. Empirically, we
show that FlexMDMs match MDMs in perplexity while modeling length statistics
with much higher fidelity. On a synthetic maze planning task, they achieve
$\approx 60 \%$ higher success rate than MDM baselines. Finally, we show
pretrained MDMs can easily be retrofitted into FlexMDMs: on 16 H100s, it takes
only three days to fine-tune LLaDA-8B into a FlexMDM, achieving superior
performance on math (GSM8K, $58\% \to 67\%$) and code infilling performance
($52\% \to 65\%$).","Kim, Jaeyeon and Cheuk-Kit, Lee and Domingo-Enrich, Carles and Du, Yilun and Kakade, Sham and Ngotiaoco, Timothy and Chen, Sitan and Albergo, Michael",2025,,,,arXiv preprint arXiv:2509.01025
"On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",http://arxiv.org/abs/2510.06190v1,sahoo2025diffusion,\cite{sahoo2025diffusion},The Diffusion Duality,http://arxiv.org/abs/2506.10892v2,"Uniform-state discrete diffusion models hold the promise of fast text
generation due to their inherent ability to self-correct. However, they are
typically outperformed by autoregressive models and masked diffusion models. In
this work, we narrow this performance gap by leveraging a key insight:
Uniform-state diffusion processes naturally emerge from an underlying Gaussian
diffusion. Our method, Duo, transfers powerful techniques from Gaussian
diffusion to improve both training and sampling. First, we introduce a
curriculum learning strategy guided by the Gaussian process, doubling training
speed by reducing variance. Models trained with curriculum learning surpass
autoregressive models in zero-shot perplexity on 3 of 7 benchmarks. Second, we
present Discrete Consistency Distillation, which adapts consistency
distillation from the continuous to the discrete setting. This algorithm
unlocks few-step generation in diffusion language models by accelerating
sampling by two orders of magnitude. We provide the code and model checkpoints
on the project page: http://s-sahoo.github.io/duo","Sahoo, Subham Sekhar and Deschenaux, Justin and Gokaslan, Aaron and Wang, Guanghan and Chiu, Justin and Kuleshov, Volodymyr",2025,,https://arxiv.org/abs/2506.10892,,
