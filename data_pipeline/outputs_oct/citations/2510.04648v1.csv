parent_paper_title,parent_arxiv_link,citation_shorthand,raw_citation_text,cited_paper_title,cited_paper_arxiv_link,cited_paper_abstract,bib_paper_authors,bib_paper_year,bib_paper_month,bib_paper_url,bib_paper_doi,bib_paper_journal
EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents,http://arxiv.org/abs/2510.04648v1,lu2022learn,\cite{lu2022learn},"Learn to Explain: Multimodal Reasoning via Thought Chains for Science
  Question Answering",http://arxiv.org/abs/2209.09513v2,"When answering a question, humans utilize the information available across
different modalities to synthesize a consistent and complete chain of thought
(CoT). This process is normally a black box in the case of deep learning models
like large-scale language models. Recently, science question benchmarks have
been used to diagnose the multi-hop reasoning ability and interpretability of
an AI system. However, existing datasets fail to provide annotations for the
answers, or are restricted to the textual-only modality, small scales, and
limited domain diversity. To this end, we present Science Question Answering
(ScienceQA), a new benchmark that consists of ~21k multimodal multiple choice
questions with a diverse set of science topics and annotations of their answers
with corresponding lectures and explanations. We further design language models
to learn to generate lectures and explanations as the chain of thought (CoT) to
mimic the multi-hop reasoning process when answering ScienceQA questions.
ScienceQA demonstrates the utility of CoT in language models, as CoT improves
the question answering performance by 1.20% in few-shot GPT-3 and 3.99% in
fine-tuned UnifiedQA. We also explore the upper bound for models to leverage
explanations by feeding those in the input; we observe that it improves the
few-shot performance of GPT-3 by 18.96%. Our analysis further shows that
language models, similar to humans, benefit from explanations to learn from
fewer data and achieve the same performance with just 40% of the data. The data
and code are available at https://scienceqa.github.io.","Lu, Pan and Mishra, Swaroop and Xia, Tanglin and Qiu, Liang and Chang, Kai-Wei and Zhu, Song-Chun and Tafjord, Oyvind and Clark, Peter and Kalyan, Ashwin",2022,,,,Advances in Neural Information Processing Systems
EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents,http://arxiv.org/abs/2510.04648v1,huang2023c,\cite{huang2023c},C-eval: A multi-level multi-discipline chinese evaluation suite for foundation models,,,"Huang, Yuzhen and Bai, Yuzhuo and Zhu, Zhihao and Zhang, Junlei and Zhang, Jinghan and Su, Tangjun and Liu, Junteng and Lv, Chuancheng and Zhang, Yikai and Fu, Yao and others",2023,,,,Advances in Neural Information Processing Systems
EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents,http://arxiv.org/abs/2510.04648v1,ang2023socratic,\cite{ang2023socratic},"Socratic question generation: A novel dataset, models, and evaluation",,,"Ang, Beng Heng and Gollapalli, Sujatha Das and Ng, See Kiong",2023,,,,
EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents,http://arxiv.org/abs/2510.04648v1,amini2019mathqa,\cite{amini2019mathqa},"MathQA: Towards Interpretable Math Word Problem Solving with
  Operation-Based Formalisms",http://arxiv.org/abs/1905.13319v1,"We introduce a large-scale dataset of math word problems and an interpretable
neural math problem solver that learns to map problems to operation programs.
Due to annotation challenges, current datasets in this domain have been either
relatively small in scale or did not offer precise operational annotations over
diverse problem types. We introduce a new representation language to model
precise operation programs corresponding to each math problem that aim to
improve both the performance and the interpretability of the learned models.
Using this representation language, our new dataset, MathQA, significantly
enhances the AQuA dataset with fully-specified operational programs. We
additionally introduce a neural sequence-to-program model enhanced with
automatic problem categorization. Our experiments show improvements over
competitive baselines in our MathQA as well as the AQuA dataset. The results
are still significantly lower than human performance indicating that the
dataset poses new challenges for future research. Our dataset is available at:
https://math-qa.github.io/math-QA/","Amini, Aida and Gabriel, Saadia and Lin, Peter and Koncel-Kedziorski, Rik and Choi, Yejin and Hajishirzi, Hannaneh",2019,,,,arXiv preprint arXiv:1905.13319
EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents,http://arxiv.org/abs/2510.04648v1,lee2025multimodality,\cite{lee2025multimodality},"Multimodality of AI for Education: Towards Artificial General
  Intelligence",http://arxiv.org/abs/2312.06037v2,"This paper presents a comprehensive examination of how multimodal artificial
intelligence (AI) approaches are paving the way towards the realization of
Artificial General Intelligence (AGI) in educational contexts. It scrutinizes
the evolution and integration of AI in educational systems, emphasizing the
crucial role of multimodality, which encompasses auditory, visual, kinesthetic,
and linguistic modes of learning. This research delves deeply into the key
facets of AGI, including cognitive frameworks, advanced knowledge
representation, adaptive learning mechanisms, strategic planning, sophisticated
language processing, and the integration of diverse multimodal data sources. It
critically assesses AGI's transformative potential in reshaping educational
paradigms, focusing on enhancing teaching and learning effectiveness, filling
gaps in existing methodologies, and addressing ethical considerations and
responsible usage of AGI in educational settings. The paper also discusses the
implications of multimodal AI's role in education, offering insights into
future directions and challenges in AGI development. This exploration aims to
provide a nuanced understanding of the intersection between AI, multimodality,
and education, setting a foundation for future research and development in AGI.","Lee, Gyeonggeon and Shi, Lehong and Latif, Ehsan and Gao, Yizhu and Bewersdorff, Arne and Nyaaba, Matthew and Guo, Shuchen and Liu, Zhengliang and Mai, Gengchen and Liu, Tianming and others",2025,,,,IEEE Transactions on Learning Technologies
EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents,http://arxiv.org/abs/2510.04648v1,xiao2025eduvqa,\cite{xiao2025eduvqa},EduVQA: A multimodal Visual Question Answering framework for smart education,,,"Xiao, Jiongen and Zhang, Zifeng",2025,,,,Alexandria Engineering Journal
EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents,http://arxiv.org/abs/2510.04648v1,song2025emotional,\cite{song2025emotional},Emotional recognition and feedback of students in English e-learning based on computer vision and face recognition algorithms,,,"Song, Xiaohuan",2025,,,,Entertainment Computing
EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents,http://arxiv.org/abs/2510.04648v1,xie2025msc,\cite{xie2025msc},MSC-Trans: A Multi-Feature-Fusion Network With Encoding Structure for Student Engagement Detecting,,,"Xie, Nan and Li, Zhengxu and Lu, Haipeng and Pang, Wei and Song, Jiayin and Lu, Beier",2025,,,,IEEE Transactions on Learning Technologies
EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents,http://arxiv.org/abs/2510.04648v1,zhang2018personalizing,\cite{zhang2018personalizing},"Personalizing Dialogue Agents: I have a dog, do you have pets too?",http://arxiv.org/abs/1801.07243v5,"Chit-chat models are known to have several problems: they lack specificity,
do not display a consistent personality and are often not very captivating. In
this work we present the task of making chit-chat more engaging by conditioning
on profile information. We collect data and train models to (i) condition on
their given profile information; and (ii) information about the person they are
talking to, resulting in improved dialogues, as measured by next utterance
prediction. Since (ii) is initially unknown our model is trained to engage its
partner with personal topics, and we show the resulting dialogue can be used to
predict profile information about the interlocutors.","Zhang, Saizheng  and
      Dinan, Emily  and
      Urbanek, Jack  and
      Szlam, Arthur  and
      Kiela, Douwe  and
      Weston, Jason",2018,,https://aclanthology.org/P18-1205/,10.18653/v1/P18-1205,
EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents,http://arxiv.org/abs/2510.04648v1,zheng2019personalized,\cite{zheng2019personalized},Personalized Dialogue Generation with Diversified Traits,http://arxiv.org/abs/1901.09672v2,"Endowing a dialogue system with particular personality traits is essential to
deliver more human-like conversations. However, due to the challenge of
embodying personality via language expression and the lack of large-scale
persona-labeled dialogue data, this research problem is still far from
well-studied. In this paper, we investigate the problem of incorporating
explicit personality traits in dialogue generation to deliver personalized
dialogues.
  To this end, firstly, we construct PersonalDialog, a large-scale multi-turn
dialogue dataset containing various traits from a large number of speakers. The
dataset consists of 20.83M sessions and 56.25M utterances from 8.47M speakers.
Each utterance is associated with a speaker who is marked with traits like Age,
Gender, Location, Interest Tags, etc. Several anonymization schemes are
designed to protect the privacy of each speaker. This large-scale dataset will
facilitate not only the study of personalized dialogue generation, but also
other researches on sociolinguistics or social science.
  Secondly, to study how personality traits can be captured and addressed in
dialogue generation, we propose persona-aware dialogue generation models within
the sequence to sequence learning framework. Explicit personality traits
(structured by key-value pairs) are embedded using a trait fusion module.
During the decoding process, two techniques, namely persona-aware attention and
persona-aware bias, are devised to capture and address trait-related
information. Experiments demonstrate that our model is able to address proper
traits in different contexts. Case studies also show interesting results for
this challenging research problem.","Zheng, Yinhe and Chen, Guanyi and Huang, Minlie and Liu, Song and Zhu, Xuan",2019,,,,arXiv preprint arXiv:1901.09672
EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents,http://arxiv.org/abs/2510.04648v1,kar2025convergence,\cite{kar2025convergence},Convergence of Chatbot Personalities Using Reinforcement Learning and Text Generation,,,"Kar, Parijat and Kar, Ridhima",2025,,,,
EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents,http://arxiv.org/abs/2510.04648v1,ouyang2022training,\cite{ouyang2022training},Training language models to follow instructions with human feedback,,,"Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",2022,,,,Advances in neural information processing systems
EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents,http://arxiv.org/abs/2510.04648v1,bai2022constitutional,\cite{bai2022constitutional},Constitutional AI: Harmlessness from AI Feedback,http://arxiv.org/abs/2212.08073v1,"As AI systems become more capable, we would like to enlist their help to
supervise other AIs. We experiment with methods for training a harmless AI
assistant through self-improvement, without any human labels identifying
harmful outputs. The only human oversight is provided through a list of rules
or principles, and so we refer to the method as 'Constitutional AI'. The
process involves both a supervised learning and a reinforcement learning phase.
In the supervised phase we sample from an initial model, then generate
self-critiques and revisions, and then finetune the original model on revised
responses. In the RL phase, we sample from the finetuned model, use a model to
evaluate which of the two samples is better, and then train a preference model
from this dataset of AI preferences. We then train with RL using the preference
model as the reward signal, i.e. we use 'RL from AI Feedback' (RLAIF). As a
result we are able to train a harmless but non-evasive AI assistant that
engages with harmful queries by explaining its objections to them. Both the SL
and RL methods can leverage chain-of-thought style reasoning to improve the
human-judged performance and transparency of AI decision making. These methods
make it possible to control AI behavior more precisely and with far fewer human
labels.","Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others",2022,,,,arXiv preprint arXiv:2212.08073
EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents,http://arxiv.org/abs/2510.04648v1,chen2024persona,\cite{chen2024persona},"From Persona to Personalization: A Survey on Role-Playing Language
  Agents",http://arxiv.org/abs/2404.18231v2,"Recent advancements in large language models (LLMs) have significantly
boosted the rise of Role-Playing Language Agents (RPLAs), i.e., specialized AI
systems designed to simulate assigned personas. By harnessing multiple advanced
abilities of LLMs, including in-context learning, instruction following, and
social intelligence, RPLAs achieve a remarkable sense of human likeness and
vivid role-playing performance. RPLAs can mimic a wide range of personas,
ranging from historical figures and fictional characters to real-life
individuals. Consequently, they have catalyzed numerous AI applications, such
as emotional companions, interactive video games, personalized assistants and
copilots, and digital clones. In this paper, we conduct a comprehensive survey
of this field, illustrating the evolution and recent progress in RPLAs
integrating with cutting-edge LLM technologies. We categorize personas into
three types: 1) Demographic Persona, which leverages statistical stereotypes;
2) Character Persona, focused on well-established figures; and 3)
Individualized Persona, customized through ongoing user interactions for
personalized services. We begin by presenting a comprehensive overview of
current methodologies for RPLAs, followed by the details for each persona type,
covering corresponding data sourcing, agent construction, and evaluation.
Afterward, we discuss the fundamental risks, existing limitations, and future
prospects of RPLAs. Additionally, we provide a brief review of RPLAs in AI
applications, which reflects practical user demands that shape and drive RPLA
research. Through this work, we aim to establish a clear taxonomy of RPLA
research and applications, and facilitate future research in this critical and
ever-evolving field, and pave the way for a future where humans and RPLAs
coexist in harmony.",Jiangjie Chen and Xintao Wang and Rui Xu and Siyu Yuan and Yikai Zhang and Wei Shi and Jian Xie and Shuang Li and Ruihan Yang and Tinghui Zhu and Aili Chen and Nianqi Li and Lida Chen and Caiyu Hu and Siye Wu and Scott Ren and Ziquan Fu and Yanghua Xiao,2024,,,,Transactions on Machine Learning Research
