parent_paper_title,parent_arxiv_link,citation_shorthand,raw_citation_text,cited_paper_title,cited_paper_arxiv_link,cited_paper_abstract,bib_paper_authors,bib_paper_year,bib_paper_month,bib_paper_url,bib_paper_doi,bib_paper_journal
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,pakov2019collaborative,\cite{pakov2019collaborative},Eye gaze and head gaze in collaborative games,,,"\v{S}pakov, Oleg and Istance, Howell and R\""{a}ih\""{a}, Kari-Jouko and Viitanen, Tiia and Siirtola, Harri",2019,,https://doi.org/10.1145/3317959.3321489,10.1145/3317959.3321489,
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,isokoski2009gazeGame,\cite{isokoski2009gazeGame},Gaze controlled games,,,"Isokoski, Poika and Joos, Markus and Spakov, Oleg and Martin, Beno{\^\i}t",2009,,,,Universal Access in the Information Society
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,Lui2021iText,\cite{Lui2021iText},iText: Hands-free Text Entry on an Imaginary Keyboard for Augmented Reality Systems,,,"Lu, Xueshi and Yu, Difeng and Liang, Hai-Ning and Goncalves, Jorge",2021,,https://doi.org/10.1145/3472749.3474788,10.1145/3472749.3474788,
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,Kurauchi2016GazeTextEntry,\cite{Kurauchi2016GazeTextEntry},EyeSwipe: Dwell-free Text Entry Using Gaze Paths,,,"Kurauchi, Andrew and Feng, Wenxin and Joshi, Ajjen and Morimoto, Carlos and Betke, Margrit",2016,,https://doi.org/10.1145/2858036.2858335,10.1145/2858036.2858335,
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,HedeshyCHI21GazeHumTextEntry,\cite{HedeshyCHI21GazeHumTextEntry},Hummer: Text Entry by Gaze and Hum,,,"Hedeshy, Ramin and Kumar, Chandan and Menges, Raphael and Staab, Steffen",2021,,https://doi.org/10.1145/3411764.3445501,10.1145/3411764.3445501,
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,meng2022textselection,\cite{meng2022textselection},"An Exploration of Hands-free Text Selection for Virtual Reality
  Head-Mounted Displays",http://arxiv.org/abs/2209.06825v2,"Hand-based interaction, such as using a handheld controller or making hand
gestures, has been widely adopted as the primary method for interacting with
both virtual reality (VR) and augmented reality (AR) head-mounted displays
(HMDs). In contrast, hands-free interaction avoids the need for users' hands
and although it can afford additional benefits, there has been limited research
in exploring and evaluating hands-free techniques for these HMDs. As VR HMDs
become ubiquitous, people will need to do text editing, which requires
selecting text segments. Similar to hands-free interaction, text selection is
underexplored. This research focuses on both, text selection via hands-free
interaction. Our exploration involves a user study with 24 participants to
investigate the performance, user experience, and workload of three hands-free
selection mechanisms (Dwell, Blink, Voice) to complement head-based pointing.
Results indicate that Blink outperforms Dwell and Voice in completion time.
Users' subjective feedback also shows that Blink is the preferred technique for
text selection. This work is the first to explore hands-free interaction for
text selection in VR HMDs. Our results provide a solid platform for further
research in this important area.","Meng, Xuanru and Xu, Wenge and Liang, Hai-Ning",2022,,,10.1109/ISMAR55827.2022.00021,
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,Stellmach2012gazeui,\cite{Stellmach2012gazeui},Designing gaze-based user interfaces for steering in virtual environments,,,"Stellmach, Sophie and Dachselt, Raimund",2012,,https://doi.org/10.1145/2168556.2168577,10.1145/2168556.2168577,
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,piotrowski2019gaze,\cite{piotrowski2019gaze},Gaze-based interaction for VR environments,,,"Piotrowski, Patryk and Nowosielski, Adam",2019,,,,
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,kang2024rayhand,\cite{kang2024rayhand},The rayhand navigation: A virtual navigation method with relative position between hand and gaze-ray,,,"Kang, Sei and Jeong, Jaejoon and Lee, Gun A and Kim, Soo-Hyung and Yang, Hyung-Jeong and Kim, Seungwon",2024,,,,
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,Yushi25TVCGSteeringLatency,\cite{Yushi25TVCGSteeringLatency},Evaluating and Modeling the Effect of Frame Rate on Steering Performance in Virtual Reality,,,"Wei, Yushi and Shi, Rongkai and Batmaz, Anil Ufuk and Li, Yue and Huang, Mengjie and Yang, Rui and Liang, Hai-Ning",2025,,,10.1109/TVCG.2024.3451491,IEEE Transactions on Visualization and Computer Graphics
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,Yushi24TVCGSteeringDirection,\cite{Yushi24TVCGSteeringDirection},Exploring and Modeling Directional Effects on Steering Behavior in Virtual Reality,,,"Wei, Yushi and Xu, Kemu and Li, Yue and Yu, Lingyun and Liang, Hai-Ning",2024,,,10.1109/TVCG.2024.3456166,IEEE Transactions on Visualization and Computer Graphics
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,Sidenmark2023Comparing,\cite{Sidenmark2023Comparing},"Comparing Gaze, Head and Controller Selection of Dynamically Revealed Targets in Head-Mounted Displays",,,"Sidenmark, Ludwig and Prummer, Franziska and Newn, Joshua and Gellersen, Hans",2023,,,10.1109/TVCG.2023.3320235,IEEE Transactions on Visualization and Computer Graphics
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,Majaranta2014Tracking,\cite{Majaranta2014Tracking},Eye Tracking and Eye-Based Human--Computer Interaction,,,"Majaranta, P{\",2014,,https://doi.org/10.1007/978-1-4471-6392-3_3,10.1007/978-1-4471-6392-3_3,
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,SibertCHI00GazeSelection,\cite{SibertCHI00GazeSelection},Evaluation of eye gaze interaction,,,"Sibert, Linda E. and Jacob, Robert J. K.",2000,,https://doi.org/10.1145/332040.332445,10.1145/332040.332445,
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,Xueshi2021UISTHandsfree,\cite{Xueshi2021UISTHandsfree},iText: Hands-free Text Entry on an Imaginary Keyboard for Augmented Reality Systems,,,"Lu, Xueshi and Yu, Difeng and Liang, Hai-Ning and Goncalves, Jorge",2021,,https://doi.org/10.1145/3472749.3474788,10.1145/3472749.3474788,
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,Xueshi2020IsmarHandsfree,\cite{Xueshi2020IsmarHandsfree},Exploration of Hands-free Text Entry Techniques For Virtual Reality,http://arxiv.org/abs/2010.03247v1,"Text entry is a common activity in virtual reality (VR) systems. There is a
limited number of available hands-free techniques, which allow users to carry
out text entry when users' hands are busy such as holding items or hand-based
devices are not available. The most used hands-free text entry technique is
DwellType, where a user selects a letter by dwelling over it for a specific
period. However, its performance is limited due to the fixed dwell time for
each character selection. In this paper, we explore two other hands-free text
entry mechanisms in VR: BlinkType and NeckType, which leverage users' eye
blinks and neck's forward and backward movements to select letters. With a user
study, we compare the performance of the two techniques with DwellType. Results
show that users can achieve an average text entry rate of 13.47, 11.18 and
11.65 words per minute with BlinkType, NeckType, and DwellType, respectively.
Users' subjective feedback shows BlinkType as the preferred technique for text
entry in VR.","Lu, Xueshi and Yu, Difeng and Liang, Hai-Ning and Xu, Wenge and Chen, Yuzheng and Li, Xiang and Hasan, Khalad",2020,,,10.1109/ISMAR50242.2020.00061,
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,Scott2004motor,\cite{Scott2004motor},Optimal feedback control and the neural basis of volitional motor control,,,"Scott, Stephen H.",2004,,https://doi.org/10.1038/nrn1427,10.1038/nrn1427,Nature Reviews Neuroscience
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,Kenneth2011eyemovement,\cite{Kenneth2011eyemovement},Eye Tracking : A Comprehensive Guide to Methods and Measures,,,Kenneth Holmqvist and Marcus Nystr{\,2011,,,,
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,Prablanc1978saccades,\cite{Prablanc1978saccades},Error-correcting mechanisms in large saccades,,,C. Prablanc and D. Mass√© and J.F. Echallier,1978,,https://www.sciencedirect.com/science/article/pii/004269897890202X,https://doi.org/10.1016/0042-6989(78)90202-X,Vision Research
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,xuning2025CHILBW,\cite{xuning2025CHILBW},Exploring and Modeling Gaze-Based Steering Behavior in Virtual Reality,,,"Hu, Xuning and Zhang, Yichuan and Wei, Yushi and Li, Yue and Stuerzlinger, Wolfgang and Liang, Hai-Ning",2025,,https://doi.org/10.1145/3706599.3720273,10.1145/3706599.3720273,
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,Zhang2010dwell-based,\cite{Zhang2010dwell-based},Modeling dwell-based eye pointing target acquisition,,,"Zhang, Xinyong and Ren, Xiangshi and Zha, Hongbin",2010,,https://doi.org/10.1145/1753326.1753645,10.1145/1753326.1753645,
Exploring the Feasibility of Gaze-Based Navigation Across Path Types,http://arxiv.org/abs/2510.07184v1,accot1997beyond,\cite{accot1997beyond},Beyond Fitts' law: models for trajectory-based HCI tasks,,,"Accot, Johnny and Zhai, Shumin",1997,,,,
