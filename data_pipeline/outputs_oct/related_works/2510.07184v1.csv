arxiv_id,arxiv_link,publication_date,title,abstract,raw_latex_related_works,clean_latex_related_works,pdf_related_works
2510.07184v1,http://arxiv.org/abs/2510.07184v1,2025-10-08 16:21:55+00:00,Exploring the Feasibility of Gaze-Based Navigation Across Path Types,"Gaze input, as a modality inherently conveying user intent, offers intuitive
and immersive experiences in extended reality (XR). With eye-tracking now being
a standard feature in modern XR headsets, gaze has been extensively applied to
tasks such as selection, text entry, and object manipulation. However, gaze
based navigation despite being a fundamental interaction task remains largely
underexplored. In particular, little is known about which path types are well
suited for gaze navigation and under what conditions it performs effectively.
To bridge this gap, we conducted a controlled user study evaluating gaze-based
navigation across three representative path types: linear, narrowing, and
circular. Our findings reveal distinct performance characteristics and
parameter ranges for each path type, offering design insights and practical
guidelines for future gaze-driven navigation systems in XR.","With the increasing adoption of eye-tracking technologies, commercial Head-Mounted Devices (HMDs) such as the Apple Vision Pro, Meta Quest Pro, and HTC Vive Focus 3 have begun to integrate gaze tracking as a key input modality. As a maturing technology, eye tracking has been applied across a wide range of domains, including gaming~\cite{pakov2019collaborative, isokoski2009gazeGame}, text entry~\cite{Lui2021iText, Kurauchi2016GazeTextEntry, HedeshyCHI21GazeHumTextEntry}, target selection~\cite{meng2022textselection}, user interface design~\cite{Stellmach2012gazeui,piotrowski2019gaze}, and navigation~\cite{kang2024rayhand, Yushi25TVCGSteeringLatency, Yushi24TVCGSteeringDirection}---either as a standalone input method or as an auxiliary modality combined with other interactions.

Gaze-based interaction offers an intuitive, hands-free alternative to conventional input methods~\cite{Sidenmark2023Comparing, Majaranta2014Tracking, SibertCHI00GazeSelection}. This makes it especially attractive in scenarios where manual input is limited or undesired~\cite{Xueshi2021UISTHandsfree, Xueshi2020IsmarHandsfree}. However, it differs fundamentally from traditional pointer-based control. Scott et al.~\cite{Scott2004motor} attributed the higher re-entry rates in gaze-based input to intrinsic limitations of the gaze system---unlike regular cursor-based input, users cannot rely on continuous visual feedback for correction and must instead make predictive adjustments. Holmqvist et al. further observed that during correction phases, users tend to alternate between short saccades and fixations~\cite{Kenneth2011eyemovement}, ranging from 100 milliseconds to several seconds, stabilizing the cursor and using saccades to compensate for positional discrepancies~\cite{Prablanc1978saccades}.

While prior work has modeled gaze-based selection and steering tasks using adapted versions of Fitts’ Law and the Steering Law~\cite{xuning2025CHILBW, Zhang2010dwell-based}, research on gaze-based performance in more complex trajectory-based navigation tasks remains limited. Key path parameters, such as curvature and path narrowing, may significantly affect user performance in trajectory-based navigation~\cite{accot1997beyond}. Yet their influence on the gaze-based navigation task has not been systematically studied. Given that trajectory-based tasks differ notably from linear steering tasks in both motor behavior and cognitive demands, further investigation is needed to understand how these path parameters affect gaze-based navigation in immersive VR environments.





\begin{figure*}[htb]
  \centering
  \includegraphics[width=\linewidth]{figures/ExperimentRevised.png}
  \caption{The red sphere indicates the user’s gaze cursor, while the green and blue spheres denote the task’s start and end positions, respectively. The path width is defined by the diameter of the target sphere. Participants manipulate the gaze cursor to guide the target sphere from the start area to the target area along the specified trajectory. (a) Constant-width Linear Path Task; (b) Narrowing Path Task; (c) Constant-Width Circular Path Task.}
  \label{F: Experiment Design}
\end{figure*}","With the increasing adoption of eye-tracking technologies, commercial Head-Mounted Devices (HMDs) such as the Apple Vision Pro, Meta Quest Pro, and HTC Vive Focus 3 have begun to integrate gaze tracking as a key input modality. As a maturing technology, eye tracking has been applied across a wide range of domains, including gaming~\cite{pakov2019collaborative, isokoski2009gazeGame}, text entry~\cite{Lui2021iText, Kurauchi2016GazeTextEntry, HedeshyCHI21GazeHumTextEntry}, target selection~\cite{meng2022textselection}, user interface design~\cite{Stellmach2012gazeui,piotrowski2019gaze}, and navigation~\cite{kang2024rayhand, Yushi25TVCGSteeringLatency, Yushi24TVCGSteeringDirection}---either as a standalone input method or as an auxiliary modality combined with other interactions.

Gaze-based interaction offers an intuitive, hands-free alternative to conventional input methods~\cite{Sidenmark2023Comparing, Majaranta2014Tracking, SibertCHI00GazeSelection}. This makes it especially attractive in scenarios where manual input is limited or undesired~\cite{Xueshi2021UISTHandsfree, Xueshi2020IsmarHandsfree}. However, it differs fundamentally from traditional pointer-based control. Scott et al.~\cite{Scott2004motor} attributed the higher re-entry rates in gaze-based input to intrinsic limitations of the gaze system---unlike regular cursor-based input, users cannot rely on continuous visual feedback for correction and must instead make predictive adjustments. Holmqvist et al. further observed that during correction phases, users tend to alternate between short saccades and fixations~\cite{Kenneth2011eyemovement}, ranging from 100 milliseconds to several seconds, stabilizing the cursor and using saccades to compensate for positional discrepancies~\cite{Prablanc1978saccades}.

While prior work has modeled gaze-based selection and steering tasks using adapted versions of Fitts’ Law and the Steering Law~\cite{xuning2025CHILBW, Zhang2010dwell-based}, research on gaze-based performance in more complex trajectory-based navigation tasks remains limited. Key path parameters, such as curvature and path narrowing, may significantly affect user performance in trajectory-based navigation~\cite{accot1997beyond}. Yet their influence on the gaze-based navigation task has not been systematically studied. Given that trajectory-based tasks differ notably from linear steering tasks in both motor behavior and cognitive demands, further investigation is needed to understand how these path parameters affect gaze-based navigation in immersive VR environments.",N/A
