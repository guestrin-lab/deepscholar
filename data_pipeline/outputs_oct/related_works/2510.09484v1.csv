arxiv_id,arxiv_link,publication_date,title,abstract,raw_latex_related_works,clean_latex_related_works,pdf_related_works
2510.09484v1,http://arxiv.org/abs/2510.09484v1,2025-10-10 15:48:31+00:00,CRPS-LAM: Regional ensemble weather forecasting from matching marginals,"Machine learning for weather prediction increasingly relies on ensemble
methods to provide probabilistic forecasts. Diffusion-based models have shown
strong performance in Limited-Area Modeling (LAM) but remain computationally
expensive at sampling time. Building on the success of global weather
forecasting models trained based on Continuous Ranked Probability Score (CRPS),
we introduce CRPS-LAM, a probabilistic LAM forecasting model trained with a
CRPS-based objective. By sampling and injecting a single latent noise vector
into the model, CRPS-LAM generates ensemble members in a single forward pass,
achieving sampling speeds up to 39 times faster than a diffusion-based model.
We evaluate the model on the MEPS regional dataset, where CRPS-LAM matches the
low errors of diffusion models. By retaining also fine-scale forecast details,
the method stands out as an effective approach for probabilistic regional
weather forecasting","\paragraph{Related Work.}
% Scoring rule based training objectives have been applied in a range of probabilistic prediction tasks, including hand pose estimation from images \citep{disconets} and, more recently,
\looseness=-1 Recently, CRPS-based training objectives have been successfully applied to global \acrshort{mlwp} models \citep{prob_fc_scoring_rules,lang2024aifscrpsensembleforecastingusing,lang_multi-scale,fourcastnet3,FGNalet2025skillfuljointprobabilisticweather,oskarsson2024probabilistic}. These approaches differ primarily in how the \acrshort{crps} is estimated and how stochasticity is introduced into the model. However, all these methods can produce skillful ensemble forecasts with a single forward pass through the network. A particularly convenient formulation is that of \citet{FGNalet2025skillfuljointprobabilisticweather}, which employs a similar conditioning mechanism commonly used in diffusion models, thereby enabling a simple transformation from a diffusion-based model to a CRPS-based one.

Previous approaches to probabilistic \acrshort{lam} have primarily relied on diffusion-based methods \citep{stormCast,larsson2025diffusionlam,hrrrcast}. Diffusion models have demonstrated strong forecasting performance, but at substantial computational cost during sampling of ensemble members. The Graph-EFM latent variable model \citep{oskarsson2023graph-lam} is capable of probabilistic \acrshort{lam} forecasting in a single forward pass, similar to our method.
Although it also incorporates a CRPS-based regularization term in its training objective, the Graph-EFM training mainly relies on a more involved variational framework.","\paragraph{Related Work.}

\looseness=-1 Recently, CRPS-based training objectives have been successfully applied to global \acrshort{mlwp} models \citep{prob_fc_scoring_rules,lang2024aifscrpsensembleforecastingusing,lang_multi-scale,fourcastnet3,FGNalet2025skillfuljointprobabilisticweather,oskarsson2024probabilistic}. These approaches differ primarily in how the \acrshort{crps} is estimated and how stochasticity is introduced into the model. However, all these methods can produce skillful ensemble forecasts with a single forward pass through the network. A particularly convenient formulation is that of \citet{FGNalet2025skillfuljointprobabilisticweather}, which employs a similar conditioning mechanism commonly used in diffusion models, thereby enabling a simple transformation from a diffusion-based model to a CRPS-based one.

Previous approaches to probabilistic \acrshort{lam} have primarily relied on diffusion-based methods \citep{stormCast,larsson2025diffusionlam,hrrrcast}. Diffusion models have demonstrated strong forecasting performance, but at substantial computational cost during sampling of ensemble members. The Graph-EFM latent variable model \citep{oskarsson2023graph-lam} is capable of probabilistic \acrshort{lam} forecasting in a single forward pass, similar to our method.
Although it also incorporates a CRPS-based regularization term in its training objective, the Graph-EFM training mainly relies on a more involved variational framework.","MLWP models [Pacchiardi et al., 2024, Lang et al., 2024b, 2025, Bonev et al., 2025, Alet et al., 2025,
Oskarsson et al., 2024]. These approaches differ primarily in how the CRPS is estimated and how
stochasticity is introduced into the model. However, all these methods can produce skillful ensemble
forecasts with a single forward pass through the network. A particularly convenient formulation is that
of Alet et al. [2025], which employs a similar conditioning mechanism commonly used in diffusion
models, thereby enabling a simple transformation from a diffusion-based model to a CRPS-based one.
Previous approaches to probabilistic LAM have primarily relied on diffusion-based methods [Pathak
et al., 2024, Larsson et al., 2025, Abdi et al., 2025]. Diffusion models have demonstrated strong
forecasting performance, but at substantial computational cost during sampling of ensemble members.
The Graph-EFM latent variable model [Oskarsson et al., 2023] is capable of probabilistic LAM
forecasting in a single forward pass, similar to our method. Although it also incorporates a CRPS-
based regularization term in its training objective, the Graph-EFM training mainly relies on a more
involved variational framework."
