arxiv_id,arxiv_link,publication_date,title,abstract,raw_latex_related_works,clean_latex_related_works,pdf_related_works
2510.10113v1,http://arxiv.org/abs/2510.10113v1,2025-10-11 08:43:38+00:00,ImmerIris: A Large-Scale Dataset and Benchmark for Immersive Iris Recognition in Open Scenes,"In egocentric applications such as augmented and virtual reality, immersive
iris recognition is emerging as an accurate and seamless way to identify
persons. While classic systems acquire iris images on-axis, i.e., via dedicated
frontal sensors in controlled settings, the immersive setup primarily captures
off-axis irises through tilt-placed headset cameras, with only mild control in
open scenes. This yields unique challenges, including perspective distortion,
intensified quality degradations, and intra-class variations in iris texture.
Datasets capturing these challenges remain scarce. To fill this gap, this paper
introduces ImmerIris, a large-scale dataset collected via VR headsets,
containing 499,791 ocular images from 564 subjects. It is, to the best of
current knowledge, the largest public dataset and among the first dedicated to
off-axis acquisition. Based on ImmerIris, evaluation protocols are constructed
to benchmark recognition methods under different challenging factors. Current
methods, primarily designed for classic on-axis imagery, perform
unsatisfactorily on the immersive setup, mainly due to reliance on fallible
normalization. To this end, this paper further proposes a normalization-free
paradigm that directly learns from ocular images with minimal adjustment.
Despite its simplicity, this approach consistently outperforms
normalization-based counterparts, pointing to a promising direction for robust
immersive recognition.","\label{sec:rw}


\subsection{Iris Recognition}
\label{subsec:rw-ir}

Existing iris recognition methods mostly operate on normalized iris textures rather than raw ocular images~\cite{nguyen2024deep}. They first employ \textit{normalization} that segments the pupillary region~\cite{daugman2002high,he2008toward,vatsa2008improving}, parameterizes the iris contour~\cite{shah2009iris,proenca2009iris}, and usually unwraps it into a rectangular strip via polar transform~\cite{daugman2009iris}, followed by \textit{feature extraction} that generates identity-discriminative templates. \textit{Training-free} methods apply hand-crafted filters, \eg, Gabor~\cite{daugman2009iris}, to produce binarized \textit{iriscodes} and match them with Hamming distance~\cite{norouzi2012hamming}, with variants such as log-Gabor~\cite{ali2007recognition}, ordinal measure~\cite{sun2008ordinal}, sparse representation~\cite{pillai2011secure}, and phase correlation~\cite{miyazawa2008effective}. More recently, \textit{learning-based} methods employ DNNs for hierarchical feature extraction, improving robustness and accuracy with CNNs~\cite{gangwar2016deepirisnet,nguyen2017iris,zhang2018deep,wei2022towards}, FCNs~\cite{zhao2017towards}, Mask R-CNN~\cite{zhao2019deep}, DenseNet~\cite{wang2019toward,boutros2020benchmarking}, ResNet~\cite{boutros2020benchmarking}, and specialized backbones incorporating periocular cues~\cite{wei2022contextual,nguyen2022complex,zhao2018improving}. Though these methods achieve exciting results in controlled setups~\cite{nguyen2017long} and to some extent under non-ideal imaging~\cite{wang2020recognition}, they are not designed for the immersive setup and perform unsatisfactorily under off-axis distortion, quality degradation, and large variations, as discussed in~\cref{sec:baseline} and validated in~\cref{sec:benchmark}.

% Existing IR methods typically operate on extracted iris textures instead of raw ocular images. A normalization stage is first employed to circularly or elliptically segment the pupillary region~\cite{daugman2002high,he2008toward,vatsa2008improving}, parameterize the iris contour~\cite{shah2009iris,proenca2009iris}, and in most time polarly transform the contoured (bounded?) region into a rectangular shape~\cite{daugman2009iris}. After that, feature extraction is performed to generate identity-discriminative feature templates. Among them, training-free methods use hand-crafted filters, \eg, Gabor filter~\cite{daugman2009iris}, to encode normalized iris into binarized templates, referred to as \textit{iriscodes}, and efficiently matching them via Hamming distance~\cite{norouzi2012hamming}. Other variants in literature includes log-Gabor filter~\cite{ali2007recognition}, ordinal measure~\cite{sun2008ordinal},sparse representation~\cite{pillai2011secure}, and phase correlation~\cite{miyazawa2008effective}.  More recently, learning-based methods use DNNs to hirachically extract features and presents more robust and advancing matching accuracy. They are built upon various model architectures~\cite{long2015fully,he2017mask,he2016deep,}, such as on CNN~\cite{gangwar2016deepirisnet,nguyen2017iris,zhang2018deep,wei2022towards}, FCN~\cite{zhao2017towards}, Mask R-CNN~\cite{zhao2019deep},  DenseNet~\cite{wang2019toward,boutros2020benchmarking}, ResNet~\cite{boutros2020benchmarking}, and designated backbones that further incorporate periocular features~\cite{wei2022contextual,nguyen2022complex,zhao2018improving}. These methods have shown exciting results in conventional controlled setups~\cite{nguyen2017long} and partly for non-ideal imaging. However, they are not designed and perform unsatisfactorily on immersive IR where images are captured in open scene and bearing distortions, degradations and rich variations, as later discussed in~\cref{sec:baseline} and experimentally found in~\cref{sec:benchmark}.

% Classical iris recognition methods often adopt the rubber-sheet model for normalization and 2D Gabor filters for phase encoding, producing binary IrisCodes that are compared using Hamming distance. Variants employ 1D log-Gabor filters, while other handcrafted approaches—such as ordinal filters, sparse representation, and phase correlation—have also shown strong performance on images from conventional sensors. Yet, their reliance on stop-and-stare acquisition limits applicability in unconstrained settings, motivating research on more flexible segmentation and matching techniques.

% For non-ideal imaging, Daugman introduced active-contour–based elliptical segmentation, while others applied perspective transforms to recover frontal views. More recent learning-based attempts at off-angle recognition often rely on manual or ground-truth masks and struggle to preserve spatial consistency.

% Deep neural networks have since driven major advances. DeepIrisNet demonstrated direct use of CNNs for iris recognition without domain-specific optimization, and Nguyen et al. explored pretrained CNN features combined with SVMs. More specialized designs include UniNet, which generates mask-guided IrisCode-like features via fully convolutional branches, later improved with Mask R-CNN for segmentation. Other frameworks leverage dilated residual kernels. Boutros et al. further investigated gaze-based recognition with pretrained models such as ResNet, DenseNet, and MobileNetV3, reflecting the growing role of advanced CNNs in the field.


\subsection{Iris Recognition Datasets}
\label{subsec:rw-ird}

\input{tab/tab_rw_dataset}

Early iris recognition datasets were primarily collected in controlled setups using either visible light (VIS) or near-infrared (NIR) sensors, where both extrinsic and intrinsic conditions were strictly regulated~\cite{omelina2021survey}. Representative examples include CASIA-IrisV1~\cite{casia-iris-v1} and its update CASIA-IrisV4~\cite{casia-iris-v4}, the IIT Delhi database~\cite{kumar2010comparison}, the CUHK Iris dataset~\cite{chun2004iris}, and ND-CrossSensor~\cite{arora2012iris,xiao2013coupled}. Later efforts introduced semi-controlled scenarios with richer variations, such as acquisition via smartphones~\cite{rattani2016icip,zhang2016btas}, at-a-distance imaging~\cite{proencca2009ubiris}, or noise injection~\cite{proencca2005ubiris}. A recent work~\cite{wang2022human} is related to ours in that it also employs VR/AR devices for iris acquisition. However, their images exhibit much less off-axis distortion and lack diversity in such as illumination changes. Current datasets are briefly summarized in~\cref{tab:rw-dataset} and further discussed in the supplementary material. Overall, they fall short for the immersive setups due to 3 limitations: 1) small scale in images and subjects; 2) some being proprietary or unavailable; and 3) insufficient coverage of intra-class variation and off-axis geometric distortion. To address these gaps, we present ImmerIris, a large-scale, open-scene dataset dedicated to immersive iris recognition, which we believe will substantially advance research in this field. % To address these gaps, we present ImmerIris, a large-scale, open-scene dataset dedicated to immersive iris recognition, which we believe will substantially advance research in this field.","\subsection{Iris Recognition}

Existing iris recognition methods mostly operate on normalized iris textures rather than raw ocular images~\cite{nguyen2024deep}. They first employ \textit{normalization} that segments the pupillary region~\cite{daugman2002high,he2008toward,vatsa2008improving}, parameterizes the iris contour~\cite{shah2009iris,proenca2009iris}, and usually unwraps it into a rectangular strip via polar transform~\cite{daugman2009iris}, followed by \textit{feature extraction} that generates identity-discriminative templates. \textit{Training-free} methods apply hand-crafted filters, \eg, Gabor~\cite{daugman2009iris}, to produce binarized \textit{iriscodes} and match them with Hamming distance~\cite{norouzi2012hamming}, with variants such as log-Gabor~\cite{ali2007recognition}, ordinal measure~\cite{sun2008ordinal}, sparse representation~\cite{pillai2011secure}, and phase correlation~\cite{miyazawa2008effective}. More recently, \textit{learning-based} methods employ DNNs for hierarchical feature extraction, improving robustness and accuracy with CNNs~\cite{gangwar2016deepirisnet,nguyen2017iris,zhang2018deep,wei2022towards}, FCNs~\cite{zhao2017towards}, Mask R-CNN~\cite{zhao2019deep}, DenseNet~\cite{wang2019toward,boutros2020benchmarking}, ResNet~\cite{boutros2020benchmarking}, and specialized backbones incorporating periocular cues~\cite{wei2022contextual,nguyen2022complex,zhao2018improving}. Though these methods achieve exciting results in controlled setups~\cite{nguyen2017long} and to some extent under non-ideal imaging~\cite{wang2020recognition}, they are not designed for the immersive setup and perform unsatisfactorily under off-axis distortion, quality degradation, and large variations, as discussed in~\cref{sec:baseline} and validated in~\cref{sec:benchmark}.










\subsection{Iris Recognition Datasets}

\input{tab/tab_rw_dataset}

Early iris recognition datasets were primarily collected in controlled setups using either visible light (VIS) or near-infrared (NIR) sensors, where both extrinsic and intrinsic conditions were strictly regulated~\cite{omelina2021survey}. Representative examples include CASIA-IrisV1~\cite{casia-iris-v1} and its update CASIA-IrisV4~\cite{casia-iris-v4}, the IIT Delhi database~\cite{kumar2010comparison}, the CUHK Iris dataset~\cite{chun2004iris}, and ND-CrossSensor~\cite{arora2012iris,xiao2013coupled}. Later efforts introduced semi-controlled scenarios with richer variations, such as acquisition via smartphones~\cite{rattani2016icip,zhang2016btas}, at-a-distance imaging~\cite{proencca2009ubiris}, or noise injection~\cite{proencca2005ubiris}. A recent work~\cite{wang2022human} is related to ours in that it also employs VR/AR devices for iris acquisition. However, their images exhibit much less off-axis distortion and lack diversity in such as illumination changes. Current datasets are briefly summarized in~\cref{tab:rw-dataset} and further discussed in the supplementary material. Overall, they fall short for the immersive setups due to 3 limitations: 1) small scale in images and subjects; 2) some being proprietary or unavailable; and 3) insufficient coverage of intra-class variation and off-axis geometric distortion. To address these gaps, we present ImmerIris, a large-scale, open-scene dataset dedicated to immersive iris recognition, which we believe will substantially advance research in this field.",N/A
