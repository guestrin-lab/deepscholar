qid,query,nuggets,supported_nuggets,partially_supported_nuggets,nuggets_metrics
2511.10376v1,"Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:
Embodied navigation is a fundamental capability for robotic agents operating. Real-world deployment requires open vocabulary generalization and low training overhead, motivating zero-shot methods rather than task-specific RL training. However, existing zero-shot methods that build explicit 3D scene graphs often compress rich visual observations into text-only relations, leading to high construction cost, irreversible loss of visual evidence, and constrained vocabularies. To address these limitations, we introduce the Multi-modal 3D Scene Graph (M3DSG), which preserves visual cues by replacing textual relational edges with dynamically assigned images. Built on M3DSG, we propose MSGNav, a zero-shot navigation system that includes a Key Subgraph Selection module for efficient reasoning, an Adaptive Vocabulary Update module for open vocabulary support, and a Closed-Loop Reasoning module for accurate exploration reasoning. Additionally, we further identify the last-mile problem in zero-shot navigation - determining the feasible target location with a suitable final viewpoint, and propose a Visibility-based Viewpoint Decision module to explicitly resolve it. Comprehensive experimental results demonstrate that MSGNav achieves state-of-the-art performance on GOAT-Bench and HM3D-OVON datasets. The open-source code will be publicly available.","[{'text': 'Multi-modal 3D Scene Graph (M3DSG) preserves visual cues', 'importance': 'vital', 'assignment': 'partial_support'}, {'text': 'MSGNav system includes Key Subgraph Selection module', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'Adaptive Vocabulary Update module supports open vocabulary', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'Closed-Loop Reasoning module for accurate exploration reasoning', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'Visibility-based Viewpoint Decision module resolves last-mile problem', 'importance': 'vital', 'assignment': 'partial_support'}, {'text': 'MSGNav achieves state-of-the-art on GOAT-Bench, HM3D-OVON', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'Zero-shot navigation avoids task-specific RL training', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Existing zero-shot methods span object-goal, image-goal, text-goal', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Zero-shot methods often ignore last-mile viewpoint challenge', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Graph-based scene exploration integrates with LLMs/VLMs', 'importance': 'okay', 'assignment': 'support'}, {'text': 'SayPlan, OVSG, imaginative world modeling use scene graphs', 'importance': 'okay', 'assignment': 'support'}, {'text': 'SG-Nav, graph-retained adaptation applied in navigation', 'importance': 'okay', 'assignment': 'support'}, {'text': 'CoW, ESC, OpenFMNav, VLFM, UniGoal, RATE-Nav for object-goal', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Mod-IIN, SIGN for image-goal navigation', 'importance': 'okay', 'assignment': 'support'}, {'text': 'InstructNav generalizes instruction following across navigation types', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'Zero-shot navigation avoids task-specific RL training', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Existing zero-shot methods span object-goal, image-goal, text-goal', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Zero-shot methods often ignore last-mile viewpoint challenge', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Graph-based scene exploration integrates with LLMs/VLMs', 'importance': 'okay', 'assignment': 'support'}, {'text': 'SayPlan, OVSG, imaginative world modeling use scene graphs', 'importance': 'okay', 'assignment': 'support'}, {'text': 'SG-Nav, graph-retained adaptation applied in navigation', 'importance': 'okay', 'assignment': 'support'}, {'text': 'CoW, ESC, OpenFMNav, VLFM, UniGoal, RATE-Nav for object-goal', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Mod-IIN, SIGN for image-goal navigation', 'importance': 'okay', 'assignment': 'support'}, {'text': 'InstructNav generalizes instruction following across navigation types', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'Multi-modal 3D Scene Graph (M3DSG) preserves visual cues', 'importance': 'vital', 'assignment': 'partial_support'}, {'text': 'Visibility-based Viewpoint Decision module resolves last-mile problem', 'importance': 'vital', 'assignment': 'partial_support'}, {'text': 'Zero-shot navigation avoids task-specific RL training', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Existing zero-shot methods span object-goal, image-goal, text-goal', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Zero-shot methods often ignore last-mile viewpoint challenge', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Graph-based scene exploration integrates with LLMs/VLMs', 'importance': 'okay', 'assignment': 'support'}, {'text': 'SayPlan, OVSG, imaginative world modeling use scene graphs', 'importance': 'okay', 'assignment': 'support'}, {'text': 'SG-Nav, graph-retained adaptation applied in navigation', 'importance': 'okay', 'assignment': 'support'}, {'text': 'CoW, ESC, OpenFMNav, VLFM, UniGoal, RATE-Nav for object-goal', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Mod-IIN, SIGN for image-goal navigation', 'importance': 'okay', 'assignment': 'support'}, {'text': 'InstructNav generalizes instruction following across navigation types', 'importance': 'okay', 'assignment': 'support'}]","{'strict_vital_score': 0.3333333333333333, 'strict_all_score': 0.6, 'vital_score': 0.4444444444444444, 'all_score': 0.6666666666666666}"
