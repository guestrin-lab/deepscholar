qid,query,nuggets,supported_nuggets,partially_supported_nuggets,nuggets_metrics
2511.05640v1,"Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:
Inverse Game Theory (IGT) methods based on the entropy-regularized Quantal Response Equilibrium (QRE) offer a tractable approach for competitive settings, but critically assume the agents' rationality parameter (temperature $τ$) is known a priori. When $τ$ is unknown, a fundamental scale ambiguity emerges that couples $τ$ with the reward parameters ($θ$), making them statistically unidentifiable. We introduce Blind-IGT, the first statistical framework to jointly recover both $θ$ and $τ$ from observed behavior. We analyze this bilinear inverse problem and establish necessary and sufficient conditions for unique identification by introducing a normalization constraint that resolves the scale ambiguity. We propose an efficient Normalized Least Squares (NLS) estimator and prove it achieves the optimal $\mathcal{O}(N^{-1/2})$ convergence rate for joint parameter recovery. When strong identifiability conditions fail, we provide partial identification guarantees through confidence set construction. We extend our framework to Markov games and demonstrate optimal convergence rates with strong empirical performance even when transition dynamics are unknown.","[{'text': 'Blind-IGT jointly recovers reward and temperature parameters', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Scale ambiguity couples temperature with reward parameters', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Normalization constraint resolves scale ambiguity in Blind-IGT', 'importance': 'vital', 'assignment': 'support'}, {'text': 'NLS estimator achieves optimal convergence rate', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Blind-IGT extends to Markov games', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Prior work assumes known temperature in IGT', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Blind-IGT provides partial identification guarantees', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Blind-IGT addresses limitations of prior QRE-based IGT', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Inverse Game Theory extends IRL to multi-agent systems', 'importance': 'okay', 'assignment': 'support'}, {'text': 'QRE models agents playing noisy best responses', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Entropy regularization stabilizes training in MARL', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Bilinear inverse problems involve non-convex optimization', 'importance': 'okay', 'assignment': 'partial_support'}, {'text': 'QRE interpolates between random play and Nash Equilibrium', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Blind-IGT demonstrates strong empirical performance', 'importance': 'okay', 'assignment': 'partial_support'}]","[{'text': 'Blind-IGT jointly recovers reward and temperature parameters', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Scale ambiguity couples temperature with reward parameters', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Normalization constraint resolves scale ambiguity in Blind-IGT', 'importance': 'vital', 'assignment': 'support'}, {'text': 'NLS estimator achieves optimal convergence rate', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Blind-IGT extends to Markov games', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Prior work assumes known temperature in IGT', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Blind-IGT provides partial identification guarantees', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Blind-IGT addresses limitations of prior QRE-based IGT', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Inverse Game Theory extends IRL to multi-agent systems', 'importance': 'okay', 'assignment': 'support'}, {'text': 'QRE models agents playing noisy best responses', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Entropy regularization stabilizes training in MARL', 'importance': 'okay', 'assignment': 'support'}, {'text': 'QRE interpolates between random play and Nash Equilibrium', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'Blind-IGT jointly recovers reward and temperature parameters', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Scale ambiguity couples temperature with reward parameters', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Normalization constraint resolves scale ambiguity in Blind-IGT', 'importance': 'vital', 'assignment': 'support'}, {'text': 'NLS estimator achieves optimal convergence rate', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Blind-IGT extends to Markov games', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Prior work assumes known temperature in IGT', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Blind-IGT provides partial identification guarantees', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Blind-IGT addresses limitations of prior QRE-based IGT', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Inverse Game Theory extends IRL to multi-agent systems', 'importance': 'okay', 'assignment': 'support'}, {'text': 'QRE models agents playing noisy best responses', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Entropy regularization stabilizes training in MARL', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Bilinear inverse problems involve non-convex optimization', 'importance': 'okay', 'assignment': 'partial_support'}, {'text': 'QRE interpolates between random play and Nash Equilibrium', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Blind-IGT demonstrates strong empirical performance', 'importance': 'okay', 'assignment': 'partial_support'}]","{'strict_vital_score': 1.0, 'strict_all_score': 0.8571428571428571, 'vital_score': 1.0, 'all_score': 0.9285714285714286}"
