qid,query,nuggets,supported_nuggets,partially_supported_nuggets,nuggets_metrics
2511.08252v1,"Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:
Text-to-music generation technology is progressing rapidly, creating new opportunities for musical composition and editing. However, existing music editing methods often fail to preserve the source music's temporal structure, including melody and rhythm, when altering particular attributes like instrument, genre, and mood. To address this challenge, this paper conducts an in-depth probing analysis on attention maps within AudioLDM 2, a diffusion-based model commonly used as the backbone for existing music editing methods. We reveal a key finding: cross-attention maps encompass details regarding distinct musical characteristics, and interventions on these maps frequently result in ineffective modifications. In contrast, self-attention maps are essential for preserving the temporal structure of the source music during its conversion into the target music. Building upon this understanding, we present Melodia, a training-free technique that selectively manipulates self-attention maps in particular layers during the denoising process and leverages an attention repository to store source music information, achieving accurate modification of musical characteristics while preserving the original structure without requiring textual descriptions of the source music. Additionally, we propose two novel metrics to better evaluate music editing methods. Both objective and subjective experiments demonstrate that our approach achieves superior results in terms of textual adherence and structural integrity across various datasets. This research enhances comprehension of internal mechanisms within music generation models and provides improved control for music creation.","[{'text': 'AudioLDM 2 improves musical structure representation', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Melodia manipulates self-attention maps for music editing', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'Cross-attention maps affect musical characteristics', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'Self-attention maps preserve temporal structure in music', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'SDEdit struggles with preserving temporal structure', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Melodia uses an attention repository for source music information', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'Novel metrics evaluate music editing methods', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'Text-to-music generation uses autoregressive and diffusion-based models', 'importance': 'okay', 'assignment': 'support'}, {'text': 'MusicLM and MusicGen offer limited editing capabilities', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Instruct-MusicGen fine-tunes models for music editing', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Zero-shot editing methods manipulate music without training', 'importance': 'okay', 'assignment': 'partial_support'}, {'text': 'MusicMagus requires keywords for editing directions', 'importance': 'okay', 'assignment': 'support'}, {'text': 'MEDIC controls self and cross-attention in music editing', 'importance': 'okay', 'assignment': 'support'}, {'text': 'DDPM Friendly lacks explicit structure guidance', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Objective and subjective experiments show superior results', 'importance': 'okay', 'assignment': 'not_support'}, {'text': 'Research enhances understanding of music generation models', 'importance': 'okay', 'assignment': 'not_support'}]","[{'text': 'AudioLDM 2 improves musical structure representation', 'importance': 'vital', 'assignment': 'support'}, {'text': 'SDEdit struggles with preserving temporal structure', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Text-to-music generation uses autoregressive and diffusion-based models', 'importance': 'okay', 'assignment': 'support'}, {'text': 'MusicLM and MusicGen offer limited editing capabilities', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Instruct-MusicGen fine-tunes models for music editing', 'importance': 'okay', 'assignment': 'support'}, {'text': 'MusicMagus requires keywords for editing directions', 'importance': 'okay', 'assignment': 'support'}, {'text': 'MEDIC controls self and cross-attention in music editing', 'importance': 'okay', 'assignment': 'support'}, {'text': 'DDPM Friendly lacks explicit structure guidance', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'AudioLDM 2 improves musical structure representation', 'importance': 'vital', 'assignment': 'support'}, {'text': 'SDEdit struggles with preserving temporal structure', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Text-to-music generation uses autoregressive and diffusion-based models', 'importance': 'okay', 'assignment': 'support'}, {'text': 'MusicLM and MusicGen offer limited editing capabilities', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Instruct-MusicGen fine-tunes models for music editing', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Zero-shot editing methods manipulate music without training', 'importance': 'okay', 'assignment': 'partial_support'}, {'text': 'MusicMagus requires keywords for editing directions', 'importance': 'okay', 'assignment': 'support'}, {'text': 'MEDIC controls self and cross-attention in music editing', 'importance': 'okay', 'assignment': 'support'}, {'text': 'DDPM Friendly lacks explicit structure guidance', 'importance': 'okay', 'assignment': 'support'}]","{'strict_vital_score': 0.2857142857142857, 'strict_all_score': 0.5, 'vital_score': 0.2857142857142857, 'all_score': 0.53125}"
