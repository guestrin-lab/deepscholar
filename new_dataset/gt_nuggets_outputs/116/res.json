{
  "qid": "2511.10621v1",
  "query": "Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:\nLarge Language Models (LLMs) have demonstrated remarkable reasoning abilities, yet existing test-time frameworks often rely on coarse self-verification and self-correction, limiting their effectiveness on complex tasks. In this paper, we propose Socratic Self-Refine (SSR), a novel framework for fine-grained evaluation and precise refinement of LLM reasoning. Our proposed SSR decomposes model responses into verifiable (sub-question, sub-answer) pairs, enabling step-level confidence estimation through controlled re-solving and self-consistency checks. By pinpointing unreliable steps and iteratively refining them, SSR produces more accurate and interpretable reasoning chains. Empirical results across five reasoning benchmarks and three LLMs show that SSR consistently outperforms state-of-the-art iterative self-refinement baselines. Beyond performance gains, SSR provides a principled black-box approach for evaluating and understanding the internal reasoning processes of LLMs. Code is available at https://github.com/SalesforceAIResearch/socratic-self-refine-reasoning.",
  "nuggets": [
    {
      "text": "Socratic Self-Refine (SSR) framework for LLM reasoning",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "SSR decomposes responses into verifiable sub-question, sub-answer pairs",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Step-level confidence estimation through controlled re-solving",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "SSR outperforms state-of-the-art iterative self-refinement baselines",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "SSR provides a principled black-box approach for LLM evaluation",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "Empirical results across five reasoning benchmarks and three LLMs",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "SSR enables reliable confidence estimation and refinement",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "SSR produces accurate and interpretable reasoning chains",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "Uncertainty-based methods estimate correctness through consistency",
      "importance": "okay",
      "assignment": "partial_support"
    },
    {
      "text": "LLM-as-a-Judge paradigm prompts models to evaluate responses",
      "importance": "okay",
      "assignment": "partial_support"
    },
    {
      "text": "Self-refinement transforms evaluation into active reliability improvement",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Process evaluation requires step-level verification of reasoning",
      "importance": "okay",
      "assignment": "partial_support"
    },
    {
      "text": "Structured search and parallel sampling enrich candidate diversity",
      "importance": "okay",
      "assignment": "partial_support"
    },
    {
      "text": "Generative verifiers guide the refinement process",
      "importance": "okay",
      "assignment": "partial_support"
    },
    {
      "text": "Code available at github.com/SalesforceAIResearch/socratic-self-refine-reasoning",
      "importance": "okay",
      "assignment": "not_support"
    }
  ],
  "supported_nuggets": [
    {
      "text": "Socratic Self-Refine (SSR) framework for LLM reasoning",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "SSR decomposes responses into verifiable sub-question, sub-answer pairs",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Step-level confidence estimation through controlled re-solving",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "SSR enables reliable confidence estimation and refinement",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Self-refinement transforms evaluation into active reliability improvement",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "partially_supported_nuggets": [
    {
      "text": "Socratic Self-Refine (SSR) framework for LLM reasoning",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "SSR decomposes responses into verifiable sub-question, sub-answer pairs",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Step-level confidence estimation through controlled re-solving",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "SSR enables reliable confidence estimation and refinement",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Uncertainty-based methods estimate correctness through consistency",
      "importance": "okay",
      "assignment": "partial_support"
    },
    {
      "text": "LLM-as-a-Judge paradigm prompts models to evaluate responses",
      "importance": "okay",
      "assignment": "partial_support"
    },
    {
      "text": "Self-refinement transforms evaluation into active reliability improvement",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Process evaluation requires step-level verification of reasoning",
      "importance": "okay",
      "assignment": "partial_support"
    },
    {
      "text": "Structured search and parallel sampling enrich candidate diversity",
      "importance": "okay",
      "assignment": "partial_support"
    },
    {
      "text": "Generative verifiers guide the refinement process",
      "importance": "okay",
      "assignment": "partial_support"
    }
  ],
  "nuggets_metrics": {
    "strict_vital_score": 0.5,
    "strict_all_score": 0.3333333333333333,
    "vital_score": 0.5,
    "all_score": 0.5
  }
}