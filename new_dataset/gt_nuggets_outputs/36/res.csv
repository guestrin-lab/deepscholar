qid,query,nuggets,supported_nuggets,partially_supported_nuggets,nuggets_metrics
2510.25807v1,"Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:
Single-cell RNA-seq foundation models achieve strong performance on downstream tasks but remain black boxes, limiting their utility for biological discovery. Recent work has shown that sparse dictionary learning can extract concepts from deep learning models, with promising applications in biomedical imaging and protein models. However, interpreting biological concepts remains challenging, as biological sequences are not inherently human-interpretable. We introduce a novel concept-based interpretability framework for single-cell RNA-seq models with a focus on concept interpretation and evaluation. We propose an attribution method with counterfactual perturbations that identifies genes that influence concept activation, moving beyond correlational approaches like differential expression analysis. We then provide two complementary interpretation approaches: an expert-driven analysis facilitated by an interactive interface and an ontology-driven method with attribution-based biological pathway enrichment. Applying our framework to two well-known single-cell RNA-seq models from the literature, we interpret concepts extracted by Top-K Sparse Auto-Encoders trained on two immune cell datasets. With a domain expert in immunology, we show that concepts improve interpretability compared to individual neurons while preserving the richness and informativeness of the latent representations. This work provides a principled framework for interpreting what biological knowledge foundation models have encoded, paving the way for their use for hypothesis generation and discovery.","[{'text': 'Sparse dictionary learning enhances model interpretability', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Attribution methods identify influential genes in scRNA-seq', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Ontology-driven pathway enrichment aids concept interpretation', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Top-K Sparse Auto-Encoders improve concept extraction', 'importance': 'vital', 'assignment': 'partial_support'}, {'text': 'Interactive interface supports expert-driven analysis', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'Concepts enhance interpretability over individual neurons', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'Existing knowledge constrains model interpretability', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Counterfactual perturbations move beyond correlational approaches', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'Concepts preserve richness of latent representations', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'Framework aids hypothesis generation and discovery', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'Post-hoc explainability interprets models after training', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Biological sequences are not inherently human-interpretable', 'importance': 'okay', 'assignment': 'not_support'}, {'text': 'Sparse Auto-Encoders uncover meaningful protein model concepts', 'importance': 'okay', 'assignment': 'partial_support'}, {'text': 'Pathway enrichment methods interpret scRNA-seq models', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Sparse dictionary learning applied to histopathology models', 'importance': 'okay', 'assignment': 'partial_support'}]","[{'text': 'Sparse dictionary learning enhances model interpretability', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Attribution methods identify influential genes in scRNA-seq', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Ontology-driven pathway enrichment aids concept interpretation', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Existing knowledge constrains model interpretability', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Post-hoc explainability interprets models after training', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Pathway enrichment methods interpret scRNA-seq models', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'Sparse dictionary learning enhances model interpretability', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Attribution methods identify influential genes in scRNA-seq', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Ontology-driven pathway enrichment aids concept interpretation', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Top-K Sparse Auto-Encoders improve concept extraction', 'importance': 'vital', 'assignment': 'partial_support'}, {'text': 'Existing knowledge constrains model interpretability', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Post-hoc explainability interprets models after training', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Sparse Auto-Encoders uncover meaningful protein model concepts', 'importance': 'okay', 'assignment': 'partial_support'}, {'text': 'Pathway enrichment methods interpret scRNA-seq models', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Sparse dictionary learning applied to histopathology models', 'importance': 'okay', 'assignment': 'partial_support'}]","{'strict_vital_score': 0.4, 'strict_all_score': 0.4, 'vital_score': 0.45, 'all_score': 0.5}"
