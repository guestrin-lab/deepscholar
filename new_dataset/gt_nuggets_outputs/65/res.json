{
  "qid": "2511.10334v1",
  "query": "Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:\nRecent advancements in weakly-supervised video anomaly detection have achieved remarkable performance by applying the multiple instance learning paradigm based on multimodal foundation models such as CLIP to highlight anomalous instances and classify categories. However, their objectives may tend to detect the most salient response segments, while neglecting to mine diverse normal patterns separated from anomalies, and are prone to category confusion due to similar appearance, leading to unsatisfactory fine-grained classification results. Therefore, we propose a novel Disentangled Semantic Alignment Network (DSANet) to explicitly separate abnormal and normal features from coarse-grained and fine-grained aspects, enhancing the distinguishability. Specifically, at the coarse-grained level, we introduce a self-guided normality modeling branch that reconstructs input video features under the guidance of learned normal prototypes, encouraging the model to exploit normality cues inherent in the video, thereby improving the temporal separation of normal patterns and anomalous events. At the fine-grained level, we present a decoupled contrastive semantic alignment mechanism, which first temporally decomposes each video into event-centric and background-centric components using frame-level anomaly scores and then applies visual-language contrastive learning to enhance class-discriminative representations. Comprehensive experiments on two standard benchmarks, namely XD-Violence and UCF-Crime, demonstrate that DSANet outperforms existing state-of-the-art methods.",
  "nuggets": [
    {
      "text": "DSANet separates abnormal and normal features for better classification.",
      "importance": "vital",
      "assignment": "partial_support"
    },
    {
      "text": "CLIP-based models highlight anomalous instances in video anomaly detection.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Weakly-supervised video anomaly detection uses multiple instance learning.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "DSANet uses self-guided normality modeling for temporal separation.",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "Decoupled contrastive semantic alignment enhances class-discriminative representations.",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "XD-Violence and UCF-Crime benchmarks used for DSANet evaluation.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Vision-Language Pre-training models like CLIP improve anomaly detection.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "RTFM captures multi-scale temporal dependencies in video analysis.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "UMIL learns stable representations to improve classifier robustness.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Feng's self-training framework refines feature representations.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Prompt-based textual cues enhance anomaly type recognition.",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "supported_nuggets": [
    {
      "text": "CLIP-based models highlight anomalous instances in video anomaly detection.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Weakly-supervised video anomaly detection uses multiple instance learning.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "XD-Violence and UCF-Crime benchmarks used for DSANet evaluation.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Vision-Language Pre-training models like CLIP improve anomaly detection.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "RTFM captures multi-scale temporal dependencies in video analysis.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "UMIL learns stable representations to improve classifier robustness.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Feng's self-training framework refines feature representations.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Prompt-based textual cues enhance anomaly type recognition.",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "partially_supported_nuggets": [
    {
      "text": "DSANet separates abnormal and normal features for better classification.",
      "importance": "vital",
      "assignment": "partial_support"
    },
    {
      "text": "CLIP-based models highlight anomalous instances in video anomaly detection.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Weakly-supervised video anomaly detection uses multiple instance learning.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "XD-Violence and UCF-Crime benchmarks used for DSANet evaluation.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Vision-Language Pre-training models like CLIP improve anomaly detection.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "RTFM captures multi-scale temporal dependencies in video analysis.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "UMIL learns stable representations to improve classifier robustness.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Feng's self-training framework refines feature representations.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Prompt-based textual cues enhance anomaly type recognition.",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "nuggets_metrics": {
    "strict_vital_score": 0.5,
    "strict_all_score": 0.7272727272727273,
    "vital_score": 0.5833333333333334,
    "all_score": 0.7727272727272727
  }
}