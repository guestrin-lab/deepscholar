qid,query,nuggets,supported_nuggets,partially_supported_nuggets,nuggets_metrics
2511.03849v2,"Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:
A canonical step in quantifying a system is to measure its entropy. Shannon entropy and other traditional entropy measures capture only the information encoded in the frequencies of a system's elements. Recently, Leinster, Cobbold, and Reeve (LCR) introduced a method that also captures the rich information encoded in the similarities and differences among elements, yielding similarity-sensitive entropy. More recently, the Vendi score (VS) was introduced as an alternative, raising the question of how LCR and VS compare, and which is preferable. Here we address these questions conceptually, analytically, and experimentally, using 53 machine-learning datasets. We show that LCR and VS can differ by orders of magnitude and can capture complementary information about a system, except in limiting cases. We demonstrate that both LCR and VS depend on how similarities are scaled and introduce the concept of ``half distance'' to parameterize this dependence. We prove that VS provides an upper bound on LCR for several values of the RÃ©nyi-Hill order parameter and conjecture that this bound holds for all values. We conclude that VS is preferable only when interpreting elements as linear combinations of a more fundamental set of ``ur-elements'' or when the system or dataset possesses a quantum-mechanical character. In the broader circumstance where one seeks simply to capture the rich information encoded by similarity, LCR is favored; nevertheless, for certain half-distances the two methods can complement each other.","[{'text': 'LCR captures similarity-sensitive entropy', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Vendi score is an alternative to LCR', 'importance': 'vital', 'assignment': 'support'}, {'text': 'LCR and VS differ by orders of magnitude', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'LCR and VS capture complementary information', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'Both LCR and VS depend on similarity scaling', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'VS provides an upper bound on LCR', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'LCR favored for capturing rich similarity information', 'importance': 'vital', 'assignment': 'partial_support'}, {'text': ""LCR extends Hill's framework with similarity matrix"", 'importance': 'vital', 'assignment': 'support'}, {'text': 'LCR and VS complement each other for certain half-distances', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'Shannon entropy measures frequency information', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Half distance parameterizes similarity scaling', 'importance': 'okay', 'assignment': 'partial_support'}, {'text': 'VS preferable for quantum-mechanical datasets', 'importance': 'okay', 'assignment': 'partial_support'}, {'text': 'LCR useful in uniform empirical samples', 'importance': 'okay', 'assignment': 'support'}, {'text': 'VS related to von Neumann entropy', 'importance': 'okay', 'assignment': 'support'}, {'text': 'VS uses eigenvalues of normalized similarity matrix', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'LCR captures similarity-sensitive entropy', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Vendi score is an alternative to LCR', 'importance': 'vital', 'assignment': 'support'}, {'text': ""LCR extends Hill's framework with similarity matrix"", 'importance': 'vital', 'assignment': 'support'}, {'text': 'Shannon entropy measures frequency information', 'importance': 'okay', 'assignment': 'support'}, {'text': 'LCR useful in uniform empirical samples', 'importance': 'okay', 'assignment': 'support'}, {'text': 'VS related to von Neumann entropy', 'importance': 'okay', 'assignment': 'support'}, {'text': 'VS uses eigenvalues of normalized similarity matrix', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'LCR captures similarity-sensitive entropy', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Vendi score is an alternative to LCR', 'importance': 'vital', 'assignment': 'support'}, {'text': 'LCR favored for capturing rich similarity information', 'importance': 'vital', 'assignment': 'partial_support'}, {'text': ""LCR extends Hill's framework with similarity matrix"", 'importance': 'vital', 'assignment': 'support'}, {'text': 'Shannon entropy measures frequency information', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Half distance parameterizes similarity scaling', 'importance': 'okay', 'assignment': 'partial_support'}, {'text': 'VS preferable for quantum-mechanical datasets', 'importance': 'okay', 'assignment': 'partial_support'}, {'text': 'LCR useful in uniform empirical samples', 'importance': 'okay', 'assignment': 'support'}, {'text': 'VS related to von Neumann entropy', 'importance': 'okay', 'assignment': 'support'}, {'text': 'VS uses eigenvalues of normalized similarity matrix', 'importance': 'okay', 'assignment': 'support'}]","{'strict_vital_score': 0.3333333333333333, 'strict_all_score': 0.4666666666666667, 'vital_score': 0.3888888888888889, 'all_score': 0.5666666666666667}"
