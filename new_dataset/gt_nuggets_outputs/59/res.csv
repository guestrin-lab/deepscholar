qid,query,nuggets,supported_nuggets,partially_supported_nuggets,nuggets_metrics
2511.09332v1,"Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:
The proliferation of complex, black-box AI models has intensified the need for techniques that can explain their decisions. Feature attribution methods have become a popular solution for providing post-hoc explanations, yet the field has historically lacked a formal problem definition. This paper addresses this gap by introducing a formal definition for the problem of feature attribution, which stipulates that explanations be supported by an underlying probability distribution represented by the given dataset. Our analysis reveals that many existing model-agnostic methods fail to meet this criterion, while even those that do often possess other limitations. To overcome these challenges, we propose Distributional Feature Attribution eXplanations (DFAX), a novel, model-agnostic method for feature attribution. DFAX is the first feature attribution method to explain classifier predictions directly based on the data distribution. We show through extensive experiments that DFAX is more effective and efficient than state-of-the-art baselines.","[{'text': 'DFAX explains classifier predictions using data distribution', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'Feature attribution methods provide post-hoc explanations', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'PFI measures feature importance by expected performance loss', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Kernel density estimation estimates data point probabilities', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Local approximation methods use surrogate models for explanations', 'importance': 'okay', 'assignment': 'support'}, {'text': 'LIME creates synthetic points for local explanations', 'importance': 'okay', 'assignment': 'support'}, {'text': 'DLIME uses clustering to define neighborhoods', 'importance': 'okay', 'assignment': 'support'}, {'text': 'MAPLE selects and weights neighboring points', 'importance': 'okay', 'assignment': 'support'}, {'text': 'SLISE fits sparse, locally linear regression models', 'importance': 'okay', 'assignment': 'support'}, {'text': 'LINEX minimizes sensitivity using invariant risk minimization', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Perturbation-based methods measure performance degradation', 'importance': 'okay', 'assignment': 'support'}, {'text': 'SHAP uses Shapley values for feature importance', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Gaussian kernel results in Gaussian Kernel Density Estimator', 'importance': 'okay', 'assignment': 'support'}, {'text': 'SiNNE is a fast alternative to GKDE', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Nystr{""o}m method accelerates kernel density estimation', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'PFI measures feature importance by expected performance loss', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Kernel density estimation estimates data point probabilities', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Local approximation methods use surrogate models for explanations', 'importance': 'okay', 'assignment': 'support'}, {'text': 'LIME creates synthetic points for local explanations', 'importance': 'okay', 'assignment': 'support'}, {'text': 'DLIME uses clustering to define neighborhoods', 'importance': 'okay', 'assignment': 'support'}, {'text': 'MAPLE selects and weights neighboring points', 'importance': 'okay', 'assignment': 'support'}, {'text': 'SLISE fits sparse, locally linear regression models', 'importance': 'okay', 'assignment': 'support'}, {'text': 'LINEX minimizes sensitivity using invariant risk minimization', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Perturbation-based methods measure performance degradation', 'importance': 'okay', 'assignment': 'support'}, {'text': 'SHAP uses Shapley values for feature importance', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Gaussian kernel results in Gaussian Kernel Density Estimator', 'importance': 'okay', 'assignment': 'support'}, {'text': 'SiNNE is a fast alternative to GKDE', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Nystr{""o}m method accelerates kernel density estimation', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'PFI measures feature importance by expected performance loss', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Kernel density estimation estimates data point probabilities', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Local approximation methods use surrogate models for explanations', 'importance': 'okay', 'assignment': 'support'}, {'text': 'LIME creates synthetic points for local explanations', 'importance': 'okay', 'assignment': 'support'}, {'text': 'DLIME uses clustering to define neighborhoods', 'importance': 'okay', 'assignment': 'support'}, {'text': 'MAPLE selects and weights neighboring points', 'importance': 'okay', 'assignment': 'support'}, {'text': 'SLISE fits sparse, locally linear regression models', 'importance': 'okay', 'assignment': 'support'}, {'text': 'LINEX minimizes sensitivity using invariant risk minimization', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Perturbation-based methods measure performance degradation', 'importance': 'okay', 'assignment': 'support'}, {'text': 'SHAP uses Shapley values for feature importance', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Gaussian kernel results in Gaussian Kernel Density Estimator', 'importance': 'okay', 'assignment': 'support'}, {'text': 'SiNNE is a fast alternative to GKDE', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Nystr{""o}m method accelerates kernel density estimation', 'importance': 'okay', 'assignment': 'support'}]","{'strict_vital_score': 0.5, 'strict_all_score': 0.8666666666666667, 'vital_score': 0.5, 'all_score': 0.8666666666666667}"
