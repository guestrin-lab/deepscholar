{
  "qid": "2511.08158v2",
  "query": "Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:\nSparse matrix-dense matrix multiplication (SpMM) is a critical kernel in both scientific computing and emerging graph learning workloads. The recent Armv9 architecture introduces Scalable Matrix Extension (SME), enabling tile-based matrix operations with high throughput. However, effectively exploiting both SME and traditional SIMD resources for unstructured sparse workloads remains an open challenge. To address this, we propose LOOPS, a hybrid execution framework that combines row-wise CSR-part with vector-wise BCSR-part layout, enabling cooperative utilization of vector instructions (NEON) and Scalable Matrix Extension (SME) resources. LOOPS supports multi-precision SpMM across FP64, FP32, and FP16 via an adaptive two-level parallelization scheme guided by a lightweight performance model. Experimental results on the entire SuiteSparse on an Apple's M4Pro CPU show that LOOPS achieves average speedups of 9.93$\\times$ (FP32)/14.4$\\times$ (FP64) against the CPU baseline TACO and 71.3$\\times$ (FP32)/54.8$\\times$ (FP64) with respect to Armadillo. A comparison of LOOPS running on the same CPU with two GPU methods (cuSPARSE, Magicube) executed on an NVIDIA A100 GPU show average speedups for LOOPS between 19.8$\\times$ and 33.5$\\times$, depending on the precision. Notably, LOOPS delivers significantly better energy efficiency than the GPU codes on the A100 GPU.",
  "nuggets": [
    {
      "text": "Sparse matrix-dense matrix multiplication (SpMM) is critical in computing.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Armv9 architecture introduces Scalable Matrix Extension (SME).",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Exploiting SME and SIMD for sparse workloads is challenging.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "LOOPS framework combines CSR-part and BCSR-part layouts.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "LOOPS utilizes NEON and SME resources cooperatively.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "LOOPS supports multi-precision SpMM: FP64, FP32, FP16.",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "LOOPS achieves significant speedups over TACO and Armadillo.",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "LOOPS delivers better energy efficiency than GPU codes.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "SME enables tile-based matrix operations with high throughput.",
      "importance": "okay",
      "assignment": "not_support"
    },
    {
      "text": "LOOPS uses an adaptive two-level parallelization scheme.",
      "importance": "okay",
      "assignment": "not_support"
    },
    {
      "text": "LOOPS outperforms GPU methods cuSPARSE and Magicube on A100.",
      "importance": "okay",
      "assignment": "partial_support"
    }
  ],
  "supported_nuggets": [
    {
      "text": "Sparse matrix-dense matrix multiplication (SpMM) is critical in computing.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Armv9 architecture introduces Scalable Matrix Extension (SME).",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Exploiting SME and SIMD for sparse workloads is challenging.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "LOOPS framework combines CSR-part and BCSR-part layouts.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "LOOPS utilizes NEON and SME resources cooperatively.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "LOOPS delivers better energy efficiency than GPU codes.",
      "importance": "vital",
      "assignment": "support"
    }
  ],
  "partially_supported_nuggets": [
    {
      "text": "Sparse matrix-dense matrix multiplication (SpMM) is critical in computing.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Armv9 architecture introduces Scalable Matrix Extension (SME).",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Exploiting SME and SIMD for sparse workloads is challenging.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "LOOPS framework combines CSR-part and BCSR-part layouts.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "LOOPS utilizes NEON and SME resources cooperatively.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "LOOPS delivers better energy efficiency than GPU codes.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "LOOPS outperforms GPU methods cuSPARSE and Magicube on A100.",
      "importance": "okay",
      "assignment": "partial_support"
    }
  ],
  "nuggets_metrics": {
    "strict_vital_score": 0.75,
    "strict_all_score": 0.5454545454545454,
    "vital_score": 0.75,
    "all_score": 0.5909090909090909
  }
}