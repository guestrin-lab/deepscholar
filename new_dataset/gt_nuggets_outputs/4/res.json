{
  "qid": "2510.00027v2",
  "query": "Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:\nAccurate and scalable machine-learned inter-atomic potentials (MLIPs) are essential for molecular simulations ranging from drug discovery to new material design. Current state-of-the-art models enforce roto-translational symmetries through equivariant neural network architectures, a hard-wired inductive bias that can often lead to reduced flexibility, computational efficiency, and scalability. In this work, we introduce TransIP: Transformer-based Inter-Atomic Potentials, a novel training paradigm for interatomic potentials achieving symmetry compliance without explicit architectural constraints. Our approach guides a generic non-equivariant Transformer-based model to learn SO(3)-equivariance by optimizing its representations in the embedding space. Trained on the recent Open Molecules (OMol25) collection, a large and diverse molecular dataset built specifically for MLIPs and covering different types of molecules (including small organics, biomolecular fragments, and electrolyte-like species), TransIP effectively learns symmetry in its latent space, providing low equivariance error. Further, compared to a data augmentation baseline, TransIP achieves 40% to 60% improvement in performance across varying OMol25 dataset sizes. More broadly, our work shows that learned equivariance can be a powerful and efficient alternative to augmentation-based MLIP models.",
  "nuggets": [
    {
      "text": "TransIP: Transformer-based Inter-Atomic Potentials for MLIPs",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "Achieves symmetry compliance without explicit architectural constraints",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Guides non-equivariant Transformer to learn SO(3)-equivariance",
      "importance": "vital",
      "assignment": "partial_support"
    },
    {
      "text": "Trained on Open Molecules (OMol25) dataset",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "TransIP provides low equivariance error",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "40% to 60% performance improvement over data augmentation",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "Learned equivariance as alternative to augmentation-based models",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Frame averaging and canonicalization for symmetry in GNNs",
      "importance": "vital",
      "assignment": "partial_support"
    },
    {
      "text": "Data augmentation in molecule-specific graph architectures",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "OMol25 includes diverse molecular types",
      "importance": "okay",
      "assignment": "not_support"
    },
    {
      "text": "Equivariant neural networks enforce roto-translational symmetries",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Equivariant GNNs reduce flexibility and scalability",
      "importance": "okay",
      "assignment": "partial_support"
    },
    {
      "text": "Unconstrained models used in vision and generative tasks",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "supported_nuggets": [
    {
      "text": "Achieves symmetry compliance without explicit architectural constraints",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Learned equivariance as alternative to augmentation-based models",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Data augmentation in molecule-specific graph architectures",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Equivariant neural networks enforce roto-translational symmetries",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Unconstrained models used in vision and generative tasks",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "partially_supported_nuggets": [
    {
      "text": "Achieves symmetry compliance without explicit architectural constraints",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Guides non-equivariant Transformer to learn SO(3)-equivariance",
      "importance": "vital",
      "assignment": "partial_support"
    },
    {
      "text": "Learned equivariance as alternative to augmentation-based models",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Frame averaging and canonicalization for symmetry in GNNs",
      "importance": "vital",
      "assignment": "partial_support"
    },
    {
      "text": "Data augmentation in molecule-specific graph architectures",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Equivariant neural networks enforce roto-translational symmetries",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Equivariant GNNs reduce flexibility and scalability",
      "importance": "okay",
      "assignment": "partial_support"
    },
    {
      "text": "Unconstrained models used in vision and generative tasks",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "nuggets_metrics": {
    "strict_vital_score": 0.3333333333333333,
    "strict_all_score": 0.38461538461538464,
    "vital_score": 0.4444444444444444,
    "all_score": 0.5
  }
}