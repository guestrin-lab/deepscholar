{
  "qid": "2511.10287v1",
  "query": "Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:\nSince Multimodal Large Language Models (MLLMs) are increasingly being integrated into everyday tools and intelligent agents, growing concerns have arisen regarding their possible output of unsafe contents, ranging from toxic language and biased imagery to privacy violations and harmful misinformation. Current safety benchmarks remain highly limited in both modality coverage and performance evaluations, often neglecting the extensive landscape of content safety. In this work, we introduce OutSafe-Bench, the first most comprehensive content safety evaluation test suite designed for the multimodal era. OutSafe-Bench includes a large-scale dataset that spans four modalities, featuring over 18,000 bilingual (Chinese and English) text prompts, 4,500 images, 450 audio clips and 450 videos, all systematically annotated across nine critical content risk categories. In addition to the dataset, we introduce a Multidimensional Cross Risk Score (MCRS), a novel metric designed to model and assess overlapping and correlated content risks across different categories. To ensure fair and robust evaluation, we propose FairScore, an explainable automated multi-reviewer weighted aggregation framework. FairScore selects top-performing models as adaptive juries, thereby mitigating biases from single-model judgments and enhancing overall evaluation reliability. Our evaluation of nine state-of-the-art MLLMs reveals persistent and substantial safety vulnerabilities, underscoring the pressing need for robust safeguards in MLLMs.",
  "nuggets": [
    {
      "text": "OutSafe-Bench evaluates MLLM content safety comprehensively.",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "OutSafe-Bench spans four modalities: text, image, audio, video.",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "OutSafe-Bench covers nine critical content risk categories.",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "Multidimensional Cross Risk Score (MCRS) models content risks.",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "FairScore framework ensures fair, robust MLLM evaluation.",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "Nine state-of-the-art MLLMs show safety vulnerabilities.",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "MultiTrust examines cross-modal vulnerabilities in MLLMs.",
      "importance": "vital",
      "assignment": "partial_support"
    },
    {
      "text": "MLLMGuard supports bilingual safety evaluation in MLLMs.",
      "importance": "vital",
      "assignment": "partial_support"
    },
    {
      "text": "Rule-based, manual, LLM-as-judge evaluation strategies exist.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "LLM-as-judge approaches offer scalability, automation.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Multi-LLM systems refine judgments through collaboration.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Hybrid systems combine LLMs with human evaluators.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "OutSafe-Bench includes 18,000 bilingual text prompts.",
      "importance": "okay",
      "assignment": "not_support"
    },
    {
      "text": "OutSafe-Bench features 4,500 images, 450 audio clips, 450 videos.",
      "importance": "okay",
      "assignment": "not_support"
    },
    {
      "text": "FairScore uses adaptive juries to mitigate single-model biases.",
      "importance": "okay",
      "assignment": "not_support"
    },
    {
      "text": "TrustLLM and Trustworthy LLMs assess LLM trustworthiness.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "MM-SafeBench focuses on text-image safety scenarios.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "PrivQA targets privacy risks in textual and visual QA.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Unicorn provides 8,500 annotated visual threat scenarios.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "SafeBench supports audio modality with limited dataset size.",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "supported_nuggets": [
    {
      "text": "Rule-based, manual, LLM-as-judge evaluation strategies exist.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "LLM-as-judge approaches offer scalability, automation.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Multi-LLM systems refine judgments through collaboration.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Hybrid systems combine LLMs with human evaluators.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "TrustLLM and Trustworthy LLMs assess LLM trustworthiness.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "MM-SafeBench focuses on text-image safety scenarios.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "PrivQA targets privacy risks in textual and visual QA.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Unicorn provides 8,500 annotated visual threat scenarios.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "SafeBench supports audio modality with limited dataset size.",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "partially_supported_nuggets": [
    {
      "text": "MultiTrust examines cross-modal vulnerabilities in MLLMs.",
      "importance": "vital",
      "assignment": "partial_support"
    },
    {
      "text": "MLLMGuard supports bilingual safety evaluation in MLLMs.",
      "importance": "vital",
      "assignment": "partial_support"
    },
    {
      "text": "Rule-based, manual, LLM-as-judge evaluation strategies exist.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "LLM-as-judge approaches offer scalability, automation.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Multi-LLM systems refine judgments through collaboration.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Hybrid systems combine LLMs with human evaluators.",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "TrustLLM and Trustworthy LLMs assess LLM trustworthiness.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "MM-SafeBench focuses on text-image safety scenarios.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "PrivQA targets privacy risks in textual and visual QA.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Unicorn provides 8,500 annotated visual threat scenarios.",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "SafeBench supports audio modality with limited dataset size.",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "nuggets_metrics": {
    "strict_vital_score": 0.3333333333333333,
    "strict_all_score": 0.45,
    "vital_score": 0.4166666666666667,
    "all_score": 0.5
  }
}