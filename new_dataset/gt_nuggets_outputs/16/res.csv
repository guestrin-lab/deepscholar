qid,query,nuggets,supported_nuggets,partially_supported_nuggets,nuggets_metrics
2511.10165v1,"Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:
Accurate exploration of protein conformational ensembles is essential for uncovering function but remains hard because molecular-dynamics (MD) simulations suffer from high computational costs and energy-barrier trapping. This paper presents Energy Preference Optimization (EPO), an online refinement algorithm that turns a pretrained protein ensemble generator into an energy-aware sampler without extra MD trajectories. Specifically, EPO leverages stochastic differential equation sampling to explore the conformational landscape and incorporates a novel energy-ranking mechanism based on list-wise preference optimization. Crucially, EPO introduces a practical upper bound to efficiently approximate the intractable probability of long sampling trajectories in continuous-time generative models, making it easily adaptable to existing pretrained generators. On Tetrapeptides, ATLAS, and Fast-Folding benchmarks, EPO successfully generates diverse and physically realistic ensembles, establishing a new state-of-the-art in nine evaluation metrics. These results demonstrate that energy-only preference signals can efficiently steer generative models toward thermodynamically consistent conformational ensembles, providing an alternative to long MD simulations and widening the applicability of learned potentials in structural biology and drug discovery.","[{'text': 'Energy Preference Optimization (EPO) refines protein ensemble generators', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'EPO uses stochastic differential equation sampling', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'EPO incorporates list-wise preference optimization for energy ranking', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'EPO approximates probability of long sampling trajectories', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'EPO adapts to pretrained generators without extra MD trajectories', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'EPO generates diverse, physically realistic protein ensembles', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'EPO offers alternative to costly MD simulations', 'importance': 'vital', 'assignment': 'not_support'}, {'text': 'MD-based methods face limitations like finite timescale coverage', 'importance': 'vital', 'assignment': 'support'}, {'text': 'ListDPO optimizes ranking metrics with list-wise information', 'importance': 'vital', 'assignment': 'support'}, {'text': 'EPO achieves state-of-the-art on Tetrapeptides, ATLAS, Fast-Folding benchmarks', 'importance': 'okay', 'assignment': 'not_support'}, {'text': 'EPO enhances applicability of learned potentials in structural biology', 'importance': 'okay', 'assignment': 'not_support'}, {'text': 'Deep learning models use SE(3)-equivariant diffusion for protein ensembles', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Experimental data like NMR, Cryo-EM enhance generative model realism', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Direct Preference Optimization (DPO) reframes preference alignment', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Diffusion-DPO combines diffusion backbone with DPO-style loss', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'MD-based methods face limitations like finite timescale coverage', 'importance': 'vital', 'assignment': 'support'}, {'text': 'ListDPO optimizes ranking metrics with list-wise information', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Deep learning models use SE(3)-equivariant diffusion for protein ensembles', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Experimental data like NMR, Cryo-EM enhance generative model realism', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Direct Preference Optimization (DPO) reframes preference alignment', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Diffusion-DPO combines diffusion backbone with DPO-style loss', 'importance': 'okay', 'assignment': 'support'}]","[{'text': 'MD-based methods face limitations like finite timescale coverage', 'importance': 'vital', 'assignment': 'support'}, {'text': 'ListDPO optimizes ranking metrics with list-wise information', 'importance': 'vital', 'assignment': 'support'}, {'text': 'Deep learning models use SE(3)-equivariant diffusion for protein ensembles', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Experimental data like NMR, Cryo-EM enhance generative model realism', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Direct Preference Optimization (DPO) reframes preference alignment', 'importance': 'okay', 'assignment': 'support'}, {'text': 'Diffusion-DPO combines diffusion backbone with DPO-style loss', 'importance': 'okay', 'assignment': 'support'}]","{'strict_vital_score': 0.2222222222222222, 'strict_all_score': 0.4, 'vital_score': 0.2222222222222222, 'all_score': 0.4}"
