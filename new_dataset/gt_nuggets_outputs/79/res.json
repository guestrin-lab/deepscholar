{
  "qid": "2511.08150v1",
  "query": "Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:\nGenerative retrieval (GR) re-frames document retrieval as a sequence-based document identifier (DocID) generation task, memorizing documents with model parameters and enabling end-to-end retrieval without explicit indexing. Existing GR methods are based on auto-regressive generative models, i.e., the token generation is performed from left to right. However, such auto-regressive methods suffer from: (1) mismatch between DocID generation and natural language generation, e.g., an incorrect DocID token generated in early left steps would lead to totally erroneous retrieval; and (2) failure to balance the trade-off between retrieval efficiency and accuracy dynamically, which is crucial for practical applications. To address these limitations, we propose generative document retrieval with diffusion language models, dubbed DiffuGR. It models DocID generation as a discrete diffusion process: during training, DocIDs are corrupted through a stochastic masking process, and a diffusion language model is learned to recover them under a retrieval-aware objective. For inference, DiffuGR attempts to generate DocID tokens in parallel and refines them through a controllable number of denoising steps. In contrast to conventional left-to-right auto-regressive decoding, DiffuGR provides a novel mechanism to first generate more confident DocID tokens and refine the generation through diffusion-based denoising. Moreover, DiffuGR also offers explicit runtime control over the qualitylatency tradeoff. Extensive experiments on benchmark retrieval datasets show that DiffuGR is competitive with strong auto-regressive generative retrievers, while offering flexible speed and accuracy tradeoffs through variable denoising budgets. Overall, our results indicate that non-autoregressive diffusion models are a practical and effective alternative for generative document retrieval.",
  "nuggets": [
    {
      "text": "Generative retrieval reframes document retrieval as DocID generation",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Auto-regressive models generate tokens left-to-right",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "DiffuGR uses diffusion models for DocID generation",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "DiffuGR generates DocID tokens in parallel",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "DiffuGR refines generation through diffusion-based denoising",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "DiffuGR offers runtime control over quality-latency tradeoff",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "DiffuGR is competitive with auto-regressive retrievers",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "Discrete diffusion models reconstruct text from corrupted sequences",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Diffusion models balance sequential coherence with parallelism",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "DiffuGR provides end-to-end retrieval without explicit indexing",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "Diffusion models are viable for natural language generation",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Learnable DocIDs use dense document representations",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Linguistic DocIDs use strings like title or URL",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Diffusion models initially used in image generation",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Scaling diffusion models extends applicability to large language models",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "supported_nuggets": [
    {
      "text": "Generative retrieval reframes document retrieval as DocID generation",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Auto-regressive models generate tokens left-to-right",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "DiffuGR uses diffusion models for DocID generation",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "DiffuGR generates DocID tokens in parallel",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "DiffuGR refines generation through diffusion-based denoising",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Discrete diffusion models reconstruct text from corrupted sequences",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Diffusion models balance sequential coherence with parallelism",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Diffusion models are viable for natural language generation",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Learnable DocIDs use dense document representations",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Linguistic DocIDs use strings like title or URL",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Diffusion models initially used in image generation",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Scaling diffusion models extends applicability to large language models",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "partially_supported_nuggets": [
    {
      "text": "Generative retrieval reframes document retrieval as DocID generation",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Auto-regressive models generate tokens left-to-right",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "DiffuGR uses diffusion models for DocID generation",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "DiffuGR generates DocID tokens in parallel",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "DiffuGR refines generation through diffusion-based denoising",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Discrete diffusion models reconstruct text from corrupted sequences",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Diffusion models balance sequential coherence with parallelism",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Diffusion models are viable for natural language generation",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Learnable DocIDs use dense document representations",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Linguistic DocIDs use strings like title or URL",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Diffusion models initially used in image generation",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Scaling diffusion models extends applicability to large language models",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "nuggets_metrics": {
    "strict_vital_score": 0.7,
    "strict_all_score": 0.8,
    "vital_score": 0.7,
    "all_score": 0.8
  }
}