{
  "qid": "2511.08577v1",
  "query": "Write a Related Works section for an academic paper given the paper's abstract. Here is the paper abstract:\nImproving reasoning capabilities of Large Language Models (LLMs), especially under parameter constraints, is crucial for real-world applications. Prior work proposes recurrent transformers, which allocate a fixed number of extra iterations per token to improve generation quality. After the first, standard forward pass, instead of verbalization, last-layer hidden states are fed back as inputs for additional iterations to refine token predictions. Yet we identify a latent overthinking phenomenon: easy token predictions that are already correct after the first pass are sometimes revised into errors in additional iterations. To address this, we propose Think-at-Hard (TaH), a dynamic latent thinking method that iterates deeper only at hard tokens. It employs a lightweight neural decider to trigger latent iterations only at tokens that are likely incorrect after the standard forward pass. During latent iterations, Low-Rank Adaptation (LoRA) modules shift the LLM objective from general next-token prediction to focused hard-token refinement. We further introduce a duo-causal attention mechanism that extends attention from the token sequence dimension to an additional iteration depth dimension. This enables cross-iteration information flow while maintaining full sequential parallelism. Experiments show that TaH boosts LLM reasoning performance across five challenging benchmarks while maintaining the same parameter count. Compared with baselines that iterate twice for all output tokens, TaH delivers 8.1-11.3% accuracy gains while exempting 94% of tokens from the second iteration. Against strong single-iteration Qwen3 models finetuned with the same data, it also delivers 4.0-5.0% accuracy gains. When allowing less than 3% additional parameters from LoRA and the iteration decider, the gains increase to 8.5-12.6% and 5.3-5.4%, respectively. Our code is available at https://github.com/thu-nics/TaH.",
  "nuggets": [
    {
      "text": "TaH improves LLM reasoning with dynamic latent thinking",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "TaH iterates deeper only at hard tokens",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Latent overthinking revises correct predictions into errors",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Neural decider triggers iterations for likely incorrect tokens",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "LoRA modules focus on hard-token refinement",
      "importance": "vital",
      "assignment": "partial_support"
    },
    {
      "text": "Duo-causal attention enables cross-iteration information flow",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "TaH maintains parameter count with accuracy gains",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "Less than 3% additional parameters increase gains",
      "importance": "vital",
      "assignment": "not_support"
    },
    {
      "text": "Recurrent transformers interleave latent and verbal reasoning",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Looped Transformer reuses last-layer hidden states",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "TaH leverages pre-trained models with minimal finetuning",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Recurrent transformers use fixed iterations per token",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "TaH exempts 94% of tokens from second iteration",
      "importance": "okay",
      "assignment": "not_support"
    },
    {
      "text": "TaH outperforms Qwen3 models with same data",
      "importance": "okay",
      "assignment": "not_support"
    },
    {
      "text": "Signal-guided control uses control tokens for reasoning",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Latent optimization compresses CoT into embeddings",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Ponder uses logit-weighted embeddings for iterations",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Selective recursion requires complete model retraining",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "supported_nuggets": [
    {
      "text": "TaH iterates deeper only at hard tokens",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Latent overthinking revises correct predictions into errors",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Recurrent transformers interleave latent and verbal reasoning",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Looped Transformer reuses last-layer hidden states",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "TaH leverages pre-trained models with minimal finetuning",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Recurrent transformers use fixed iterations per token",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Signal-guided control uses control tokens for reasoning",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Latent optimization compresses CoT into embeddings",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Ponder uses logit-weighted embeddings for iterations",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Selective recursion requires complete model retraining",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "partially_supported_nuggets": [
    {
      "text": "TaH iterates deeper only at hard tokens",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Latent overthinking revises correct predictions into errors",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "LoRA modules focus on hard-token refinement",
      "importance": "vital",
      "assignment": "partial_support"
    },
    {
      "text": "Recurrent transformers interleave latent and verbal reasoning",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Looped Transformer reuses last-layer hidden states",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "TaH leverages pre-trained models with minimal finetuning",
      "importance": "vital",
      "assignment": "support"
    },
    {
      "text": "Recurrent transformers use fixed iterations per token",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Signal-guided control uses control tokens for reasoning",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Latent optimization compresses CoT into embeddings",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Ponder uses logit-weighted embeddings for iterations",
      "importance": "okay",
      "assignment": "support"
    },
    {
      "text": "Selective recursion requires complete model retraining",
      "importance": "okay",
      "assignment": "support"
    }
  ],
  "nuggets_metrics": {
    "strict_vital_score": 0.45454545454545453,
    "strict_all_score": 0.5555555555555556,
    "vital_score": 0.5,
    "all_score": 0.5833333333333334
  }
}